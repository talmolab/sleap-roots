{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"sleap-roots","text":"<p>Analysis tools for SLEAP-based plant root phenotyping.</p> <ul> <li> <p> Fast Root Phenotyping</p> <p>Extract 50+ morphological traits from plant root images using pose estimation with SLEAP.</p> <p> Quick Start</p> </li> <li> <p> Pipeline-Based Analysis</p> <p>Pre-built pipelines for dicots, monocots, and custom root system architectures.</p> <p> Pipeline Guide</p> </li> <li> <p> Scientifically Validated</p> <p>Published methods with reproducible trait computations and batch processing.</p> <p> Read the Paper</p> </li> <li> <p> Developer Friendly</p> <p>Clean Python API with comprehensive docs, type hints, and 99% test coverage.</p> <p> API Reference</p> </li> </ul>"},{"location":"#what-is-sleap-roots","title":"What is sleap-roots?","text":"<p>sleap-roots is a Python package for extracting morphological traits from plant root images analyzed with SLEAP (Social LEAP Estimates Animal Poses). While SLEAP is designed for animal pose estimation, it works exceptionally well for tracking plant root landmarks over time.</p> <p>This package provides:</p> <ul> <li>Trait pipelines for different root system architectures (dicots, monocots)</li> <li>50+ morphological traits including lengths, angles, counts, and topology</li> <li>Batch processing for high-throughput phenotyping experiments</li> <li>Modular utilities for custom trait development</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#multiple-pipeline-support","title":"Multiple Pipeline Support","text":"<p>Choose from pre-built pipelines optimized for different plant types:</p> <ul> <li>DicotPipeline \u2013 Primary + lateral roots (soy, canola, arabidopsis)</li> <li>YoungerMonocotPipeline \u2013 Primary + crown roots (early-stage rice, maize)</li> <li>OlderMonocotPipeline \u2013 Crown roots only (mature rice, maize)</li> <li>MultipleDicotPipeline \u2013 Multi-plant dicot setups</li> <li>PrimaryRootPipeline \u2013 Primary root only</li> <li>LateralRootPipeline \u2013 Lateral roots only</li> </ul> <p>Or create your own custom pipeline!</p>"},{"location":"#high-performance","title":"High Performance","text":"<ul> <li>Process hundreds of plants in minutes</li> <li>Vectorized NumPy operations for fast computation</li> <li>Efficient batch processing with parallelization support</li> </ul>"},{"location":"#research-ready","title":"Research Ready","text":"<ul> <li>Published validation in Plant Phenomics</li> <li>Reproducible trait computations with clear documentation</li> <li>CSV export compatible with statistical analysis tools</li> </ul>"},{"location":"#extensible","title":"Extensible","text":"<ul> <li>Modular design for custom trait development</li> <li>Clean Python API with comprehensive type hints</li> <li>Well-tested codebase (99% coverage)</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\n# Load SLEAP predictions\nseries = sr.Series.load(\n    series_name=\"my_plant\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary_roots.slp\",\n    lateral_path=\"lateral_roots.slp\"\n)\n\n# Compute traits using dicot pipeline\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\n# Access individual traits\nprint(f\"Primary root length: {traits['primary_length'].iloc[0]:.2f} pixels\")\nprint(f\"Lateral root count: {traits['lateral_count'].iloc[0]}\")\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you use sleap-roots in your research, please cite:</p> <p>E.M. Berrigan et al., \"Fast and Efficient Root Phenotyping via Pose Estimation\", Plant Phenomics. DOI: 10.34133/plantphenomics.0175</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>Created by the Talmo Lab and Busch Lab at the Salk Institute, as part of the Harnessing Plants Initiative.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Elizabeth Berrigan</li> <li>Lin Wang</li> <li>Andrew O'Connor</li> <li>Talmo Pereira</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to sleap-roots will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Comprehensive MkDocs documentation site with Material theme</li> <li>Auto-generated API reference from docstrings</li> <li>User guides for all pipeline types (7 pipelines)</li> <li>Trait reference documentation</li> <li>Developer guides and contributing documentation</li> <li>8 tutorial pages for all pipelines</li> <li>Cookbook with code recipes (filtering, custom traits, batch optimization, exporting)</li> <li>Troubleshooting guide with common issues and solutions</li> <li>uv package manager support with PEP 735 dependency groups</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Updated installation documentation with uv best practices</li> <li>Enhanced developer setup guide with modern workflows</li> <li>Migrated to uv for development dependency management</li> </ul>"},{"location":"changelog/#014-2024-11-10","title":"0.1.4 - 2024-11-10","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li><code>MultiplePrimaryRootPipeline</code> for analyzing plants with multiple primary roots</li> <li><code>MultipleDicotPipeline</code> tests for multi-plant batch analysis</li> <li>Comprehensive Claude Code slash command suite for developer workflows</li> <li>OpenSpec project documentation and change management</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Improved test coverage across pipeline classes</li> <li>Updated README with latest pipeline examples</li> </ul>"},{"location":"changelog/#013-2024-10-29","title":"0.1.3 - 2024-10-29","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li><code>LateralRootPipeline</code> for lateral-root-only analysis</li> </ul>"},{"location":"changelog/#012-2024-08-26","title":"0.1.2 - 2024-08-26","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Version bump and maintenance release</li> </ul>"},{"location":"changelog/#011-2024-08-26","title":"0.1.1 - 2024-08-26","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Corrected <code>crown-curve-indices</code> definition in trait pipeline</li> <li>Applied Black formatting to test files</li> </ul>"},{"location":"changelog/#010-2024-05-13","title":"0.1.0 - 2024-05-13","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li><code>Series.load()</code> method for loading SLEAP predictions directly</li> <li>High-level imports: <code>find_all_h5_paths</code>, <code>find_all_slp_paths</code>, <code>load_series_from_h5s</code>, <code>load_series_from_slps</code></li> <li>Increased test coverage across modules</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Breaking: <code>Series</code> class now takes SLEAP predictions directly using <code>Series.load()</code></li> <li>Breaking: H5 paths are now optional (but required for plotting)</li> <li>Breaking: <code>series_name</code> is now an attribute instead of a property</li> <li>Breaking: <code>find_all_series</code> removed (use <code>find_all_h5_paths</code> or <code>find_all_slp_paths</code>)</li> <li>Upgraded Python requirement to 3.11</li> <li>Improved geometry intersection helper functions</li> </ul>"},{"location":"changelog/#009-2024-04-23","title":"0.0.9 - 2024-04-23","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Quality control property for batch processing over genotypes</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Edge cases in older monocot pipeline traits</li> </ul>"},{"location":"changelog/#008-2024-04-12","title":"0.0.8 - 2024-04-12","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Jupyter notebooks for code instruction</li> <li>Enhanced documentation</li> <li>JupyterLab to development environment</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Excluded Jupyter notebooks from language statistics</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Tips calculation functions</li> </ul>"},{"location":"changelog/#007-2024-03-31","title":"0.0.7 - 2024-03-31","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li><code>MultipleDicotPipeline</code> for analyzing multiple dicot plants simultaneously</li> </ul>"},{"location":"changelog/#006-2024-03-11","title":"0.0.6 - 2024-03-11","text":""},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li><code>OlderMonocotPipeline</code> for mature monocot analysis</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Updated README with pipeline examples</li> </ul>"},{"location":"changelog/#005-2023-10-08","title":"0.0.5 - 2023-10-08","text":""},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li><code>YoungerMonocotPipeline</code> for younger monocot plants</li> </ul>"},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>Renamed <code>grav_index</code> to <code>curve_index</code> for clarity</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li><code>get_network_distribution</code> function</li> </ul>"},{"location":"changelog/#004-2023-09-13","title":"0.0.4 - 2023-09-13","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>Version bump</li> </ul>"},{"location":"changelog/#003-2023-09-13","title":"0.0.3 - 2023-09-13","text":""},{"location":"changelog/#changed_8","title":"Changed","text":"<ul> <li>Updated sleap-io minimum version to 0.0.11</li> </ul>"},{"location":"changelog/#002-2023-09-12","title":"0.0.2 - 2023-09-12","text":""},{"location":"changelog/#added_9","title":"Added","text":"<ul> <li>Python 3.7 compatibility</li> <li>Checks and tests for ellipse fitter</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Node index calculation</li> <li>Dicot pipeline edge cases</li> <li>Ellipse fitting robustness</li> </ul>"},{"location":"changelog/#001-2023-09-03","title":"0.0.1 - 2023-09-03","text":"<p>Initial release of sleap-roots package.</p>"},{"location":"changelog/#added_10","title":"Added","text":"<ul> <li>Core <code>Series</code> class for SLEAP prediction data</li> <li><code>DicotPipeline</code> for dicot root analysis</li> <li>Trait computation modules:</li> <li><code>bases</code> - Root base detection and analysis</li> <li><code>tips</code> - Root tip identification</li> <li><code>angle</code> - Root angle measurements</li> <li><code>convhull</code> - Convex hull calculations</li> <li><code>lengths</code> - Root length measurements</li> <li><code>networklength</code> - Network-level metrics</li> <li><code>scanline</code> - Scan line analysis</li> <li><code>ellipse</code> - Ellipse fitting</li> <li><code>points</code> - Point extraction utilities</li> <li><code>summary</code> - Summary statistics</li> <li>Test suite with fixtures for rice and soy</li> <li>Basic plotting functionality</li> <li>sleap-io integration for loading predictions</li> </ul>"},{"location":"changelog/#new-contributors","title":"New Contributors","text":"<ul> <li>@talmo - Project lead and core architecture</li> <li>@eberrigan - Primary developer, pipelines and traits</li> <li>@linwang9926 - Trait modules and testing</li> <li>@emdavis02 - Test coverage improvements</li> </ul>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate API reference pages and navigation.\n\nThis script auto-generates API documentation from the sleap_roots package\nusing mkdocstrings. It creates a reference page for each Python module.\n\"\"\"\n</pre> \"\"\"Generate API reference pages and navigation.  This script auto-generates API documentation from the sleap_roots package using mkdocstrings. It creates a reference page for each Python module. \"\"\" In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre># Root of the package to document\nnav = mkdocs_gen_files.Nav()\nroot = Path(__file__).parent.parent\nsrc = root / \"sleap_roots\"\n</pre> # Root of the package to document nav = mkdocs_gen_files.Nav() root = Path(__file__).parent.parent src = root / \"sleap_roots\" In\u00a0[\u00a0]: Copied! <pre># Iterate through all Python files in the sleap_roots package\nfor path in sorted(src.rglob(\"*.py\")):\n    # Get module path relative to package root\n    module_path = path.relative_to(src.parent).with_suffix(\"\")\n    doc_path = path.relative_to(src.parent).with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    # Get parts for navigation\n    parts = tuple(module_path.parts)\n\n    # Skip __init__.py files but include in nav\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1].startswith(\"_\"):\n        # Skip private modules\n        continue\n\n    # Add to navigation\n    nav[parts] = doc_path.as_posix()\n\n    # Create the documentation file\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        # Convert module path to import identifier\n        ident = \".\".join(parts)\n        # Write mkdocstrings directive\n        fd.write(f\"::: {ident}\")\n\n    # Set edit path for GitHub integration\n    mkdocs_gen_files.set_edit_path(full_doc_path, path.relative_to(root))\n</pre> # Iterate through all Python files in the sleap_roots package for path in sorted(src.rglob(\"*.py\")):     # Get module path relative to package root     module_path = path.relative_to(src.parent).with_suffix(\"\")     doc_path = path.relative_to(src.parent).with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      # Get parts for navigation     parts = tuple(module_path.parts)      # Skip __init__.py files but include in nav     if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1].startswith(\"_\"):         # Skip private modules         continue      # Add to navigation     nav[parts] = doc_path.as_posix()      # Create the documentation file     with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         # Convert module path to import identifier         ident = \".\".join(parts)         # Write mkdocstrings directive         fd.write(f\"::: {ident}\")      # Set edit path for GitHub integration     mkdocs_gen_files.set_edit_path(full_doc_path, path.relative_to(root)) In\u00a0[\u00a0]: Copied! <pre># Write navigation file\nwith mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> # Write navigation file with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"api/","title":"API Reference","text":"<p>Welcome to the sleap-roots API reference documentation. This page provides an overview of the entire API organized by functional area.</p>"},{"location":"api/#quick-links","title":"Quick Links","text":"<ul> <li>New to sleap-roots? Start with the Quick Start Guide</li> <li>Ready to analyze? Check out Common Workflows</li> <li>Need a specific function? Browse by category below</li> </ul>"},{"location":"api/#core-modules","title":"Core Modules","text":"<p>The foundation of sleap-roots: loading data and running analysis pipelines.</p>"},{"location":"api/#series","title":"Series","text":"<p>Load and manage SLEAP predictions</p> <p>The <code>Series</code> class is your primary interface for working with SLEAP root tracking data. Load predictions from .slp files and access point arrays for analysis.</p> <p>Key methods: - <code>Series.load()</code> - Load single plant - <code>get_primary_points()</code> - Extract primary root coordinates - <code>get_lateral_points()</code> - Extract lateral root coordinates - <code>get_crown_points()</code> - Extract crown root coordinates</p> <p>View Series documentation \u2192</p>"},{"location":"api/#pipelines","title":"Pipelines","text":"<p>Pre-built trait extraction workflows</p> <p>Choose from 7 specialized pipelines for different root system architectures. Each pipeline automatically computes dozens of relevant traits.</p> <p>Available pipelines: - <code>DicotPipeline</code> - Primary + lateral roots (canola, Arabidopsis) - <code>YoungerMonocotPipeline</code> - Primary + crown roots (young rice, wheat) - <code>OlderMonocotPipeline</code> - Crown roots only (mature monocots) - <code>MultipleDicotPipeline</code> - Multiple dicot plants per image - <code>PrimaryRootPipeline</code> - Single primary root analysis - <code>MultiplePrimaryRootPipeline</code> - Multiple primary roots per image - <code>LateralRootPipeline</code> - Individual lateral root analysis</p> <p>View Pipelines documentation \u2192</p>"},{"location":"api/#trait-computation-modules","title":"Trait Computation Modules","text":"<p>Individual functions for computing specific root traits. Use these for custom analysis workflows.</p>"},{"location":"api/#lengths","title":"Lengths","text":"<p>Measure root lengths and curvature.</p> <p>Functions: <code>get_root_lengths</code>, <code>get_curve_index</code>, <code>get_max_length_pts</code></p> <p>View documentation \u2192</p>"},{"location":"api/#angles","title":"Angles","text":"<p>Analyze root growth angles and gravitropism.</p> <p>Functions: <code>get_root_angle</code>, <code>get_vector_angle_from_gravity</code>, <code>get_node_ind</code></p> <p>View documentation \u2192</p>"},{"location":"api/#tips","title":"Tips","text":"<p>Detect and analyze root tips for growth tracking.</p> <p>Functions: <code>get_tips</code>, <code>get_tip_xs</code>, <code>get_tip_ys</code></p> <p>View documentation \u2192</p>"},{"location":"api/#bases","title":"Bases","text":"<p>Analyze lateral root emergence patterns and density.</p> <p>Functions: <code>get_bases</code>, <code>get_base_length</code>, <code>get_base_ct_density</code>, <code>get_root_widths</code></p> <p>View documentation \u2192</p>"},{"location":"api/#convex-hull","title":"Convex Hull","text":"<p>Compute spatial coverage and distribution metrics.</p> <p>Functions: <code>get_convhull</code>, <code>get_convhull_features</code>, <code>get_chull_area</code>, <code>get_chull_perimeter</code></p> <p>View documentation \u2192</p>"},{"location":"api/#ellipse","title":"Ellipse","text":"<p>Fit ellipses to root point distributions.</p> <p>Functions: <code>get_ellipse</code>, <code>fit_ellipse</code></p> <p>View documentation \u2192</p>"},{"location":"api/#network-length","title":"Network Length","text":"<p>Analyze whole-plant network-level metrics.</p> <p>Functions: <code>get_network_length</code>, <code>get_network_width_depth_ratio</code>, <code>get_network_distribution</code>, <code>get_bbox</code></p> <p>View documentation \u2192</p>"},{"location":"api/#scanline","title":"Scanline","text":"<p>Count root intersections with horizontal scan lines.</p> <p>Functions: <code>count_scanline_intersections</code>, <code>get_scanline_first_ind</code>, <code>get_scanline_last_ind</code></p> <p>View documentation \u2192</p>"},{"location":"api/#points","title":"Points","text":"<p>Utility functions for manipulating root point arrays.</p> <p>Functions: <code>join_pts</code>, <code>get_all_pts_array</code>, <code>associate_lateral_to_primary</code>, <code>filter_roots_with_nans</code></p> <p>View documentation \u2192</p>"},{"location":"api/#utilities","title":"Utilities","text":""},{"location":"api/#summary-statistics","title":"Summary Statistics","text":"<p>Compute comprehensive summary statistics for trait distributions.</p> <p>Function: <code>get_summary</code> - Calculate min, max, mean, median, std, and percentiles</p> <p>View documentation \u2192</p>"},{"location":"api/#examples-and-workflows","title":"Examples and Workflows","text":""},{"location":"api/#common-workflows","title":"Common Workflows","text":"<p>Complete end-to-end examples for typical analysis tasks.</p> <p>Workflows included: 1. Quick pipeline analysis 2. Custom trait computation 3. Lateral root analysis 4. Temporal growth tracking 5. Network-level spatial analysis 6. Batch processing multiple plants 7. Quality control and filtering 8. Multiple dicot plants</p> <p>View workflows \u2192</p>"},{"location":"api/#api-organization","title":"API Organization","text":"<p>The sleap-roots API is organized hierarchically:</p> <pre><code>sleap_roots/\n\u251c\u2500\u2500 Series                    # Data loading\n\u251c\u2500\u2500 DicotPipeline            # Pre-built pipelines\n\u251c\u2500\u2500 YoungerMonocotPipeline\n\u251c\u2500\u2500 OlderMonocotPipeline\n\u251c\u2500\u2500 MultipleDicotPipeline\n\u251c\u2500\u2500 PrimaryRootPipeline\n\u251c\u2500\u2500 MultiplePrimaryRootPipeline\n\u251c\u2500\u2500 LateralRootPipeline\n\u2502\n\u251c\u2500\u2500 get_root_lengths()       # Individual trait functions\n\u251c\u2500\u2500 get_root_angle()\n\u251c\u2500\u2500 get_tips()\n\u251c\u2500\u2500 get_bases()\n\u251c\u2500\u2500 get_convhull()\n\u251c\u2500\u2500 get_ellipse()\n\u251c\u2500\u2500 get_network_length()\n\u251c\u2500\u2500 count_scanline_intersections()\n\u2502\n\u251c\u2500\u2500 join_pts()               # Utility functions\n\u251c\u2500\u2500 get_all_pts_array()\n\u251c\u2500\u2500 filter_roots_with_nans()\n\u2514\u2500\u2500 get_summary()\n</code></pre>"},{"location":"api/#finding-what-you-need","title":"Finding What You Need","text":"<p>I want to...</p> <ul> <li>Load SLEAP predictions \u2192 Series</li> <li>Extract traits automatically \u2192 Pipelines</li> <li>Measure root lengths \u2192 Lengths</li> <li>Analyze growth angles \u2192 Angles</li> <li>Track tip movement \u2192 Tips</li> <li>Study lateral emergence \u2192 Bases</li> <li>Measure spatial coverage \u2192 Convex Hull</li> <li>Analyze network architecture \u2192 Network Length</li> <li>Process multiple plants \u2192 Common Workflows</li> <li>Get summary statistics \u2192 Summary Statistics</li> </ul>"},{"location":"api/#complete-function-reference","title":"Complete Function Reference","text":"<p>For auto-generated documentation from source code, see the reference/ section.</p>"},{"location":"api/#see-also","title":"See Also","text":"<ul> <li>Getting Started Guide - Your first sleap-roots analysis</li> <li>Tutorials - Step-by-step pipeline guides</li> <li>User Guide - In-depth explanations</li> <li>Cookbook - Recipes for common tasks</li> </ul>"},{"location":"api/core/pipelines/","title":"Pipelines","text":""},{"location":"api/core/pipelines/#overview","title":"Overview","text":"<p>Pipeline classes provide pre-configured workflows for extracting traits from SLEAP root predictions. Each pipeline is optimized for specific plant types and root architectures, combining multiple trait computation functions into a single <code>fit_series()</code> call.</p> <p>Key features:</p> <ul> <li>Pre-built trait computation workflows</li> <li>Optimized for different plant types (dicots, monocots)</li> <li>Automatic handling of multiple root types</li> <li>JSON/CSV export capabilities</li> <li>Consistent API across all pipelines</li> </ul> <p>When to use pipelines:</p> <ul> <li>You want a complete set of traits without manual computation</li> <li>You're analyzing a specific plant type (dicot, monocot, etc.)</li> <li>You need standardized, reproducible trait extraction</li> <li>You want easy export to CSV/JSON for downstream analysis</li> </ul>"},{"location":"api/core/pipelines/#which-pipeline-should-i-use","title":"Which Pipeline Should I Use?","text":"<pre><code>graph TD\n    A[Start] --&gt; B{Plant Type?}\n    B --&gt;|Dicot| C{Multiple Plants?}\n    B --&gt;|Monocot| D{Plant Age?}\n\n    C --&gt;|Single| E[DicotPipeline]\n    C --&gt;|Multiple| F[MultipleDicotPipeline]\n\n    D --&gt;|Young| G[YoungerMonocotPipeline]\n    D --&gt;|Mature| H[OlderMonocotPipeline]\n\n    B --&gt;|Primary Only| I{Multiple Plants?}\n    I --&gt;|Single| J[PrimaryRootPipeline]\n    I --&gt;|Multiple| K[MultiplePrimaryRootPipeline]\n\n    B --&gt;|Lateral Only| L[LateralRootPipeline]</code></pre> <p>Quick Decision Guide:</p> Plant Type Root System Pipeline Dicot (single plant) Primary + Lateral DicotPipeline Dicot (multiple plants) Primary + Lateral MultipleDicotPipeline Monocot (young) Crown roots YoungerMonocotPipeline Monocot (mature) Crown roots OlderMonocotPipeline Any (single plant) Primary only PrimaryRootPipeline Any (multiple plants) Primary only MultiplePrimaryRootPipeline Any Lateral only LateralRootPipeline"},{"location":"api/core/pipelines/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\n# Load plant data\nseries = sr.Series.load(\n    \"arabidopsis_1\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Run pipeline\npipeline = sr.DicotPipeline()\ntraits = pipeline.fit_series(series)\n\n# Access traits\nprint(f\"Primary root length: {traits['primary_length']}\")\nprint(f\"Lateral root count: {traits['lateral_count']}\")\n\n# Export to CSV\nimport pandas as pd\ndf = pd.DataFrame([traits])\ndf.to_csv(\"traits.csv\", index=False)\n</code></pre>"},{"location":"api/core/pipelines/#dicotpipeline","title":"DicotPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.DicotPipeline","title":"DicotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for dicot plants (primary + lateral roots).</p> <p>Attributes:</p> Name Type Description <code>img_height</code> <code>int</code> <p>Image height.</p> <code>root_width_tolerance</code> <code>float</code> <p>Difference in projection norm between right and left side.</p> <code>n_scanlines</code> <code>int</code> <p>Number of scan lines, np.nan for no interaction.</p> <code>network_fraction</code> <code>float</code> <p>Length found in the lower fraction value of the network.</p>"},{"location":"api/core/pipelines/#overview_1","title":"Overview","text":"<p>For analyzing dicot plants with both primary and lateral roots (e.g., Arabidopsis, canola, soybean).</p> <p>Root System: Primary root + Lateral roots Plant Count: Single plant per series Use Case: Most common dicot analysis workflow</p>"},{"location":"api/core/pipelines/#computed-traits","title":"Computed Traits","text":"<p>Primary Root Traits: - <code>primary_length</code> - Total primary root length - <code>primary_angle</code> - Angle relative to gravity - <code>primary_tip_x</code>, <code>primary_tip_y</code> - Tip coordinates</p> <p>Lateral Root Traits: - <code>lateral_count</code> - Number of lateral roots - <code>lateral_lengths</code> - Individual lateral root lengths - <code>lateral_angles</code> - Individual lateral root angles - <code>lateral_base_xs</code>, <code>lateral_base_ys</code> - Base point coordinates - <code>lateral_tip_xs</code>, <code>lateral_tip_ys</code> - Tip point coordinates - <code>base_length</code> - Length of lateral root zone on primary - <code>base_ct_density</code> - Lateral root density</p> <p>Network Traits: - <code>network_length</code> - Total root system length - <code>network_width_depth_ratio</code> - W:D ratio - <code>network_distribution</code> - Root distribution metrics - <code>network_solidity</code> - Compactness measure - <code>convhull_area</code>, <code>convhull_perimeter</code> - Convex hull features</p>"},{"location":"api/core/pipelines/#example","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load dicot plant\nseries = sr.Series.load(\n    \"arabidopsis_1\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Run pipeline\npipeline = sr.DicotPipeline()\ntraits = pipeline.fit_series(series)\n\n# Access specific traits\nprint(f\"Primary length: {traits['primary_length']:.2f} px\")\nprint(f\"Lateral count: {traits['lateral_count']}\")\nprint(f\"Total network length: {traits['network_length']:.2f} px\")\nprint(f\"W:D ratio: {traits['network_width_depth_ratio']:.2f}\")\n\n# Export\nimport json\nwith open(\"traits.json\", \"w\") as f:\n    json.dump(traits, f, indent=2, cls=sr.NumpyArrayEncoder)\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: DicotPipeline</li> <li>MultipleDicotPipeline - For multiple plants</li> </ul>"},{"location":"api/core/pipelines/#multipledicotpipeline","title":"MultipleDicotPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.MultipleDicotPipeline","title":"MultipleDicotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for multiple dicot plants.</p>"},{"location":"api/core/pipelines/#overview_2","title":"Overview","text":"<p>For analyzing multiple dicot plants in the same field of view.</p> <p>Root System: Primary root + Lateral roots (per plant) Plant Count: Multiple plants per series Use Case: High-throughput screening, population studies</p>"},{"location":"api/core/pipelines/#computed-traits_1","title":"Computed Traits","text":"<p>Same as DicotPipeline but computed per plant: - Traits are arrays where each element = one plant - Allows comparison between plants in same image - Handles varying numbers of lateral roots per plant</p>"},{"location":"api/core/pipelines/#example_1","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load multiple dicot plants\nseries = sr.Series.load(\n    \"canola_multipl e\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Run pipeline\npipeline = sr.MultipleDicotPipeline()\ntraits = pipeline.fit_series(series)\n\n# Traits are arrays (one value per plant)\nimport numpy as np\nprint(f\"Number of plants: {len(traits['primary_length'])}\")\nprint(f\"Mean primary length: {np.nanmean(traits['primary_length']):.2f} px\")\nprint(f\"Lateral counts per plant: {traits['lateral_count']}\")\n\n# Per-plant analysis\nfor i, length in enumerate(traits['primary_length']):\n    lat_count = traits['lateral_count'][i]\n    print(f\"Plant {i}: primary={length:.1f}px, laterals={lat_count}\")\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: Multiple Dicot Pipeline</li> <li>DicotPipeline - For single plants</li> </ul>"},{"location":"api/core/pipelines/#youngermonocotpipeline","title":"YoungerMonocotPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.YoungerMonocotPipeline","title":"YoungerMonocotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for young monocot plants (primary + crown roots).</p> <p>Attributes:</p> Name Type Description <code>img_height</code> <code>int</code> <p>Image height.</p> <code>n_scanlines</code> <code>int</code> <p>Number of scan lines, np.nan for no interaction.</p> <code>network_fraction</code> <code>float</code> <p>Lower fraction value. Defaults to 2/3.</p>"},{"location":"api/core/pipelines/#overview_3","title":"Overview","text":"<p>For analyzing young monocot plants with emerging crown root systems (e.g., rice, wheat, maize at early stages).</p> <p>Root System: Crown roots Plant Count: Single plant per series Use Case: Early-stage monocot seedlings</p>"},{"location":"api/core/pipelines/#computed-traits_2","title":"Computed Traits","text":"<p>Crown Root Traits (per root): - <code>crown_lengths</code> - Individual crown root lengths - <code>crown_angles</code> - Individual crown root angles - <code>crown_tip_xs</code>, <code>crown_tip_ys</code> - Tip coordinates</p> <p>Network Traits: - <code>network_length</code> - Total crown root length - <code>network_width_depth_ratio</code> - W:D ratio - <code>network_distribution</code> - Root distribution - <code>convhull_area</code>, <code>convhull_perimeter</code> - Spatial metrics</p>"},{"location":"api/core/pipelines/#example_2","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load young monocot\nseries = sr.Series.load(\n    \"rice_seedling\",\n    h5_path=\"data.h5\",\n    crown_path=\"crown.slp\"\n)\n\n# Run pipeline\npipeline = sr.YoungerMonocotPipeline()\ntraits = pipeline.fit_series(series)\n\n# Analyze crown roots\nimport numpy as np\ncrown_lengths = traits['crown_lengths']\nprint(f\"Number of crown roots: {len(crown_lengths)}\")\nprint(f\"Mean crown root length: {np.nanmean(crown_lengths):.2f} px\")\nprint(f\"Crown root angles: {traits['crown_angles']}\")\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: Younger Monocot Pipeline</li> <li>OlderMonocotPipeline - For mature plants</li> </ul>"},{"location":"api/core/pipelines/#oldermonocotpipeline","title":"OlderMonocotPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.OlderMonocotPipeline","title":"OlderMonocotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for older monocot plants (crown roots only).</p> <p>Attributes:</p> Name Type Description <code>img_height</code> <code>int</code> <p>Image height.</p> <code>n_scanlines</code> <code>int</code> <p>Number of scan lines, np.nan for no interaction.</p> <code>network_fraction</code> <code>float</code> <p>Lower fraction value. Defaults to 2/3.</p>"},{"location":"api/core/pipelines/#overview_4","title":"Overview","text":"<p>For analyzing mature monocot plants with established crown root systems.</p> <p>Root System: Crown roots (mature) Plant Count: Single plant per series Use Case: Later-stage monocot plants with complex root architecture</p>"},{"location":"api/core/pipelines/#computed-traits_3","title":"Computed Traits","text":"<p>Similar to YoungerMonocotPipeline with additional metrics for mature root systems: - More robust network analysis - Additional spatial distribution metrics - Optimized for denser root systems</p>"},{"location":"api/core/pipelines/#example_3","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load mature monocot\nseries = sr.Series.load(\n    \"wheat_mature\",\n    h5_path=\"data.h5\",\n    crown_path=\"crown.slp\"\n)\n\n# Run pipeline\npipeline = sr.OlderMonocotPipeline()\ntraits = pipeline.fit_series(series)\n\n# Analyze mature root system\nprint(f\"Network length: {traits['network_length']:.2f} px\")\nprint(f\"W:D ratio: {traits['network_width_depth_ratio']:.2f}\")\nprint(f\"Root system solidity: {traits['network_solidity']:.3f}\")\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: Older Monocot Pipeline</li> <li>YoungerMonocotPipeline - For seedlings</li> </ul>"},{"location":"api/core/pipelines/#primaryrootpipeline","title":"PrimaryRootPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.PrimaryRootPipeline","title":"PrimaryRootPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for a single primary root.</p>"},{"location":"api/core/pipelines/#overview_5","title":"Overview","text":"<p>For analyzing plants with only primary root (no laterals tracked).</p> <p>Root System: Primary root only Plant Count: Single plant per series Use Case: Primary root-focused analysis, plants before lateral emergence</p>"},{"location":"api/core/pipelines/#computed-traits_4","title":"Computed Traits","text":"<p>Primary Root Traits: - <code>primary_length</code> - Total primary root length - <code>primary_angle</code> - Gravitropic angle - <code>primary_tip_x</code>, <code>primary_tip_y</code> - Tip position - <code>curve_index</code> - Root curvature measure</p>"},{"location":"api/core/pipelines/#example_4","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load plant with primary root only\nseries = sr.Series.load(\n    \"early_seedling\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\"\n)\n\n# Run pipeline\npipeline = sr.PrimaryRootPipeline()\ntraits = pipeline.fit_series(series)\n\n# Analyze primary root\nprint(f\"Primary length: {traits['primary_length']:.2f} px\")\nprint(f\"Gravitropic angle: {traits['primary_angle']:.1f}\u00b0\")\nprint(f\"Curvature index: {traits['curve_index']:.3f}\")\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: Primary Root Pipeline</li> <li>MultiplePrimaryRootPipeline - For multiple plants</li> </ul>"},{"location":"api/core/pipelines/#multipleprimaryrootpipeline","title":"MultiplePrimaryRootPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.MultiplePrimaryRootPipeline","title":"MultiplePrimaryRootPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for multiple primary roots.</p>"},{"location":"api/core/pipelines/#overview_6","title":"Overview","text":"<p>For analyzing multiple plants, each with a primary root.</p> <p>Root System: Primary roots (one per plant) Plant Count: Multiple plants per series Use Case: High-throughput primary root phenotyping</p>"},{"location":"api/core/pipelines/#computed-traits_5","title":"Computed Traits","text":"<p>Same as PrimaryRootPipeline but as arrays (one value per plant).</p>"},{"location":"api/core/pipelines/#example_5","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load multiple plants\nseries = sr.Series.load(\n    \"primary_array\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\"\n)\n\n# Run pipeline\npipeline = sr.MultiplePrimaryRootPipeline()\ntraits = pipeline.fit_series(series)\n\n# Per-plant analysis\nimport numpy as np\nn_plants = len(traits['primary_length'])\nprint(f\"Analyzed {n_plants} plants\")\nprint(f\"Mean length: {np.nanmean(traits['primary_length']):.2f} px\")\nprint(f\"Mean angle: {np.nanmean(traits['primary_angle']):.1f}\u00b0\")\n\n# Compare plants\nfor i in range(n_plants):\n    print(f\"Plant {i}: {traits['primary_length'][i]:.1f} px, {traits['primary_angle'][i]:.1f}\u00b0\")\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: Multiple Primary Root Pipeline</li> <li>PrimaryRootPipeline - For single plants</li> </ul>"},{"location":"api/core/pipelines/#lateralrootpipeline","title":"LateralRootPipeline","text":""},{"location":"api/core/pipelines/#sleap_roots.LateralRootPipeline","title":"LateralRootPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline just for computing traits for lateral roots.</p>"},{"location":"api/core/pipelines/#overview_7","title":"Overview","text":"<p>For analyzing lateral roots independently (without primary root context).</p> <p>Root System: Lateral roots only Plant Count: Single plant per series Use Case: Lateral root-specific studies, cases where primary isn't tracked</p>"},{"location":"api/core/pipelines/#computed-traits_6","title":"Computed Traits","text":"<p>Lateral Root Traits: - <code>lateral_count</code> - Number of lateral roots - <code>lateral_lengths</code> - Individual lateral lengths - <code>lateral_angles</code> - Individual lateral angles - <code>lateral_tip_xs</code>, <code>lateral_tip_ys</code> - Tip coordinates</p>"},{"location":"api/core/pipelines/#example_6","title":"Example","text":"<pre><code>import sleap_roots as sr\n\n# Load lateral roots only\nseries = sr.Series.load(\n    \"lateral_study\",\n    h5_path=\"data.h5\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Run pipeline\npipeline = sr.LateralRootPipeline()\ntraits = pipeline.fit_series(series)\n\n# Analyze laterals\nimport numpy as np\nprint(f\"Lateral count: {traits['lateral_count']}\")\nprint(f\"Mean lateral length: {np.nanmean(traits['lateral_lengths']):.2f} px\")\nprint(f\"Lateral angles: {traits['lateral_angles']}\")\n</code></pre> <p>See Also:</p> <ul> <li>Tutorial: Lateral Root Pipeline</li> <li>DicotPipeline - For primary + lateral analysis</li> </ul>"},{"location":"api/core/pipelines/#pipeline-comparison","title":"Pipeline Comparison","text":""},{"location":"api/core/pipelines/#trait-coverage","title":"Trait Coverage","text":"Trait Category Dicot Multiple Dicot Younger Monocot Older Monocot Primary Multiple Primary Lateral Primary Root \u2713 \u2713 - - \u2713 \u2713 - Lateral Roots \u2713 \u2713 - - - - \u2713 Crown Roots - - \u2713 \u2713 - - - Network Metrics \u2713 \u2713 \u2713 \u2713 - - - Convex Hull \u2713 \u2713 \u2713 \u2713 - - - Multi-Plant - \u2713 - - - \u2713 -"},{"location":"api/core/pipelines/#performance-considerations","title":"Performance Considerations","text":"<p>Trait extraction performance (measured on GitHub Actions Ubuntu 22.04 runners):</p> <ul> <li>Single plant pipelines: ~0.1-0.5s per plant</li> <li>DicotPipeline, YoungerMonocotPipeline, OlderMonocotPipeline</li> <li>PrimaryRootPipeline, LateralRootPipeline</li> <li>Multiple plant pipelines: ~0.5-2s depending on plant count</li> <li>MultipleDicotPipeline, MultiplePrimaryRootPipeline</li> </ul> <p>Performance testing: All pipelines have automated benchmarks in the test suite. See Benchmarking Guide for details on running performance tests locally.</p> <p>Note: Actual performance depends on: - Number and complexity of roots in the image - Plant developmental stage (more roots = longer processing) - Hardware specifications (CPU, memory) - Frame count in the series (72 frames is typical)</p>"},{"location":"api/core/pipelines/#advanced-usage","title":"Advanced Usage","text":""},{"location":"api/core/pipelines/#custom-trait-filtering","title":"Custom Trait Filtering","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"p.slp\", lateral_path=\"l.slp\")\npipeline = sr.DicotPipeline()\nall_traits = pipeline.fit_series(series)\n\n# Extract only length-related traits\nlength_traits = {\n    k: v for k, v in all_traits.items()\n    if 'length' in k\n}\n\n# Extract only lateral traits\nlateral_traits = {\n    k: v for k, v in all_traits.items()\n    if 'lateral' in k\n}\n</code></pre>"},{"location":"api/core/pipelines/#batch-processing","title":"Batch Processing","text":"<pre><code>import sleap_roots as sr\nfrom pathlib import Path\n\n# Load all plants\nplants = sr.load_series_from_slps(\n    \"data/experiment1/\",\n    primary_pattern=\"*primary*.slp\",\n    lateral_pattern=\"*lateral*.slp\"\n)\n\n# Process with pipeline\npipeline = sr.DicotPipeline()\nresults = []\n\nfor series in plants:\n    try:\n        traits = pipeline.fit_series(series)\n        traits['plant_id'] = series.series_name\n        results.append(traits)\n    except Exception as e:\n        print(f\"Failed on {series.series_name}: {e}\")\n\n# Export to CSV\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.to_csv(\"batch_results.csv\", index=False)\nprint(f\"Processed {len(results)} plants\")\n</code></pre>"},{"location":"api/core/pipelines/#combining-with-quality-control","title":"Combining with Quality Control","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"plant1\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Set QC expectations\nseries.expected_count(primary=1, lateral=5)\n\n# Only process if QC passes\nif not series.qc_fail():\n    pipeline = sr.DicotPipeline()\n    traits = pipeline.fit_series(series)\n    print(\"\u2713 Traits computed successfully\")\nelse:\n    print(\"\u2717 QC failed - skipping trait computation\")\n</code></pre>"},{"location":"api/core/pipelines/#related-modules","title":"Related Modules","text":"<ul> <li>Series - Loading data for pipelines</li> <li>Trait Modules - Individual trait computation functions used by pipelines</li> <li>Summary - Exporting pipeline results</li> </ul>"},{"location":"api/core/pipelines/#see-also","title":"See Also","text":"<ul> <li>Pipeline Tutorials - Step-by-step guides for each pipeline</li> <li>Quick Start - First analysis walkthrough</li> <li>Batch Processing Guide - Processing multiple plants</li> </ul>"},{"location":"api/core/series/","title":"Series","text":""},{"location":"api/core/series/#overview","title":"Overview","text":"<p>The <code>Series</code> class is the primary data structure in sleap-roots for working with SLEAP predictions. It provides a unified interface for loading prediction files, accessing root point data, and managing plant metadata.</p> <p>Key features: - Load SLEAP <code>.slp</code> prediction files and <code>.h5</code> image series - Access root points for primary, lateral, and crown roots - Quality control and filtering capabilities - Integration with pipeline classes for trait computation - Plotting and visualization</p> <p>When to use: - You have SLEAP predictions and want to extract root point data - You need to load multiple plants for batch processing - You want to filter plants based on root count or quality - You're building custom trait computation workflows</p>"},{"location":"api/core/series/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\n# Load a single plant\nseries = sr.Series.load(\n    series_name=\"canola_plant1\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary_roots.slp\",\n    lateral_path=\"lateral_roots.slp\"\n)\n\n# Access root points\nprimary_pts = series.get_primary_points()  # (plants, frames, nodes, 2)\nlateral_pts_list = series.get_lateral_points()  # List of arrays\n\nprint(f\"Loaded {series.series_name}\")\nprint(f\"Primary shape: {primary_pts.shape}\")\nprint(f\"Lateral roots: {len(lateral_pts_list)}\")\n</code></pre>"},{"location":"api/core/series/#api-reference","title":"API Reference","text":""},{"location":"api/core/series/#series-class","title":"Series Class","text":""},{"location":"api/core/series/#sleap_roots.Series","title":"Series","text":"<p>Data and predictions for a single image series.</p> <p>Attributes:</p> Name Type Description <code>series_name</code> <code>str</code> <p>Unique identifier for the series.</p> <code>h5_path</code> <code>Optional[str]</code> <p>Optional path to the HDF5-formatted image series.</p> <code>primary_path</code> <code>Optional[str]</code> <p>Optional path to the primary root predictions file. At least one of the primary, lateral, or crown paths must be provided.</p> <code>lateral_path</code> <code>Optional[str]</code> <p>Optional path to the lateral root predictions file. At least one of the primary, lateral, or crown paths must be provided.</p> <code>crown_path</code> <code>Optional[str]</code> <p>Optional path to the crown predictions file. At least one of the primary, lateral, or crown paths must be provided.</p> <code>primary_labels</code> <code>Optional[Labels]</code> <p>Optional <code>sio.Labels</code> corresponding to the primary root predictions.</p> <code>lateral_labels</code> <code>Optional[Labels]</code> <p>Optional <code>sio.Labels</code> corresponding to the lateral root predictions.</p> <code>crown_labels</code> <code>Optional[Labels]</code> <p>Optional <code>sio.Labels</code> corresponding to the crown predictions.</p> <code>video</code> <code>Optional[Video]</code> <p>Optional <code>sio.Video</code> corresponding to the image series.</p> <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <p>Methods:</p> Name Description <code>load</code> <p>Load a set of predictions for this series.</p> <code>__len__</code> <p>Length of the series (number of images).</p> <code>__getitem__</code> <p>Return labeled frames for predictions.</p> <code>__iter__</code> <p>Iterator for looping through predictions.</p> <code>get_frame</code> <p>Return labeled frames for predictions.</p> <code>plot</code> <p>Plot predictions on top of the image.</p> <code>get_primary_points</code> <p>Get primary root points.</p> <code>get_lateral_points</code> <p>Get lateral root points.</p> <code>get_crown_points</code> <p>Get crown root points.</p> Properties <p>expected_count: Fetch the expected plant count for this series from the CSV. group: Group name for the series from the CSV. qc_fail: Flag to indicate if the series failed QC from the CSV.</p>"},{"location":"api/core/series/#loading-data","title":"Loading Data","text":"<p>Example: <pre><code>import sleap_roots as sr\n\n# Load plant with primary and lateral roots\nseries = sr.Series.load(\n    series_name=\"my_plant\",\n    h5_path=\"data/predictions.h5\",\n    primary_path=\"data/primary.slp\",\n    lateral_path=\"data/lateral.slp\"\n)\n\n# Load plant with all root types\nseries = sr.Series.load(\n    series_name=\"complete_plant\",\n    h5_path=\"data/predictions.h5\",\n    primary_path=\"data/primary.slp\",\n    lateral_path=\"data/lateral.slp\",\n    crown_path=\"data/crown.slp\"\n)\n\n# Load without video (points only)\nseries = sr.Series.load(\n    series_name=\"points_only\",\n    primary_path=\"data/primary.slp\",\n    lateral_path=\"data/lateral.slp\"\n)\n</code></pre></p> <p>Common Use Cases:</p> <pre><code># Dicot plant (primary + lateral)\nseries = sr.Series.load(\n    \"dicot1\",\n    h5_path=\"dicot.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Monocot plant (crown roots only)\nseries = sr.Series.load(\n    \"monocot1\",\n    h5_path=\"monocot.h5\",\n    crown_path=\"crown.slp\"\n)\n\n# Multiple primary roots\nseries = sr.Series.load(\n    \"multiple_primary\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\"\n)\n</code></pre> <p>See Also:</p> <ul> <li>find_all_h5_paths - Find all H5 files in directory</li> <li>find_all_slp_paths - Find all SLP files in directory</li> <li>load_series_from_h5s - Batch load from H5 files</li> <li>load_series_from_slps - Batch load from SLP files</li> </ul>"},{"location":"api/core/series/#sleap_roots.Series.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(\n    series_name: str,\n    h5_path: Optional[str] = None,\n    primary_path: Optional[str] = None,\n    lateral_path: Optional[str] = None,\n    crown_path: Optional[str] = None,\n    csv_path: Optional[str] = None,\n) -&gt; Series\n</code></pre> <p>Load a set of predictions for this series.</p> <p>Parameters:</p> Name Type Description Default <code>series_name</code> <code>str</code> <p>Unique identifier for the series.</p> required <code>h5_path</code> <code>Optional[str]</code> <p>Optional path to the HDF5-formatted image series, which will be used to load the video.</p> <code>None</code> <code>primary_path</code> <code>Optional[str]</code> <p>Optional path to the primary root '.slp' predictions file.</p> <code>None</code> <code>lateral_path</code> <code>Optional[str]</code> <p>Optional path to the lateral root '.slp' predictions file.</p> <code>None</code> <code>crown_path</code> <code>Optional[str]</code> <p>Optional path to the crown '.slp' predictions file.</p> <code>None</code> <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>An instance of Series loaded with the specified predictions.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>@classmethod\ndef load(\n    cls,\n    series_name: str,\n    h5_path: Optional[str] = None,\n    primary_path: Optional[str] = None,\n    lateral_path: Optional[str] = None,\n    crown_path: Optional[str] = None,\n    csv_path: Optional[str] = None,\n) -&gt; \"Series\":\n    \"\"\"Load a set of predictions for this series.\n\n    Args:\n        series_name: Unique identifier for the series.\n        h5_path: Optional path to the HDF5-formatted image series, which will be\n            used to load the video.\n        primary_path: Optional path to the primary root '.slp' predictions file.\n        lateral_path: Optional path to the lateral root '.slp' predictions file.\n        crown_path: Optional path to the crown '.slp' predictions file.\n        csv_path: Optional path to the CSV file containing the expected plant count.\n\n    Returns:\n        An instance of Series loaded with the specified predictions.\n    \"\"\"\n    # Initialize the labels as None\n    primary_labels, lateral_labels, crown_labels = None, None, None\n\n    # Attempt to load the predictions, with error handling\n    try:\n        if primary_path:\n            # Make path object\n            primary_path = Path(primary_path)\n            # Check if the file exists\n            if primary_path.exists():\n                # Make the primary_path POSIX-compliant\n                primary_path = primary_path.as_posix()\n                # Load the primary predictions\n                primary_labels = sio.load_slp(primary_path)\n            else:\n                print(f\"Primary prediction file not found: {primary_path}\")\n        if lateral_path:\n            # Make path object\n            lateral_path = Path(lateral_path)\n            # Check if the file exists\n            if lateral_path.exists():\n                # Make the lateral_path POSIX-compliant\n                lateral_path = lateral_path.as_posix()\n                # Load the lateral predictions\n                lateral_labels = sio.load_slp(lateral_path)\n            else:\n                print(f\"Lateral prediction file not found: {lateral_path}\")\n        if crown_path:\n            # Make path object\n            crown_path = Path(crown_path)\n            # Check if the file exists\n            if crown_path.exists():\n                # Make the crown_path POSIX-compliant\n                crown_path = crown_path.as_posix()\n                # Load the crown predictions\n                crown_labels = sio.load_slp(crown_path)\n            else:\n                print(f\"Crown prediction file not found: {crown_path}\")\n    except Exception as e:\n        print(f\"Error loading prediction files: {e}\")\n\n    # Attempt to load the video, with error handling\n    video = None\n    try:\n        if h5_path:\n            # Make path object\n            h5_path = Path(h5_path)\n            # Check if the file exists\n            if h5_path.exists():\n                # Make the h5_path POSIX-compliant\n                h5_path = h5_path.as_posix()\n                # Load the video\n                video = sio.Video.from_filename(h5_path)\n                # Replace the filename in the labels with the h5_path\n                for labels in [primary_labels, lateral_labels, crown_labels]:\n                    if labels is not None:\n                        labels.video.replace_filename(h5_path)\n            else:\n                print(f\"Video file not found: {h5_path}\")\n    except Exception as e:\n        print(f\"Error loading video file {h5_path}: {e}\")\n\n    # Make the csv path POSIX-compliant\n    if csv_path:\n        csv_path = Path(csv_path).as_posix()\n\n    return cls(\n        series_name=series_name,\n        h5_path=h5_path,\n        primary_path=primary_path,\n        lateral_path=lateral_path,\n        crown_path=crown_path,\n        primary_labels=primary_labels,\n        lateral_labels=lateral_labels,\n        crown_labels=crown_labels,\n        video=video,\n        csv_path=csv_path,\n    )\n</code></pre>"},{"location":"api/core/series/#accessing-root-points","title":"Accessing Root Points","text":"<p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"plant1\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\"\n)\n\n# Get all primary root points\npts = series.get_primary_points()\nprint(pts.shape)  # (plants, frames, nodes, 2)\n\n# Access specific frame\nframe_pts = pts[0, 0]  # First plant, first frame\nprint(frame_pts.shape)  # (nodes, 2) - x,y coordinates\n\n# Get x and y coordinates\nx_coords = pts[..., 0]  # All x coordinates\ny_coords = pts[..., 1]  # All y coordinates\n</code></pre></p> <p>See Also:</p> <ul> <li>get_lateral_points</li> <li>get_crown_points</li> </ul> <p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"plant1\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Get lateral root points (returns list)\nlateral_pts_list = series.get_lateral_points()\n\n# Each element is an array for one lateral root\nfor i, root_pts in enumerate(lateral_pts_list):\n    print(f\"Lateral root {i}: {root_pts.shape}\")\n    # Shape: (plants, frames, nodes, 2)\n\n# Access specific lateral root\nfirst_lateral = lateral_pts_list[0]\nfirst_frame = first_lateral[0, 0]  # (nodes, 2)\n</code></pre></p> <p>Working with lateral roots: <pre><code># Count lateral roots\nn_lateral = len(lateral_pts_list)\n\n# Filter lateral roots with valid points\nimport numpy as np\nvalid_laterals = [\n    pts for pts in lateral_pts_list\n    if not np.all(np.isnan(pts))\n]\n\n# Get all lateral points as single array\nfrom sleap_roots.points import join_pts\nall_lateral = join_pts(lateral_pts_list)\n</code></pre></p> <p>See Also:</p> <ul> <li>get_primary_points</li> <li>sleap_roots.points.join_pts - Combine point arrays</li> </ul> <p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"monocot1\",\n    h5_path=\"data.h5\",\n    crown_path=\"crown.slp\"\n)\n\n# Get crown root points (returns list)\ncrown_pts_list = series.get_crown_points()\n\n# Process each crown root\nfor i, root_pts in enumerate(crown_pts_list):\n    print(f\"Crown root {i}: {root_pts.shape}\")\n    # Shape: (plants, frames, nodes, 2)\n</code></pre></p> <p>See Also:</p> <ul> <li>get_primary_points</li> <li>get_lateral_points</li> </ul>"},{"location":"api/core/series/#sleap_roots.Series.get_primary_points","title":"get_primary_points","text":"<pre><code>get_primary_points(frame_idx: int) -&gt; ndarray\n</code></pre> <p>Get primary root points.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Primary root points as array of shape <code>(n_instances, n_nodes, 2)</code>.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_primary_points(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Get primary root points.\n\n    Args:\n        frame_idx: Frame index.\n\n    Returns:\n        Primary root points as array of shape `(n_instances, n_nodes, 2)`.\n    \"\"\"\n    # Check that self.primary_labels is not None\n    if self.primary_labels is None:\n        raise ValueError(\"Primary labels are not available.\")\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n    # Get the primary labeled frame\n    primary_lf = frames.get(\"primary\")\n    # Get the ground truth instances and unused predictions\n    gt_instances_pr = primary_lf.user_instances + primary_lf.unused_predictions\n    # If there are no instances, return an empty array\n    if len(gt_instances_pr) == 0:\n        primary_pts = np.array([[(np.nan, np.nan), (np.nan, np.nan)]])\n    # Otherwise, stack the instances into an array\n    else:\n        primary_pts = np.stack([inst.numpy() for inst in gt_instances_pr], axis=0)\n    return primary_pts\n</code></pre>"},{"location":"api/core/series/#sleap_roots.Series.get_lateral_points","title":"get_lateral_points","text":"<pre><code>get_lateral_points(frame_idx: int) -&gt; ndarray\n</code></pre> <p>Get lateral root points.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Lateral root points as array of shape <code>(n_instances, n_nodes, 2)</code>.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_lateral_points(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Get lateral root points.\n\n    Args:\n        frame_idx: Frame index.\n\n    Returns:\n        Lateral root points as array of shape `(n_instances, n_nodes, 2)`.\n    \"\"\"\n    # Check that self.lateral_labels is not None\n    if self.lateral_labels is None:\n        raise ValueError(\"Lateral labels are not available.\")\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n    # Get the lateral labeled frame\n    lateral_lf = frames.get(\"lateral\")\n    # Get the ground truth instances and unused predictions\n    gt_instances_lr = lateral_lf.user_instances + lateral_lf.unused_predictions\n    # If there are no instances, return an empty array\n    if len(gt_instances_lr) == 0:\n        lateral_pts = np.array([[(np.nan, np.nan), (np.nan, np.nan)]])\n    # Otherwise, stack the instances into an array\n    else:\n        lateral_pts = np.stack([inst.numpy() for inst in gt_instances_lr], axis=0)\n    return lateral_pts\n</code></pre>"},{"location":"api/core/series/#sleap_roots.Series.get_crown_points","title":"get_crown_points","text":"<pre><code>get_crown_points(frame_idx: int) -&gt; ndarray\n</code></pre> <p>Get crown root points.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Crown root points as array of shape <code>(n_instances, n_nodes, 2)</code>.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_crown_points(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Get crown root points.\n\n    Args:\n        frame_idx: Frame index.\n\n    Returns:\n        Crown root points as array of shape `(n_instances, n_nodes, 2)`.\n    \"\"\"\n    # Check that self.crown_labels is not None\n    if self.crown_labels is None:\n        raise ValueError(\"Crown labels are not available.\")\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n    # Get the crown labeled frame\n    crown_lf = frames.get(\"crown\")\n    # Get the ground truth instances and unused predictions\n    gt_instances_cr = crown_lf.user_instances + crown_lf.unused_predictions\n    # If there are no instances, return an empty array\n    if len(gt_instances_cr) == 0:\n        crown_pts = np.array([[(np.nan, np.nan), (np.nan, np.nan)]])\n    # Otherwise, stack the instances into an array\n    else:\n        crown_pts = np.stack([inst.numpy() for inst in gt_instances_cr], axis=0)\n    return crown_pts\n</code></pre>"},{"location":"api/core/series/#quality-control","title":"Quality Control","text":"<p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"plant1\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Set expected root counts\nseries.expected_count(primary=1, lateral=5)\n\n# Check if counts match\nif not series.qc_fail():\n    print(\"\u2713 Root counts match expected\")\n    # Proceed with analysis\nelse:\n    print(\"\u2717 Unexpected root counts\")\n    # Handle QC failure\n</code></pre></p> <p>Batch filtering: <pre><code># Load multiple plants\nplants = sr.load_series_from_slps(\n    \"data/\",\n    primary_pattern=\"*primary*.slp\",\n    lateral_pattern=\"*lateral*.slp\"\n)\n\n# Set expected counts for all\nfor s in plants:\n    s.expected_count(primary=1, lateral=5)\n\n# Filter plants that pass QC\nvalid_plants = [s for s in plants if not s.qc_fail()]\nprint(f\"Valid plants: {len(valid_plants)}/{len(plants)}\")\n</code></pre></p> <p>See Also:</p> <ul> <li>qc_fail</li> </ul> <p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"plant1\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Set expected counts\nseries.expected_count(primary=1, lateral=5)\n\n# Check QC status\nif series.qc_fail():\n    print(f\"QC failed for {series.series_name}\")\n    print(f\"Expected: 1 primary, 5 lateral\")\n    print(f\"Found: {len(series.get_primary_points())}, {len(series.get_lateral_points())}\")\nelse:\n    print(\"QC passed - proceeding with analysis\")\n</code></pre></p> <p>See Also:</p> <ul> <li>expected_count</li> </ul>"},{"location":"api/core/series/#sleap_roots.Series.expected_count","title":"expected_count  <code>property</code>","text":"<pre><code>expected_count: Union[float, int]\n</code></pre> <p>Fetch the expected plant count for this series from the CSV.</p>"},{"location":"api/core/series/#sleap_roots.Series.qc_fail","title":"qc_fail  <code>property</code>","text":"<pre><code>qc_fail: Union[int, float]\n</code></pre> <p>Flag to indicate if the series failed QC from the CSV.</p>"},{"location":"api/core/series/#visualization","title":"Visualization","text":"<p>Example: <pre><code>import sleap_roots as sr\nimport matplotlib.pyplot as plt\n\nseries = sr.Series.load(\n    \"plant1\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\"\n)\n\n# Get frame as image array\nframe_img = series.get_frame(\n    frame_idx=0,\n    video_idx=0,\n    return_rgb=True\n)\n\n# Display with matplotlib\nplt.imshow(frame_img)\nplt.title(f\"{series.series_name} - Frame 0\")\nplt.axis('off')\nplt.show()\n</code></pre></p> <p>See Also:</p> <ul> <li>plot - High-level plotting with predictions overlaid</li> </ul> <p>Example: <pre><code>import sleap_roots as sr\nimport matplotlib.pyplot as plt\n\nseries = sr.Series.load(\n    \"plant1\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Plot with predictions overlaid\nfig = series.plot(\n    frame_idx=0,\n    primary=True,\n    lateral=True,\n    plot_scale=1.0\n)\nplt.show()\n\n# Customize plot\nfig = series.plot(\n    frame_idx=5,\n    primary=True,\n    lateral=True,\n    plot_scale=0.5  # Smaller display\n)\nplt.title(f\"{series.series_name} - Frame 5\")\nplt.show()\n</code></pre></p> <p>See Also:</p> <ul> <li>get_frame</li> </ul>"},{"location":"api/core/series/#sleap_roots.Series.get_frame","title":"get_frame","text":"<pre><code>get_frame(frame_idx: int) -&gt; dict\n</code></pre> <p>Return labeled frames for primary, lateral, and crown predictions.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Integer frame number.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with keys 'primary', 'lateral', and 'crown', each corresponding</p> <code>dict</code> <p>to the <code>sio.LabeledFrame</code> from each set of predictions on the same frame. If</p> <code>dict</code> <p>any set of predictions is not available, its value will be None.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_frame(self, frame_idx: int) -&gt; dict:\n    \"\"\"Return labeled frames for primary, lateral, and crown predictions.\n\n    Args:\n        frame_idx: Integer frame number.\n\n    Returns:\n        Dictionary with keys 'primary', 'lateral', and 'crown', each corresponding\n        to the `sio.LabeledFrame` from each set of predictions on the same frame. If\n        any set of predictions is not available, its value will be None.\n    \"\"\"\n    frames = {}\n\n    # For primary predictions\n    if self.primary_labels is not None:\n        frames[\"primary\"] = self.primary_labels.find(\n            self.primary_labels.video, frame_idx, return_new=True\n        )[0]\n    else:\n        frames[\"primary\"] = None\n\n    # For lateral predictions\n    if self.lateral_labels is not None:\n        frames[\"lateral\"] = self.lateral_labels.find(\n            self.lateral_labels.video, frame_idx, return_new=True\n        )[0]\n    else:\n        frames[\"lateral\"] = None\n\n    # For crown predictions\n    if self.crown_labels is not None:\n        frames[\"crown\"] = self.crown_labels.find(\n            self.crown_labels.video, frame_idx, return_new=True\n        )[0]\n    else:\n        frames[\"crown\"] = None\n\n    return frames\n</code></pre>"},{"location":"api/core/series/#sleap_roots.Series.plot","title":"plot","text":"<pre><code>plot(\n    frame_idx: int, scale: float = 1.0, **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot predictions on top of the image.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index to visualize.</p> required <code>scale</code> <code>float</code> <p>Relative size of the visualized image. Useful for plotting smaller images within notebooks.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Figure</code> <p>matplotlib.figure.Figure object that shows predictions on top of images.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def plot(\n    self, frame_idx: int, scale: float = 1.0, **kwargs\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"Plot predictions on top of the image.\n\n    Args:\n        frame_idx: Frame index to visualize.\n        scale: Relative size of the visualized image. Useful for plotting smaller\n            images within notebooks.\n\n    Returns:\n        matplotlib.figure.Figure object that shows predictions on top of images.\n    \"\"\"\n    # Check if the video is available\n    if self.video is None:\n        raise ValueError(\"Video is not available. Specify the h5_path to load it.\")\n\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n\n    # Generate the color palette from seaborn\n    cmap = sns.color_palette(\"tab10\")\n\n    # Define the order of preference for the predictions for plotting the image\n    prediction_order = [\"primary\", \"lateral\", \"crown\"]\n\n    # Variable to keep track if the image has been plotted\n    image_plotted = False\n\n    # First, find the first available prediction to plot the image\n    for prediction in prediction_order:\n        labeled_frame = frames.get(prediction)\n        if labeled_frame is not None and not image_plotted:\n            # Plot the image\n            plot_img(labeled_frame.image, scale=scale)\n            # Set the flag to True to avoid plotting the image again\n            image_plotted = True\n\n    # Then, iterate through all predictions to plot instances\n    for i, prediction in enumerate(prediction_order):\n        labeled_frame = frames.get(prediction)\n        if labeled_frame is not None:\n            # Use the color map index for each prediction type\n            # Modulo the length of the color map to avoid index out of range\n            color = cmap[i % len(cmap)]\n\n            # Plot the instances\n            plot_instances(labeled_frame.instances, cmap=[color], **kwargs)\n\n    # Capture the current plot after calling plot_img and plot_instances.\n    fig = plt.gcf()\n\n    # Close the captured fig to avoid duplicate rendering from Jupyter.\n    plt.close(fig)\n\n    # Return the figure. In a cell, Jupyter will automatically render the plot.\n    return fig\n</code></pre>"},{"location":"api/core/series/#properties","title":"Properties","text":"<p>The <code>Series</code> class has the following attributes:</p> <ul> <li>series_name: <code>str</code> - Name identifier for the plant</li> <li>h5_path: <code>str | None</code> - Path to H5 image file</li> <li>primary_path: <code>str | None</code> - Path to primary root SLP file</li> <li>lateral_path: <code>str | None</code> - Path to lateral root SLP file</li> <li>crown_path: <code>str | None</code> - Path to crown root SLP file</li> <li>primary_labels: <code>sleap_io.Labels | None</code> - Loaded primary root labels</li> <li>lateral_labels: <code>sleap_io.Labels | None</code> - Loaded lateral root labels</li> <li>crown_labels: <code>sleap_io.Labels | None</code> - Loaded crown root labels</li> <li>video: <code>sleap_io.Video | None</code> - Loaded video object</li> <li>csv_path: <code>str | None</code> - Path for CSV export</li> </ul> <p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"plant1\",\n    h5_path=\"data.h5\",\n    primary_path=\"primary.slp\"\n)\n\n# Access properties\nprint(f\"Plant name: {series.series_name}\")\nprint(f\"H5 path: {series.h5_path}\")\nprint(f\"Primary predictions: {series.primary_path}\")\nprint(f\"Has video: {series.video is not None}\")\n\n# Check what was loaded\nhas_primary = series.primary_labels is not None\nhas_lateral = series.lateral_labels is not None\nhas_crown = series.crown_labels is not None\nprint(f\"Loaded: primary={has_primary}, lateral={has_lateral}, crown={has_crown}\")\n</code></pre></p>"},{"location":"api/core/series/#utility-functions","title":"Utility Functions","text":"<p>These module-level functions help with batch loading:</p> <p>Example: <pre><code>from sleap_roots import find_all_h5_paths\n\n# Find all H5 files in directory\nh5_files = find_all_h5_paths(\"data/predictions/\")\nprint(f\"Found {len(h5_files)} H5 files\")\n\nfor h5_path in h5_files:\n    print(h5_path)\n</code></pre></p> <p>Example: <pre><code>from sleap_roots import find_all_slp_paths\n\n# Find all SLP files in directory\nslp_files = find_all_slp_paths(\"data/predictions/\")\nprint(f\"Found {len(slp_files)} SLP files\")\n\n# Filter by pattern\nprimary_files = [f for f in slp_files if 'primary' in f.name]\nlateral_files = [f for f in slp_files if 'lateral' in f.name]\n</code></pre></p>"},{"location":"api/core/series/#sleap_roots.find_all_h5_paths","title":"find_all_h5_paths","text":"<pre><code>find_all_h5_paths(\n    data_folders: Union[str, List[str]],\n) -&gt; List[str]\n</code></pre> <p>Find all .h5 paths from a list of folders.</p> <p>Parameters:</p> Name Type Description Default <code>data_folders</code> <code>Union[str, List[str]]</code> <p>Path or list of paths to folders containing .h5 paths.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of filenames to .h5 paths.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def find_all_h5_paths(data_folders: Union[str, List[str]]) -&gt; List[str]:\n    \"\"\"Find all .h5 paths from a list of folders.\n\n    Args:\n        data_folders: Path or list of paths to folders containing .h5 paths.\n\n    Returns:\n        A list of filenames to .h5 paths.\n    \"\"\"\n    if type(data_folders) != list:\n        data_folders = [data_folders]\n\n    h5_paths = []\n    for data_folder in data_folders:\n        h5_paths.extend([Path(p).as_posix() for p in Path(data_folder).glob(\"*.h5\")])\n    return h5_paths\n</code></pre>"},{"location":"api/core/series/#sleap_roots.find_all_slp_paths","title":"find_all_slp_paths","text":"<pre><code>find_all_slp_paths(\n    data_folders: Union[str, List[str]],\n) -&gt; List[str]\n</code></pre> <p>Find all .slp paths from a list of folders.</p> <p>Parameters:</p> Name Type Description Default <code>data_folders</code> <code>Union[str, List[str]]</code> <p>Path or list of paths to folders containing .slp paths.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of filenames to .slp paths.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def find_all_slp_paths(data_folders: Union[str, List[str]]) -&gt; List[str]:\n    \"\"\"Find all .slp paths from a list of folders.\n\n    Args:\n        data_folders: Path or list of paths to folders containing .slp paths.\n\n    Returns:\n        A list of filenames to .slp paths.\n    \"\"\"\n    if type(data_folders) != list:\n        data_folders = [data_folders]\n\n    slp_paths = []\n    for data_folder in data_folders:\n        slp_paths.extend([Path(p).as_posix() for p in Path(data_folder).glob(\"*.slp\")])\n    return slp_paths\n</code></pre>"},{"location":"api/core/series/#sleap_roots.load_series_from_h5s","title":"load_series_from_h5s","text":"<pre><code>load_series_from_h5s(\n    h5_paths: List[str],\n    model_id: str,\n    csv_path: Optional[str] = None,\n) -&gt; List[Series]\n</code></pre> <p>Load a list of Series from a list of .h5 paths.</p> <p>To load the <code>Series</code>, the files must be named with the following convention: h5_path: '/path/to/scan/series_name.h5' primary_path: '/path/to/scan/series_name.model{model_id}.rootprimary.slp' lateral_path: '/path/to/scan/series_name.model{model_id}.rootlateral.slp' crown_path: '/path/to/scan/series_name.model{model_id}.rootcrown.slp'</p> <p>Our pipeline outputs prediction files with this format: //scan{scan_id}.model{model_id}.root{model_type}.slp <p>Parameters:</p> Name Type Description Default <code>h5_paths</code> <code>List[str]</code> <p>List of paths to .h5 files.</p> required <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Series]</code> <p>A list of Series loaded with the specified .h5 files.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def load_series_from_h5s(\n    h5_paths: List[str], model_id: str, csv_path: Optional[str] = None\n) -&gt; List[Series]:\n    \"\"\"Load a list of Series from a list of .h5 paths.\n\n    To load the `Series`, the files must be named with the following convention:\n    h5_path: '/path/to/scan/series_name.h5'\n    primary_path: '/path/to/scan/series_name.model{model_id}.rootprimary.slp'\n    lateral_path: '/path/to/scan/series_name.model{model_id}.rootlateral.slp'\n    crown_path: '/path/to/scan/series_name.model{model_id}.rootcrown.slp'\n\n    Our pipeline outputs prediction files with this format:\n    /&lt;output_folder&gt;/scan{scan_id}.model{model_id}.root{model_type}.slp\n\n    Args:\n        h5_paths: List of paths to .h5 files.\n        csv_path: Optional path to the CSV file containing the expected plant count.\n\n    Returns:\n        A list of Series loaded with the specified .h5 files.\n    \"\"\"\n    series_list = []\n    for h5_path in h5_paths:\n        # Extract the series name from the h5 path\n        series_name = Path(h5_path).name.split(\".\")[0]\n        # Generate the paths for the primary, lateral, and crown predictions\n        primary_path = h5_path.replace(\".h5\", f\".model{model_id}.rootprimary.slp\")\n        lateral_path = h5_path.replace(\".h5\", f\".model{model_id}.rootlateral.slp\")\n        crown_path = h5_path.replace(\".h5\", f\".model{model_id}.rootcrown.slp\")\n        # Load the Series\n        series = Series.load(\n            series_name,\n            h5_path=h5_path,\n            primary_path=primary_path,\n            lateral_path=lateral_path,\n            crown_path=crown_path,\n            csv_path=csv_path,\n        )\n        series_list.append(series)\n    return series_list\n</code></pre> <p>Example: <pre><code>from sleap_roots import load_series_from_h5s\n\n# Load all plants from H5 directory\nplants = load_series_from_h5s(\n    h5_dir=\"data/h5_files/\",\n    primary_pattern=\"*primary*.slp\",\n    lateral_pattern=\"*lateral*.slp\"\n)\n\nprint(f\"Loaded {len(plants)} plants\")\n\n# Process each plant\nfor series in plants:\n    primary_pts = series.get_primary_points()\n    print(f\"{series.series_name}: {primary_pts.shape}\")\n</code></pre></p>"},{"location":"api/core/series/#sleap_roots.load_series_from_slps","title":"load_series_from_slps","text":"<pre><code>load_series_from_slps(\n    slp_paths: List[str],\n    h5s: bool = False,\n    csv_path: Optional[str] = None,\n) -&gt; List[Series]\n</code></pre> <p>Load a list of Series from a list of .slp paths.</p> <p>To load the <code>Series</code>, the files must be named with the following convention. The <code>slp_paths</code> are expeted to have the <code>series_name</code> in the filename and \"primary\", \"lateral\", or \"crown\" in the filename to differentiate the predictions. h5_path: '/path/to/scan/series_name.h5' Note that everything is expected to be in the same folder.</p> <p>Our pipeline outputs prediction files with this format: //scan{scan_id}.model{model_id}.root{model_type}.slp <p>Parameters:</p> Name Type Description Default <code>slp_paths</code> <code>List[str]</code> <p>List of paths to .slp files.</p> required <code>h5s</code> <code>bool</code> <p>Boolean flag to indicate if the .h5 files are available. Default is False.</p> <code>False</code> <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <code>None</code> Source code in <code>sleap_roots/series.py</code> <pre><code>def load_series_from_slps(\n    slp_paths: List[str], h5s: bool = False, csv_path: Optional[str] = None\n) -&gt; List[Series]:\n    \"\"\"Load a list of Series from a list of .slp paths.\n\n    To load the `Series`, the files must be named with the following convention.\n    The `slp_paths` are expeted to have the `series_name` in the filename and \"primary\",\n    \"lateral\", or \"crown\" in the filename to differentiate the predictions.\n    h5_path: '/path/to/scan/series_name.h5'\n    Note that everything is expected to be in the same folder.\n\n    Our pipeline outputs prediction files with this format:\n    /&lt;output_folder&gt;/scan{scan_id}.model{model_id}.root{model_type}.slp\n\n\n    Args:\n        slp_paths: List of paths to .slp files.\n        h5s: Boolean flag to indicate if the .h5 files are available. Default is False.\n        csv_path: Optional path to the CSV file containing the expected plant count.\n    \"\"\"\n    series_list = []\n    series_names = list(set([Path(p).name.split(\".\")[0] for p in slp_paths]))\n    for series_name in series_names:\n        # Generate the paths for the primary, lateral, and crown predictions\n        primary_path = [p for p in slp_paths if series_name in p and \"primary\" in p]\n        lateral_path = [p for p in slp_paths if series_name in p and \"lateral\" in p]\n        crown_path = [p for p in slp_paths if series_name in p and \"crown\" in p]\n        # Check if the .h5 files are available\n        if h5s:\n            # Get directory of the h5s\n            h5_dir = Path(slp_paths[0]).parent\n            # Create path to the .h5 file\n            h5_path = h5_dir / f\"{series_name}.h5\"\n        else:\n            h5_path = None\n        # Load the Series\n        series = Series.load(\n            series_name,\n            primary_path=primary_path[0] if primary_path else None,\n            lateral_path=lateral_path[0] if lateral_path else None,\n            crown_path=crown_path[0] if crown_path else None,\n            h5_path=h5_path,\n            csv_path=csv_path,\n        )\n        series_list.append(series)\n    return series_list\n</code></pre> <p>Example: <pre><code>from sleap_roots import load_series_from_slps\n\n# Load all plants from SLP directory\nplants = load_series_from_slps(\n    slp_dir=\"data/predictions/\",\n    primary_pattern=\"*primary*.slp\",\n    lateral_pattern=\"*lateral*.slp\",\n    crown_pattern=\"*crown*.slp\"\n)\n\nprint(f\"Loaded {len(plants)} plants\")\n\n# Batch processing\nfor series in plants:\n    # Set QC expectations\n    series.expected_count(primary=1, lateral=5)\n\n    # Filter by QC\n    if not series.qc_fail():\n        # Run analysis\n        primary_pts = series.get_primary_points()\n        lateral_pts_list = series.get_lateral_points()\n</code></pre></p>"},{"location":"api/core/series/#complete-workflow-example","title":"Complete Workflow Example","text":"<pre><code>import sleap_roots as sr\nimport numpy as np\n\n# 1. Load plant data\nseries = sr.Series.load(\n    series_name=\"arabidopsis_1\",\n    h5_path=\"data/arabidopsis.h5\",\n    primary_path=\"data/arabidopsis_primary.slp\",\n    lateral_path=\"data/arabidopsis_lateral.slp\"\n)\n\n# 2. Quality control\nseries.expected_count(primary=1, lateral=8)\nif series.qc_fail():\n    print(f\"Warning: {series.series_name} failed QC\")\n\n# 3. Extract root points\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\nprint(f\"Primary roots: {primary_pts.shape}\")\nprint(f\"Lateral roots: {len(lateral_pts_list)}\")\n\n# 4. Compute custom trait\nfrom sleap_roots import get_root_lengths\n\nprimary_lengths = get_root_lengths(primary_pts)\nlateral_lengths = [get_root_lengths(pts) for pts in lateral_pts_list]\n\nprint(f\"Primary root length: {np.nanmean(primary_lengths):.2f} pixels\")\nprint(f\"Mean lateral length: {np.nanmean([np.nanmean(l) for l in lateral_lengths]):.2f} pixels\")\n\n# 5. Visualize\nimport matplotlib.pyplot as plt\nfig = series.plot(frame_idx=0, primary=True, lateral=True)\nplt.show()\n\n# 6. Or use a pipeline for full trait extraction\npipeline = sr.DicotPipeline()\ntraits = pipeline.fit_series(series)\nprint(f\"Computed {len(traits)} traits\")\n</code></pre>"},{"location":"api/core/series/#advanced-usage","title":"Advanced Usage","text":""},{"location":"api/core/series/#working-with-multiple-frames","title":"Working with Multiple Frames","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant1\", primary_path=\"primary.slp\")\nprimary_pts = series.get_primary_points()\n\n# Shape: (plants, frames, nodes, 2)\nn_plants, n_frames, n_nodes, _ = primary_pts.shape\n\n# Analyze each frame\nfor frame_idx in range(n_frames):\n    frame_pts = primary_pts[0, frame_idx]  # (nodes, 2)\n\n    # Compute per-frame traits\n    from sleap_roots import get_root_angle\n    angle = get_root_angle(frame_pts[np.newaxis, :, :])\n    print(f\"Frame {frame_idx}: angle = {angle[0]:.1f}\u00b0\")\n</code></pre>"},{"location":"api/core/series/#batch-processing","title":"Batch Processing","text":"<pre><code>import sleap_roots as sr\nfrom pathlib import Path\n\n# Load all plants\nplants = sr.load_series_from_slps(\n    slp_dir=\"data/experiment1/\",\n    primary_pattern=\"*primary*.slp\",\n    lateral_pattern=\"*lateral*.slp\"\n)\n\n# Process with QC\nresults = []\nfor series in plants:\n    series.expected_count(primary=1, lateral=5)\n\n    if not series.qc_fail():\n        # Run pipeline\n        pipeline = sr.DicotPipeline()\n        traits = pipeline.fit_series(series)\n        results.append({\n            'plant': series.series_name,\n            **traits\n        })\n\n# Export results\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.to_csv(\"experiment1_results.csv\", index=False)\nprint(f\"Processed {len(results)} valid plants\")\n</code></pre>"},{"location":"api/core/series/#related-modules","title":"Related Modules","text":"<ul> <li>Pipelines - Pre-built trait computation workflows that use Series</li> <li>Trait Modules - Individual trait computation functions</li> <li>Points Utilities - Helper functions for manipulating point arrays</li> </ul>"},{"location":"api/core/series/#see-also","title":"See Also","text":"<ul> <li>Installation Guide - Setting up sleap-roots</li> <li>Quick Start Tutorial - First analysis walkthrough</li> <li>Data Formats Guide - Understanding SLP and H5 files</li> <li>DicotPipeline Tutorial - Complete pipeline example</li> </ul>"},{"location":"api/examples/common-workflows/","title":"Common Workflows","text":"<p>Complete end-to-end examples for typical sleap-roots analysis tasks.</p>"},{"location":"api/examples/common-workflows/#workflow-1-quick-pipeline-analysis","title":"Workflow 1: Quick Pipeline Analysis","text":"<p>The fastest way to extract traits from SLEAP predictions.</p> <pre><code>import sleap_roots as sr\n\n# Load data\nseries = sr.Series.load(\n    series_name=\"rice_plant1\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary_roots.slp\",\n    lateral_path=\"lateral_roots.slp\"\n)\n\n# Choose appropriate pipeline\npipeline = sr.YoungerMonocotPipeline()\n\n# Extract all traits\ntraits_dict = pipeline.compute_plant_traits(series)\n\n# Access specific traits\nprint(f\"Primary root count: {traits_dict['primary_count']}\")\nprint(f\"Primary max length: {traits_dict['primary_max_length']:.2f} px\")\nprint(f\"Lateral count: {traits_dict['lateral_count']}\")\nprint(f\"Network length: {traits_dict['network_length_lower']:.2f} px\")\n</code></pre> <p>When to use: You need standard traits quickly and don't need custom computations.</p> <p>See also: Pipelines documentation</p>"},{"location":"api/examples/common-workflows/#workflow-2-custom-trait-computation","title":"Workflow 2: Custom Trait Computation","text":"<p>Compute specific traits with fine-grained control.</p> <pre><code>import sleap_roots as sr\nimport numpy as np\n\n# Load data\nseries = sr.Series.load(\"canola_plant1\", primary_path=\"primary.slp\")\n\n# Get point arrays\nprimary_pts = series.get_primary_points()  # (plants, frames, nodes, 2)\n\n# Compute multiple traits\nlengths = sr.get_root_lengths(primary_pts)\nangles = sr.get_root_angle(primary_pts, n_points=5)\ncurve_indices = sr.get_curve_index(primary_pts)\n\n# Get first frame, first plant\nframe_0 = 0\nplant_0 = 0\n\nprint(f\"Primary root length: {lengths[plant_0, frame_0]:.2f} px\")\nprint(f\"Growth angle: {angles[plant_0, frame_0]:.2f}\u00b0\")\nprint(f\"Curvature index: {curve_indices[plant_0, frame_0]:.3f}\")\n\n# Compute summary statistics across time\nmean_length = np.nanmean(lengths[plant_0, :])\nstd_angle = np.nanstd(angles[plant_0, :])\n\nprint(f\"\\nAcross {series.frame_count} frames:\")\nprint(f\"Mean length: {mean_length:.2f} px\")\nprint(f\"Angle variability: {std_angle:.2f}\u00b0\")\n</code></pre> <p>When to use: You need specific traits not available in pipelines, or want custom processing.</p> <p>See also: Lengths, Angles</p>"},{"location":"api/examples/common-workflows/#workflow-3-lateral-root-analysis","title":"Workflow 3: Lateral Root Analysis","text":"<p>Analyze lateral root emergence and distribution patterns.</p> <pre><code>import sleap_roots as sr\nimport numpy as np\n\n# Load with laterals\nseries = sr.Series.load(\n    \"wheat_plant1\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Get lateral points (list of arrays)\nlateral_pts_list = series.get_lateral_points()\nprimary_pts = series.get_primary_points()\n\n# Analyze each lateral root\nlateral_count = len(lateral_pts_list)\nprint(f\"Detected {lateral_count} lateral roots\\n\")\n\nfor i, lateral_pts in enumerate(lateral_pts_list):\n    # Compute traits for this lateral\n    length = sr.get_root_lengths(lateral_pts)[0, 0]\n    angle = sr.get_root_angle(lateral_pts)[0, 0]\n\n    print(f\"Lateral {i+1}:\")\n    print(f\"  Length: {length:.2f} px\")\n    print(f\"  Angle: {angle:.2f}\u00b0\")\n\n# Get lateral base positions along primary\nbases = sr.get_bases(primary_pts, lateral_pts_list)\nbase_ys = bases[:, 1]  # y-coordinates\n\n# Compute emergence density\nprimary_length = sr.get_root_lengths(primary_pts)[0, 0]\nbase_density = sr.get_base_ct_density(primary_pts, lateral_pts_list)[0, 0]\n\nprint(f\"\\nEmergence pattern:\")\nprint(f\"Primary length: {primary_length:.2f} px\")\nprint(f\"Lateral density: {base_density:.3f} laterals/px\")\nprint(f\"Base positions (y): {base_ys}\")\n</code></pre> <p>When to use: Studying lateral root development, emergence patterns, or architecture.</p> <p>See also: Bases, Lateral Pipeline</p>"},{"location":"api/examples/common-workflows/#workflow-4-temporal-growth-analysis","title":"Workflow 4: Temporal Growth Analysis","text":"<p>Track root growth over time using multiple frames.</p> <pre><code>import sleap_roots as sr\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load time series data\nseries = sr.Series.load(\"timeseries_plant\", primary_path=\"primary.slp\")\nprimary_pts = series.get_primary_points()  # (1, frames, nodes, 2)\n\nframes = series.frame_count\nplant_idx = 0\n\n# Compute traits over time\nlengths_over_time = []\nangles_over_time = []\ntip_ys_over_time = []\n\nfor frame_idx in range(frames):\n    frame_pts = primary_pts[plant_idx:plant_idx+1, frame_idx:frame_idx+1]\n\n    length = sr.get_root_lengths(frame_pts)[0, 0]\n    angle = sr.get_root_angle(frame_pts)[0, 0]\n    tip_y = sr.get_tip_ys(frame_pts)[0, 0]\n\n    lengths_over_time.append(length)\n    angles_over_time.append(angle)\n    tip_ys_over_time.append(tip_y)\n\n# Analyze growth rate\ngrowth_rates = np.diff(lengths_over_time)\nmean_growth_rate = np.mean(growth_rates)\n\nprint(f\"Analysis across {frames} frames:\")\nprint(f\"Initial length: {lengths_over_time[0]:.2f} px\")\nprint(f\"Final length: {lengths_over_time[-1]:.2f} px\")\nprint(f\"Total growth: {lengths_over_time[-1] - lengths_over_time[0]:.2f} px\")\nprint(f\"Mean growth rate: {mean_growth_rate:.2f} px/frame\")\n\n# Plot growth trajectory\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\naxes[0].plot(lengths_over_time)\naxes[0].set_title('Root Length Over Time')\naxes[0].set_xlabel('Frame')\naxes[0].set_ylabel('Length (px)')\n\naxes[1].plot(angles_over_time)\naxes[1].set_title('Growth Angle Over Time')\naxes[1].set_xlabel('Frame')\naxes[1].set_ylabel('Angle (\u00b0)')\n\naxes[2].plot(tip_ys_over_time)\naxes[2].set_title('Tip Position Over Time')\naxes[2].set_xlabel('Frame')\naxes[2].set_ylabel('Y Position (px)')\n\nplt.tight_layout()\nplt.savefig('growth_analysis.png', dpi=150)\nprint(\"\\nSaved growth_analysis.png\")\n</code></pre> <p>When to use: Time-lapse experiments, growth rate analysis, gravitropism studies.</p> <p>See also: Series documentation, Tips</p>"},{"location":"api/examples/common-workflows/#workflow-5-network-level-spatial-analysis","title":"Workflow 5: Network-Level Spatial Analysis","text":"<p>Analyze whole root system architecture and spatial distribution.</p> <pre><code>import sleap_roots as sr\nfrom sleap_roots import join_pts\n\n# Load complete root system\nseries = sr.Series.load(\n    \"mature_plant\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Get all roots\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\n# Combine into single point array\nall_pts = join_pts([primary_pts] + lateral_pts_list)\n\n# Network-level metrics\nnetwork_length = sr.get_network_length(all_pts)\nwd_ratio = sr.get_network_width_depth_ratio(all_pts)\nbbox = sr.get_bbox(all_pts)\n\nprint(\"Network Metrics:\")\nprint(f\"Total network length: {network_length:.2f} px\")\nprint(f\"Width:Depth ratio: {wd_ratio:.2f}\")\nprint(f\"Bounding box: {bbox}\")\n\n# Spatial coverage\nhull_area = sr.convhull.get_chull_area(all_pts)\nhull_perimeter = sr.convhull.get_chull_perimeter(all_pts)\nprint(f\"\\nSpatial Coverage:\")\nprint(f\"Convex hull area: {hull_area:.2f} px\u00b2\")\nprint(f\"Convex hull perimeter: {hull_perimeter:.2f} px\")\n\n# Ellipse fit for compact representation\npts_2d = sr.points.get_all_pts_array(all_pts)  # Flatten to (n_points, 2)\nellipse = sr.ellipse.fit_ellipse(pts_2d)\na = sr.ellipse.get_ellipse_a(ellipse)\nb = sr.ellipse.get_ellipse_b(ellipse)\nprint(f\"\\nEllipse major axis: {a:.2f} px, minor axis: {b:.2f} px\")\n\n# Distribution analysis using scanlines\ny_positions = [100, 200, 300, 400, 500]\nfor y in y_positions:\n    intersections = sr.count_scanline_intersections(all_pts, y=y)\n    print(f\"Intersections at y={y}: {intersections}\")\n</code></pre> <p>When to use: Characterizing root system architecture, comparing genotypes, spatial phenotyping.</p> <p>See also: Network Length, Convex Hull, Scanline</p>"},{"location":"api/examples/common-workflows/#workflow-6-batch-processing-multiple-plants","title":"Workflow 6: Batch Processing Multiple Plants","text":"<p>Process multiple plant series and aggregate results.</p> <pre><code>import sleap_roots as sr\nimport pandas as pd\nfrom pathlib import Path\n\n# Define plant data\nplants = [\n    {\"name\": \"plant1\", \"h5\": \"plant1.h5\", \"primary\": \"plant1_primary.slp\"},\n    {\"name\": \"plant2\", \"h5\": \"plant2.h5\", \"primary\": \"plant2_primary.slp\"},\n    {\"name\": \"plant3\", \"h5\": \"plant3.h5\", \"primary\": \"plant3_primary.slp\"},\n]\n\n# Load all series\nall_series = []\nfor plant_info in plants:\n    series = sr.Series.load(\n        plant_info[\"name\"],\n        h5_path=plant_info[\"h5\"],\n        primary_path=plant_info[\"primary\"]\n    )\n    all_series.append(series)\n\n# Run batch pipeline processing\npipeline = sr.DicotPipeline()\nbatch_traits = pipeline.compute_batch_traits(all_series)\n\n# Convert to DataFrame\ndf = pd.DataFrame(batch_traits)\ndf[\"plant_name\"] = [p[\"name\"] for p in plants]\n\nprint(\"Results:\")\nprint(df[[\"plant_name\", \"primary_length\", \"primary_angle\", \"lateral_count\"]])\n\n# Save to CSV\ndf.to_csv(\"batch_analysis_results.csv\", index=False)\nprint(\"\\nSaved batch_analysis_results.csv\")\n\n# Compute summary statistics\nprint(\"\\nSummary Statistics:\")\nfor col in [\"primary_length\", \"primary_angle\", \"lateral_count\"]:\n    stats = sr.get_summary(df[col].values, prefix=f\"{col}_\")\n    print(f\"\\n{col}:\")\n    print(f\"  Mean: {stats[f'{col}_mean']:.2f}\")\n    print(f\"  Std: {stats[f'{col}_std']:.2f}\")\n    print(f\"  Range: {stats[f'{col}_min']:.2f} - {stats[f'{col}_max']:.2f}\")\n</code></pre> <p>When to use: High-throughput phenotyping, genotype comparisons, experimental studies.</p> <p>See also: Pipelines, Summary Statistics</p>"},{"location":"api/examples/common-workflows/#workflow-7-quality-control-and-filtering","title":"Workflow 7: Quality Control and Filtering","text":"<p>Filter out invalid roots and handle edge cases.</p> <pre><code>import sleap_roots as sr\nimport numpy as np\n\n# Load data\nseries = sr.Series.load(\n    \"experimental_data\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\nlateral_pts_list = series.get_lateral_points()\n\nprint(f\"Initial lateral count: {len(lateral_pts_list)}\")\n\n# Filter out roots with NaN values (incomplete tracking)\nvalid_laterals = sr.filter_roots_with_nans(lateral_pts_list)\nprint(f\"Valid laterals after NaN filtering: {len(valid_laterals)}\")\n\n# Additional quality filtering: remove very short roots\nmin_length_threshold = 10.0  # pixels\n\nfiltered_laterals = []\nfor lateral_pts in valid_laterals:\n    length = sr.get_root_lengths(lateral_pts)[0, 0]\n    if length &gt;= min_length_threshold:\n        filtered_laterals.append(lateral_pts)\n\nprint(f\"Valid laterals after length filtering: {len(filtered_laterals)}\")\n\n# Compute traits only on valid roots\nif len(filtered_laterals) &gt; 0:\n    lengths = [sr.get_root_lengths(pts)[0, 0] for pts in filtered_laterals]\n    angles = [sr.get_root_angle(pts)[0, 0] for pts in filtered_laterals]\n\n    print(f\"\\nFiltered Lateral Statistics:\")\n    print(f\"Mean length: {np.mean(lengths):.2f} px\")\n    print(f\"Mean angle: {np.mean(angles):.2f}\u00b0\")\n    print(f\"Length range: {np.min(lengths):.2f} - {np.max(lengths):.2f} px\")\nelse:\n    print(\"No valid lateral roots after filtering\")\n\n# Check primary root quality\nprimary_pts = series.get_primary_points()\nhas_nans = np.any(np.isnan(primary_pts))\n\nif has_nans:\n    print(\"\\nWarning: Primary root contains NaN values\")\n    # Handle by using only valid frames\n    valid_frames = ~np.any(np.isnan(primary_pts), axis=(0, 2, 3))\n    clean_pts = primary_pts[:, valid_frames, :, :]\n    print(f\"Using {np.sum(valid_frames)}/{len(valid_frames)} valid frames\")\nelse:\n    print(\"\\nPrimary root tracking is complete\")\n</code></pre> <p>When to use: Working with incomplete tracking data, ensuring data quality, debugging.</p> <p>See also: Points utilities, Series</p>"},{"location":"api/examples/common-workflows/#workflow-8-multiple-dicot-plants","title":"Workflow 8: Multiple Dicot Plants","text":"<p>Process multiple dicot plants simultaneously with specialized pipeline.</p> <pre><code>import sleap_roots as sr\n\n# Load series with multiple plants\nseries = sr.Series.load(\n    \"arabidopsis_tray\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary_roots.slp\",\n    lateral_path=\"lateral_roots.slp\"\n)\n\n# Use multiple dicot pipeline\npipeline = sr.MultipleDicotPipeline()\ntraits_dict = pipeline.compute_multiple_dicots_traits(series)\n\n# Access per-plant traits\nprint(f\"Plants detected: {len(traits_dict['primary_length'])}\")\n\nfor i, (length, angle, lat_count) in enumerate(zip(\n    traits_dict['primary_length'],\n    traits_dict['primary_angle'],\n    traits_dict['lateral_count']\n)):\n    print(f\"\\nPlant {i+1}:\")\n    print(f\"  Primary length: {length:.2f} px\")\n    print(f\"  Primary angle: {angle:.2f}\u00b0\")\n    print(f\"  Lateral count: {lat_count}\")\n</code></pre> <p>When to use: High-throughput imaging with multiple plants per image.</p> <p>See also: MultipleDicotPipeline</p>"},{"location":"api/examples/common-workflows/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference - Explore all available functions</li> <li>Pipelines Guide - Choose the right pipeline</li> <li>Tutorial Notebooks - Interactive learning</li> </ul>"},{"location":"api/traits/angles/","title":"Angles","text":""},{"location":"api/traits/angles/#overview","title":"Overview","text":"<p>Compute root angle measurements relative to gravity (vertical axis). Essential for gravitropism analysis and root growth direction studies.</p> <p>Key functions: - <code>get_root_angle</code> - Calculate root angle from proximal points - <code>get_vector_angles_from_gravity</code> - Core angle calculation from vectors - <code>get_node_ind</code> - Select points for angle computation</p> <p>Angle Convention: 0\u00b0 = straight down (with gravity), 90\u00b0 = horizontal, 180\u00b0 = straight up</p>"},{"location":"api/traits/angles/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\npts = series.get_primary_points()\n\n# Compute root angle\nangles = sr.get_root_angle(pts, n_points=5)\nprint(f\"Primary root angle: {angles[0, 0]:.1f}\u00b0\")\n</code></pre>"},{"location":"api/traits/angles/#api-reference","title":"API Reference","text":""},{"location":"api/traits/angles/#get_root_angle","title":"get_root_angle","text":"<p>Example: <pre><code>import sleap_roots as sr\nimport numpy as np\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\npts = series.get_primary_points()\n\n# Default: use first 5 points\nangles = sr.get_root_angle(pts)\nprint(f\"Angle (5 pts): {angles[0, 0]:.1f}\u00b0\")\n\n# Use more points for smoother estimate\nangles_smooth = sr.get_root_angle(pts, n_points=10)\nprint(f\"Angle (10 pts): {angles_smooth[0, 0]:.1f}\u00b0\")\n\n# Interpret results\nangle = angles[0, 0]\nif angle &lt; 30:\n    print(\"Root growing downward (positive gravitropism)\")\nelif angle &gt; 150:\n    print(\"Root growing upward (negative gravitropism)\")\nelse:\n    print(\"Root growing at an angle\")\n</code></pre></p> <p>See Also: DicotPipeline</p>"},{"location":"api/traits/angles/#sleap_roots.angle.get_root_angle","title":"get_root_angle","text":"<pre><code>get_root_angle(\n    pts: ndarray,\n    node_ind: ndarray,\n    proximal: bool = True,\n    base_ind: int = 0,\n) -&gt; ndarray\n</code></pre> <p>Find angles for each root.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Numpy array of points of shape (instances, nodes, 2).</p> required <code>node_ind</code> <code>ndarray</code> <p>Primary or lateral root node index.</p> required <code>proximal</code> <code>bool</code> <p>Boolean value, where true is proximal (default), false is distal.</p> <code>True</code> <code>base_ind</code> <code>int</code> <p>Index of base node in the skeleton (default: 0).</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of shape (instances,) of angles in degrees, modulo 360.</p> Source code in <code>sleap_roots/angle.py</code> <pre><code>def get_root_angle(\n    pts: np.ndarray, node_ind: np.ndarray, proximal: bool = True, base_ind: int = 0\n) -&gt; np.ndarray:\n    \"\"\"Find angles for each root.\n\n    Args:\n        pts: Numpy array of points of shape (instances, nodes, 2).\n        node_ind: Primary or lateral root node index.\n        proximal: Boolean value, where true is proximal (default), false is distal.\n        base_ind: Index of base node in the skeleton (default: 0).\n\n    Returns:\n        An array of shape (instances,) of angles in degrees, modulo 360.\n    \"\"\"\n    # if node_ind is a single  int value, make it as array to keep consistent\n    if not isinstance(node_ind, np.ndarray):\n        node_ind = [node_ind]\n\n    if np.isnan(node_ind).all():\n        return np.nan\n\n    if pts.ndim == 2:\n        pts = np.expand_dims(pts, axis=0)\n\n    angs_root = []\n    # Calculate the angle for each instance\n    for i in range(pts.shape[0]):\n        # if the node_ind is 0, do NOT calculate angs\n        if node_ind[i] == 0:\n            angs = np.nan\n        else:\n            xy = pts[i, node_ind[i], :] - pts[i, base_ind, :]  # center on base node\n            # calculate the angle and convert to the start with gravity direction\n            ang = np.arctan2(-xy[1], xy[0]) * 180 / np.pi\n            angs = abs(ang + 90) if ang &lt; 90 else abs(-(360 - 90 - ang))\n        angs_root.append(angs)\n    angs_root = np.array(angs_root)\n\n    # If only one root, return a scalar instead of a single-element array\n    if angs_root.shape[0] == 1:\n        return angs_root[0]\n    return angs_root\n</code></pre>"},{"location":"api/traits/angles/#get_vector_angles_from_gravity","title":"get_vector_angles_from_gravity","text":""},{"location":"api/traits/angles/#sleap_roots.angle.get_vector_angles_from_gravity","title":"get_vector_angles_from_gravity","text":"<pre><code>get_vector_angles_from_gravity(vectors: ndarray) -&gt; ndarray\n</code></pre> <p>Calculate the angle of given vectors from the gravity vector.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>ndarray</code> <p>An array of vectorss with shape (instances, 2), each representing a vector     from start to end in an instance.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of angles in degrees with shape (instances,), representing the angle</p> <code>ndarray</code> <p>between each vector and the downward-pointing gravity vector.</p> Source code in <code>sleap_roots/angle.py</code> <pre><code>def get_vector_angles_from_gravity(vectors: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Calculate the angle of given vectors from the gravity vector.\n\n    Args:\n        vectors: An array of vectorss with shape (instances, 2), each representing a vector\n                from start to end in an instance.\n\n    Returns:\n        An array of angles in degrees with shape (instances,), representing the angle\n        between each vector and the downward-pointing gravity vector.\n    \"\"\"\n    gravity_vector = np.array([0, 1])  # Downwards along the positive y-axis\n    # Calculate the angle between the vectors and the gravity vectors\n    angles = np.arctan2(vectors[:, 1], vectors[:, 0]) - np.arctan2(\n        gravity_vector[1], gravity_vector[0]\n    )\n    angles = np.degrees(angles)\n    # Normalize angles to the range [0, 180] since direction doesn't matter\n    angles = np.abs(angles)\n    angles[angles &gt; 180] = 360 - angles[angles &gt; 180]\n\n    # If only one root, return a scalar instead of a single-element array\n    if angles.shape[0] == 1:\n        return angles[0]\n    return angles\n</code></pre>"},{"location":"api/traits/angles/#get_node_ind","title":"get_node_ind","text":"<p>Example: <pre><code>import sleap_roots as sr\n\npts = sr.Series.load(\"plant\", primary_path=\"primary.slp\").get_primary_points()\n\n# Get indices for proximal 5 points\nindices = sr.get_node_ind(pts, n_points=5)\nprint(f\"Selected nodes: {indices[0, 0]}\")  # Array of node indices\n</code></pre></p>"},{"location":"api/traits/angles/#sleap_roots.angle.get_node_ind","title":"get_node_ind","text":"<pre><code>get_node_ind(\n    pts: ndarray, proximal: bool = True\n) -&gt; ndarray\n</code></pre> <p>Find proximal/distal node index.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Numpy array of points of shape (instances, nodes, 2) or (nodes, 2).</p> required <code>proximal</code> <code>bool</code> <p>Boolean value, where true is proximal (default), false is distal.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of shape (instances,) of proximal or distal node indices.</p> <code>ndarray</code> <p>The proximal node is the first non-NaN node in the first half of the root.</p> <code>ndarray</code> <p>The distal node is the last non-NaN node in the last half of the root.</p> <code>ndarray</code> <p>If all nodes (or all nodes in the half of the root) are NaN, then zero is</p> <code>ndarray</code> <p>returned.</p> Source code in <code>sleap_roots/angle.py</code> <pre><code>def get_node_ind(pts: np.ndarray, proximal: bool = True) -&gt; np.ndarray:\n    \"\"\"Find proximal/distal node index.\n\n    Args:\n        pts: Numpy array of points of shape (instances, nodes, 2) or (nodes, 2).\n        proximal: Boolean value, where true is proximal (default), false is distal.\n\n    Returns:\n        An array of shape (instances,) of proximal or distal node indices.\n\n        The proximal node is the first non-NaN node in the first half of the root.\n\n        The distal node is the last non-NaN node in the last half of the root.\n\n        If all nodes (or all nodes in the half of the root) are NaN, then zero is\n        returned.\n    \"\"\"\n    # Check if pts is 2D, if so, reshape to 3D\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    n_instances, n_nodes, _ = pts.shape\n\n    # Identify where NaN values exist\n    is_nan = np.isnan(pts).any(axis=-1)  # (n_instances, n_nodes)\n\n    # If only NaN values, return NaN\n    if is_nan.all():\n        return np.zeros((n_instances,))\n\n    if proximal:\n        # Proximal nodes are in the first half of the root.\n        is_nan = is_nan[:, 1 : (n_nodes + 1) // 2]\n        node_ind = np.argmax(~is_nan, axis=-1) + 1\n    else:\n        # Distal nodes are in the last half of the root.\n        is_nan = is_nan[:, (n_nodes + 1) // 2 :]\n        node_ind = np.argmax(~is_nan[:, ::-1], axis=-1)\n        node_ind = n_nodes - node_ind - 1\n\n    # If the selected index is missing originally, return 0.\n    node_ind = np.where(is_nan.all(axis=-1), 0, node_ind)\n\n    return node_ind\n</code></pre>"},{"location":"api/traits/angles/#related-modules","title":"Related Modules","text":"<ul> <li>Lengths - Root length measurements</li> <li>Tips - Tip point detection</li> </ul>"},{"location":"api/traits/angles/#see-also","title":"See Also","text":"<ul> <li>Gravitropism Analysis Guide</li> </ul>"},{"location":"api/traits/bases/","title":"Bases","text":""},{"location":"api/traits/bases/#overview","title":"Overview","text":"<p>Detect lateral root base points and compute base-related traits. Critical for understanding lateral root emergence patterns and density.</p> <p>Key functions: - <code>get_bases</code> - Detect base points where laterals emerge from primary - <code>get_base_length</code> - Length of lateral root zone - <code>get_base_ct_density</code> - Lateral root density - <code>get_root_widths</code> - Root width measurements</p>"},{"location":"api/traits/bases/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\", lateral_path=\"lateral.slp\")\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\n# Detect base points\nbases = sr.get_bases(primary_pts, lateral_pts_list)\nprint(f\"Base points shape: {bases.shape}\")\n\n# Compute base zone length\nbase_length = sr.get_base_length(bases)\nprint(f\"Lateral root zone length: {base_length:.2f} px\")\n</code></pre>"},{"location":"api/traits/bases/#api-reference","title":"API Reference","text":""},{"location":"api/traits/bases/#get_bases","title":"get_bases","text":""},{"location":"api/traits/bases/#sleap_roots.bases.get_bases","title":"get_bases","text":"<pre><code>get_bases(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Return bases (r1) from each root.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of bases <code>(instances, (x, y))</code>. If the input is <code>(nodes, 2)</code>, an array of shape <code>(2,)</code> will be returned.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_bases(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return bases (r1) from each root.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        Array of bases `(instances, (x, y))`. If the input is `(nodes, 2)`, an array of\n            shape `(2,)` will be returned.\n    \"\"\"\n    # If the input has shape `(nodes, 2)`, reshape it for consistency\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    # Get the first point of each instance\n    base_pts = pts[:, 0]  # Shape is `(instances, 2)`\n\n    # If the input was `(nodes, 2)`, return an array of shape `(2,)` instead of `(1, 2)`\n    if base_pts.shape[0] == 1:\n        return base_pts[0]\n\n    return base_pts\n</code></pre>"},{"location":"api/traits/bases/#get_base_length","title":"get_base_length","text":""},{"location":"api/traits/bases/#sleap_roots.bases.get_base_length","title":"get_base_length","text":"<pre><code>get_base_length(lateral_base_ys: ndarray) -&gt; float\n</code></pre> <p>Get the y-axis difference from the top lateral base to the bottom lateral base.</p> <p>Parameters:</p> Name Type Description Default <code>lateral_base_ys</code> <code>ndarray</code> <p>y-coordinates of the base points of lateral roots of shape <code>(instances,)</code>.</p> required Return <p>The distance between the top base y-coordinate and the deepest base y-coordinate.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_length(lateral_base_ys: np.ndarray) -&gt; float:\n    \"\"\"Get the y-axis difference from the top lateral base to the bottom lateral base.\n\n    Args:\n        lateral_base_ys: y-coordinates of the base points of lateral roots of shape\n            `(instances,)`.\n\n    Return:\n        The distance between the top base y-coordinate and the deepest\n        base y-coordinate.\n    \"\"\"\n    # Compute the difference between the maximum and minimum y-coordinates\n    base_length = np.nanmax(lateral_base_ys) - np.nanmin(lateral_base_ys)\n    return base_length\n</code></pre>"},{"location":"api/traits/bases/#get_base_ct_density","title":"get_base_ct_density","text":"<p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"dicot\", primary_path=\"primary.slp\", lateral_path=\"lateral.slp\")\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\nbases = sr.get_bases(primary_pts, lateral_pts_list)\ndensity = sr.get_base_ct_density(bases, primary_pts)\n\nprint(f\"Lateral root density: {density:.3f} roots/pixel\")\n</code></pre></p>"},{"location":"api/traits/bases/#sleap_roots.bases.get_base_ct_density","title":"get_base_ct_density","text":"<pre><code>get_base_ct_density(\n    primary_length_max: float, lateral_base_pts: ndarray\n) -&gt; float\n</code></pre> <p>Get a ratio of the number of base points to maximum primary root length.</p> <p>Parameters:</p> Name Type Description Default <code>primary_length_max</code> <code>float</code> <p>Scalar of maximum primary root length.</p> required <code>lateral_base_pts</code> <code>ndarray</code> <p>Base points of lateral roots as returned by <code>get_bases</code>, shape <code>(instances, 2)</code> or <code>(2,)</code>.</p> required Return <p>Scalar of base count density.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_ct_density(\n    primary_length_max: float, lateral_base_pts: np.ndarray\n) -&gt; float:\n    \"\"\"Get a ratio of the number of base points to maximum primary root length.\n\n    Args:\n        primary_length_max: Scalar of maximum primary root length.\n        lateral_base_pts: Base points of lateral roots as returned by `get_bases`,\n            shape `(instances, 2)` or `(2,)`.\n\n    Return:\n        Scalar of base count density.\n    \"\"\"\n    # Check if the input is valid for lateral_base_pts\n    if (\n        isinstance(lateral_base_pts, (np.floating, float, np.integer, int))\n        or np.isnan(lateral_base_pts).all()\n    ):\n        return np.nan\n\n    # Handle the case where lateral_base_pts has shape `(2,)`\n    if lateral_base_pts.ndim == 1 and lateral_base_pts.shape[0] == 2:\n        base_ct = 1  # Only one base point in this case\n\n    # Handle the case where lateral_base_pts has shape `(instances, 2)`\n    else:\n        base_ct = len(lateral_base_pts[~np.isnan(lateral_base_pts[:, 0])])\n\n    # Handle cases where maximum primary length is zero or NaN to avoid division by zero\n    if primary_length_max == 0 or np.isnan(primary_length_max):\n        return np.nan\n\n    # Calculate base_ct_density\n    base_ct_density = base_ct / primary_length_max\n\n    return base_ct_density\n</code></pre>"},{"location":"api/traits/bases/#get_root_widths","title":"get_root_widths","text":""},{"location":"api/traits/bases/#sleap_roots.bases.get_root_widths","title":"get_root_widths","text":"<pre><code>get_root_widths(\n    primary_max_length_pts: ndarray,\n    lateral_pts: ndarray,\n    tolerance: float = 0.02,\n    return_inds: bool = False,\n) -&gt; Tuple[ndarray, list, ndarray, ndarray]\n</code></pre> <p>Estimate root width using bases of lateral roots.</p> <p>Parameters:</p> Name Type Description Default <code>primary_max_length_pts</code> <code>ndarray</code> <p>Longest primary root, represented as a 2D array of shape (nodes, 2).</p> required <code>lateral_pts</code> <code>ndarray</code> <p>Lateral roots, represented as a 3D array of shape (n, nodes, 2).</p> required <code>tolerance</code> <code>float</code> <p>Tolerance level for the projection difference between matched roots. Defaults to 0.02.</p> <code>0.02</code> <code>return_inds</code> <code>bool</code> <p>Flag to indicate whether to return matched indices along with distances. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <ul> <li>If <code>return_inds</code> is False (default): Returns an array of distances between the bases of matched roots. If no matched indices are found, NaN is returned.</li> </ul> <code>list</code> <ul> <li>If <code>return_inds</code> is True: Returns a tuple containing the following four elements:<ul> <li>matched_dists: Distances between the bases of matched roots. If no     matched indices are found, NaN is returned.</li> <li>matched_indices: List of tuples, each containing the indices     of matched roots on the left and right sides. A list containing a     tuple of NaNs is returned if no matched indices are found.</li> <li>left_bases_final: (n, 2) array containing the (x, y)     coordinates of the left bases of the matched roots. An array of     NaNs is returned if no matched indices are found.</li> <li>right_bases_final: (n, 2) array containing the (x, y)     coordinates of the right bases of the matched roots. An array of     NaNs is returned if no matched indices are found.</li> </ul> </li> </ul> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_root_widths(\n    primary_max_length_pts: np.ndarray,\n    lateral_pts: np.ndarray,\n    tolerance: float = 0.02,\n    return_inds: bool = False,\n) -&gt; Tuple[np.ndarray, list, np.ndarray, np.ndarray]:\n    \"\"\"Estimate root width using bases of lateral roots.\n\n    Args:\n        primary_max_length_pts: Longest primary root, represented\n            as a 2D array of shape (nodes, 2).\n        lateral_pts: Lateral roots, represented as a 3D array of\n            shape (n, nodes, 2).\n        tolerance: Tolerance level for the projection difference between matched roots.\n            Defaults to 0.02.\n        return_inds: Flag to indicate whether to return matched indices along with\n            distances. Defaults to False.\n\n    Returns:\n        - If `return_inds` is False (default):\n            Returns an array of distances between the bases of matched roots. If no\n            matched indices are found, NaN is returned.\n\n        - If `return_inds` is True:\n            Returns a tuple containing the following four elements:\n                - matched_dists: Distances between the bases of matched roots. If no\n                    matched indices are found, NaN is returned.\n                - matched_indices: List of tuples, each containing the indices\n                    of matched roots on the left and right sides. A list containing a\n                    tuple of NaNs is returned if no matched indices are found.\n                - left_bases_final: (n, 2) array containing the (x, y)\n                    coordinates of the left bases of the matched roots. An array of\n                    NaNs is returned if no matched indices are found.\n                - right_bases_final: (n, 2) array containing the (x, y)\n                    coordinates of the right bases of the matched roots. An array of\n                    NaNs is returned if no matched indices are found.\n    \"\"\"\n    # Validate tolerance\n    if tolerance &lt;= 0:\n        raise ValueError(\"Tolerance should be a positive number\")\n\n    # Check array dimensions\n    if primary_max_length_pts.ndim != 2 or lateral_pts.ndim != 3:\n        raise ValueError(\"Input arrays should be 2-dimensional and 3-dimensional\")\n\n    # Check the shape of the last dimensions\n    if primary_max_length_pts.shape[1] != 2 or lateral_pts.shape[2] != 2:\n        raise ValueError(\"The last dimension should contain x and y coordinates\")\n\n    # Initialize default return values\n    default_dists = np.nan\n    default_indices = [(np.nan, np.nan)]  # List of tuples with NaN values\n    default_left_bases = np.full((1, 2), np.nan)  # 2D array filled with NaN values\n    default_right_bases = np.full((1, 2), np.nan)  # 2D array filled with NaN values\n\n    # Check for minimum length, or all NaNs in arrays\n    if (\n        len(primary_max_length_pts) &lt; 2\n        or len(lateral_pts) &lt; 2\n        or np.isnan(primary_max_length_pts).all()\n        or np.isnan(lateral_pts).all()\n    ):\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Filter out any NaN points from the primary root points\n    primary_pts_filtered = primary_max_length_pts[\n        ~np.isnan(primary_max_length_pts).any(axis=-1)\n    ]\n    # Create a LineString object for the primary root\n    primary_line = LineString(primary_pts_filtered)\n\n    # Identify lateral roots that have a defined base (not NaN)\n    has_base = ~np.isnan(lateral_pts[:, 0, 0])\n    # Filter the lateral roots based on the valid base points\n    lateral_pts = lateral_pts[has_base]\n\n    # Determine if the base of each lateral root is to the left or right of the rest of\n    # the root\n    is_left = lateral_pts[:, 0, 0] &gt; np.nanmin(lateral_pts[:, 1:, 0], axis=1)\n\n    # If all lateral roots are on the same side, return default values\n    if is_left.all() or (~is_left).all():\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Split lateral roots into left and right bases\n    left_bases, right_bases = lateral_pts[is_left, 0], lateral_pts[~is_left, 0]\n\n    # Find the nearest points on the primary root for each right base\n    nearest_primary_right = [\n        nearest_points(primary_line, Point(right_base))[0] for right_base in right_bases\n    ]\n\n    # Find the nearest points on the primary root for each left base\n    nearest_primary_left = [\n        nearest_points(primary_line, Point(left_base))[0] for left_base in left_bases\n    ]\n\n    # Calculate the normalized projection of each nearest point on the primary root\n    # (right side)\n    nearest_primary_norm_right = np.array(\n        [primary_line.project(pt, normalized=True) for pt in nearest_primary_right]\n    )\n\n    # Calculate the normalized projection of each nearest point on the primary root\n    # (left side)\n    nearest_primary_norm_left = np.array(\n        [primary_line.project(pt, normalized=True) for pt in nearest_primary_left]\n    )\n\n    # Create a cost matrix based on the differences in projections between left and\n    # right bases\n    cost_matrix = np.abs(\n        nearest_primary_norm_left.reshape(-1, 1)\n        - nearest_primary_norm_right.reshape(1, -1)\n    )\n\n    # Use the Hungarian algorithm to find an optimal pairing that minimizes the sum of\n    # projection differences\n    left_inds, right_inds = linear_sum_assignment(cost_matrix)\n\n    # Filter out pairs where the projection difference exceeds the given tolerance\n    valid_pairs = cost_matrix[left_inds, right_inds] &lt;= tolerance\n    left_inds = left_inds[valid_pairs]\n    right_inds = right_inds[valid_pairs]\n\n    # If no valid pairs remain, return default values\n    if len(left_inds) == 0 or len(right_inds) == 0:\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Filter out pairs that do not intersect the primary root\n    is_intersecting = np.array(\n        [\n            primary_line.intersects(\n                LineString([left_bases[left_ind], right_bases[right_ind]])\n            )\n            for left_ind, right_ind in zip(left_inds, right_inds)\n        ]\n    )\n    left_inds = left_inds[is_intersecting]\n    right_inds = right_inds[is_intersecting]\n\n    # If no valid pairs remain, return default values\n    if len(left_inds) == 0 or len(right_inds) == 0:\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Update the left and right bases of the final paired coordinates\n    left_bases_final = left_bases[left_inds]\n    right_bases_final = right_bases[right_inds]\n\n    # Calculate the Euclidean distance between the bases of the valid pairs\n    match_dists = np.linalg.norm(\n        left_bases[left_inds] - right_bases[right_inds],\n        axis=-1,\n    )\n\n    # Create a list of tuples representing the indices of the matched pairs\n    matched_indices = list(zip(left_inds, right_inds))\n\n    if return_inds:\n        # Return the distances, matched indices, and the final left and right bases\n        return match_dists, matched_indices, left_bases_final, right_bases_final\n    else:\n        # Default: Return the distances\n        return match_dists\n</code></pre>"},{"location":"api/traits/bases/#related-modules","title":"Related Modules","text":"<ul> <li>Tips - Tip point detection</li> <li>Lengths - Base-to-tip distances</li> <li>DicotPipeline - Uses base functions</li> </ul>"},{"location":"api/traits/convhull/","title":"Convex Hull","text":""},{"location":"api/traits/convhull/#overview","title":"Overview","text":"<p>Compute convex hull features for spatial root system analysis. Useful for measuring root system spread and spatial distribution.</p> <p>Key functions: - <code>get_convhull</code> - Compute convex hull polygon - <code>get_chull_area</code> - Hull area - <code>get_chull_perimeter</code> - Hull perimeter</p>"},{"location":"api/traits/convhull/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\", lateral_path=\"lateral.slp\")\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\n# Get all points\nfrom sleap_roots import join_pts\nall_pts = join_pts([primary_pts] + lateral_pts_list)\n\n# Compute convex hull\nhull = sr.convhull.get_convhull(all_pts)\n\n# Compute hull traits\narea = sr.convhull.get_chull_area(all_pts)\nperimeter = sr.convhull.get_chull_perimeter(all_pts)\n\nprint(f\"Hull area: {area:.2f} px\u00b2\")\nprint(f\"Hull perimeter: {perimeter:.2f} px\")\n</code></pre>"},{"location":"api/traits/convhull/#api-reference","title":"API Reference","text":""},{"location":"api/traits/convhull/#get_convhull","title":"get_convhull","text":""},{"location":"api/traits/convhull/#sleap_roots.convhull.get_convhull","title":"get_convhull","text":"<pre><code>get_convhull(pts: ndarray) -&gt; Optional[ConvexHull]\n</code></pre> <p>Compute the convex hull for the points per frame.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as an array of shape (..., 2).</p> required <p>Returns:</p> Type Description <code>Optional[ConvexHull]</code> <p>An object representing the convex hull or None if a hull can't be formed.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_convhull(pts: np.ndarray) -&gt; Optional[ConvexHull]:\n    \"\"\"Compute the convex hull for the points per frame.\n\n    Args:\n        pts: Root landmarks as an array of shape (..., 2).\n\n    Returns:\n        An object representing the convex hull or None if a hull can't be formed.\n    \"\"\"\n    # Ensure the input is an array of shape (..., 2)\n    if pts.ndim &lt; 2 or pts.shape[-1] != 2:\n        raise ValueError(\"Input points should be of shape (..., 2).\")\n\n    # Reshape and filter out NaN values\n    pts = pts.reshape(-1, 2)\n    pts = pts[~np.isnan(pts).any(axis=-1)]\n\n    # Check for infinite values\n    if np.isinf(pts).any():\n        logging.info(\"Cannot compute convex hull: input contains infinite values.\")\n        return None\n\n    # Ensure there are at least 3 unique non-collinear points\n    unique_pts = np.unique(pts, axis=0)\n    if len(unique_pts) &lt; 3:\n        logging.info(\"Cannot compute convex hull: not enough unique points.\")\n        return None\n\n    try:\n        # Compute and return the convex hull\n        return ConvexHull(unique_pts)\n    except Exception as e:\n        logging.info(f\"Cannot compute convex hull: {e}\")\n        return None\n</code></pre>"},{"location":"api/traits/convhull/#get_chull_area","title":"get_chull_area","text":""},{"location":"api/traits/convhull/#sleap_roots.convhull.get_chull_area","title":"get_chull_area","text":"<pre><code>get_chull_area(hull: Union[ndarray, ConvexHull]) -&gt; float\n</code></pre> <p>Calculate the area of the convex hull formed by the given points.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull]</code> <p>Either an array of landmark points or a pre-computed convex hull.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Scalar value representing the area of the convex hull. Returns NaN if unable</p> <code>float</code> <p>to compute the convex hull.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_area(hull: Union[np.ndarray, ConvexHull]) -&gt; float:\n    \"\"\"Calculate the area of the convex hull formed by the given points.\n\n    Args:\n        hull: Either an array of landmark points or a pre-computed convex hull.\n\n    Returns:\n        Scalar value representing the area of the convex hull. Returns NaN if unable\n        to compute the convex hull.\n    \"\"\"\n    # If the input hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # If the input is an array, compute its convex hull\n    if isinstance(hull, np.ndarray):\n        hull = get_convhull(hull)\n\n    # If hull becomes None after attempting to compute the convex hull, return NaN\n    if hull is None:\n        return np.nan\n\n    # Ensure that the hull is of type ConvexHull\n    if not isinstance(hull, ConvexHull):\n        raise TypeError(\"After processing, the input must be a ConvexHull object.\")\n\n    # If hull couldn't be formed, return NaN\n    if hull is None:\n        return np.nan\n\n    # Return the area of the convex hull\n    return hull.volume\n</code></pre>"},{"location":"api/traits/convhull/#get_chull_perimeter","title":"get_chull_perimeter","text":""},{"location":"api/traits/convhull/#sleap_roots.convhull.get_chull_perimeter","title":"get_chull_perimeter","text":"<pre><code>get_chull_perimeter(\n    hull: Union[ndarray, ConvexHull, None],\n) -&gt; float\n</code></pre> <p>Calculate the perimeter of the convex hull formed by the given points.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull, None]</code> <p>Either an array of landmark points, a pre-computed convex hull, or None.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Scalar value representing the perimeter of the convex hull. Returns NaN if</p> <code>float</code> <p>unable to compute the convex hull or if the input is None.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_perimeter(hull: Union[np.ndarray, ConvexHull, None]) -&gt; float:\n    \"\"\"Calculate the perimeter of the convex hull formed by the given points.\n\n    Args:\n        hull: Either an array of landmark points, a pre-computed convex hull, or None.\n\n    Returns:\n        Scalar value representing the perimeter of the convex hull. Returns NaN if\n        unable to compute the convex hull or if the input is None.\n    \"\"\"\n    # If the input hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # If the input is an array, compute its convex hull\n    if isinstance(hull, np.ndarray):\n        hull = get_convhull(hull)\n\n    # If hull becomes None after attempting to compute the convex hull, return NaN\n    if hull is None:\n        return np.nan\n\n    # Ensure that the hull is of type ConvexHull\n    if not isinstance(hull, ConvexHull):\n        raise TypeError(\"After processing, the input must be a ConvexHull object.\")\n\n    # Compute the perimeter of the convex hull\n    return hull.area\n</code></pre>"},{"location":"api/traits/convhull/#related-modules","title":"Related Modules","text":"<ul> <li>Network Length - Network-level spatial metrics</li> <li>Ellipse - Alternative spatial representation</li> </ul>"},{"location":"api/traits/ellipse/","title":"Ellipse","text":""},{"location":"api/traits/ellipse/#overview","title":"Overview","text":"<p>Fit ellipses to root point distributions for compact spatial representation.</p> <p>Key functions: - <code>fit_ellipse</code> - Fit ellipse to root points - <code>get_ellipse_a</code> - Get ellipse major axis - <code>get_ellipse_b</code> - Get ellipse minor axis - <code>get_ellipse_ratio</code> - Get ellipse aspect ratio</p>"},{"location":"api/traits/ellipse/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\nimport numpy as np\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\npts = series.get_primary_points()\n\n# Flatten to 2D points\npts_2d = pts[0, 0]  # (nodes, 2)\n\n# Fit ellipse\nellipse = sr.ellipse.fit_ellipse(pts_2d)\na = sr.ellipse.get_ellipse_a(ellipse)\nb = sr.ellipse.get_ellipse_b(ellipse)\nratio = sr.ellipse.get_ellipse_ratio(ellipse)\n\nprint(f\"Major axis (a): {a:.2f} px\")\nprint(f\"Minor axis (b): {b:.2f} px\")\nprint(f\"Aspect ratio: {ratio:.2f}\")\n</code></pre>"},{"location":"api/traits/ellipse/#api-reference","title":"API Reference","text":""},{"location":"api/traits/ellipse/#fit_ellipse","title":"fit_ellipse","text":""},{"location":"api/traits/ellipse/#sleap_roots.ellipse.fit_ellipse","title":"fit_ellipse","text":"<pre><code>fit_ellipse(pts: ndarray) -&gt; Tuple[float, float, float]\n</code></pre> <p>Find a best fit ellipse for the points per frame.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape (..., 2).</p> required <p>Returns:</p> Type Description <code>float</code> <p>A tuple of (a, b, ratio) containing the semi-major axis length,</p> <code>float</code> <p>semi-minor axis length, and the ratio of the major to minor lengths.</p> <code>float</code> <p>If the ellipse fitting fails, NaNs are returned.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def fit_ellipse(pts: np.ndarray) -&gt; Tuple[float, float, float]:\n    \"\"\"Find a best fit ellipse for the points per frame.\n\n    Args:\n        pts: Root landmarks as array of shape (..., 2).\n\n    Returns:\n        A tuple of (a, b, ratio) containing the semi-major axis length,\n        semi-minor axis length, and the ratio of the major to minor lengths.\n\n        If the ellipse fitting fails, NaNs are returned.\n    \"\"\"\n    # Reshape the input array and filter out rows containing NaNs\n    pts = pts.reshape(-1, 2)\n    pts = pts[~(np.isnan(pts).all(axis=-1))]\n\n    # Check for a minimum number of points to fit an ellipse\n    if len(pts) &lt; 5:\n        return np.nan, np.nan, np.nan\n\n    # Initialize the ellipse model\n    ell = EllipseModel()\n\n    # Try to estimate the ellipse parameters\n    try:\n        success = ell.estimate(pts)\n    except TypeError as e:\n        # If the estimation fails, return NaNs\n        return np.nan, np.nan, np.nan\n\n    # Check if the estimation was successful\n    if success:\n        # Extract the ellipse parameters.\n        xc, yc, a_f, b_f, theta = ell.params\n\n        # Check for complex numbers in the parameters.\n        if np.iscomplex([xc, yc, a_f, b_f, theta]).any():\n            return np.nan, np.nan, np.nan\n\n        # Check for invalid (zero or NaN) major or minor axes.\n        if np.isnan(a_f) or np.isnan(b_f) or a_f == 0 or b_f == 0:\n            return np.nan, np.nan, np.nan\n\n        # Ensure a_f is the semi-major axis and b_f is the semi-minor axis.\n        a_f, b_f = np.maximum(a_f, b_f), np.minimum(a_f, b_f)\n\n        # Calculate the ratio of the major to minor axis.\n        ratio_ba_f = a_f / b_f\n\n        return a_f, b_f, ratio_ba_f\n\n    else:\n        # Return NaNs if the ellipse fitting was not successful.\n        return np.nan, np.nan, np.nan\n</code></pre>"},{"location":"api/traits/ellipse/#get_ellipse_a","title":"get_ellipse_a","text":""},{"location":"api/traits/ellipse/#sleap_roots.ellipse.get_ellipse_a","title":"get_ellipse_a","text":"<pre><code>get_ellipse_a(\n    pts_all_array: Union[\n        ndarray, Tuple[float, float, float]\n    ],\n)\n</code></pre> <p>Get semi-major axis length of the fitted ellipse.</p> <p>Parameters:</p> Name Type Description Default <code>pts_all_array</code> <code>Union[ndarray, Tuple[float, float, float]]</code> <p>landmark points or tuple of ellipse restults.</p> required Return <p>Scalar of semi-major axis length.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def get_ellipse_a(pts_all_array: Union[np.ndarray, Tuple[float, float, float]]):\n    \"\"\"Get semi-major axis length of the fitted ellipse.\n\n    Args:\n        pts_all_array: landmark points or tuple of ellipse restults.\n\n    Return:\n        Scalar of semi-major axis length.\n    \"\"\"\n    if type(pts_all_array) == tuple:\n        ellipse_a = pts_all_array[0]\n    else:\n        ellipse_features = fit_ellipse(pts_all_array)\n        ellipse_a = ellipse_features[0]\n    return ellipse_a\n</code></pre>"},{"location":"api/traits/ellipse/#get_ellipse_b","title":"get_ellipse_b","text":""},{"location":"api/traits/ellipse/#sleap_roots.ellipse.get_ellipse_b","title":"get_ellipse_b","text":"<pre><code>get_ellipse_b(\n    pts_all_array: Union[\n        ndarray, Tuple[float, float, float]\n    ],\n)\n</code></pre> <p>Get semi-minor axis length of the fitted ellipse.</p> <p>Parameters:</p> Name Type Description Default <code>pts_all_array</code> <code>Union[ndarray, Tuple[float, float, float]]</code> <p>landmark points or tuple of ellipse restults.</p> required Return <p>Scalar of semi-minor axis length.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def get_ellipse_b(pts_all_array: Union[np.ndarray, Tuple[float, float, float]]):\n    \"\"\"Get semi-minor axis length of the fitted ellipse.\n\n    Args:\n        pts_all_array: landmark points or tuple of ellipse restults.\n\n    Return:\n        Scalar of semi-minor axis length.\n    \"\"\"\n    if type(pts_all_array) == tuple:\n        ellipse_b = pts_all_array[1]\n    else:\n        ellipse_features = fit_ellipse(pts_all_array)\n        ellipse_b = ellipse_features[1]\n    return ellipse_b\n</code></pre>"},{"location":"api/traits/ellipse/#get_ellipse_ratio","title":"get_ellipse_ratio","text":""},{"location":"api/traits/ellipse/#sleap_roots.ellipse.get_ellipse_ratio","title":"get_ellipse_ratio","text":"<pre><code>get_ellipse_ratio(\n    pts_all_array: Union[\n        ndarray, Tuple[float, float, float]\n    ],\n)\n</code></pre> <p>Get ratio of the minor to major lengths of the fitted ellipse.</p> <p>Parameters:</p> Name Type Description Default <code>pts_all_array</code> <code>Union[ndarray, Tuple[float, float, float]]</code> <p>landmark points or tuple of ellipse restults.</p> required Return <p>Scalar of ratio of the minor to major lengths.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def get_ellipse_ratio(pts_all_array: Union[np.ndarray, Tuple[float, float, float]]):\n    \"\"\"Get ratio of the minor to major lengths of the fitted ellipse.\n\n    Args:\n        pts_all_array: landmark points or tuple of ellipse restults.\n\n    Return:\n        Scalar of ratio of the minor to major lengths.\n    \"\"\"\n    if type(pts_all_array) == tuple:\n        ellipse_ratio = pts_all_array[2]\n    else:\n        ellipse_features = fit_ellipse(pts_all_array)\n        ellipse_ratio = ellipse_features[2]\n    return ellipse_ratio\n</code></pre>"},{"location":"api/traits/ellipse/#related-modules","title":"Related Modules","text":"<ul> <li>Convex Hull - Alternative spatial analysis</li> </ul>"},{"location":"api/traits/lengths/","title":"Lengths","text":""},{"location":"api/traits/lengths/#overview","title":"Overview","text":"<p>The <code>lengths</code> module provides functions for computing root length measurements from point coordinates. These are fundamental traits used across all pipelines.</p> <p>Key functions: - <code>get_root_lengths</code> - Calculate total root lengths - <code>get_curve_index</code> - Measure root curvature - <code>get_max_length_pts</code> - Find longest root path</p> <p>When to use: - Computing primary or lateral root lengths - Measuring root curvature and tortuosity - Comparing root lengths across treatments</p>"},{"location":"api/traits/lengths/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\nimport numpy as np\n\n# Get root points\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\npts = series.get_primary_points()  # (plants, frames, nodes, 2)\n\n# Compute lengths\nlengths = sr.get_root_lengths(pts)\nprint(f\"Primary root length: {lengths[0, 0]:.2f} pixels\")\n\n# Compute curvature\ncurve_idx = sr.get_curve_index(pts)\nprint(f\"Curvature index: {curve_idx[0, 0]:.3f}\")\n</code></pre>"},{"location":"api/traits/lengths/#api-reference","title":"API Reference","text":""},{"location":"api/traits/lengths/#get_root_lengths","title":"get_root_lengths","text":"<p>Example: <pre><code>import sleap_roots as sr\nimport numpy as np\n\n# Load and extract points\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\nprimary_pts = series.get_primary_points()\n\n# Calculate lengths\nlengths = sr.get_root_lengths(primary_pts)\n\n# Results shape: (plants, frames)\nprint(f\"Shape: {lengths.shape}\")\nprint(f\"Frame 0 length: {lengths[0, 0]:.2f} px\")\n\n# Handle NaN (missing data)\nvalid_lengths = lengths[~np.isnan(lengths)]\nprint(f\"Mean length: {np.mean(valid_lengths):.2f} px\")\n</code></pre></p> <p>See Also: - get_curve_index - Root curvature - DicotPipeline - Uses this function</p>"},{"location":"api/traits/lengths/#sleap_roots.lengths.get_root_lengths","title":"get_root_lengths","text":"<pre><code>get_root_lengths(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Return root lengths for all roots in a frame.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of root lengths of shape <code>(instances,)</code>. If there is no root, or the root</p> <code>ndarray</code> <p>is one point only (all of the rest of the points are NaNs), an array of NaNs</p> <code>ndarray</code> <p>with shape (len(pts),) is returned. This is also the case for non-contiguous</p> <code>ndarray</code> <p>points.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_root_lengths(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return root lengths for all roots in a frame.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        Array of root lengths of shape `(instances,)`. If there is no root, or the root\n        is one point only (all of the rest of the points are NaNs), an array of NaNs\n        with shape (len(pts),) is returned. This is also the case for non-contiguous\n        points.\n    \"\"\"\n    # If the input has shape `(nodes, 2)`, reshape it for consistency\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    # Get the (x,y) differences of segments for each instance\n    segment_diffs = np.diff(pts, axis=1)\n    # Get the lengths of each segment by taking the norm\n    segment_lengths = np.linalg.norm(segment_diffs, axis=-1)\n    # Add the segments together to get the total length using nansum\n    total_lengths = np.nansum(segment_lengths, axis=-1)\n    # Find the NaN segment lengths and record NaN in place of 0 when finding the total\n    # length\n    total_lengths[np.isnan(segment_lengths).all(axis=-1)] = np.nan\n\n    # If there is 1 instance, return a scalar instead of an array of length 1\n    if len(total_lengths) == 1:\n        return total_lengths[0]\n\n    return total_lengths\n</code></pre>"},{"location":"api/traits/lengths/#get_curve_index","title":"get_curve_index","text":"<p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\npts = series.get_primary_points()\n\n# Compute curvature index\ncurve_idx = sr.get_curve_index(pts)\n\n# Lower values = straighter root\n# Higher values = more curved/tortuous root\nprint(f\"Curvature index: {curve_idx[0, 0]:.3f}\")\n</code></pre></p>"},{"location":"api/traits/lengths/#sleap_roots.lengths.get_curve_index","title":"get_curve_index","text":"<pre><code>get_curve_index(\n    lengths: Union[float, ndarray],\n    base_tip_dists: Union[float, ndarray],\n) -&gt; Union[float, ndarray]\n</code></pre> <p>Calculate the curvature index of a root.</p> <p>The curvature index quantifies the curviness of the root's growth. A higher curvature index indicates a curvier root (less responsive to gravity), while a lower index indicates a straighter root (more responsive to gravity). The index is computed as the difference between the maximum root length and straight-line distance from the base to the tip of the root, normalized by the root length.</p> <p>Parameters:</p> Name Type Description Default <code>lengths</code> <code>Union[float, ndarray]</code> <p>Maximum length of the root(s). Can be a scalar or a 1D numpy array of shape <code>(instances,)</code>.</p> required <code>base_tip_dists</code> <code>Union[float, ndarray]</code> <p>The straight-line distance from the base to the tip of the root(s). Can be a scalar or a 1D numpy array of shape <code>(instances,)</code>.</p> required <p>Returns:</p> Type Description <code>Union[float, ndarray]</code> <p>Curvature index of the root(s), quantifying its/their curviness. Will be a   scalar if input is scalar, or a 1D numpy array of shape <code>(instances,)</code>   otherwise.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_curve_index(\n    lengths: Union[float, np.ndarray], base_tip_dists: Union[float, np.ndarray]\n) -&gt; Union[float, np.ndarray]:\n    \"\"\"Calculate the curvature index of a root.\n\n    The curvature index quantifies the curviness of the root's growth. A higher\n    curvature index indicates a curvier root (less responsive to gravity), while a\n    lower index indicates a straighter root (more responsive to gravity). The index is\n    computed as the difference between the maximum root length and straight-line\n    distance from the base to the tip of the root, normalized by the root length.\n\n    Args:\n        lengths: Maximum length of the root(s). Can be a scalar or a 1D numpy array\n            of shape `(instances,)`.\n        base_tip_dists: The straight-line distance from the base to the tip of the\n            root(s). Can be a scalar or a 1D numpy array of shape `(instances,)`.\n\n    Returns:\n       Curvature index of the root(s), quantifying its/their curviness. Will be a\n            scalar if input is scalar, or a 1D numpy array of shape `(instances,)`\n            otherwise.\n    \"\"\"\n    # Check if the input is scalar or array\n    is_scalar_input = np.isscalar(lengths) and np.isscalar(base_tip_dists)\n\n    # Convert scalars to numpy arrays for uniform handling\n    lengths = np.atleast_1d(np.asarray(lengths, dtype=float))\n    base_tip_dists = np.atleast_1d(np.asarray(base_tip_dists, dtype=float))\n\n    # Check for shape mismatch\n    if lengths.shape != base_tip_dists.shape:\n        raise ValueError(\"The shapes of lengths and base_tip_dists must match.\")\n\n    # Calculate the curvature index where possible\n    curve_index = np.where(\n        (~np.isnan(lengths))\n        &amp; (~np.isnan(base_tip_dists))\n        &amp; (lengths &gt; 0)\n        &amp; (lengths &gt;= base_tip_dists),\n        (lengths - base_tip_dists) / np.where(lengths != 0, lengths, np.nan),\n        np.nan,\n    )\n\n    # Return scalar or array based on the input type\n    if is_scalar_input:\n        return curve_index.item()\n    else:\n        return curve_index\n</code></pre>"},{"location":"api/traits/lengths/#get_max_length_pts","title":"get_max_length_pts","text":"<p>Example: <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", lateral_path=\"lateral.slp\")\nlateral_pts_list = series.get_lateral_points()\n\n# Find longest lateral root\nmax_pts = sr.get_max_length_pts(lateral_pts_list)\nmax_length = sr.get_root_lengths(max_pts[np.newaxis, ...])[0, 0]\nprint(f\"Longest lateral: {max_length:.2f} px\")\n</code></pre></p>"},{"location":"api/traits/lengths/#sleap_roots.lengths.get_max_length_pts","title":"get_max_length_pts","text":"<pre><code>get_max_length_pts(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Points of the root with maximum length (intended for primary root traits).</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of points with shape <code>(nodes, 2)</code> from the root with maximum</p> <code>ndarray</code> <p>length, or the input array unchanged if its shape is <code>(nodes, 2)</code>.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_max_length_pts(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Points of the root with maximum length (intended for primary root traits).\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        np.ndarray: Array of points with shape `(nodes, 2)` from the root with maximum\n        length, or the input array unchanged if its shape is `(nodes, 2)`.\n    \"\"\"\n    # Return the input array unchanged if its shape is (nodes, 2)\n    if pts.ndim == 2 and pts.shape[1] == 2:\n        return pts\n\n    # Return NaN points if the input array is empty\n    if len(pts) == 0:\n        return np.array([[np.nan, np.nan]])\n\n    # Check if pts has the correct shape for processing multiple instances\n    if pts.ndim != 3 or pts.shape[2] != 2:\n        raise ValueError(\n            \"Input array should have shape (instances, nodes, 2) for multiple instances\"\n        )\n\n    # Calculate the differences between consecutive points in each root\n    segment_diffs = np.diff(pts, axis=1)\n\n    # Calculate the length of each segment\n    segment_lengths = np.linalg.norm(segment_diffs, axis=-1)\n\n    # Sum the lengths of the segments for each root\n    total_lengths = np.nansum(segment_lengths, axis=-1)\n\n    # Handle roots where all segment lengths are NaN,\n    # recording NaN in place of the total length for these roots\n    total_lengths[np.isnan(segment_lengths).all(axis=-1)] = np.nan\n\n    # Return NaN points if all total lengths are NaN\n    if np.isnan(total_lengths).all():\n        return np.array([[np.nan, np.nan]])\n\n    # Find the index of the root with the maximum total length\n    max_length_idx = np.nanargmax(total_lengths)\n\n    # Return the points of the root with this index\n    return pts[max_length_idx]\n</code></pre>"},{"location":"api/traits/lengths/#related-modules","title":"Related Modules","text":"<ul> <li>Angles - Root angle measurements</li> <li>Network Length - Whole-plant length metrics</li> <li>Pipelines - Use length functions</li> </ul>"},{"location":"api/traits/lengths/#see-also","title":"See Also","text":"<ul> <li>Pipeline Tutorials</li> <li>Batch Processing Guide</li> </ul>"},{"location":"api/traits/networklength/","title":"Network Length","text":""},{"location":"api/traits/networklength/#overview","title":"Overview","text":"<p>Compute whole-plant network-level metrics including bounding box, width-depth ratio, and distribution statistics.</p> <p>Key functions: - <code>get_network_length</code> - Total root system length - <code>get_network_width_depth_ratio</code> - W:D ratio - <code>get_network_distribution</code> - Spatial distribution metrics - <code>get_bbox</code> - Bounding box coordinates</p>"},{"location":"api/traits/networklength/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\", lateral_path=\"lateral.slp\")\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\n# Network metrics\nfrom sleap_roots import join_pts\nall_pts = join_pts([primary_pts] + lateral_pts_list)\n\nnetwork_len = sr.get_network_length(all_pts)\nwd_ratio = sr.get_network_width_depth_ratio(all_pts)\n\nprint(f\"Total network length: {network_len:.2f} px\")\nprint(f\"Width:Depth ratio: {wd_ratio:.2f}\")\n</code></pre>"},{"location":"api/traits/networklength/#api-reference","title":"API Reference","text":""},{"location":"api/traits/networklength/#get_network_length","title":"get_network_length","text":""},{"location":"api/traits/networklength/#sleap_roots.networklength.get_network_length","title":"get_network_length","text":"<pre><code>get_network_length(\n    lengths0: Union[float, ndarray],\n    *args: Optional[Union[float, ndarray]]\n) -&gt; float\n</code></pre> <p>Return the total root network length given primary and lateral root lengths.</p> <p>Parameters:</p> Name Type Description Default <code>lengths0</code> <code>Union[float, ndarray]</code> <p>Either a float representing the length of a single root or an array of root lengths with shape <code>(instances,)</code>.</p> required <code>*args</code> <code>Optional[Union[float, ndarray]]</code> <p>Additional optional floats representing the lengths of single roots or arrays of root lengths with shape <code>(instances,)</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>float</code> <p>Total length of root network.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_length(\n    lengths0: Union[float, np.ndarray],\n    *args: Optional[Union[float, np.ndarray]],\n) -&gt; float:\n    \"\"\"Return the total root network length given primary and lateral root lengths.\n\n    Args:\n        lengths0: Either a float representing the length of a single\n            root or an array of root lengths with shape `(instances,)`.\n        *args: Additional optional floats representing the lengths of single\n            roots or arrays of root lengths with shape `(instances,)`.\n\n    Returns:\n        Total length of root network.\n    \"\"\"\n    # Initialize an empty list to store the lengths\n    all_lengths = []\n    # Loop over the input arrays\n    for length in [lengths0] + list(args):\n        if length is None:\n            continue  # Skip None values\n        # Ensure length is either a scalar or has the correct shape\n        if not (np.isscalar(length) or (hasattr(length, \"ndim\") and length.ndim == 1)):\n            raise ValueError(\n                \"Input length must be a scalar or have shape (instances,).\"\n            )\n        # Add the length to the list\n        if np.isscalar(length):\n            all_lengths.append(length)\n        else:\n            all_lengths.extend(list(length))\n\n    # Calculate the total root network length using np.nansum so the total length\n    # will not be NaN if one of primary or lateral lengths are NaN\n    total_network_length = np.nansum(all_lengths)\n\n    return total_network_length\n</code></pre>"},{"location":"api/traits/networklength/#get_network_width_depth_ratio","title":"get_network_width_depth_ratio","text":""},{"location":"api/traits/networklength/#sleap_roots.networklength.get_network_width_depth_ratio","title":"get_network_width_depth_ratio","text":"<pre><code>get_network_width_depth_ratio(\n    pts: Union[ndarray, Tuple[float, float, float, float]],\n) -&gt; float\n</code></pre> <p>Return width to depth ratio of bounding box for root network.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>Union[ndarray, Tuple[float, float, float, float]]</code> <p>Root landmarks as array of shape (..., 2) or boundary box.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Float of bounding box width to depth ratio of root network.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_width_depth_ratio(\n    pts: Union[np.ndarray, Tuple[float, float, float, float]],\n) -&gt; float:\n    \"\"\"Return width to depth ratio of bounding box for root network.\n\n    Args:\n        pts: Root landmarks as array of shape (..., 2) or boundary box.\n\n    Returns:\n        Float of bounding box width to depth ratio of root network.\n    \"\"\"\n    # get the bounding box\n    if type(pts) == tuple:\n        bbox = pts\n    else:\n        bbox = get_bbox(pts)\n    width, height = bbox[2], bbox[3]\n    if width &gt; 0 and height &gt; 0:\n        ratio = width / height\n        return ratio\n    else:\n        return np.nan\n</code></pre>"},{"location":"api/traits/networklength/#get_network_distribution","title":"get_network_distribution","text":""},{"location":"api/traits/networklength/#sleap_roots.networklength.get_network_distribution","title":"get_network_distribution","text":"<pre><code>get_network_distribution(\n    pts_list: List[ndarray],\n    bounding_box: Tuple[float, float, float, float],\n    fraction: float = 2 / 3,\n) -&gt; float\n</code></pre> <p>Return the root length in the lower fraction of the plant.</p> <p>Parameters:</p> Name Type Description Default <code>pts_list</code> <code>List[ndarray]</code> <p>A list of arrays, each having shape <code>(nodes, 2)</code>.</p> required <code>bounding_box</code> <code>Tuple[float, float, float, float]</code> <p>Tuple in the form <code>(left_x, top_y, width, height)</code>.</p> required <code>fraction</code> <code>float</code> <p>Lower fraction value. Defaults to 2/3.</p> <code>2 / 3</code> <p>Returns:</p> Type Description <code>float</code> <p>Root network length in the lower fraction of the plant.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_distribution(\n    pts_list: List[np.ndarray],\n    bounding_box: Tuple[float, float, float, float],\n    fraction: float = 2 / 3,\n) -&gt; float:\n    \"\"\"Return the root length in the lower fraction of the plant.\n\n    Args:\n        pts_list: A list of arrays, each having shape `(nodes, 2)`.\n        bounding_box: Tuple in the form `(left_x, top_y, width, height)`.\n        fraction: Lower fraction value. Defaults to 2/3.\n\n    Returns:\n        Root network length in the lower fraction of the plant.\n    \"\"\"\n    # Input validation for pts_list\n    if any(pts.ndim != 2 or pts.shape[-1] != 2 for pts in pts_list):\n        raise ValueError(\n            \"Each pts array in pts_list should have a shape of `(nodes, 2)`.\"\n        )\n\n    # Input validation for bounding_box\n    if len(bounding_box) != 4:\n        raise ValueError(\n            \"bounding_box must contain exactly 4 elements: `(left_x, top_y, width, height)`.\"\n        )\n\n    # Filter out NaN values\n    pts_list = [pts[~np.isnan(pts).any(axis=-1)] for pts in pts_list]\n\n    # Get the vertices of the bounding box\n    left_x, top_y, width, height = bounding_box\n\n    # Calculate the bounding box of the lower fraction\n    lower_height = height * fraction\n    if np.isnan(lower_height):\n        return np.nan\n\n    # Convert lower bounding box to polygon\n    lower_box = Polygon(\n        [\n            [left_x, top_y + (height - lower_height)],\n            [left_x, top_y + height],\n            [left_x + width, top_y + height],\n            [left_x + width, top_y + (height - lower_height)],\n        ]\n    )\n\n    # Calculate length of roots within the lower bounding box\n    network_length = 0\n    for root in pts_list:\n        if len(root) &gt; 1:  # Ensure that root has more than one point\n            root_poly = LineString(root)\n            lower_intersection = root_poly.intersection(lower_box)\n            root_length = lower_intersection.length\n            network_length += root_length if ~np.isnan(root_length) else 0\n\n    return network_length\n</code></pre>"},{"location":"api/traits/networklength/#get_bbox","title":"get_bbox","text":""},{"location":"api/traits/networklength/#sleap_roots.networklength.get_bbox","title":"get_bbox","text":"<pre><code>get_bbox(pts: ndarray) -&gt; Tuple[float, float, float, float]\n</code></pre> <p>Return the bounding box of all landmarks.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape (..., 2).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Tuple of four parameters in bounding box:</p> <code>float</code> <p>left_x, the x axis value of left side</p> <code>float</code> <p>top_y, the y axis value of top side</p> <code>float</code> <p>width, the width of the bounding box</p> <code>Tuple[float, float, float, float]</code> <p>height, the height of bounding box.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_bbox(pts: np.ndarray) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Return the bounding box of all landmarks.\n\n    Args:\n        pts: Root landmarks as array of shape (..., 2).\n\n    Returns:\n        Tuple of four parameters in bounding box:\n        left_x, the x axis value of left side\n        top_y, the y axis value of top side\n        width, the width of the bounding box\n        height, the height of bounding box.\n    \"\"\"\n    # reshape to (# instance, 2) and filter out NaNs.\n    pts2 = pts.reshape(-1, 2)\n    pts2 = pts2[~(np.isnan(pts2).any(axis=-1))]\n\n    # get the bounding box\n    if pts2.shape[0] == 0:\n        return (np.nan, np.nan, np.nan, np.nan)\n    else:\n        left_x, top_y = np.min(pts2[:, 0]), np.min(pts2[:, 1])\n        width, height = np.max(pts2[:, 0]) - np.min(pts2[:, 0]), np.max(\n            pts2[:, 1]\n        ) - np.min(pts2[:, 1])\n        bbox = (left_x, top_y, width, height)\n    return bbox\n</code></pre>"},{"location":"api/traits/networklength/#related-modules","title":"Related Modules","text":"<ul> <li>Convex Hull - Spatial analysis</li> <li>Lengths - Individual root lengths</li> </ul>"},{"location":"api/traits/points/","title":"Points","text":""},{"location":"api/traits/points/#overview","title":"Overview","text":"<p>Utility functions for manipulating, filtering, and transforming root point arrays.</p> <p>Key functions: - <code>join_pts</code> - Combine multiple point arrays - <code>get_all_pts_array</code> - Flatten to 2D array - <code>associate_lateral_to_primary</code> - Map laterals to primary - <code>filter_roots_with_nans</code> - Remove invalid roots</p>"},{"location":"api/traits/points/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\", lateral_path=\"lateral.slp\")\nprimary_pts = series.get_primary_points()\nlateral_pts_list = series.get_lateral_points()\n\n# Combine all points\nall_pts = sr.join_pts([primary_pts] + lateral_pts_list)\nprint(f\"Combined points shape: {all_pts.shape}\")\n\n# Filter out roots with NaN\nvalid_laterals = sr.filter_roots_with_nans(lateral_pts_list)\nprint(f\"Valid laterals: {len(valid_laterals)}/{len(lateral_pts_list)}\")\n</code></pre>"},{"location":"api/traits/points/#api-reference","title":"API Reference","text":""},{"location":"api/traits/points/#join_pts","title":"join_pts","text":""},{"location":"api/traits/points/#sleap_roots.points.join_pts","title":"join_pts","text":"<pre><code>join_pts(\n    pts0: ndarray, *args: Optional[ndarray]\n) -&gt; List[ndarray]\n</code></pre> <p>Join an arbitrary number of points arrays and return them as a list.</p> <p>Parameters:</p> Name Type Description Default <code>pts0</code> <code>ndarray</code> <p>The first array of points. Should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <code>*args</code> <code>Optional[ndarray]</code> <p>Additional optional arrays of points. Each should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>A list of arrays, each having shape <code>(nodes, 2)</code>.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def join_pts(pts0: np.ndarray, *args: Optional[np.ndarray]) -&gt; List[np.ndarray]:\n    \"\"\"Join an arbitrary number of points arrays and return them as a list.\n\n    Args:\n        pts0: The first array of points. Should have shape `(instances, nodes, 2)`\n            or `(nodes, 2)`.\n        *args: Additional optional arrays of points. Each should have shape\n            `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        A list of arrays, each having shape `(nodes, 2)`.\n    \"\"\"\n    # Initialize an empty list to store the points\n    all_pts = []\n    # Loop over the input arrays\n    for pts in [pts0] + list(args):\n        if pts is None:\n            continue  # Skip None values\n\n        # If an array has shape `(nodes, 2)`, expand dimensions to `(1, nodes, 2)`\n        if pts.ndim == 2 and pts.shape[-1] == 2:\n            pts = pts[np.newaxis, :, :]\n\n        # Validate the shape of each array\n        if pts.ndim != 3 or pts.shape[-1] != 2:\n            raise ValueError(\n                \"Points should have a shape of `(instances, nodes, 2)` or `(nodes, 2)`.\"\n            )\n\n        # Add the points to the list\n        all_pts.extend(list(pts))\n\n    return all_pts\n</code></pre>"},{"location":"api/traits/points/#get_all_pts_array","title":"get_all_pts_array","text":""},{"location":"api/traits/points/#sleap_roots.points.get_all_pts_array","title":"get_all_pts_array","text":"<pre><code>get_all_pts_array(\n    pts0: ndarray, *args: Optional[ndarray]\n) -&gt; ndarray\n</code></pre> <p>Get all landmark points within a given frame as a flat array of coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>pts0</code> <code>ndarray</code> <p>The first array of points. Should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <code>*args</code> <code>Optional[ndarray]</code> <p>Additional optional arrays of points. Each should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array of shape (n_points, 2), containing the coordinates of all extracted</p> <code>ndarray</code> <p>points.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_all_pts_array(pts0: np.ndarray, *args: Optional[np.ndarray]) -&gt; np.ndarray:\n    \"\"\"Get all landmark points within a given frame as a flat array of coordinates.\n\n    Args:\n        pts0: The first array of points. Should have shape `(instances, nodes, 2)`\n            or `(nodes, 2)`.\n        *args: Additional optional arrays of points. Each should have shape\n            `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        A 2D array of shape (n_points, 2), containing the coordinates of all extracted\n        points.\n    \"\"\"\n    # Initialize an empty list to store the points\n    concatenated_pts = []\n\n    # Loop over the input arrays\n    for pts in [pts0] + list(args):\n        if pts is None:\n            continue\n\n        # Check if the array has the right number of dimensions\n        if pts.ndim not in [2, 3]:\n            raise ValueError(\"Each input array should be 2D or 3D.\")\n\n        # Check if the last dimension of the array has size 2\n        # (representing x and y coordinates)\n        if pts.shape[-1] != 2:\n            raise ValueError(\n                \"The last dimension should have size 2, representing x and y coordinates.\"\n            )\n\n        # Flatten the array to 2D and append to list\n        flat_pts = pts.reshape(-1, 2)\n        concatenated_pts.append(flat_pts)\n\n    # Concatenate all points into a single array\n    return np.concatenate(concatenated_pts, axis=0)\n</code></pre>"},{"location":"api/traits/points/#associate_lateral_to_primary","title":"associate_lateral_to_primary","text":""},{"location":"api/traits/points/#sleap_roots.points.associate_lateral_to_primary","title":"associate_lateral_to_primary","text":"<pre><code>associate_lateral_to_primary(\n    primary_pts: ndarray, lateral_pts: ndarray\n) -&gt; dict\n</code></pre> <p>Associates each lateral root with the closest primary root.</p> <p>Parameters:</p> Name Type Description Default <code>primary_pts</code> <code>ndarray</code> <p>A numpy array of primary root points with shape (instances, nodes, 2), where 'instances' is the number of primary roots, 'nodes' is the number of points in each root, and '2' corresponds to the x and y coordinates. Points cannot have NaN values.</p> required <code>lateral_pts</code> <code>ndarray</code> <p>A numpy array of lateral root points with a shape similar to primary_pts, representing the lateral roots. Points cannot have NaN values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary where each key is an index of a primary root (from the primary_pts</p> <code>dict</code> <p>array) and each value is a dictionary containing 'primary_points' as the points of</p> <code>dict</code> <p>the primary root (1, nodes, 2) and 'lateral_points' as an array of</p> <code>dict</code> <p>lateral root points that are closest to that primary root. The shape of</p> <code>dict</code> <p>'lateral_points' is (instances, nodes, 2), where instances is the number of</p> <code>dict</code> <p>lateral roots associated with the primary root.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def associate_lateral_to_primary(\n    primary_pts: np.ndarray, lateral_pts: np.ndarray\n) -&gt; dict:\n    \"\"\"Associates each lateral root with the closest primary root.\n\n    Args:\n        primary_pts: A numpy array of primary root points with shape\n            (instances, nodes, 2), where 'instances' is the number of primary roots,\n            'nodes' is the number of points in each root, and '2' corresponds to the x and y\n            coordinates. Points cannot have NaN values.\n        lateral_pts: A numpy array of lateral root points with a shape similar\n            to primary_pts, representing the lateral roots. Points cannot have NaN values.\n\n    Returns:\n        dict: A dictionary where each key is an index of a primary root (from the primary_pts\n        array) and each value is a dictionary containing 'primary_points' as the points of\n        the primary root (1, nodes, 2) and 'lateral_points' as an array of\n        lateral root points that are closest to that primary root. The shape of\n        'lateral_points' is (instances, nodes, 2), where instances is the number of\n        lateral roots associated with the primary root.\n    \"\"\"\n    # Basic input validation\n    if not isinstance(primary_pts, np.ndarray) or not isinstance(\n        lateral_pts, np.ndarray\n    ):\n        raise ValueError(\"Both primary_pts and lateral_pts must be numpy arrays.\")\n    if len(primary_pts.shape) != 3 or len(lateral_pts.shape) != 3:\n        raise ValueError(\"Input arrays must have a shape of (instances, nodes, 2).\")\n    if primary_pts.shape[2] != 2 or lateral_pts.shape[2] != 2:\n        raise ValueError(\n            \"The last dimension of input arrays must be 2, representing x and y coordinates.\"\n        )\n\n    plant_associations = {}\n\n    # Initialize plant associations dictionary\n    for i, primary_root in enumerate(primary_pts):\n        if not is_line_valid(primary_root):\n            continue  # Skip primary roots containing NaN values\n        plant_associations[i] = {\n            \"primary_points\": primary_root,\n            \"lateral_points\": [],\n        }\n\n    # Associate each lateral root with the closest primary root\n    for lateral_root in lateral_pts:\n        if not is_line_valid(lateral_root):\n            continue  # Skip lateral roots containing NaN values\n\n        lateral_line = LineString(lateral_root)\n        min_distance = float(\"inf\")\n        closest_primary_index = None\n\n        for primary_index, primary_data in plant_associations.items():\n            primary_root = primary_data[\"primary_points\"]\n            try:\n                primary_line = LineString(primary_root)\n                distance = primary_line.distance(lateral_line)\n            except Exception as e:\n                print(f\"Error computing distance: {e}\")\n                continue\n\n            if distance &lt; min_distance:\n                min_distance = distance\n                closest_primary_index = primary_index\n\n        if closest_primary_index is not None:\n            plant_associations[closest_primary_index][\"lateral_points\"].append(\n                lateral_root\n            )\n\n    # Convert lateral points lists into arrays\n    for primary_index, data in plant_associations.items():\n        lateral_points_list = data[\"lateral_points\"]\n        if lateral_points_list:  # Check if there are any lateral points to convert\n            lateral_points_array = np.array(lateral_points_list)\n            plant_associations[primary_index][\"lateral_points\"] = lateral_points_array\n        else:\n            # Create an array of NaNs if there are no lateral points\n            shape = (1, lateral_pts.shape[1], 2)  # Shape of lateral points array\n            plant_associations[primary_index][\"lateral_points\"] = np.full(shape, np.nan)\n\n    return plant_associations\n</code></pre>"},{"location":"api/traits/points/#filter_roots_with_nans","title":"filter_roots_with_nans","text":""},{"location":"api/traits/points/#sleap_roots.points.filter_roots_with_nans","title":"filter_roots_with_nans","text":"<pre><code>filter_roots_with_nans(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Remove roots with NaN values from an array of root points.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>An array of points representing roots, with shape (instances, nodes, 2), where 'instances' is the number of roots, 'nodes' is the number of points in each root, and '2' corresponds to the x and y coordinates.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of shape (instances, nodes, 2) with NaN-containing roots removed. If all roots contain NaN values, an empty array of shape (0, nodes, 2) is returned.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def filter_roots_with_nans(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Remove roots with NaN values from an array of root points.\n\n    Args:\n        pts: An array of points representing roots, with shape (instances, nodes, 2),\n            where 'instances' is the number of roots, 'nodes' is the number of points in\n            each root, and '2' corresponds to the x and y coordinates.\n\n    Returns:\n        np.ndarray: An array of shape (instances, nodes, 2) with NaN-containing roots\n            removed. If all roots contain NaN values, an empty array of shape\n            (0, nodes, 2) is returned.\n    \"\"\"\n    if not isinstance(pts, np.ndarray):\n        raise TypeError(\"Input must be a numpy array.\")\n    if pts.ndim != 3 or pts.shape[2] != 2:\n        raise ValueError(\"Input array must have a shape of (instances, nodes, 2).\")\n\n    cleaned_pts = np.array([root for root in pts if not np.isnan(root).any()])\n\n    if cleaned_pts.size == 0:\n        return np.empty((0, pts.shape[1], 2))\n\n    return cleaned_pts\n</code></pre>"},{"location":"api/traits/points/#related-modules","title":"Related Modules","text":"<ul> <li>Series - Loading point data</li> <li>All trait modules use point utilities</li> </ul>"},{"location":"api/traits/scanline/","title":"Scanline","text":""},{"location":"api/traits/scanline/#overview","title":"Overview","text":"<p>Count root intersections with horizontal scan lines for distribution analysis.</p> <p>Key functions: - <code>count_scanline_intersections</code> - Count intersections at given y-coordinates - <code>get_scanline_first_ind</code> - First intersection index - <code>get_scanline_last_ind</code> - Last intersection index</p>"},{"location":"api/traits/scanline/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\nimport numpy as np\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\")\npts = series.get_primary_points()\n\n# Count intersections at y=100\nintersections = sr.count_scanline_intersections(pts, y=100)\nprint(f\"Intersections at y=100: {intersections}\")\n</code></pre>"},{"location":"api/traits/scanline/#api-reference","title":"API Reference","text":""},{"location":"api/traits/scanline/#count_scanline_intersections","title":"count_scanline_intersections","text":""},{"location":"api/traits/scanline/#sleap_roots.scanline.count_scanline_intersections","title":"count_scanline_intersections","text":"<pre><code>count_scanline_intersections(\n    pts_list: List[ndarray],\n    height: int = 1080,\n    n_line: int = 50,\n) -&gt; ndarray\n</code></pre> <p>Count intersections of roots with a series of horizontal scanlines.</p> <p>This function calculates the number of intersections between the provided primary and lateral root points and a set of horizontal scanlines. The scanlines are equally spaced across the specified height.</p> <p>Parameters:</p> Name Type Description Default <code>pts_list</code> <code>List[ndarray]</code> <p>A list of arrays, each having shape <code>(nodes, 2)</code>.</p> required <code>height</code> <code>int</code> <p>The height of the image or cylinder. Defaults to 1080.</p> <code>1080</code> <code>n_line</code> <code>int</code> <p>Number of scanlines to use. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array with shape <code>(n_line,)</code> representing the number of intersections of roots with each scanline.</p> Source code in <code>sleap_roots/scanline.py</code> <pre><code>def count_scanline_intersections(\n    pts_list: List[np.ndarray],\n    height: int = 1080,\n    n_line: int = 50,\n) -&gt; np.ndarray:\n    \"\"\"Count intersections of roots with a series of horizontal scanlines.\n\n    This function calculates the number of intersections between the provided\n    primary and lateral root points and a set of horizontal scanlines. The scanlines\n    are equally spaced across the specified height.\n\n    Args:\n        pts_list: A list of arrays, each having shape `(nodes, 2)`.\n        height: The height of the image or cylinder. Defaults to 1080.\n        n_line: Number of scanlines to use. Defaults to 50.\n\n    Returns:\n        An array with shape `(n_line,)` representing the number of intersections\n            of roots with each scanline.\n    \"\"\"\n    # Input validation for pts_list\n    if any(pts.ndim != 2 or pts.shape[-1] != 2 for pts in pts_list):\n        raise ValueError(\n            \"Each pts array in pts_list should have a shape of `(nodes, 2)`.\"\n        )\n\n    # Calculate the interval between two scanlines\n    interval = height / (n_line - 1)\n\n    intersections = []\n\n    # Iterate over scanlines\n    for i in range(n_line):\n        y_coord = interval * i\n        line_intersections = 0\n\n        for root_points in pts_list:\n            # Remove NaN values\n            valid_points = root_points[(~np.isnan(root_points)).any(axis=1)]\n\n            if len(valid_points) &gt; 1:\n                for j in range(len(valid_points) - 1):\n                    y1 = valid_points[j][1]\n                    y2 = valid_points[j + 1][1]\n\n                    if (y1 &gt;= y_coord &gt;= y2) or (y2 &gt;= y_coord &gt;= y1):\n                        line_intersections += 1\n\n        intersections.append(line_intersections)\n\n    return np.array(intersections)\n</code></pre>"},{"location":"api/traits/scanline/#get_scanline_first_ind","title":"get_scanline_first_ind","text":""},{"location":"api/traits/scanline/#sleap_roots.scanline.get_scanline_first_ind","title":"get_scanline_first_ind","text":"<pre><code>get_scanline_first_ind(\n    scanline_intersection_counts: ndarray,\n)\n</code></pre> <p>Get the index of count_scanline_interaction for the first interaction.</p> <p>Parameters:</p> Name Type Description Default <code>scanline_intersection_counts</code> <code>ndarray</code> <p>An array with shape of <code>(#Nline,)</code> of intersection numbers of each scan line.</p> required Return <p>Scalar of count_scanline_interaction index for the first interaction.</p> Source code in <code>sleap_roots/scanline.py</code> <pre><code>def get_scanline_first_ind(scanline_intersection_counts: np.ndarray):\n    \"\"\"Get the index of count_scanline_interaction for the first interaction.\n\n    Args:\n        scanline_intersection_counts: An array with shape of `(#Nline,)` of intersection\n            numbers of each scan line.\n\n    Return:\n        Scalar of count_scanline_interaction index for the first interaction.\n    \"\"\"\n    # get the first scanline index using scanline_intersection_counts\n    if np.where((scanline_intersection_counts &gt; 0))[0].shape[0] &gt; 0:\n        scanline_first_ind = np.where((scanline_intersection_counts &gt; 0))[0][0]\n        return scanline_first_ind\n    else:\n        return np.nan\n</code></pre>"},{"location":"api/traits/scanline/#get_scanline_last_ind","title":"get_scanline_last_ind","text":""},{"location":"api/traits/scanline/#sleap_roots.scanline.get_scanline_last_ind","title":"get_scanline_last_ind","text":"<pre><code>get_scanline_last_ind(\n    scanline_intersection_counts: ndarray,\n)\n</code></pre> <p>Get the index of count_scanline_interaction for the last interaction.</p> <p>Parameters:</p> Name Type Description Default <code>scanline_intersection_counts</code> <code>ndarray</code> <p>An array with shape of <code>(#Nline,)</code> of intersection numbers of each scan line.</p> required Return <p>Scalar of count_scanline_interaction index for the last interaction.</p> Source code in <code>sleap_roots/scanline.py</code> <pre><code>def get_scanline_last_ind(scanline_intersection_counts: np.ndarray):\n    \"\"\"Get the index of count_scanline_interaction for the last interaction.\n\n    Args:\n        scanline_intersection_counts: An array with shape of `(#Nline,)` of intersection\n            numbers of each scan line.\n\n    Return:\n        Scalar of count_scanline_interaction index for the last interaction.\n    \"\"\"\n    # get the last scanline index using scanline_intersection_counts\n    if np.where((scanline_intersection_counts &gt; 0))[0].shape[0] &gt; 0:\n        scanline_last_ind = np.where((scanline_intersection_counts &gt; 0))[0][-1]\n        return scanline_last_ind\n    else:\n        return np.nan\n</code></pre>"},{"location":"api/traits/scanline/#related-modules","title":"Related Modules","text":"<ul> <li>Network Length - Network metrics</li> </ul>"},{"location":"api/traits/tips/","title":"Tips","text":""},{"location":"api/traits/tips/#overview","title":"Overview","text":"<p>Detect and extract root tip coordinates. Used for tracking root growth direction and computing tip-based traits.</p> <p>Key functions: - <code>get_tips</code> - Extract tip points from root arrays - <code>get_tip_xs</code> - Get x-coordinates of tips - <code>get_tip_ys</code> - Get y-coordinates of tips</p>"},{"location":"api/traits/tips/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\"plant\", lateral_path=\"lateral.slp\")\nlateral_pts_list = series.get_lateral_points()\n\n# Get tip points\ntips = sr.get_tips(lateral_pts_list)\nprint(f\"Tip shape: {tips.shape}\")  # (n_laterals, 2)\nprint(f\"First tip: x={tips[0, 0]:.1f}, y={tips[0, 1]:.1f}\")\n</code></pre>"},{"location":"api/traits/tips/#api-reference","title":"API Reference","text":""},{"location":"api/traits/tips/#get_tips","title":"get_tips","text":"<p>Example: <pre><code>import sleap_roots as sr\nimport numpy as np\n\nseries = sr.Series.load(\"plant\", lateral_path=\"lateral.slp\")\nlateral_pts_list = series.get_lateral_points()\n\n# Extract all lateral tips\ntips = sr.get_tips(lateral_pts_list)\n\n# Handle NaN (missing tips)\nvalid_tips = tips[~np.isnan(tips).any(axis=1)]\nprint(f\"Valid tips: {len(valid_tips)}/{len(tips)}\")\n</code></pre></p>"},{"location":"api/traits/tips/#sleap_roots.tips.get_tips","title":"get_tips","text":"<pre><code>get_tips(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Return tips (last node) from each root.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of tips. If the input is <code>(nodes, 2)</code>, an array of shape <code>(2,)</code> will be</p> <code>ndarray</code> <p>returned. If the input is <code>(instances, nodes, 2)</code>, an array of shape</p> <code>ndarray</code> <p><code>(instances, 2)</code> will be returned. If there is no root, or the roots don't have</p> <code>ndarray</code> <p>tips, an array of shape <code>(instances, 2)</code> of NaNs will be returned.</p> Source code in <code>sleap_roots/tips.py</code> <pre><code>def get_tips(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return tips (last node) from each root.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        Array of tips. If the input is `(nodes, 2)`, an array of shape `(2,)` will be\n        returned. If the input is `(instances, nodes, 2)`, an array of shape\n        `(instances, 2)` will be returned. If there is no root, or the roots don't have\n        tips, an array of shape `(instances, 2)` of NaNs will be returned.\n    \"\"\"\n    # If the input has shape `(nodes, 2)`, reshape it for consistency\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    # Get the last point of each instance\n    tip_pts = pts[:, -1, :]  # Shape is `(instances, 2)`\n\n    # If the shape is `(1, 2)` return pts with shape `(2,)` instead\n    if tip_pts.shape[0] == 1:\n        return tip_pts[0]\n\n    return tip_pts\n</code></pre>"},{"location":"api/traits/tips/#get_tip_xs","title":"get_tip_xs","text":""},{"location":"api/traits/tips/#sleap_roots.tips.get_tip_xs","title":"get_tip_xs","text":"<pre><code>get_tip_xs(tip_pts: ndarray) -&gt; ndarray | floating\n</code></pre> <p>Get x coordinates of tip points.</p> <p>Parameters:</p> Name Type Description Default <code>tip_pts</code> <code>ndarray</code> <p>Root tip points as array of shape <code>(instances, 2)</code> or <code>(2,)</code> when there is only one tip.</p> required Return <p>An array of tip x-coordinates (instances,) or a scalar when there is only one root.</p> Source code in <code>sleap_roots/tips.py</code> <pre><code>def get_tip_xs(tip_pts: np.ndarray) -&gt; np.ndarray | np.floating:\n    \"\"\"Get x coordinates of tip points.\n\n    Args:\n        tip_pts: Root tip points as array of shape `(instances, 2)` or `(2,)` when there\n            is only one tip.\n\n    Return:\n        An array of tip x-coordinates (instances,) or a scalar when there is only one root.\n    \"\"\"\n    # Check for the 2D shape of the input array\n    if tip_pts.ndim == 1:\n        # If shape is `(2,)`, then reshape it to `(1, 2)` for consistency\n        tip_pts = tip_pts.reshape(1, 2)\n    elif tip_pts.ndim != 2:\n        raise ValueError(\"Input array must be of shape `(instances, 2)` or `(2, )`.\")\n\n    # At this point, `tip_pts` should be of shape `(instances, 2)`.\n    # Get the tip x-value\n    tip_xs = tip_pts[:, 0]\n\n    # Now it has shape `(instances,)`\n    if tip_xs.shape == (1,):\n        # Return a scalar\n        return tip_xs[0]\n\n    return tip_xs\n</code></pre>"},{"location":"api/traits/tips/#get_tip_ys","title":"get_tip_ys","text":"<p>Example: <pre><code>import sleap_roots as sr\n\nlateral_pts_list = sr.Series.load(\"plant\", lateral_path=\"lateral.slp\").get_lateral_points()\n\n# Get tip coordinates separately\ntip_xs = sr.get_tip_xs(lateral_pts_list)\ntip_ys = sr.get_tip_ys(lateral_pts_list)\n\nprint(f\"Tip x-coordinates: {tip_xs}\")\nprint(f\"Tip y-coordinates: {tip_ys}\")\n</code></pre></p>"},{"location":"api/traits/tips/#sleap_roots.tips.get_tip_ys","title":"get_tip_ys","text":"<pre><code>get_tip_ys(tip_pts: ndarray) -&gt; ndarray | floating\n</code></pre> <p>Get y coordinates of tip points.</p> <p>Parameters:</p> Name Type Description Default <code>tip_pts</code> <code>ndarray</code> <p>Root tip points as array of shape <code>(instances, 2)</code> or <code>(2,)</code> when there is only one tip.</p> required Return <p>An array of tip y-coordinates (instances,) or a scalar when there is only one root.</p> Source code in <code>sleap_roots/tips.py</code> <pre><code>def get_tip_ys(tip_pts: np.ndarray) -&gt; np.ndarray | np.floating:\n    \"\"\"Get y coordinates of tip points.\n\n    Args:\n        tip_pts: Root tip points as array of shape `(instances, 2)` or `(2,)` when there\n            is only one tip.\n\n    Return:\n        An array of tip y-coordinates (instances,) or a scalar when there is only one root.\n    \"\"\"\n    # Check for the 2D shape of the input array\n    if tip_pts.ndim == 1:\n        # If shape is `(2,)`, then reshape it to `(1, 2)` for consistency\n        tip_pts = tip_pts.reshape(1, 2)\n    elif tip_pts.ndim != 2:\n        raise ValueError(\"Input array must be of shape `(instances, 2)` or `(2, )`.\")\n\n    # At this point, `tip_pts` should be of shape `(instances, 2)`.\n    # Get the tip y-value\n    tip_ys = tip_pts[:, 1]\n    # Now it has shape `(instances,)`\n    if tip_ys.shape == (1,):\n        # Return a scalar\n        return tip_ys[0]\n\n    return tip_ys\n</code></pre>"},{"location":"api/traits/tips/#related-modules","title":"Related Modules","text":"<ul> <li>Bases - Base point detection (opposite end of root)</li> <li>Lengths - Tip-to-base distances</li> </ul>"},{"location":"api/traits/tips/#see-also","title":"See Also","text":"<ul> <li>DicotPipeline</li> </ul>"},{"location":"api/utilities/summary/","title":"Summary Statistics","text":""},{"location":"api/utilities/summary/#overview","title":"Overview","text":"<p>Compute comprehensive summary statistics for trait vectors. Essential for analyzing root trait distributions across multiple plants or time points.</p> <p>Key function: <code>get_summary</code> - Compute 9 summary statistics (min, max, mean, median, std, percentiles)</p>"},{"location":"api/utilities/summary/#quick-example","title":"Quick Example","text":"<pre><code>import sleap_roots as sr\nimport numpy as np\n\nseries = sr.Series.load(\"plant\", primary_path=\"primary.slp\", lateral_path=\"lateral.slp\")\nprimary_pts = series.get_primary_points()\n\n# Compute lengths for all plants/frames\nlengths = sr.get_root_lengths(primary_pts)  # (plants, frames)\n\n# Flatten to get all length values\nall_lengths = lengths.flatten()\n\n# Get summary statistics\nstats = sr.get_summary(all_lengths)\nprint(f\"Mean length: {stats['mean']:.2f} px\")\nprint(f\"Median length: {stats['median']:.2f} px\")\nprint(f\"Std deviation: {stats['std']:.2f} px\")\nprint(f\"5th percentile: {stats['p5']:.2f} px\")\nprint(f\"95th percentile: {stats['p95']:.2f} px\")\n</code></pre> <p>Output: <pre><code>Mean length: 245.67 px\nMedian length: 238.50 px\nStd deviation: 45.32 px\n5th percentile: 178.23 px\n95th percentile: 325.89 px\n</code></pre></p>"},{"location":"api/utilities/summary/#using-prefixes-for-multiple-traits","title":"Using Prefixes for Multiple Traits","text":"<pre><code># Compute multiple traits\nlengths = sr.get_root_lengths(primary_pts).flatten()\nangles = sr.get_root_angle(primary_pts).flatten()\n\n# Get summaries with prefixes\nlength_stats = sr.get_summary(lengths, prefix=\"length_\")\nangle_stats = sr.get_summary(angles, prefix=\"angle_\")\n\n# Combine into single dictionary\nall_stats = {**length_stats, **angle_stats}\n\nprint(f\"Length mean: {all_stats['length_mean']:.2f} px\")\nprint(f\"Angle mean: {all_stats['angle_mean']:.2f}\u00b0\")\n</code></pre>"},{"location":"api/utilities/summary/#handling-edge-cases","title":"Handling Edge Cases","text":"<pre><code># Empty arrays\nempty_stats = sr.get_summary(np.array([]))\nprint(empty_stats['mean'])  # nan\n\n# Arrays with NaN values\nwith_nans = np.array([10.0, 20.0, np.nan, 30.0])\nstats = sr.get_summary(with_nans)\nprint(f\"Mean (ignoring NaN): {stats['mean']:.2f}\")  # 20.00\n</code></pre>"},{"location":"api/utilities/summary/#pipeline-integration","title":"Pipeline Integration","text":"<pre><code># Use with pipeline output\npipeline = sr.DicotPipeline()\ntraits = pipeline.fit_series(series)\n\n# Get summary of lateral lengths\nlateral_lengths = traits['lateral_length']  # Array of all lateral lengths\nlateral_stats = sr.get_summary(lateral_lengths, prefix=\"lateral_length_\")\n\nprint(f\"Lateral length mean: {lateral_stats['lateral_length_mean']:.2f} px\")\nprint(f\"Lateral length range: {lateral_stats['lateral_length_min']:.2f} - {lateral_stats['lateral_length_max']:.2f} px\")\n</code></pre>"},{"location":"api/utilities/summary/#api-reference","title":"API Reference","text":""},{"location":"api/utilities/summary/#get_summary","title":"get_summary","text":"<p>Returns:</p> <p>A dictionary with the following keys (prefixed if <code>prefix</code> is specified):</p> Key Description <code>min</code> Minimum value <code>max</code> Maximum value <code>mean</code> Mean (average) <code>median</code> Median (50th percentile) <code>std</code> Standard deviation <code>p5</code> 5th percentile <code>p25</code> 25th percentile (Q1) <code>p75</code> 75th percentile (Q3) <code>p95</code> 95th percentile <p>Notes: - Uses <code>np.nan*</code> functions to ignore NaN values - Returns all NaN values if input is empty or all NaN - Handles non-numeric arrays gracefully</p>"},{"location":"api/utilities/summary/#sleap_roots.summary.get_summary","title":"get_summary","text":"<pre><code>get_summary(\n    X: ndarray, prefix: Optional[str] = None\n) -&gt; Dict[str, float]\n</code></pre> <p>Get summary of a vector of observations.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Vector of values as a numpy array of shape <code>(n,)</code>.</p> required <code>prefix</code> <code>Optional[str]</code> <p>Prefix of the variable name. If not <code>None</code>, this string will be appended to the key names of the returned dictionary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary of summary statistics of the input vector with keys: \"min\", \"max\", \"mean\", \"median\", \"std\", \"p5\", \"p25\", \"p75\", \"p95\"</p> <code>Dict[str, float]</code> <p>If <code>prefix</code> was specified, the keys will be prefixed with the string.</p> Source code in <code>sleap_roots/summary.py</code> <pre><code>def get_summary(\n    X: np.ndarray,\n    prefix: Optional[str] = None,\n) -&gt; Dict[str, float]:\n    \"\"\"Get summary of a vector of observations.\n\n    Args:\n        X: Vector of values as a numpy array of shape `(n,)`.\n        prefix: Prefix of the variable name. If not `None`, this string will be appended\n            to the key names of the returned dictionary.\n\n    Returns:\n        A dictionary of summary statistics of the input vector with keys:\n            \"min\", \"max\", \"mean\", \"median\", \"std\", \"p5\", \"p25\", \"p75\", \"p95\"\n\n        If `prefix` was specified, the keys will be prefixed with the string.\n    \"\"\"\n    if prefix is None:\n        prefix = \"\"\n\n    X = np.atleast_1d(X)\n\n    if len(X) == 0 or np.all(np.isnan(X)):\n        return {\n            f\"{prefix}min\": np.nan,\n            f\"{prefix}max\": np.nan,\n            f\"{prefix}mean\": np.nan,\n            f\"{prefix}median\": np.nan,\n            f\"{prefix}std\": np.nan,\n            f\"{prefix}p5\": np.nan,\n            f\"{prefix}p25\": np.nan,\n            f\"{prefix}p75\": np.nan,\n            f\"{prefix}p95\": np.nan,\n        }\n    elif np.issubdtype(X.dtype, np.number):\n        return {\n            f\"{prefix}min\": np.nanmin(X),\n            f\"{prefix}max\": np.nanmax(X),\n            f\"{prefix}mean\": np.nanmean(X),\n            f\"{prefix}median\": np.nanmedian(X),\n            f\"{prefix}std\": np.nanstd(X),\n            f\"{prefix}p5\": np.nanpercentile(X, 5),\n            f\"{prefix}p25\": np.nanpercentile(X, 25),\n            f\"{prefix}p75\": np.nanpercentile(X, 75),\n            f\"{prefix}p95\": np.nanpercentile(X, 95),\n        }\n    else:\n        print(\"X contains non-numeric values\")\n        return {\n            f\"{prefix}min\": np.nan,\n            f\"{prefix}max\": np.nan,\n            f\"{prefix}mean\": np.nan,\n            f\"{prefix}median\": np.nan,\n            f\"{prefix}std\": np.nan,\n            f\"{prefix}p5\": np.nan,\n            f\"{prefix}p25\": np.nan,\n            f\"{prefix}p75\": np.nan,\n            f\"{prefix}p95\": np.nan,\n        }\n</code></pre>"},{"location":"api/utilities/summary/#related-modules","title":"Related Modules","text":"<ul> <li>Pipelines - Generate trait vectors for summarization</li> <li>All trait modules - Compute traits to summarize</li> </ul>"},{"location":"api/utilities/summary/#see-also","title":"See Also","text":"<ul> <li>Common Workflows - End-to-end analysis examples</li> </ul>"},{"location":"cookbook/","title":"Cookbook","text":"<p>Examples and recipes coming soon.</p>"},{"location":"cookbook/batch-optimization/","title":"Batch Processing Optimization","text":"<p>This recipe shows how to efficiently process large numbers of plants and optimize performance for high-throughput phenotyping.</p>"},{"location":"cookbook/batch-optimization/#problem","title":"Problem","text":"<p>Processing hundreds or thousands of plants can be slow and memory-intensive. You need to:</p> <ul> <li>Process large datasets efficiently</li> <li>Minimize memory usage</li> <li>Utilize multiple CPU cores</li> <li>Handle errors gracefully</li> <li>Track progress</li> </ul>"},{"location":"cookbook/batch-optimization/#solution-overview","title":"Solution Overview","text":"<p>Optimize batch processing through: 1. Parallel processing: Use multiprocessing 2. Memory management: Process in batches, clear unused data 3. Progress tracking: Monitor long-running jobs 4. Error handling: Continue despite failures 5. Smart I/O: Efficient file reading/writing</p>"},{"location":"cookbook/batch-optimization/#basic-batch-processing","title":"Basic Batch Processing","text":""},{"location":"cookbook/batch-optimization/#sequential-processing","title":"Sequential Processing","text":"<pre><code>import sleap_roots as sr\nfrom pathlib import Path\n\n# Find all H5 files\ndata_dir = Path(\"data/\")\nh5_files = list(data_dir.glob(\"*.h5\"))\n\nprint(f\"Found {len(h5_files)} plants to process\")\n\n# Process each plant\npipeline = sr.DicotPipeline()\nall_traits = []\n\nfor h5_file in h5_files:\n    print(f\"Processing {h5_file.name}...\")\n\n    series = sr.Series.load(\n        series_name=h5_file.stem,\n        h5_path=h5_file,\n        primary_path=h5_file.with_suffix(\".primary.slp\"),\n        lateral_path=h5_file.with_suffix(\".lateral.slp\")\n    )\n\n    traits = pipeline.compute_plant_traits(series)\n    traits['plant_id'] = h5_file.stem\n    all_traits.append(traits)\n\n# Combine results\nimport pandas as pd\ncombined_traits = pd.concat(all_traits, ignore_index=True)\ncombined_traits.to_csv(\"all_traits.csv\", index=False)\n\nprint(f\"Processed {len(all_traits)} plants\")\n</code></pre>"},{"location":"cookbook/batch-optimization/#parallel-processing","title":"Parallel Processing","text":""},{"location":"cookbook/batch-optimization/#using-multiprocessing","title":"Using multiprocessing","text":"<pre><code>from multiprocessing import Pool, cpu_count\nfrom functools import partial\n\ndef process_single_plant(h5_file, primary_suffix=\".primary.slp\", lateral_suffix=\".lateral.slp\"):\n    \"\"\"\n    Process a single plant (function for parallel execution).\n\n    Args:\n        h5_file: Path to H5 file\n        primary_suffix: Suffix for primary root file\n        lateral_suffix: Suffix for lateral root file\n\n    Returns:\n        DataFrame with traits, or None if processing failed\n    \"\"\"\n    try:\n        series = sr.Series.load(\n            series_name=h5_file.stem,\n            h5_path=h5_file,\n            primary_path=h5_file.with_suffix(primary_suffix),\n            lateral_path=h5_file.with_suffix(lateral_suffix)\n        )\n\n        pipeline = sr.DicotPipeline()\n        traits = pipeline.compute_plant_traits(series)\n        traits['plant_id'] = h5_file.stem\n\n        return traits\n\n    except Exception as e:\n        print(f\"Error processing {h5_file.name}: {e}\")\n        return None\n\n# Parallel processing\nh5_files = list(Path(\"data/\").glob(\"*.h5\"))\n\n# Use 75% of available cores\nn_workers = max(1, int(cpu_count() * 0.75))\nprint(f\"Processing {len(h5_files)} plants with {n_workers} workers...\")\n\nwith Pool(processes=n_workers) as pool:\n    results = pool.map(process_single_plant, h5_files)\n\n# Filter out failed plants and combine\nsuccessful_results = [r for r in results if r is not None]\ncombined_traits = pd.concat(successful_results, ignore_index=True)\ncombined_traits.to_csv(\"all_traits.csv\", index=False)\n\nprint(f\"Successfully processed {len(successful_results)}/{len(h5_files)} plants\")\n</code></pre>"},{"location":"cookbook/batch-optimization/#with-progress-bar","title":"With Progress Bar","text":"<pre><code>from tqdm import tqdm\nfrom multiprocessing import Pool\n\n# Process with progress bar\nh5_files = list(Path(\"data/\").glob(\"*.h5\"))\nn_workers = 4\n\nwith Pool(processes=n_workers) as pool:\n    results = list(tqdm(\n        pool.imap(process_single_plant, h5_files),\n        total=len(h5_files),\n        desc=\"Processing plants\"\n    ))\n\nsuccessful = [r for r in results if r is not None]\nprint(f\"\\nSuccessfully processed: {len(successful)}/{len(h5_files)}\")\n</code></pre>"},{"location":"cookbook/batch-optimization/#memory-management","title":"Memory Management","text":""},{"location":"cookbook/batch-optimization/#batch-processing","title":"Batch Processing","text":"<p>Process in chunks to limit memory usage:</p> <pre><code>def process_in_batches(h5_files, batch_size=100, output_dir=\"output\"):\n    \"\"\"\n    Process files in batches to manage memory.\n\n    Args:\n        h5_files: List of H5 file paths\n        batch_size: Number of files per batch\n        output_dir: Directory for batch output files\n\n    Returns:\n        List of batch output file paths\n    \"\"\"\n    from pathlib import Path\n    import gc\n\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True)\n\n    batch_files = []\n    pipeline = sr.DicotPipeline()\n\n    for batch_idx in range(0, len(h5_files), batch_size):\n        batch = h5_files[batch_idx:batch_idx + batch_size]\n\n        print(f\"Processing batch {batch_idx//batch_size + 1}/{len(h5_files)//batch_size + 1}...\")\n\n        batch_results = []\n        for h5_file in tqdm(batch, desc=\"Batch progress\"):\n            try:\n                series = sr.Series.load(\n                    series_name=h5_file.stem,\n                    h5_path=h5_file,\n                    primary_path=h5_file.with_suffix(\".primary.slp\"),\n                    lateral_path=h5_file.with_suffix(\".lateral.slp\")\n                )\n\n                traits = pipeline.compute_plant_traits(series)\n                traits['plant_id'] = h5_file.stem\n                batch_results.append(traits)\n\n                # Clear series to free memory\n                del series\n\n            except Exception as e:\n                print(f\"Error: {h5_file.name} - {e}\")\n\n        # Save batch results\n        if batch_results:\n            batch_df = pd.concat(batch_results, ignore_index=True)\n            batch_file = output_dir / f\"batch_{batch_idx//batch_size:03d}.csv\"\n            batch_df.to_csv(batch_file, index=False)\n            batch_files.append(batch_file)\n\n            # Clear batch results from memory\n            del batch_results\n            del batch_df\n            gc.collect()\n\n    return batch_files\n\n# Process large dataset in batches\nh5_files = list(Path(\"data/\").glob(\"*.h5\"))\nbatch_files = process_in_batches(h5_files, batch_size=100)\n\n# Combine batch files\nall_dfs = [pd.read_csv(f) for f in batch_files]\ncombined = pd.concat(all_dfs, ignore_index=True)\ncombined.to_csv(\"all_traits_combined.csv\", index=False)\n</code></pre>"},{"location":"cookbook/batch-optimization/#memory-efficient-loading","title":"Memory-Efficient Loading","text":"<pre><code>def process_with_memory_limit(h5_files, max_memory_mb=2000):\n    \"\"\"\n    Process plants while monitoring memory usage.\n\n    Args:\n        h5_files: List of H5 files\n        max_memory_mb: Maximum memory to use (MB)\n\n    Returns:\n        DataFrame with results\n    \"\"\"\n    import psutil\n    import gc\n\n    process = psutil.Process()\n    results = []\n    pipeline = sr.DicotPipeline()\n\n    for h5_file in h5_files:\n        # Check memory before loading\n        memory_mb = process.memory_info().rss / 1024 / 1024\n\n        if memory_mb &gt; max_memory_mb:\n            print(f\"Memory limit reached ({memory_mb:.0f}MB), forcing garbage collection...\")\n            gc.collect()\n            memory_mb = process.memory_info().rss / 1024 / 1024\n\n            if memory_mb &gt; max_memory_mb:\n                print(f\"Still over limit, saving intermediate results...\")\n                # Save and clear results\n                if results:\n                    intermediate_df = pd.concat(results)\n                    intermediate_df.to_csv(\n                        f\"intermediate_{len(results)}.csv\",\n                        index=False\n                    )\n                    results = []\n                    gc.collect()\n\n        # Process plant\n        try:\n            series = sr.Series.load(\n                series_name=h5_file.stem,\n                h5_path=h5_file,\n                primary_path=h5_file.with_suffix(\".primary.slp\"),\n                lateral_path=h5_file.with_suffix(\".lateral.slp\")\n            )\n            traits = pipeline.compute_plant_traits(series)\n            traits['plant_id'] = h5_file.stem\n            results.append(traits)\n\n            del series\n        except Exception as e:\n            print(f\"Error: {h5_file.name} - {e}\")\n\n    return pd.concat(results) if results else pd.DataFrame()\n</code></pre>"},{"location":"cookbook/batch-optimization/#error-handling","title":"Error Handling","text":""},{"location":"cookbook/batch-optimization/#robust-processing","title":"Robust Processing","text":"<pre><code>import logging\nfrom datetime import datetime\n\ndef setup_logging(log_file=\"processing.log\"):\n    \"\"\"Set up logging for batch processing.\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler(log_file),\n            logging.StreamHandler()\n        ]\n    )\n\ndef process_plant_robust(h5_file, max_retries=3):\n    \"\"\"\n    Process plant with error handling and retries.\n\n    Args:\n        h5_file: Path to H5 file\n        max_retries: Number of retry attempts\n\n    Returns:\n        Tuple of (traits DataFrame, status dict)\n    \"\"\"\n    status = {\n        'plant_id': h5_file.stem,\n        'success': False,\n        'error': None,\n        'retries': 0,\n        'processing_time': 0\n    }\n\n    start_time = datetime.now()\n\n    for attempt in range(max_retries):\n        try:\n            series = sr.Series.load(\n                series_name=h5_file.stem,\n                h5_path=h5_file,\n                primary_path=h5_file.with_suffix(\".primary.slp\"),\n                lateral_path=h5_file.with_suffix(\".lateral.slp\")\n            )\n\n            pipeline = sr.DicotPipeline()\n            traits = pipeline.compute_plant_traits(series)\n            traits['plant_id'] = h5_file.stem\n\n            status['success'] = True\n            status['processing_time'] = (datetime.now() - start_time).total_seconds()\n\n            logging.info(f\"Successfully processed {h5_file.stem}\")\n            return traits, status\n\n        except Exception as e:\n            status['retries'] = attempt + 1\n            status['error'] = str(e)\n            logging.warning(f\"Attempt {attempt+1}/{max_retries} failed for {h5_file.stem}: {e}\")\n\n            if attempt &lt; max_retries - 1:\n                time.sleep(1)  # Brief pause before retry\n            else:\n                logging.error(f\"All retries failed for {h5_file.stem}\")\n                return None, status\n\n    return None, status\n\n# Batch process with error tracking\nsetup_logging()\nh5_files = list(Path(\"data/\").glob(\"*.h5\"))\n\nall_traits = []\nall_statuses = []\n\nfor h5_file in tqdm(h5_files):\n    traits, status = process_plant_robust(h5_file)\n\n    if traits is not None:\n        all_traits.append(traits)\n\n    all_statuses.append(status)\n\n# Save results and status report\nif all_traits:\n    combined_traits = pd.concat(all_traits, ignore_index=True)\n    combined_traits.to_csv(\"all_traits.csv\", index=False)\n\nstatus_df = pd.DataFrame(all_statuses)\nstatus_df.to_csv(\"processing_status.csv\", index=False)\n\n# Print summary\nprint(f\"\\nProcessing Summary:\")\nprint(f\"Total plants: {len(all_statuses)}\")\nprint(f\"Successful: {status_df['success'].sum()}\")\nprint(f\"Failed: {(~status_df['success']).sum()}\")\nprint(f\"Mean processing time: {status_df[status_df['success']]['processing_time'].mean():.2f}s\")\n</code></pre>"},{"location":"cookbook/batch-optimization/#progress-tracking","title":"Progress Tracking","text":""},{"location":"cookbook/batch-optimization/#advanced-progress-monitoring","title":"Advanced Progress Monitoring","text":"<pre><code>from tqdm import tqdm\nimport time\n\nclass ProgressTracker:\n    \"\"\"Track processing progress with detailed metrics.\"\"\"\n\n    def __init__(self, total_plants):\n        self.total = total_plants\n        self.processed = 0\n        self.failed = 0\n        self.start_time = time.time()\n        self.pbar = tqdm(total=total_plants, desc=\"Processing\")\n\n    def update(self, success=True):\n        \"\"\"Update progress.\"\"\"\n        self.processed += 1\n        if not success:\n            self.failed += 1\n\n        # Update progress bar\n        self.pbar.update(1)\n        self.pbar.set_postfix({\n            'success': self.processed - self.failed,\n            'failed': self.failed,\n            'rate': f'{self._get_rate():.1f}/s'\n        })\n\n    def _get_rate(self):\n        \"\"\"Get processing rate.\"\"\"\n        elapsed = time.time() - self.start_time\n        return self.processed / elapsed if elapsed &gt; 0 else 0\n\n    def finish(self):\n        \"\"\"Finish progress tracking.\"\"\"\n        self.pbar.close()\n\n        elapsed = time.time() - self.start_time\n        rate = self.processed / elapsed\n\n        print(f\"\\nProcessing completed in {elapsed:.1f}s\")\n        print(f\"Rate: {rate:.2f} plants/second\")\n        print(f\"Success: {self.processed - self.failed}/{self.total}\")\n\n        if self.failed &gt; 0:\n            print(f\"Failed: {self.failed} ({self.failed/self.total*100:.1f}%)\")\n\n# Usage\nh5_files = list(Path(\"data/\").glob(\"*.h5\"))\ntracker = ProgressTracker(len(h5_files))\n\nfor h5_file in h5_files:\n    success = process_single_plant(h5_file) is not None\n    tracker.update(success=success)\n\ntracker.finish()\n</code></pre>"},{"location":"cookbook/batch-optimization/#performance-optimization","title":"Performance Optimization","text":""},{"location":"cookbook/batch-optimization/#profiling","title":"Profiling","text":"<pre><code>import cProfile\nimport pstats\n\ndef profile_processing(h5_file):\n    \"\"\"Profile single plant processing.\"\"\"\n\n    profiler = cProfile.Profile()\n    profiler.enable()\n\n    # Process plant\n    series = sr.Series.load(\n        series_name=h5_file.stem,\n        h5_path=h5_file,\n        primary_path=h5_file.with_suffix(\".primary.slp\"),\n        lateral_path=h5_file.with_suffix(\".lateral.slp\")\n    )\n    pipeline = sr.DicotPipeline()\n    traits = pipeline.compute_plant_traits(series)\n\n    profiler.disable()\n\n    # Print stats\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(20)  # Top 20 functions\n\n# Profile to find bottlenecks\nh5_file = Path(\"data/sample.h5\")\nprofile_processing(h5_file)\n</code></pre>"},{"location":"cookbook/batch-optimization/#caching","title":"Caching","text":"<pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef load_series_cached(h5_path, primary_path, lateral_path):\n    \"\"\"\n    Load series with caching (for repeated processing).\n\n    Warning: Only use if processing same files multiple times.\n    \"\"\"\n    return sr.Series.load(\n        series_name=Path(h5_path).stem,\n        h5_path=h5_path,\n        primary_path=primary_path,\n        lateral_path=lateral_path\n    )\n</code></pre>"},{"location":"cookbook/batch-optimization/#complete-batch-processing-system","title":"Complete Batch Processing System","text":""},{"location":"cookbook/batch-optimization/#production-ready-implementation","title":"Production-Ready Implementation","text":"<pre><code>import sleap_roots as sr\nfrom pathlib import Path\nfrom multiprocessing import Pool, cpu_count\nfrom tqdm import tqdm\nimport pandas as pd\nimport logging\nimport time\nimport gc\n\nclass BatchProcessor:\n    \"\"\"\n    Production-ready batch processor for plant phenotyping.\n\n    Features:\n    - Parallel processing\n    - Progress tracking\n    - Error handling\n    - Memory management\n    - Logging\n    \"\"\"\n\n    def __init__(\n        self,\n        pipeline_class=sr.DicotPipeline,\n        n_workers=None,\n        batch_size=100,\n        output_dir=\"output\",\n        log_file=\"processing.log\"\n    ):\n        \"\"\"\n        Initialize batch processor.\n\n        Args:\n            pipeline_class: Pipeline class to use\n            n_workers: Number of parallel workers (None = auto)\n            batch_size: Batch size for memory management\n            output_dir: Output directory\n            log_file: Log file path\n        \"\"\"\n        self.pipeline_class = pipeline_class\n        self.n_workers = n_workers or max(1, int(cpu_count() * 0.75))\n        self.batch_size = batch_size\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(exist_ok=True)\n\n        # Set up logging\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(levelname)s - %(message)s',\n            handlers=[\n                logging.FileHandler(log_file),\n                logging.StreamHandler()\n            ]\n        )\n        self.logger = logging.getLogger(__name__)\n\n    def process_directory(self, data_dir, pattern=\"*.h5\"):\n        \"\"\"\n        Process all files in directory.\n\n        Args:\n            data_dir: Directory containing data files\n            pattern: Glob pattern for finding files\n\n        Returns:\n            DataFrame with all traits\n        \"\"\"\n        data_dir = Path(data_dir)\n        h5_files = sorted(data_dir.glob(pattern))\n\n        self.logger.info(f\"Found {len(h5_files)} files to process\")\n        self.logger.info(f\"Using {self.n_workers} workers\")\n\n        # Process in batches\n        all_results = []\n        start_time = time.time()\n\n        for batch_idx in range(0, len(h5_files), self.batch_size):\n            batch = h5_files[batch_idx:batch_idx + self.batch_size]\n            batch_num = batch_idx // self.batch_size + 1\n            total_batches = (len(h5_files) + self.batch_size - 1) // self.batch_size\n\n            self.logger.info(f\"Processing batch {batch_num}/{total_batches}\")\n\n            batch_results = self._process_batch(batch)\n            all_results.extend(batch_results)\n\n            # Force garbage collection after batch\n            gc.collect()\n\n        # Combine results\n        successful = [r for r in all_results if r is not None]\n        combined = pd.concat(successful, ignore_index=True) if successful else pd.DataFrame()\n\n        # Save results\n        output_file = self.output_dir / \"all_traits.csv\"\n        combined.to_csv(output_file, index=False)\n\n        # Log summary\n        elapsed = time.time() - start_time\n        self.logger.info(f\"Processing completed in {elapsed:.1f}s\")\n        self.logger.info(f\"Successfully processed {len(successful)}/{len(h5_files)} plants\")\n        self.logger.info(f\"Results saved to {output_file}\")\n\n        return combined\n\n    def _process_batch(self, h5_files):\n        \"\"\"Process a batch of files in parallel.\"\"\"\n        with Pool(processes=self.n_workers) as pool:\n            results = list(tqdm(\n                pool.imap(self._process_single, h5_files),\n                total=len(h5_files),\n                desc=\"Batch progress\"\n            ))\n        return results\n\n    def _process_single(self, h5_file):\n        \"\"\"Process single plant.\"\"\"\n        try:\n            series = sr.Series.load(\n                series_name=h5_file.stem,\n                h5_path=h5_file,\n                primary_path=h5_file.with_suffix(\".primary.slp\"),\n                lateral_path=h5_file.with_suffix(\".lateral.slp\")\n            )\n\n            pipeline = self.pipeline_class()\n            traits = pipeline.compute_plant_traits(series)\n            traits['plant_id'] = h5_file.stem\n            traits['h5_file'] = str(h5_file)\n\n            return traits\n\n        except Exception as e:\n            self.logger.error(f\"Error processing {h5_file.name}: {e}\")\n            return None\n\n# Usage\nprocessor = BatchProcessor(\n    pipeline_class=sr.DicotPipeline,\n    n_workers=4,\n    batch_size=100,\n    output_dir=\"results\"\n)\n\ntraits = processor.process_directory(\"data/\", pattern=\"*.h5\")\nprint(f\"Processed {len(traits)} plants\")\n</code></pre>"},{"location":"cookbook/batch-optimization/#benchmarking","title":"Benchmarking","text":""},{"location":"cookbook/batch-optimization/#performance-comparison","title":"Performance Comparison","text":"<pre><code>import time\n\ndef benchmark_processing_methods(h5_files):\n    \"\"\"Compare different processing methods.\"\"\"\n\n    results = {}\n\n    # Sequential\n    start = time.time()\n    sequential_results = []\n    for h5_file in h5_files[:10]:  # Test on subset\n        result = process_single_plant(h5_file)\n        sequential_results.append(result)\n    results['sequential'] = time.time() - start\n\n    # Parallel\n    start = time.time()\n    with Pool(processes=4) as pool:\n        parallel_results = pool.map(process_single_plant, h5_files[:10])\n    results['parallel_4workers'] = time.time() - start\n\n    # Print comparison\n    print(\"Benchmark Results (10 plants):\")\n    for method, elapsed in results.items():\n        print(f\"{method}: {elapsed:.2f}s ({10/elapsed:.2f} plants/s)\")\n\n# Run benchmark\nh5_files = list(Path(\"data/\").glob(\"*.h5\"))\nbenchmark_processing_methods(h5_files)\n</code></pre>"},{"location":"cookbook/batch-optimization/#next-steps","title":"Next Steps","text":"<ul> <li>See Filtering Data for data quality improvements</li> <li>Read Batch Processing Guide for general workflow</li> <li>Check Troubleshooting for common issues</li> </ul>"},{"location":"cookbook/custom-traits/","title":"Creating Custom Traits","text":"<p>This recipe demonstrates how to implement custom trait computations for specialized research questions.</p>"},{"location":"cookbook/custom-traits/#problem","title":"Problem","text":"<p>Pre-built pipelines may not include the specific traits you need for your research. You want to:</p> <ul> <li>Compute novel morphological metrics</li> <li>Combine existing traits in custom ways</li> <li>Implement domain-specific calculations</li> <li>Add experimental trait definitions</li> </ul>"},{"location":"cookbook/custom-traits/#solution-overview","title":"Solution Overview","text":"<p>Create custom trait functions and integrate them into your analysis workflow.</p>"},{"location":"cookbook/custom-traits/#simple-custom-trait","title":"Simple Custom Trait","text":""},{"location":"cookbook/custom-traits/#root-tortuosity-example","title":"Root Tortuosity Example","text":"<p>Let's implement a root tortuosity metric:</p> <pre><code>import numpy as np\nfrom sleap_roots import lengths\n\ndef compute_tortuosity(pts):\n    \"\"\"\n    Compute root tortuosity (path length / Euclidean distance).\n\n    Higher values indicate more curved/winding roots.\n\n    Args:\n        pts: Root coordinates (n, 2)\n\n    Returns:\n        Tortuosity value (\u2265 1.0)\n    \"\"\"\n    if len(pts) &lt; 2:\n        return np.nan\n\n    # Path length\n    path_length = lengths.get_root_lengths([pts])[0]\n\n    # Euclidean distance\n    euclidean_dist = np.linalg.norm(pts[-1] - pts[0])\n\n    if euclidean_dist == 0:\n        return np.inf\n\n    return path_length / euclidean_dist\n\n# Use it\nimport sleap_roots as sr\n\nseries = sr.Series.load(...)\nprimary_pts = series.primary_pts[0]\n\ntortuosity = compute_tortuosity(primary_pts)\nprint(f\"Root tortuosity: {tortuosity:.2f}\")\n</code></pre>"},{"location":"cookbook/custom-traits/#add-to-pipeline","title":"Add to Pipeline","text":"<pre><code>class ExtendedDicotPipeline(sr.DicotPipeline):\n    \"\"\"DicotPipeline with custom tortuosity trait.\"\"\"\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute standard + custom traits.\"\"\"\n\n        # Get standard traits\n        traits = super().compute_plant_traits(series, write_csv=False)\n\n        # Add custom trait\n        primary_pts = series.get_primary_root_points()\n        traits['primary_tortuosity'] = compute_tortuosity(primary_pts)\n\n        # Add for laterals too\n        lateral_pts_list = series.get_lateral_root_points()\n        if len(lateral_pts_list) &gt; 0:\n            lateral_tortuosities = [compute_tortuosity(pts) for pts in lateral_pts_list]\n            traits['mean_lateral_tortuosity'] = np.mean(lateral_tortuosities)\n\n        # Write to CSV if requested\n        if write_csv:\n            output_path = csv_path or f\"{series.series_name}_extended_traits.csv\"\n            traits.to_csv(output_path, index=False)\n\n        return traits\n</code></pre>"},{"location":"cookbook/custom-traits/#complex-custom-trait","title":"Complex Custom Trait","text":""},{"location":"cookbook/custom-traits/#root-branching-density","title":"Root Branching Density","text":"<p>Compute lateral root density along primary root:</p> <pre><code>import numpy as np\nfrom scipy.ndimage import gaussian_filter1d\n\ndef compute_branching_density(primary_pts, lateral_pts_list, window_size=50):\n    \"\"\"\n    Compute spatial density of lateral root emergence along primary.\n\n    Args:\n        primary_pts: Primary root coordinates (n, 2)\n        lateral_pts_list: List of lateral root arrays\n        window_size: Spatial window for density calculation (pixels)\n\n    Returns:\n        Dictionary with density metrics\n    \"\"\"\n    if len(lateral_pts_list) == 0:\n        return {\n            'branching_density': 0.0,\n            'density_profile': np.array([]),\n            'peak_density': 0.0,\n            'peak_position': np.nan\n        }\n\n    # Get lateral base positions along primary axis\n    # (Assuming first point of each lateral is base)\n    lateral_bases = np.array([pts[0] for pts in lateral_pts_list])\n\n    # Project lateral bases onto primary root axis\n    # Simple approach: use distance from primary base\n    primary_base = primary_pts[0]\n    distances_from_base = np.linalg.norm(\n        lateral_bases - primary_base,\n        axis=1\n    )\n\n    # Create density histogram\n    primary_length = lengths.get_root_lengths([primary_pts])[0]\n    bins = np.arange(0, primary_length, window_size)\n\n    hist, bin_edges = np.histogram(distances_from_base, bins=bins)\n\n    # Smooth density profile\n    density_profile = gaussian_filter1d(hist.astype(float), sigma=2.0)\n\n    # Overall density\n    overall_density = len(lateral_pts_list) / primary_length\n\n    # Peak density and position\n    peak_density = np.max(density_profile)\n    peak_bin = np.argmax(density_profile)\n    peak_position = bin_edges[peak_bin]\n\n    return {\n        'branching_density': overall_density,\n        'density_profile': density_profile,\n        'peak_density': peak_density,\n        'peak_position': peak_position,\n        'bin_edges': bin_edges[:-1]  # For plotting\n    }\n\n# Example usage\nprimary_pts = series.primary_pts[0]\nlateral_pts_list = series.lateral_pts[0]\n\ndensity_metrics = compute_branching_density(\n    primary_pts,\n    lateral_pts_list,\n    window_size=30\n)\n\nprint(f\"Overall branching density: {density_metrics['branching_density']:.4f} laterals/pixel\")\nprint(f\"Peak density at: {density_metrics['peak_position']:.1f} pixels from base\")\n\n# Visualize\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.bar(\n    density_metrics['bin_edges'],\n    density_metrics['density_profile'],\n    width=30,\n    edgecolor='black'\n)\nplt.xlabel('Distance from Primary Base (pixels)')\nplt.ylabel('Lateral Density')\nplt.title('Lateral Root Branching Density Profile')\nplt.show()\n</code></pre>"},{"location":"cookbook/custom-traits/#multi-root-custom-trait","title":"Multi-Root Custom Trait","text":""},{"location":"cookbook/custom-traits/#root-system-asymmetry","title":"Root System Asymmetry","text":"<p>Measure left-right asymmetry of lateral roots:</p> <pre><code>from sleap_roots import angles\n\ndef compute_lateral_asymmetry(primary_pts, lateral_pts_list):\n    \"\"\"\n    Compute left-right asymmetry of lateral root distribution.\n\n    Args:\n        primary_pts: Primary root coordinates\n        lateral_pts_list: Lateral root arrays\n\n    Returns:\n        Dictionary with asymmetry metrics\n    \"\"\"\n    if len(lateral_pts_list) == 0:\n        return {\n            'asymmetry_index': 0.0,\n            'left_count': 0,\n            'right_count': 0,\n            'left_total_length': 0.0,\n            'right_total_length': 0.0\n        }\n\n    # Get emergence angles\n    emergence_angles = []\n    for lateral_pts in lateral_pts_list:\n        angle = angles.get_lateral_emergence_angle(primary_pts, lateral_pts)\n        emergence_angles.append(angle)\n\n    emergence_angles = np.array(emergence_angles)\n\n    # Classify left vs. right (negative = left, positive = right)\n    left_mask = emergence_angles &lt; 0\n    right_mask = emergence_angles &gt; 0\n\n    left_count = left_mask.sum()\n    right_count = right_mask.sum()\n\n    # Compute lengths\n    all_lengths = lengths.get_root_lengths(lateral_pts_list)\n    left_total_length = all_lengths[left_mask].sum() if left_count &gt; 0 else 0.0\n    right_total_length = all_lengths[right_mask].sum() if right_count &gt; 0 else 0.0\n\n    # Asymmetry indices\n    count_asymmetry = abs(left_count - right_count) / (left_count + right_count)\n    total_length = left_total_length + right_total_length\n    length_asymmetry = abs(left_total_length - right_total_length) / total_length if total_length &gt; 0 else 0.0\n\n    # Combined asymmetry (0 = symmetric, 1 = fully asymmetric)\n    asymmetry_index = (count_asymmetry + length_asymmetry) / 2\n\n    return {\n        'asymmetry_index': asymmetry_index,\n        'count_asymmetry': count_asymmetry,\n        'length_asymmetry': length_asymmetry,\n        'left_count': int(left_count),\n        'right_count': int(right_count),\n        'left_total_length': float(left_total_length),\n        'right_total_length': float(right_total_length)\n    }\n\n# Usage\nasymmetry = compute_lateral_asymmetry(primary_pts, lateral_pts_list)\nprint(f\"Asymmetry index: {asymmetry['asymmetry_index']:.2f}\")\nprint(f\"Left: {asymmetry['left_count']} roots, {asymmetry['left_total_length']:.1f} px\")\nprint(f\"Right: {asymmetry['right_count']} roots, {asymmetry['right_total_length']:.1f} px\")\n</code></pre>"},{"location":"cookbook/custom-traits/#temporal-custom-trait","title":"Temporal Custom Trait","text":""},{"location":"cookbook/custom-traits/#growth-rate-analysis","title":"Growth Rate Analysis","text":"<pre><code>def compute_growth_rates(trait_series, time_units='frame'):\n    \"\"\"\n    Compute instantaneous and cumulative growth rates.\n\n    Args:\n        trait_series: Pandas Series of trait values over time\n        time_units: Time unit for rates ('frame', 'hour', etc.)\n\n    Returns:\n        DataFrame with growth metrics\n    \"\"\"\n    import pandas as pd\n\n    results = pd.DataFrame({\n        'value': trait_series.values,\n        'instantaneous_rate': trait_series.diff(),\n        'cumulative_growth': trait_series - trait_series.iloc[0],\n        'relative_growth': trait_series.pct_change()\n    })\n\n    # Moving average growth rate\n    results['avg_rate_5frame'] = results['instantaneous_rate'].rolling(5, center=True).mean()\n\n    return results\n\n# Example with temporal data\nseries = sr.Series.load(...)  # Multi-frame series\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series)\n\n# Compute growth rates for primary length\ngrowth_rates = compute_growth_rates(traits['primary_length'])\n\n# Visualize\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.plot(growth_rates['value'])\nplt.title('Primary Root Length')\nplt.xlabel('Frame')\n\nplt.subplot(1, 3, 2)\nplt.plot(growth_rates['instantaneous_rate'], 'o-', alpha=0.5, label='Instantaneous')\nplt.plot(growth_rates['avg_rate_5frame'], linewidth=2, label='5-frame avg')\nplt.title('Growth Rate')\nplt.xlabel('Frame')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(growth_rates['cumulative_growth'])\nplt.title('Cumulative Growth')\nplt.xlabel('Frame')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"cookbook/custom-traits/#statistical-custom-traits","title":"Statistical Custom Traits","text":""},{"location":"cookbook/custom-traits/#root-length-distribution-metrics","title":"Root Length Distribution Metrics","text":"<pre><code>from scipy import stats\n\ndef compute_length_distribution_metrics(lateral_pts_list):\n    \"\"\"\n    Compute statistical metrics of lateral root length distribution.\n\n    Args:\n        lateral_pts_list: List of lateral root arrays\n\n    Returns:\n        Dictionary of distribution metrics\n    \"\"\"\n    if len(lateral_pts_list) == 0:\n        return {\n            'mean': np.nan,\n            'median': np.nan,\n            'std': np.nan,\n            'cv': np.nan,\n            'skewness': np.nan,\n            'kurtosis': np.nan,\n            'iqr': np.nan\n        }\n\n    root_lengths = lengths.get_root_lengths(lateral_pts_list)\n\n    metrics = {\n        'mean': np.mean(root_lengths),\n        'median': np.median(root_lengths),\n        'std': np.std(root_lengths),\n        'cv': np.std(root_lengths) / np.mean(root_lengths),  # Coefficient of variation\n        'skewness': stats.skew(root_lengths),\n        'kurtosis': stats.kurtosis(root_lengths),\n        'iqr': stats.iqr(root_lengths),\n        'range': np.ptp(root_lengths),  # Peak-to-peak (max - min)\n        'q25': np.percentile(root_lengths, 25),\n        'q75': np.percentile(root_lengths, 75)\n    }\n\n    return metrics\n\n# Usage\ndist_metrics = compute_length_distribution_metrics(lateral_pts_list)\nprint(f\"Mean \u00b1 SD: {dist_metrics['mean']:.1f} \u00b1 {dist_metrics['std']:.1f}\")\nprint(f\"Coefficient of variation: {dist_metrics['cv']:.2f}\")\nprint(f\"Skewness: {dist_metrics['skewness']:.2f}\")\n</code></pre>"},{"location":"cookbook/custom-traits/#geometry-based-custom-traits","title":"Geometry-Based Custom Traits","text":""},{"location":"cookbook/custom-traits/#root-angle-distribution","title":"Root Angle Distribution","text":"<pre><code>def compute_angle_distribution(primary_pts, window_size=10):\n    \"\"\"\n    Compute distribution of local angles along root.\n\n    Args:\n        primary_pts: Root coordinates\n        window_size: Window for local angle calculation\n\n    Returns:\n        Dictionary with angle distribution metrics\n    \"\"\"\n    local_angles = []\n\n    for i in range(window_size, len(primary_pts) - window_size):\n        # Local tangent vector\n        before = primary_pts[i] - primary_pts[i-window_size]\n        after = primary_pts[i+window_size] - primary_pts[i]\n\n        # Angle between segments\n        angle = np.arctan2(\n            before[0]*after[1] - before[1]*after[0],\n            before[0]*after[0] + before[1]*after[1]\n        )\n        local_angles.append(np.degrees(angle))\n\n    local_angles = np.array(local_angles)\n\n    return {\n        'mean_curvature': np.mean(np.abs(local_angles)),\n        'max_curvature': np.max(np.abs(local_angles)),\n        'curvature_variance': np.var(local_angles),\n        'direction_changes': np.sum(np.abs(np.diff(np.sign(local_angles))) &gt; 0)\n    }\n\n# Usage\nangle_metrics = compute_angle_distribution(primary_pts, window_size=5)\nprint(f\"Mean curvature: {angle_metrics['mean_curvature']:.2f}\u00b0\")\nprint(f\"Direction changes: {angle_metrics['direction_changes']}\")\n</code></pre>"},{"location":"cookbook/custom-traits/#complete-custom-pipeline-example","title":"Complete Custom Pipeline Example","text":""},{"location":"cookbook/custom-traits/#research-specific-pipeline","title":"Research-Specific Pipeline","text":"<pre><code>import sleap_roots as sr\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nclass ResearchPipeline:\n    \"\"\"\n    Custom pipeline with domain-specific traits.\n\n    Example: Rice root system architecture study.\n    \"\"\"\n\n    def __init__(self):\n        self.name = \"Rice RSA Pipeline\"\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute custom research traits.\"\"\"\n\n        traits = {}\n\n        # Get root data\n        primary_pts = series.get_primary_root_points()\n        crown_pts_list = series.get_crown_root_points()  # For monocots\n\n        # === Primary root traits ===\n        traits.update(self._compute_primary_traits(primary_pts))\n\n        # === Crown root traits ===\n        traits.update(self._compute_crown_traits(crown_pts_list))\n\n        # === System-level traits ===\n        traits.update(self._compute_system_traits(primary_pts, crown_pts_list))\n\n        # === Custom research traits ===\n        traits.update(self._compute_research_specific_traits(primary_pts, crown_pts_list))\n\n        df = pd.DataFrame([traits])\n\n        if write_csv:\n            output_path = csv_path or f\"{series.series_name}_research_traits.csv\"\n            df.to_csv(output_path, index=False)\n\n        return df\n\n    def _compute_primary_traits(self, pts):\n        \"\"\"Basic primary root traits.\"\"\"\n        return {\n            'primary_length': lengths.get_root_lengths([pts])[0],\n            'primary_tortuosity': compute_tortuosity(pts)\n        }\n\n    def _compute_crown_traits(self, crown_pts_list):\n        \"\"\"Crown root traits.\"\"\"\n        if len(crown_pts_list) == 0:\n            return {\n                'crown_count': 0,\n                'crown_total_length': 0.0,\n                'crown_length_cv': np.nan\n            }\n\n        crown_lengths = lengths.get_root_lengths(crown_pts_list)\n\n        return {\n            'crown_count': len(crown_pts_list),\n            'crown_total_length': np.sum(crown_lengths),\n            'crown_mean_length': np.mean(crown_lengths),\n            'crown_length_cv': np.std(crown_lengths) / np.mean(crown_lengths)\n        }\n\n    def _compute_system_traits(self, primary_pts, crown_pts_list):\n        \"\"\"Whole system traits.\"\"\"\n        all_roots = [primary_pts] + crown_pts_list\n        all_lengths = lengths.get_root_lengths(all_roots)\n\n        return {\n            'total_root_length': np.sum(all_lengths),\n            'total_root_count': len(all_roots),\n            'root_length_gini': self._compute_gini_coefficient(all_lengths)\n        }\n\n    def _compute_research_specific_traits(self, primary_pts, crown_pts_list):\n        \"\"\"Domain-specific trait calculations.\"\"\"\n\n        # Example: Rice-specific traits\n        traits = {}\n\n        # Crown-to-primary ratio\n        primary_len = lengths.get_root_lengths([primary_pts])[0]\n        crown_total = np.sum(lengths.get_root_lengths(crown_pts_list)) if crown_pts_list else 0\n        traits['crown_primary_ratio'] = crown_total / primary_len if primary_len &gt; 0 else 0\n\n        # Root depth efficiency (length per vertical depth)\n        depth = np.max(primary_pts[:, 1]) - np.min(primary_pts[:, 1])\n        traits['depth_efficiency'] = primary_len / depth if depth &gt; 0 else 0\n\n        # Shallow root fraction (crown roots in top 30% of depth)\n        if len(crown_pts_list) &gt; 0:\n            shallow_count = 0\n            depth_threshold = 0.3 * depth\n\n            for crown_pts in crown_pts_list:\n                crown_depth = crown_pts[:, 1].max() - crown_pts[:, 1].min()\n                if crown_depth &lt; depth_threshold:\n                    shallow_count += 1\n\n            traits['shallow_root_fraction'] = shallow_count / len(crown_pts_list)\n        else:\n            traits['shallow_root_fraction'] = 0.0\n\n        return traits\n\n    def _compute_gini_coefficient(self, values):\n        \"\"\"Compute Gini coefficient of length distribution.\"\"\"\n        values = np.array(values)\n        if len(values) == 0:\n            return np.nan\n\n        sorted_values = np.sort(values)\n        n = len(values)\n        index = np.arange(1, n + 1)\n        return (2 * np.sum(index * sorted_values)) / (n * np.sum(sorted_values)) - (n + 1) / n\n\n\n# Usage\nresearch_pipeline = ResearchPipeline()\ntraits = research_pipeline.compute_plant_traits(series, write_csv=True)\nprint(traits)\n</code></pre>"},{"location":"cookbook/custom-traits/#testing-custom-traits","title":"Testing Custom Traits","text":""},{"location":"cookbook/custom-traits/#unit-tests","title":"Unit Tests","text":"<pre><code>import pytest\n\ndef test_tortuosity_straight_line():\n    \"\"\"Straight line should have tortuosity of 1.0.\"\"\"\n    pts = np.array([[0, 0], [1, 0], [2, 0]])\n    tortuosity = compute_tortuosity(pts)\n    assert np.isclose(tortuosity, 1.0)\n\ndef test_tortuosity_curved_path():\n    \"\"\"Curved path should have tortuosity &gt; 1.0.\"\"\"\n    pts = np.array([[0, 0], [1, 1], [2, 0]])\n    tortuosity = compute_tortuosity(pts)\n    assert tortuosity &gt; 1.0\n\ndef test_tortuosity_invalid_input():\n    \"\"\"Should handle edge cases.\"\"\"\n    # Single point\n    pts = np.array([[0, 0]])\n    assert np.isnan(compute_tortuosity(pts))\n\n    # Coincident endpoints\n    pts = np.array([[0, 0], [1, 1], [0, 0]])\n    assert np.isinf(compute_tortuosity(pts))\n</code></pre>"},{"location":"cookbook/custom-traits/#best-practices","title":"Best Practices","text":""},{"location":"cookbook/custom-traits/#1-validate-trait","title":"1. Validate Trait","text":"<ul> <li>Test with known inputs</li> <li>Check edge cases</li> <li>Verify biological relevance</li> </ul>"},{"location":"cookbook/custom-traits/#2-document-thoroughly","title":"2. Document Thoroughly","text":"<pre><code>def my_custom_trait(pts):\n    \"\"\"\n    One-line description.\n\n    Detailed explanation of what the trait measures,\n    biological interpretation, and any caveats.\n\n    Args:\n        pts: Root coordinates (n, 2)\n\n    Returns:\n        Trait value with units and expected range\n\n    Example:\n        &gt;&gt;&gt; pts = np.array([[0, 0], [1, 1]])\n        &gt;&gt;&gt; my_custom_trait(pts)\n        1.414\n\n    References:\n        Smith et al. (2020). Journal of Plant Science.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"cookbook/custom-traits/#3-make-reusable","title":"3. Make Reusable","text":"<p>Package custom traits as a module:</p> <pre><code># my_custom_traits.py\nimport numpy as np\n\ndef tortuosity(pts):\n    \"\"\"...\"\"\"\n    pass\n\ndef branching_density(primary, laterals, window=50):\n    \"\"\"...\"\"\"\n    pass\n\n# Use across projects\nfrom my_custom_traits import tortuosity, branching_density\n</code></pre>"},{"location":"cookbook/custom-traits/#next-steps","title":"Next Steps","text":"<ul> <li>See Creating Pipelines for full pipeline development</li> <li>Read Adding Traits to contribute traits to sleap-roots</li> <li>Check API Reference for available utility functions</li> </ul>"},{"location":"cookbook/exporting-results/","title":"Exporting Results","text":"<p>This recipe shows various methods for exporting trait data for statistical analysis, visualization, and sharing.</p>"},{"location":"cookbook/exporting-results/#problem","title":"Problem","text":"<p>You've computed traits and need to export them in formats suitable for: - Statistical software (R, SPSS, SAS) - Spreadsheet analysis (Excel, Google Sheets) - Data visualization tools - Collaborator sharing - Long-term archival</p>"},{"location":"cookbook/exporting-results/#solution-overview","title":"Solution Overview","text":"<p>Export strategies for different use cases: 1. CSV: Universal format for most tools 2. Excel: Multi-sheet workbooks with metadata 3. HDF5: Large datasets with hierarchical organization 4. JSON: Web integration and APIs 5. Parquet: Efficient storage for big data</p>"},{"location":"cookbook/exporting-results/#basic-csv-export","title":"Basic CSV Export","text":""},{"location":"cookbook/exporting-results/#standard-export","title":"Standard Export","text":"<pre><code>import sleap_roots as sr\nimport pandas as pd\n\n# Compute traits\nseries = sr.Series.load(...)\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series)\n\n# Export to CSV\ntraits.to_csv(\"traits.csv\", index=False)\n</code></pre>"},{"location":"cookbook/exporting-results/#with-metadata","title":"With Metadata","text":"<pre><code>def export_with_metadata(traits, output_path, metadata=None):\n    \"\"\"\n    Export traits with metadata header.\n\n    Args:\n        traits: DataFrame with trait data\n        output_path: Output CSV path\n        metadata: Dictionary of metadata to include\n    \"\"\"\n    with open(output_path, 'w') as f:\n        # Write metadata as comments\n        if metadata:\n            f.write(\"# Trait Data Export\\n\")\n            for key, value in metadata.items():\n                f.write(f\"# {key}: {value}\\n\")\n            f.write(\"#\\n\")\n\n        # Write traits data\n        traits.to_csv(f, index=False)\n\n# Usage\nmetadata = {\n    'experiment': 'Drought stress 2024',\n    'pipeline': 'DicotPipeline',\n    'date': '2024-01-15',\n    'researcher': 'J. Smith'\n}\n\nexport_with_metadata(traits, \"traits_with_metadata.csv\", metadata)\n</code></pre>"},{"location":"cookbook/exporting-results/#multiple-plants","title":"Multiple Plants","text":"<pre><code># Process multiple plants\nall_traits = []\n\nfor h5_file in Path(\"data/\").glob(\"*.h5\"):\n    series = sr.Series.load(\n        series_name=h5_file.stem,\n        h5_path=h5_file,\n        primary_path=h5_file.with_suffix(\".primary.slp\"),\n        lateral_path=h5_file.with_suffix(\".lateral.slp\")\n    )\n\n    traits = pipeline.compute_plant_traits(series)\n    traits['plant_id'] = h5_file.stem\n    traits['genotype'] = get_genotype_from_filename(h5_file.stem)\n    traits['treatment'] = get_treatment_from_filename(h5_file.stem)\n    all_traits.append(traits)\n\n# Combine and export\ncombined = pd.concat(all_traits, ignore_index=True)\ncombined.to_csv(\"all_plants_traits.csv\", index=False)\n</code></pre>"},{"location":"cookbook/exporting-results/#excel-export","title":"Excel Export","text":""},{"location":"cookbook/exporting-results/#single-sheet","title":"Single Sheet","text":"<pre><code># Simple Excel export\ntraits.to_excel(\"traits.xlsx\", index=False, sheet_name=\"Traits\")\n</code></pre>"},{"location":"cookbook/exporting-results/#multi-sheet-workbook","title":"Multi-Sheet Workbook","text":"<pre><code>from openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill\nfrom openpyxl.utils.dataframe import dataframe_to_rows\n\ndef export_to_excel_multisheet(\n    traits,\n    output_path,\n    metadata=None,\n    summary_stats=True\n):\n    \"\"\"\n    Export traits to multi-sheet Excel workbook.\n\n    Args:\n        traits: DataFrame with trait data\n        output_path: Output Excel path\n        metadata: Dictionary of metadata\n        summary_stats: Whether to include summary statistics\n    \"\"\"\n    # Create workbook\n    wb = Workbook()\n\n    # Sheet 1: Metadata\n    if metadata:\n        ws_meta = wb.active\n        ws_meta.title = \"Metadata\"\n\n        ws_meta['A1'] = \"Parameter\"\n        ws_meta['B1'] = \"Value\"\n        ws_meta['A1'].font = Font(bold=True)\n        ws_meta['B1'].font = Font(bold=True)\n\n        for i, (key, value) in enumerate(metadata.items(), start=2):\n            ws_meta[f'A{i}'] = key\n            ws_meta[f'B{i}'] = value\n\n    # Sheet 2: Raw Traits\n    ws_traits = wb.create_sheet(\"Traits\")\n\n    for r in dataframe_to_rows(traits, index=False, header=True):\n        ws_traits.append(r)\n\n    # Style header row\n    for cell in ws_traits[1]:\n        cell.font = Font(bold=True)\n        cell.fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n\n    # Sheet 3: Summary Statistics\n    if summary_stats:\n        ws_summary = wb.create_sheet(\"Summary\")\n\n        # Compute summary statistics\n        summary = traits.describe()\n        for r in dataframe_to_rows(summary, index=True, header=True):\n            ws_summary.append(r)\n\n        # Style header\n        for cell in ws_summary[1]:\n            cell.font = Font(bold=True)\n            cell.fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n\n    # Sheet 4: Per-Plant Summary\n    if 'plant_id' in traits.columns:\n        ws_plant_summary = wb.create_sheet(\"Per-Plant Summary\")\n\n        plant_summary = traits.groupby('plant_id').agg(['mean', 'std', 'count'])\n        for r in dataframe_to_rows(plant_summary, index=True, header=True):\n            ws_plant_summary.append(r)\n\n    # Save workbook\n    wb.save(output_path)\n\n# Usage\nmetadata = {\n    'Experiment': 'Root phenotyping 2024',\n    'Pipeline': 'DicotPipeline',\n    'Date': '2024-01-15',\n    'Number of Plants': len(traits['plant_id'].unique()) if 'plant_id' in traits.columns else 1,\n    'Traits Computed': len(traits.columns)\n}\n\nexport_to_excel_multisheet(\n    traits,\n    \"comprehensive_traits.xlsx\",\n    metadata=metadata,\n    summary_stats=True\n)\n</code></pre>"},{"location":"cookbook/exporting-results/#excel-with-plots","title":"Excel with Plots","text":"<pre><code>from openpyxl.chart import LineChart, Reference\n\ndef export_excel_with_plots(traits, output_path):\n    \"\"\"Export with embedded plots.\"\"\"\n\n    # Create workbook with traits\n    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n        traits.to_excel(writer, sheet_name=\"Traits\", index=False)\n\n        # Access workbook\n        wb = writer.book\n        ws = wb[\"Traits\"]\n\n        # Add line chart for growth over time\n        if 'frame' in traits.columns and 'primary_length' in traits.columns:\n            chart = LineChart()\n            chart.title = \"Primary Root Growth\"\n            chart.x_axis.title = \"Frame\"\n            chart.y_axis.title = \"Length (pixels)\"\n\n            data = Reference(ws, min_col=traits.columns.get_loc('primary_length') + 1,\n                           min_row=1, max_row=len(traits) + 1)\n            cats = Reference(ws, min_col=traits.columns.get_loc('frame') + 1,\n                           min_row=2, max_row=len(traits) + 1)\n\n            chart.add_data(data, titles_from_data=True)\n            chart.set_categories(cats)\n\n            ws.add_chart(chart, \"N2\")  # Position chart\n\n# Usage\nexport_excel_with_plots(traits, \"traits_with_plots.xlsx\")\n</code></pre>"},{"location":"cookbook/exporting-results/#hdf5-export","title":"HDF5 Export","text":""},{"location":"cookbook/exporting-results/#basic-hdf5","title":"Basic HDF5","text":"<pre><code>import h5py\nimport numpy as np\n\ndef export_to_hdf5(traits, output_path, include_arrays=True):\n    \"\"\"\n    Export traits to HDF5 format.\n\n    Args:\n        traits: DataFrame with traits\n        output_path: Output HDF5 path\n        include_arrays: Whether to save array-valued traits\n    \"\"\"\n    with h5py.File(output_path, 'w') as f:\n        # Create groups\n        grp_traits = f.create_group('traits')\n        grp_metadata = f.create_group('metadata')\n\n        # Save scalar traits\n        for col in traits.columns:\n            if traits[col].dtype == 'object':\n                # Skip arrays or convert to strings\n                if not include_arrays:\n                    continue\n\n                # Try to save as array\n                try:\n                    data = np.array([np.array(x) for x in traits[col]])\n                    grp_traits.create_dataset(col, data=data)\n                except:\n                    # Save as strings\n                    str_data = traits[col].astype(str).values\n                    grp_traits.create_dataset(\n                        col,\n                        data=str_data,\n                        dtype=h5py.special_dtype(vlen=str)\n                    )\n            else:\n                # Save numeric data\n                grp_traits.create_dataset(col, data=traits[col].values)\n\n        # Save metadata\n        grp_metadata.attrs['export_date'] = str(pd.Timestamp.now())\n        grp_metadata.attrs['n_plants'] = len(traits)\n        grp_metadata.attrs['n_traits'] = len(traits.columns)\n\n# Usage\nexport_to_hdf5(traits, \"traits.h5\")\n</code></pre>"},{"location":"cookbook/exporting-results/#hierarchical-hdf5","title":"Hierarchical HDF5","text":"<pre><code>def export_hierarchical_hdf5(all_traits_dict, output_path):\n    \"\"\"\n    Export multiple plants to hierarchical HDF5.\n\n    Args:\n        all_traits_dict: Dict mapping plant_id -&gt; traits DataFrame\n        output_path: Output HDF5 path\n    \"\"\"\n    with h5py.File(output_path, 'w') as f:\n        # Create group for each plant\n        for plant_id, traits in all_traits_dict.items():\n            plant_grp = f.create_group(f'plant_{plant_id}')\n\n            # Save traits for this plant\n            for col in traits.columns:\n                if traits[col].dtype != 'object':\n                    plant_grp.create_dataset(col, data=traits[col].values)\n\n            # Add plant metadata\n            plant_grp.attrs['plant_id'] = plant_id\n            plant_grp.attrs['n_frames'] = len(traits)\n\n        # Global metadata\n        f.attrs['n_plants'] = len(all_traits_dict)\n        f.attrs['export_date'] = str(pd.Timestamp.now())\n\n# Usage\ntraits_by_plant = {\n    'plant_001': traits_001,\n    'plant_002': traits_002,\n    # ...\n}\n\nexport_hierarchical_hdf5(traits_by_plant, \"all_plants.h5\")\n</code></pre>"},{"location":"cookbook/exporting-results/#json-export","title":"JSON Export","text":""},{"location":"cookbook/exporting-results/#standard-json","title":"Standard JSON","text":"<pre><code># Simple JSON export\ntraits.to_json(\"traits.json\", orient=\"records\", indent=2)\n</code></pre>"},{"location":"cookbook/exporting-results/#custom-json-with-arrays","title":"Custom JSON with Arrays","text":"<pre><code>import json\nimport numpy as np\n\nclass NumpyEncoder(json.JSONEncoder):\n    \"\"\"JSON encoder for numpy arrays.\"\"\"\n\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        if isinstance(obj, np.integer):\n            return int(obj)\n        if isinstance(obj, np.floating):\n            return float(obj)\n        return super().default(obj)\n\ndef export_to_json(traits, output_path, metadata=None):\n    \"\"\"\n    Export traits to JSON with proper array handling.\n\n    Args:\n        traits: DataFrame with traits\n        output_path: Output JSON path\n        metadata: Optional metadata dictionary\n    \"\"\"\n    data = {\n        'metadata': metadata or {},\n        'traits': traits.to_dict(orient='records')\n    }\n\n    with open(output_path, 'w') as f:\n        json.dump(data, f, cls=NumpyEncoder, indent=2)\n\n# Usage\nmetadata = {\n    'experiment': 'Drought stress 2024',\n    'pipeline': 'DicotPipeline',\n    'date': '2024-01-15'\n}\n\nexport_to_json(traits, \"traits.json\", metadata)\n</code></pre>"},{"location":"cookbook/exporting-results/#parquet-export","title":"Parquet Export","text":""},{"location":"cookbook/exporting-results/#efficient-parquet","title":"Efficient Parquet","text":"<pre><code># Parquet is efficient for large datasets\ntraits.to_parquet(\"traits.parquet\", compression='snappy', index=False)\n\n# Read back\ntraits_loaded = pd.read_parquet(\"traits.parquet\")\n</code></pre>"},{"location":"cookbook/exporting-results/#with-partitioning","title":"With Partitioning","text":"<pre><code>def export_partitioned_parquet(traits, output_dir, partition_cols=['genotype', 'treatment']):\n    \"\"\"\n    Export to partitioned Parquet for efficient filtering.\n\n    Args:\n        traits: DataFrame with traits\n        output_dir: Output directory\n        partition_cols: Columns to partition by\n    \"\"\"\n    traits.to_parquet(\n        output_dir,\n        partition_cols=partition_cols,\n        compression='snappy',\n        index=False\n    )\n\n# Usage\nexport_partitioned_parquet(\n    all_traits,\n    \"traits_partitioned/\",\n    partition_cols=['genotype', 'treatment']\n)\n\n# Read specific partition\nspecific_traits = pd.read_parquet(\n    \"traits_partitioned/\",\n    filters=[('genotype', '==', 'WT'), ('treatment', '==', 'drought')]\n)\n</code></pre>"},{"location":"cookbook/exporting-results/#wide-vs-long-format","title":"Wide vs. Long Format","text":""},{"location":"cookbook/exporting-results/#convert-to-long-format","title":"Convert to Long Format","text":"<pre><code>def convert_to_long_format(traits, id_vars=['plant_id', 'frame']):\n    \"\"\"\n    Convert traits from wide to long format for easier plotting.\n\n    Args:\n        traits: Wide-format DataFrame\n        id_vars: Columns that identify each observation\n\n    Returns:\n        Long-format DataFrame\n    \"\"\"\n    return pd.melt(\n        traits,\n        id_vars=id_vars,\n        var_name='trait',\n        value_name='value'\n    )\n\n# Usage\ntraits_long = convert_to_long_format(traits, id_vars=['plant_id', 'frame'])\ntraits_long.to_csv(\"traits_long.csv\", index=False)\n\n# Now easy to plot with seaborn/ggplot\nimport seaborn as sns\n\nsns.lineplot(data=traits_long, x='frame', y='value', hue='trait')\n</code></pre>"},{"location":"cookbook/exporting-results/#convert-to-wide-format","title":"Convert to Wide Format","text":"<pre><code># If you have long format, convert to wide\ntraits_wide = traits_long.pivot_table(\n    index=['plant_id', 'frame'],\n    columns='trait',\n    values='value'\n).reset_index()\n\ntraits_wide.to_csv(\"traits_wide.csv\", index=False)\n</code></pre>"},{"location":"cookbook/exporting-results/#export-for-statistical-software","title":"Export for Statistical Software","text":""},{"location":"cookbook/exporting-results/#r-compatible-csv","title":"R-Compatible CSV","text":"<pre><code># Export for R (handles special characters differently)\ntraits.to_csv(\n    \"traits_for_R.csv\",\n    index=False,\n    na_rep='NA',  # R's missing value representation\n    quoting=1  # Quote all text fields\n)\n</code></pre>"},{"location":"cookbook/exporting-results/#spsssas-format","title":"SPSS/SAS Format","text":"<pre><code># Export for SPSS\ntraits.to_stata(\"traits.dta\", write_index=False)\n\n# Or use CSV with specific formatting\ntraits.to_csv(\n    \"traits_for_spss.csv\",\n    index=False,\n    na_rep='.',  # SPSS uses '.' for missing\n    decimal=','  # Some locales use comma for decimal\n)\n</code></pre>"},{"location":"cookbook/exporting-results/#export-with-experimental-design","title":"Export with Experimental Design","text":""},{"location":"cookbook/exporting-results/#include-design-matrix","title":"Include Design Matrix","text":"<pre><code>def export_with_design(traits, design_matrix, output_path):\n    \"\"\"\n    Export traits merged with experimental design.\n\n    Args:\n        traits: DataFrame with traits\n        design_matrix: DataFrame with experimental design\n            (must have matching ID column)\n        output_path: Output path\n    \"\"\"\n    # Merge traits with design\n    merged = traits.merge(design_matrix, on='plant_id', how='left')\n\n    # Export\n    merged.to_csv(output_path, index=False)\n\n    # Also save design separately for reference\n    design_matrix.to_csv(\n        output_path.replace('.csv', '_design.csv'),\n        index=False\n    )\n\n# Example design matrix\ndesign = pd.DataFrame({\n    'plant_id': ['plant_001', 'plant_002', 'plant_003'],\n    'genotype': ['WT', 'WT', 'mutant'],\n    'treatment': ['control', 'drought', 'control'],\n    'replicate': [1, 2, 1],\n    'plate': ['A', 'A', 'B']\n})\n\nexport_with_design(traits, design, \"traits_with_design.csv\")\n</code></pre>"},{"location":"cookbook/exporting-results/#data-validation-before-export","title":"Data Validation Before Export","text":""},{"location":"cookbook/exporting-results/#quality-checks","title":"Quality Checks","text":"<pre><code>def validate_and_export(traits, output_path):\n    \"\"\"\n    Validate traits before export.\n\n    Args:\n        traits: DataFrame with traits\n        output_path: Output path\n\n    Returns:\n        Dictionary with validation results\n    \"\"\"\n    validation = {\n        'valid': True,\n        'issues': []\n    }\n\n    # Check for missing values\n    missing = traits.isnull().sum()\n    if missing.any():\n        validation['issues'].append(f\"Missing values: {missing[missing &gt; 0].to_dict()}\")\n\n    # Check for infinite values\n    numeric_cols = traits.select_dtypes(include=[np.number]).columns\n    for col in numeric_cols:\n        if np.isinf(traits[col]).any():\n            validation['issues'].append(f\"Infinite values in {col}\")\n\n    # Check for unexpected ranges\n    if 'primary_length' in traits.columns:\n        if (traits['primary_length'] &lt; 0).any():\n            validation['issues'].append(\"Negative primary_length values\")\n            validation['valid'] = False\n\n    # Export if valid, otherwise raise warning\n    if validation['valid']:\n        traits.to_csv(output_path, index=False)\n        print(f\"Exported to {output_path}\")\n    else:\n        print(\"Validation failed:\")\n        for issue in validation['issues']:\n            print(f\"  - {issue}\")\n        print(\"Fix issues before exporting\")\n\n    return validation\n\n# Usage\nvalidation_result = validate_and_export(traits, \"validated_traits.csv\")\n</code></pre>"},{"location":"cookbook/exporting-results/#archival-and-documentation","title":"Archival and Documentation","text":""},{"location":"cookbook/exporting-results/#create-analysis-package","title":"Create Analysis Package","text":"<pre><code>import zipfile\nimport shutil\nfrom datetime import datetime\n\ndef create_analysis_package(\n    traits,\n    metadata,\n    output_dir=\"analysis_package\"\n):\n    \"\"\"\n    Create complete analysis package with all files.\n\n    Args:\n        traits: DataFrame with traits\n        metadata: Dictionary with metadata\n        output_dir: Output directory name\n\n    Returns:\n        Path to created package\n    \"\"\"\n    # Create output directory\n    pkg_dir = Path(output_dir)\n    pkg_dir.mkdir(exist_ok=True)\n\n    # Export traits in multiple formats\n    traits.to_csv(pkg_dir / \"traits.csv\", index=False)\n    traits.to_excel(pkg_dir / \"traits.xlsx\", index=False)\n    traits.to_json(pkg_dir / \"traits.json\", orient=\"records\", indent=2)\n\n    # Export summary statistics\n    summary = traits.describe()\n    summary.to_csv(pkg_dir / \"summary_statistics.csv\")\n\n    # Create README\n    readme_content = f\"\"\"\n# Root Trait Analysis Package\n\n## Experiment Information\n- Experiment: {metadata.get('experiment', 'N/A')}\n- Date: {metadata.get('date', datetime.now().strftime('%Y-%m-%d'))}\n- Researcher: {metadata.get('researcher', 'N/A')}\n- Pipeline: {metadata.get('pipeline', 'N/A')}\n\n## Files Included\n- `traits.csv`: Raw trait data (universal format)\n- `traits.xlsx`: Trait data in Excel format\n- `traits.json`: Trait data in JSON format\n- `summary_statistics.csv`: Descriptive statistics\n- `metadata.json`: Detailed metadata\n- `README.md`: This file\n\n## Data Dictionary\n{_generate_data_dictionary(traits)}\n\n## Citation\nIf you use this data, please cite:\n[Add citation information]\n\n## Contact\n[Add contact information]\n\"\"\"\n\n    with open(pkg_dir / \"README.md\", 'w') as f:\n        f.write(readme_content)\n\n    # Save metadata as JSON\n    with open(pkg_dir / \"metadata.json\", 'w') as f:\n        json.dump(metadata, f, indent=2)\n\n    # Create zip archive\n    zip_path = f\"{output_dir}_{datetime.now().strftime('%Y%m%d')}.zip\"\n    shutil.make_archive(\n        zip_path.replace('.zip', ''),\n        'zip',\n        pkg_dir\n    )\n\n    print(f\"Analysis package created: {zip_path}\")\n    return zip_path\n\ndef _generate_data_dictionary(traits):\n    \"\"\"Generate data dictionary from DataFrame.\"\"\"\n    lines = []\n    for col in traits.columns:\n        dtype = traits[col].dtype\n        lines.append(f\"- `{col}`: {dtype}\")\n    return '\\n'.join(lines)\n\n# Usage\nmetadata = {\n    'experiment': 'Drought stress response 2024',\n    'date': '2024-01-15',\n    'researcher': 'J. Smith',\n    'pipeline': 'DicotPipeline',\n    'n_plants': len(traits['plant_id'].unique()) if 'plant_id' in traits.columns else 1\n}\n\npackage_path = create_analysis_package(traits, metadata)\n</code></pre>"},{"location":"cookbook/exporting-results/#best-practices","title":"Best Practices","text":""},{"location":"cookbook/exporting-results/#1-always-include-metadata","title":"1. Always Include Metadata","text":"<pre><code># Good: metadata included\nexport_with_metadata(traits, \"traits.csv\", metadata={...})\n\n# Less useful: just data\ntraits.to_csv(\"traits.csv\")\n</code></pre>"},{"location":"cookbook/exporting-results/#2-use-multiple-formats","title":"2. Use Multiple Formats","text":"<pre><code># Export in multiple formats for different use cases\ntraits.to_csv(\"traits.csv\", index=False)  # Universal\ntraits.to_excel(\"traits.xlsx\", index=False)  # Spreadsheets\ntraits.to_parquet(\"traits.parquet\")  # Efficient storage\n</code></pre>"},{"location":"cookbook/exporting-results/#3-validate-before-sharing","title":"3. Validate Before Sharing","text":"<pre><code># Always validate before sharing\nvalidation = validate_and_export(traits, \"traits.csv\")\nif not validation['valid']:\n    print(\"Fix issues before sharing!\")\n</code></pre>"},{"location":"cookbook/exporting-results/#next-steps","title":"Next Steps","text":"<ul> <li>See Batch Processing for exporting large datasets</li> <li>Read Custom Traits for specialized export needs</li> <li>Check Filtering Data for data quality before export</li> </ul>"},{"location":"cookbook/filtering-data/","title":"Filtering and Cleaning Data","text":"<p>This recipe shows how to filter and clean root tracking data before trait computation, ensuring high-quality results.</p>"},{"location":"cookbook/filtering-data/#problem","title":"Problem","text":"<p>SLEAP predictions may contain: - Low-confidence tracks - Incomplete root segments - Tracking artifacts - Outlier points</p> <p>These issues can lead to incorrect trait values. Filtering data before analysis improves accuracy.</p>"},{"location":"cookbook/filtering-data/#solution-overview","title":"Solution Overview","text":"<p>Apply filtering at multiple levels: 1. Confidence thresholding: Remove low-confidence predictions 2. Point count filtering: Exclude roots with too few points 3. Outlier detection: Remove anomalous measurements 4. Temporal smoothing: Reduce noise in time series</p>"},{"location":"cookbook/filtering-data/#basic-confidence-filtering","title":"Basic Confidence Filtering","text":""},{"location":"cookbook/filtering-data/#filter-during-loading","title":"Filter During Loading","text":"<pre><code>import sleap_roots as sr\n\n# Set confidence threshold when loading\nseries = sr.Series.load(\n    \"plant\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\",\n    confidence_threshold=0.3  # Default: 0.0 (keep all)\n)\n\nprint(f\"Loaded {len(series.primary_pts[0])} primary root points\")\n</code></pre> <p>Recommended thresholds: - <code>0.1-0.2</code>: Lenient (keep most tracks, some noise) - <code>0.3-0.5</code>: Moderate (good balance) - <code>0.5-0.7</code>: Strict (high quality, may lose data)</p>"},{"location":"cookbook/filtering-data/#post-loading-filtering","title":"Post-Loading Filtering","text":"<pre><code>import numpy as np\n\ndef filter_by_confidence(pts, confidence, threshold=0.3):\n    \"\"\"\n    Filter points below confidence threshold.\n\n    Args:\n        pts: Root coordinates (n, 2)\n        confidence: Confidence scores (n,)\n        threshold: Minimum confidence\n\n    Returns:\n        Filtered points array\n    \"\"\"\n    mask = confidence &gt;= threshold\n    return pts[mask]\n\n# Apply to loaded data\nconfidence_scores = series.get_confidence_scores()\nfiltered_pts = filter_by_confidence(\n    series.primary_pts[0],\n    confidence_scores,\n    threshold=0.4\n)\n</code></pre>"},{"location":"cookbook/filtering-data/#point-count-filtering","title":"Point Count Filtering","text":""},{"location":"cookbook/filtering-data/#filter-incomplete-roots","title":"Filter Incomplete Roots","text":"<pre><code>def filter_short_roots(pts_list, min_points=10):\n    \"\"\"\n    Remove roots with too few points.\n\n    Args:\n        pts_list: List of root coordinate arrays\n        min_points: Minimum number of points required\n\n    Returns:\n        List of roots meeting criteria\n    \"\"\"\n    return [pts for pts in pts_list if len(pts) &gt;= min_points]\n\n# Filter lateral roots\nlateral_pts_list = series.lateral_pts[0]\nvalid_laterals = filter_short_roots(lateral_pts_list, min_points=15)\n\nprint(f\"Kept {len(valid_laterals)}/{len(lateral_pts_list)} lateral roots\")\n</code></pre>"},{"location":"cookbook/filtering-data/#frame-level-filtering","title":"Frame-Level Filtering","text":"<pre><code>def filter_frames_by_point_count(series, min_points=20):\n    \"\"\"\n    Keep only frames with sufficient tracking points.\n\n    Args:\n        series: Series object\n        min_points: Minimum points for primary root\n\n    Returns:\n        List of valid frame indices\n    \"\"\"\n    valid_frames = []\n    for i, pts in enumerate(series.primary_pts):\n        if len(pts) &gt;= min_points:\n            valid_frames.append(i)\n    return valid_frames\n\n# Get valid frames\nvalid_frames = filter_frames_by_point_count(series, min_points=30)\n\n# Process only valid frames\nfor frame_idx in valid_frames:\n    pts = series.primary_pts[frame_idx]\n    # Compute traits for this frame\n</code></pre>"},{"location":"cookbook/filtering-data/#outlier-detection","title":"Outlier Detection","text":""},{"location":"cookbook/filtering-data/#length-based-outliers","title":"Length-Based Outliers","text":"<pre><code>from sleap_roots import lengths\n\ndef detect_length_outliers(lateral_pts_list, std_threshold=3.0):\n    \"\"\"\n    Detect lateral roots with outlier lengths.\n\n    Args:\n        lateral_pts_list: List of lateral root arrays\n        std_threshold: Number of standard deviations for outlier\n\n    Returns:\n        Boolean mask (True = keep, False = outlier)\n    \"\"\"\n    root_lengths = lengths.get_root_lengths(lateral_pts_list)\n\n    mean_length = np.mean(root_lengths)\n    std_length = np.std(root_lengths)\n\n    # Mark outliers (too short or too long)\n    lower_bound = mean_length - std_threshold * std_length\n    upper_bound = mean_length + std_threshold * std_length\n\n    mask = (root_lengths &gt;= lower_bound) &amp; (root_lengths &lt;= upper_bound)\n\n    return mask\n\n# Apply outlier detection\nlateral_pts_list = series.lateral_pts[0]\noutlier_mask = detect_length_outliers(lateral_pts_list, std_threshold=2.5)\nclean_laterals = [pts for pts, keep in zip(lateral_pts_list, outlier_mask) if keep]\n\nprint(f\"Removed {(~outlier_mask).sum()} outliers\")\n</code></pre>"},{"location":"cookbook/filtering-data/#angle-based-outliers","title":"Angle-Based Outliers","text":"<pre><code>from sleap_roots import angles\n\ndef detect_angle_outliers(lateral_pts_list, primary_pts, angle_range=(-90, 90)):\n    \"\"\"\n    Detect lateral roots with unrealistic emergence angles.\n\n    Args:\n        lateral_pts_list: Lateral root arrays\n        primary_pts: Primary root array\n        angle_range: Valid angle range (min, max) in degrees\n\n    Returns:\n        Boolean mask for valid roots\n    \"\"\"\n    mask = []\n\n    for lateral_pts in lateral_pts_list:\n        if len(lateral_pts) &lt; 2:\n            mask.append(False)\n            continue\n\n        angle = angles.get_lateral_root_angle(primary_pts, lateral_pts)\n\n        # Check if angle is in valid range\n        valid = angle_range[0] &lt;= angle &lt;= angle_range[1]\n        mask.append(valid)\n\n    return np.array(mask)\n\n# Filter by angle\nangle_mask = detect_angle_outliers(\n    lateral_pts_list,\n    series.primary_pts[0],\n    angle_range=(-80, 80)  # Most laterals within \u00b180\u00b0\n)\nvalid_laterals = [pts for pts, keep in zip(lateral_pts_list, angle_mask) if keep]\n</code></pre>"},{"location":"cookbook/filtering-data/#temporal-smoothing","title":"Temporal Smoothing","text":""},{"location":"cookbook/filtering-data/#smooth-time-series","title":"Smooth Time Series","text":"<pre><code>from scipy.ndimage import gaussian_filter1d\nimport pandas as pd\n\ndef smooth_trait_timeseries(trait_values, sigma=2.0):\n    \"\"\"\n    Apply Gaussian smoothing to trait time series.\n\n    Args:\n        trait_values: Array of trait values over time\n        sigma: Smoothing parameter (higher = more smoothing)\n\n    Returns:\n        Smoothed trait values\n    \"\"\"\n    return gaussian_filter1d(trait_values, sigma=sigma)\n\n# Example: smooth primary root length over time\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series)\n\n# Smooth lengths\ntraits['primary_length_smooth'] = smooth_trait_timeseries(\n    traits['primary_length'].values,\n    sigma=3.0\n)\n\n# Plot comparison\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.plot(traits['frame'], traits['primary_length'], 'o-', alpha=0.5, label='Raw')\nplt.plot(traits['frame'], traits['primary_length_smooth'], '-', linewidth=2, label='Smoothed')\nplt.xlabel('Frame')\nplt.ylabel('Primary Root Length (pixels)')\nplt.legend()\nplt.title('Effect of Temporal Smoothing')\nplt.show()\n</code></pre>"},{"location":"cookbook/filtering-data/#median-filtering","title":"Median Filtering","text":"<pre><code>from scipy.signal import medfilt\n\ndef median_filter_traits(trait_values, kernel_size=5):\n    \"\"\"\n    Apply median filter to remove spikes.\n\n    Args:\n        trait_values: Trait time series\n        kernel_size: Window size (must be odd)\n\n    Returns:\n        Filtered values\n    \"\"\"\n    return medfilt(trait_values, kernel_size=kernel_size)\n\n# Remove spikes from lateral count\ntraits['lateral_count_filtered'] = median_filter_traits(\n    traits['lateral_count'].values,\n    kernel_size=3\n)\n</code></pre>"},{"location":"cookbook/filtering-data/#complete-filtering-pipeline","title":"Complete Filtering Pipeline","text":""},{"location":"cookbook/filtering-data/#comprehensive-example","title":"Comprehensive Example","text":"<pre><code>import sleap_roots as sr\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d\n\nclass FilteredPipeline(sr.DicotPipeline):\n    \"\"\"DicotPipeline with integrated data filtering.\"\"\"\n\n    def __init__(\n        self,\n        confidence_threshold=0.3,\n        min_primary_points=20,\n        min_lateral_points=5,\n        lateral_length_std=3.0,\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.confidence_threshold = confidence_threshold\n        self.min_primary_points = min_primary_points\n        self.min_lateral_points = min_lateral_points\n        self.lateral_length_std = lateral_length_std\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute traits with filtering.\"\"\"\n\n        # Filter primary root\n        primary_pts = series.get_primary_root_points()\n        if len(primary_pts) &lt; self.min_primary_points:\n            print(f\"Warning: Primary root has only {len(primary_pts)} points\")\n            # Handle insufficient data\n            return pd.DataFrame()  # Return empty or NaN traits\n\n        # Filter lateral roots\n        lateral_pts_list = series.get_lateral_root_points()\n        lateral_pts_list = self._filter_laterals(lateral_pts_list)\n\n        # Create filtered series (optional: wrap in new Series object)\n        # For now, modify in place\n\n        # Compute traits normally\n        traits = super().compute_plant_traits(series, write_csv=False)\n\n        # Post-process: smooth temporal data if multiple frames\n        if len(traits) &gt; 1:\n            traits = self._smooth_traits(traits)\n\n        # Write to CSV if requested\n        if write_csv:\n            output_path = csv_path or f\"{series.series_name}_filtered_traits.csv\"\n            traits.to_csv(output_path, index=False)\n\n        return traits\n\n    def _filter_laterals(self, lateral_pts_list):\n        \"\"\"Apply lateral root filters.\"\"\"\n\n        # 1. Point count filter\n        valid_laterals = [\n            pts for pts in lateral_pts_list\n            if len(pts) &gt;= self.min_lateral_points\n        ]\n\n        if len(valid_laterals) == 0:\n            return []\n\n        # 2. Length outlier filter\n        lengths_array = sr.lengths.get_root_lengths(valid_laterals)\n        mean_len = np.mean(lengths_array)\n        std_len = np.std(lengths_array)\n\n        outlier_mask = np.abs(lengths_array - mean_len) &lt; (self.lateral_length_std * std_len)\n        filtered_laterals = [\n            pts for pts, keep in zip(valid_laterals, outlier_mask)\n            if keep\n        ]\n\n        return filtered_laterals\n\n    def _smooth_traits(self, traits):\n        \"\"\"Smooth traits across frames.\"\"\"\n\n        smoothable_traits = [\n            'primary_length',\n            'lateral_count',\n            'total_length'\n        ]\n\n        for trait in smoothable_traits:\n            if trait in traits.columns:\n                traits[f'{trait}_smooth'] = gaussian_filter1d(\n                    traits[trait].values,\n                    sigma=2.0\n                )\n\n        return traits\n\n# Usage\nseries = sr.Series.load(\n    \"plant\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\",\n    confidence_threshold=0.3  # Filter during load\n)\n\nfiltered_pipeline = FilteredPipeline(\n    confidence_threshold=0.3,\n    min_primary_points=25,\n    min_lateral_points=8,\n    lateral_length_std=2.5\n)\n\ntraits = filtered_pipeline.compute_plant_traits(series, write_csv=True)\nprint(f\"Computed {len(traits)} frames of traits\")\n</code></pre>"},{"location":"cookbook/filtering-data/#quality-metrics","title":"Quality Metrics","text":""},{"location":"cookbook/filtering-data/#assess-data-quality","title":"Assess Data Quality","text":"<pre><code>def compute_quality_metrics(series):\n    \"\"\"\n    Compute metrics indicating data quality.\n\n    Returns:\n        Dictionary of quality metrics\n    \"\"\"\n    metrics = {}\n\n    # Primary root metrics\n    primary_pts = series.primary_pts[0]\n    metrics['primary_point_count'] = len(primary_pts)\n    metrics['primary_completeness'] = len(primary_pts) / 200  # Assume 200 is ideal\n\n    # Lateral root metrics\n    lateral_pts_list = series.lateral_pts[0]\n    metrics['lateral_count'] = len(lateral_pts_list)\n    metrics['lateral_mean_points'] = np.mean([len(pts) for pts in lateral_pts_list])\n\n    # Tracking continuity\n    gaps = []\n    for i in range(len(primary_pts) - 1):\n        dist = np.linalg.norm(primary_pts[i+1] - primary_pts[i])\n        gaps.append(dist)\n\n    metrics['mean_gap'] = np.mean(gaps)\n    metrics['max_gap'] = np.max(gaps)\n    metrics['gap_std'] = np.std(gaps)\n\n    # Quality score (0-1)\n    quality_score = (\n        min(metrics['primary_point_count'] / 200, 1.0) * 0.5 +\n        min(metrics['lateral_count'] / 10, 1.0) * 0.3 +\n        (1.0 - min(metrics['gap_std'] / 10, 1.0)) * 0.2\n    )\n    metrics['quality_score'] = quality_score\n\n    return metrics\n\n# Assess quality\nquality = compute_quality_metrics(series)\nprint(f\"Data quality score: {quality['quality_score']:.2f}\")\n\nif quality['quality_score'] &lt; 0.5:\n    print(\"Warning: Low data quality, consider re-tracking in SLEAP\")\n</code></pre>"},{"location":"cookbook/filtering-data/#best-practices","title":"Best Practices","text":""},{"location":"cookbook/filtering-data/#1-filter-early","title":"1. Filter Early","text":"<p>Apply confidence thresholds during loading: <pre><code># Good: filter during load\nseries = sr.Series.load(..., confidence_threshold=0.3)\n\n# Less efficient: filter after loading\n# (already loaded low-confidence points)\n</code></pre></p>"},{"location":"cookbook/filtering-data/#2-document-filtering","title":"2. Document Filtering","text":"<p>Keep track of filtering parameters: <pre><code>metadata = {\n    'confidence_threshold': 0.3,\n    'min_primary_points': 20,\n    'min_lateral_points': 5,\n    'smoothing_sigma': 2.0,\n    'date_filtered': '2024-01-15'\n}\n\n# Save with traits\ntraits['metadata'] = str(metadata)\ntraits.to_csv('traits_with_metadata.csv')\n</code></pre></p>"},{"location":"cookbook/filtering-data/#3-validate-results","title":"3. Validate Results","text":"<p>Check filtered vs. unfiltered: <pre><code># Compare filtered vs. unfiltered\ntraits_raw = pipeline.compute_plant_traits(series_unfiltered)\ntraits_filtered = filtered_pipeline.compute_plant_traits(series)\n\ncomparison = pd.DataFrame({\n    'trait': traits_raw.columns,\n    'raw_mean': traits_raw.mean(),\n    'filtered_mean': traits_filtered.mean(),\n    'difference': traits_raw.mean() - traits_filtered.mean()\n})\n\nprint(comparison)\n</code></pre></p>"},{"location":"cookbook/filtering-data/#troubleshooting","title":"Troubleshooting","text":"<p>Too much data removed: - Lower confidence threshold - Reduce min_points requirements - Relax outlier detection (higher std_threshold)</p> <p>Still have noisy data: - Increase confidence threshold - Apply more aggressive outlier detection - Use temporal smoothing - Consider re-tracking in SLEAP with better model</p> <p>Temporal smoothing causes lag: - Reduce sigma parameter - Use median filter instead of Gaussian - Apply smoothing only to specific traits</p>"},{"location":"cookbook/filtering-data/#next-steps","title":"Next Steps","text":"<ul> <li>See Batch Processing for filtering large datasets</li> <li>Read Troubleshooting for common data issues</li> <li>Check Custom Traits for filtered trait computations</li> </ul>"},{"location":"dev/adding-traits/","title":"Adding Traits","text":"<p>This guide explains how to add new trait computations to sleap-roots, from initial implementation to testing and documentation.</p>"},{"location":"dev/adding-traits/#overview","title":"Overview","text":"<p>Adding a new trait involves:</p> <ol> <li>Implementing the trait computation function</li> <li>Adding it to the appropriate module</li> <li>Writing comprehensive tests</li> <li>Documenting the trait</li> <li>Integrating it into pipelines</li> <li>Adding to trait reference</li> </ol>"},{"location":"dev/adding-traits/#trait-computation-principles","title":"Trait Computation Principles","text":""},{"location":"dev/adding-traits/#design-philosophy","title":"Design Philosophy","text":"<p>Good traits are: - Biologically meaningful: Captures relevant morphological feature - Reproducible: Same inputs always give same outputs - Well-documented: Clear description, units, and formula - Tested: Comprehensive unit and integration tests - Efficient: Vectorized when possible, reasonable performance</p> <p>Avoid: - Overly complex computations without clear biological interpretation - Traits that are just combinations of existing traits (do this at analysis time) - Platform-specific or non-portable code</p>"},{"location":"dev/adding-traits/#trait-categories","title":"Trait Categories","text":"<p>sleap-roots organizes traits into modules:</p> <ul> <li><code>lengths.py</code>: Length-based measurements</li> <li><code>angles.py</code>: Angular measurements</li> <li><code>tips.py</code>: Root tip-related traits</li> <li><code>bases.py</code>: Root base-related traits</li> <li><code>convhull.py</code>: Convex hull and area metrics</li> <li><code>networklength.py</code>: Network-level traits</li> <li><code>monocots.py</code>: Monocot-specific traits</li> <li><code>trait_pipelines.py</code>: Complete pipeline implementations</li> </ul>"},{"location":"dev/adding-traits/#step-by-step-adding-a-new-trait","title":"Step-by-Step: Adding a New Trait","text":""},{"location":"dev/adding-traits/#step-1-implement-the-function","title":"Step 1: Implement the Function","text":"<p>Create your trait computation function in the appropriate module.</p> <p>Example: Adding a \"root sinuosity\" trait to <code>lengths.py</code></p> <pre><code># sleap_roots/lengths.py\n\nimport numpy as np\nfrom typing import Union\n\ndef get_root_sinuosity(pts: np.ndarray) -&gt; float:\n    \"\"\"\n    Compute root sinuosity (tortuosity index).\n\n    Sinuosity measures how much a root deviates from a straight line,\n    defined as the ratio of path length to Euclidean distance.\n\n    Args:\n        pts: Array of shape (n, 2) containing root coordinates from\n            base to tip.\n\n    Returns:\n        Sinuosity value. 1.0 indicates perfectly straight root,\n        higher values indicate more curved/tortuous roots.\n\n    Raises:\n        ValueError: If pts has fewer than 2 points.\n\n    Example:\n        &gt;&gt;&gt; pts = np.array([[0, 0], [1, 0], [2, 0]])  # Straight line\n        &gt;&gt;&gt; get_root_sinuosity(pts)\n        1.0\n\n        &gt;&gt;&gt; pts = np.array([[0, 0], [1, 1], [2, 0]])  # Curved\n        &gt;&gt;&gt; get_root_sinuosity(pts)\n        1.414...\n\n    Note:\n        - Value of 1.0 = perfectly straight\n        - Higher values = more tortuous/sinuous\n        - Sensitive to tracking noise; consider smoothing pts first\n    \"\"\"\n    if len(pts) &lt; 2:\n        raise ValueError(\"Need at least 2 points to compute sinuosity\")\n\n    # Path length: sum of segment lengths\n    segment_lengths = np.linalg.norm(np.diff(pts, axis=0), axis=1)\n    path_length = np.sum(segment_lengths)\n\n    # Euclidean distance: straight line from base to tip\n    euclidean_distance = np.linalg.norm(pts[-1] - pts[0])\n\n    # Handle edge case: coincident points\n    if euclidean_distance == 0:\n        return np.inf if path_length &gt; 0 else 1.0\n\n    return path_length / euclidean_distance\n</code></pre>"},{"location":"dev/adding-traits/#step-2-write-tests","title":"Step 2: Write Tests","text":"<p>Create comprehensive tests in the corresponding test file.</p> <pre><code># tests/test_lengths.py\n\nimport numpy as np\nimport pytest\nfrom sleap_roots import lengths\n\nclass TestRootSinuosity:\n    \"\"\"Tests for get_root_sinuosity function.\"\"\"\n\n    def test_straight_line(self):\n        \"\"\"Straight line should have sinuosity of 1.0.\"\"\"\n        pts = np.array([[0, 0], [1, 0], [2, 0], [3, 0]])\n        sinuosity = lengths.get_root_sinuosity(pts)\n        assert np.isclose(sinuosity, 1.0)\n\n    def test_curved_path(self):\n        \"\"\"Curved path should have sinuosity &gt; 1.0.\"\"\"\n        pts = np.array([[0, 0], [1, 1], [2, 0]])\n        sinuosity = lengths.get_root_sinuosity(pts)\n        assert sinuosity &gt; 1.0\n\n    def test_circular_path(self):\n        \"\"\"Circular/highly curved path should have high sinuosity.\"\"\"\n        # Create semicircle\n        theta = np.linspace(0, np.pi, 50)\n        pts = np.column_stack([np.cos(theta), np.sin(theta)])\n\n        sinuosity = lengths.get_root_sinuosity(pts)\n        expected = np.pi / 2  # Semicircle path length / diameter\n        assert np.isclose(sinuosity, expected, rtol=0.1)\n\n    def test_minimum_points(self):\n        \"\"\"Should work with exactly 2 points.\"\"\"\n        pts = np.array([[0, 0], [1, 1]])\n        sinuosity = lengths.get_root_sinuosity(pts)\n        assert np.isclose(sinuosity, 1.0)\n\n    def test_insufficient_points(self):\n        \"\"\"Should raise error with &lt; 2 points.\"\"\"\n        pts = np.array([[0, 0]])\n        with pytest.raises(ValueError, match=\"at least 2 points\"):\n            lengths.get_root_sinuosity(pts)\n\n    def test_coincident_points(self):\n        \"\"\"Should handle case where base == tip.\"\"\"\n        pts = np.array([[1, 1], [1.1, 1.05], [1, 1]])  # Returns to start\n        sinuosity = lengths.get_root_sinuosity(pts)\n        assert sinuosity == np.inf  # Path length &gt; 0 but Euclidean = 0\n\n    def test_single_point_repeated(self):\n        \"\"\"All same point should return 1.0.\"\"\"\n        pts = np.array([[5, 5], [5, 5], [5, 5]])\n        sinuosity = lengths.get_root_sinuosity(pts)\n        assert sinuosity == 1.0\n\n    def test_numerical_precision(self):\n        \"\"\"Test with realistic noisy data.\"\"\"\n        # Create slightly noisy straight line\n        np.random.seed(42)\n        x = np.linspace(0, 10, 100)\n        y = np.random.normal(0, 0.1, 100)  # Small noise\n        pts = np.column_stack([x, y])\n\n        sinuosity = lengths.get_root_sinuosity(pts)\n        assert 1.0 &lt;= sinuosity &lt;= 1.1  # Should be close to 1.0\n\n    def test_different_scales(self):\n        \"\"\"Sinuosity should be scale-invariant.\"\"\"\n        pts_small = np.array([[0, 0], [1, 1], [2, 0]])\n        pts_large = pts_small * 100\n\n        sin_small = lengths.get_root_sinuosity(pts_small)\n        sin_large = lengths.get_root_sinuosity(pts_large)\n\n        assert np.isclose(sin_small, sin_large)\n\n    def test_real_world_data(self, test_data_fixture):\n        \"\"\"Test with actual SLEAP tracking data.\"\"\"\n        series = test_data_fixture\n        pts = series.primary_pts[0]\n\n        sinuosity = lengths.get_root_sinuosity(pts)\n\n        # Sanity checks for real data\n        assert 1.0 &lt;= sinuosity &lt;= 5.0  # Reasonable range\n        assert not np.isnan(sinuosity)\n        assert not np.isinf(sinuosity)\n</code></pre>"},{"location":"dev/adding-traits/#step-3-document-the-trait","title":"Step 3: Document the Trait","text":"<p>Add the trait to the trait reference documentation.</p> <p><pre><code>&lt;!-- docs/guides/trait-reference.md --&gt;\n\n#### Root Sinuosity\n\n**Module**: `sleap_roots.lengths.get_root_sinuosity`\n\n**Description**: Measures root tortuosity as the ratio of actual path length\nto straight-line distance from base to tip.\n\n**Formula**:\n$$\n\\\\text{sinuosity} = \\\\frac{\\\\text{path length}}{\\\\text{Euclidean distance}}\n$$\n\n**Units**: Dimensionless ratio\n\n**Range**: [1.0, \u221e)\n- 1.0 = perfectly straight root\n- 1.5 = moderately curved\n- 2.0+ = highly tortuous\n\n**Biological Relevance**: Sinuosity reflects root growth patterns and\nenvironmental responses. Higher sinuosity may indicate:\n- Obstacle avoidance behavior\n- Resource seeking (e.g., following nutrient patches)\n- Response to soil compaction or impedance\n- Gravitropic or thigmotropic responses\n\n**Interpretation**:\n- **Low sinuosity (1.0-1.2)**: Direct, efficient growth path\n- **Medium sinuosity (1.2-1.8)**: Moderate curvature, normal exploration\n- **High sinuosity (&gt;1.8)**: Highly curved, possibly stress response\n\n**Limitations**:\n- Sensitive to tracking noise (consider smoothing)\n- May be affected by frame rate/sampling density\n- Less meaningful for very short roots\n\n**Related Traits**:\n- `primary_length`: Path length component\n- `primary_euclidean_length`: Straight-line distance component\n\n**Example**:\n```python\nimport sleap_roots as sr\n\nseries = sr.Series.load(...)\npts = series.primary_pts[0]\nsinuosity = sr.lengths.get_root_sinuosity(pts)\nprint(f\"Root sinuosity: {sinuosity:.2f}\")\n</code></pre> <pre><code>### Step 4: Integrate into Pipelines\n\nAdd the new trait to relevant pipelines.\n\n```python\n# sleap_roots/trait_pipelines.py\n\nclass DicotPipeline:\n    \"\"\"Pipeline for dicot root systems.\"\"\"\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute all dicot traits including new sinuosity trait.\"\"\"\n\n        traits = {}\n\n        # Get root points\n        primary_pts = series.get_primary_root_points()\n\n        # Existing traits\n        traits['primary_length'] = lengths.get_root_lengths([primary_pts])[0]\n        # ... other traits ...\n\n        # NEW TRAIT: Add sinuosity\n        traits['primary_sinuosity'] = lengths.get_root_sinuosity(primary_pts)\n\n        # ... rest of pipeline ...\n\n        return pd.DataFrame([traits])\n</code></pre></p>"},{"location":"dev/adding-traits/#step-5-add-to-trait-definitions","title":"Step 5: Add to Trait Definitions","text":"<p>Update trait metadata for documentation generation.</p> <pre><code># sleap_roots/trait_definitions.py (if exists)\n\nTRAIT_DEFINITIONS = {\n    'primary_sinuosity': {\n        'name': 'Primary Root Sinuosity',\n        'description': 'Ratio of root path length to Euclidean distance',\n        'units': 'dimensionless',\n        'range': '[1.0, inf)',\n        'formula': 'path_length / euclidean_distance',\n        'module': 'sleap_roots.lengths',\n        'function': 'get_root_sinuosity',\n        'category': 'morphology',\n        'biological_relevance': 'Indicates root tortuosity and growth pattern'\n    }\n}\n</code></pre>"},{"location":"dev/adding-traits/#complex-example-multi-value-trait","title":"Complex Example: Multi-Value Trait","text":"<p>Some traits return arrays or multiple values. Here's how to handle them:</p> <pre><code># sleap_roots/angles.py\n\ndef get_lateral_emergence_angles(\n    primary_pts: np.ndarray,\n    lateral_pts_list: list[np.ndarray]\n) -&gt; tuple[np.ndarray, float, float]:\n    \"\"\"\n    Compute emergence angles for all lateral roots.\n\n    Args:\n        primary_pts: Primary root coordinates (n, 2)\n        lateral_pts_list: List of lateral root coordinate arrays\n\n    Returns:\n        Tuple of:\n        - angles: Array of emergence angles for each lateral (degrees)\n        - mean_angle: Mean emergence angle (degrees)\n        - angle_std: Standard deviation of angles (degrees)\n\n    Example:\n        &gt;&gt;&gt; angles, mean, std = get_lateral_emergence_angles(primary, laterals)\n        &gt;&gt;&gt; print(f\"Mean emergence angle: {mean:.1f}\u00b0 \u00b1 {std:.1f}\u00b0\")\n    \"\"\"\n    angles = []\n\n    for lateral_pts in lateral_pts_list:\n        if len(lateral_pts) &lt; 2:\n            continue\n\n        # Get base and direction points\n        base_pt = lateral_pts[0]\n        direction_pt = lateral_pts[min(5, len(lateral_pts)-1)]\n\n        # Compute angle relative to primary axis\n        lateral_vector = direction_pt - base_pt\n        primary_vector = primary_pts[-1] - primary_pts[0]\n\n        angle = compute_angle_between_vectors(lateral_vector, primary_vector)\n        angles.append(angle)\n\n    angles = np.array(angles)\n    mean_angle = np.mean(angles) if len(angles) &gt; 0 else np.nan\n    angle_std = np.std(angles) if len(angles) &gt; 0 else np.nan\n\n    return angles, mean_angle, angle_std\n</code></pre> <p>Using in pipeline:</p> <pre><code># In pipeline\nangles, mean_angle, angle_std = angles.get_lateral_emergence_angles(\n    primary_pts, lateral_pts_list\n)\n\ntraits['lateral_emergence_angles'] = angles  # Store array\ntraits['mean_emergence_angle'] = mean_angle  # Store scalar\ntraits['emergence_angle_std'] = angle_std    # Store scalar\n</code></pre>"},{"location":"dev/adding-traits/#testing-strategy","title":"Testing Strategy","text":""},{"location":"dev/adding-traits/#unit-tests","title":"Unit Tests","text":"<p>Test individual functions in isolation:</p> <pre><code>def test_basic_functionality():\n    \"\"\"Test with simple, known input.\"\"\"\n    pts = np.array([[0, 0], [1, 0]])\n    result = my_trait_function(pts)\n    assert result == expected_value\n\ndef test_edge_cases():\n    \"\"\"Test edge cases.\"\"\"\n    # Empty input\n    # Single point\n    # Coincident points\n    # Very large/small values\n\ndef test_error_handling():\n    \"\"\"Test that errors are raised appropriately.\"\"\"\n    with pytest.raises(ValueError):\n        my_trait_function(invalid_input)\n</code></pre>"},{"location":"dev/adding-traits/#integration-tests","title":"Integration Tests","text":"<p>Test traits within pipelines:</p> <pre><code>def test_trait_in_pipeline(test_series):\n    \"\"\"Test new trait integrates correctly in pipeline.\"\"\"\n    pipeline = sr.DicotPipeline()\n    traits = pipeline.compute_plant_traits(test_series)\n\n    # Verify trait is computed\n    assert 'my_new_trait' in traits.columns\n\n    # Verify trait value is reasonable\n    value = traits['my_new_trait'].iloc[0]\n    assert not np.isnan(value)\n    assert 0 &lt;= value &lt;= 100  # Expected range\n</code></pre>"},{"location":"dev/adding-traits/#performance-tests","title":"Performance Tests","text":"<p>For computationally intensive traits:</p> <pre><code>import time\n\ndef test_performance():\n    \"\"\"Ensure trait computation is reasonably fast.\"\"\"\n    # Large but realistic input\n    pts = np.random.rand(1000, 2)\n\n    start = time.time()\n    result = my_trait_function(pts)\n    elapsed = time.time() - start\n\n    assert elapsed &lt; 0.1  # Should complete in &lt;100ms\n</code></pre>"},{"location":"dev/adding-traits/#code-style-guidelines","title":"Code Style Guidelines","text":""},{"location":"dev/adding-traits/#function-signatures","title":"Function Signatures","text":"<pre><code>def my_trait_function(\n    pts: np.ndarray,\n    param1: float = 1.0,\n    param2: Optional[str] = None\n) -&gt; Union[float, np.ndarray]:\n    \"\"\"\n    One-line summary.\n\n    Detailed description explaining what the trait measures,\n    biological relevance, and any important caveats.\n\n    Args:\n        pts: Root coordinates (n, 2) from base to tip.\n        param1: Description of parameter 1 (default: 1.0).\n        param2: Optional description (default: None).\n\n    Returns:\n        Trait value(s) with units and expected range.\n\n    Raises:\n        ValueError: When and why this error occurs.\n\n    Example:\n        &gt;&gt;&gt; pts = np.array([[0, 0], [1, 1]])\n        &gt;&gt;&gt; result = my_trait_function(pts)\n        &gt;&gt;&gt; print(result)\n        1.414\n\n    Note:\n        Any important implementation details or limitations.\n    \"\"\"\n    # Implementation\n    pass\n</code></pre>"},{"location":"dev/adding-traits/#type-hints","title":"Type Hints","text":"<p>Always use type hints:</p> <pre><code>from typing import Union, Optional, Tuple, List\nimport numpy as np\n\ndef process_roots(\n    primary_pts: np.ndarray,\n    lateral_pts_list: List[np.ndarray],\n    threshold: float = 0.5\n) -&gt; Tuple[float, int]:\n    \"\"\"Type hints make code self-documenting and enable static checking.\"\"\"\n    pass\n</code></pre>"},{"location":"dev/adding-traits/#docstring-style","title":"Docstring Style","text":"<p>Follow Google style docstrings:</p> <pre><code>def example_function(arg1: int, arg2: str = \"default\") -&gt; bool:\n    \"\"\"\n    Short one-line summary ending with period.\n\n    Longer description providing context, explaining what the function\n    does, and any important details.\n\n    Args:\n        arg1: Description of arg1.\n        arg2: Description of arg2 (default: \"default\").\n\n    Returns:\n        Description of return value.\n\n    Raises:\n        ValueError: When arg1 is negative.\n        TypeError: When arg2 is not a string.\n\n    Example:\n        &gt;&gt;&gt; result = example_function(5, \"test\")\n        &gt;&gt;&gt; print(result)\n        True\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dev/adding-traits/#vectorization-tips","title":"Vectorization Tips","text":"<p>Vectorize computations for better performance:</p>"},{"location":"dev/adding-traits/#before-slow","title":"Before (Slow)","text":"<pre><code>def compute_lengths_slow(pts_list):\n    \"\"\"Iterative computation.\"\"\"\n    lengths = []\n    for pts in pts_list:\n        length = 0\n        for i in range(len(pts) - 1):\n            segment = pts[i+1] - pts[i]\n            length += np.linalg.norm(segment)\n        lengths.append(length)\n    return np.array(lengths)\n</code></pre>"},{"location":"dev/adding-traits/#after-fast","title":"After (Fast)","text":"<pre><code>def compute_lengths_fast(pts_list):\n    \"\"\"Vectorized computation.\"\"\"\n    lengths = []\n    for pts in pts_list:\n        # Vectorized: compute all segments at once\n        segments = np.diff(pts, axis=0)\n        length = np.sum(np.linalg.norm(segments, axis=1))\n        lengths.append(length)\n    return np.array(lengths)\n</code></pre>"},{"location":"dev/adding-traits/#contributing-your-trait","title":"Contributing Your Trait","text":"<p>To contribute your new trait to sleap-roots:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b add-sinuosity-trait</code></li> <li>Implement trait with tests and documentation</li> <li>Run all tests: <code>pytest tests/ -v</code></li> <li>Run code quality checks:    <pre><code>black sleap_roots tests\npydocstyle sleap_roots/\n</code></pre></li> <li>Create pull request with:</li> <li>Clear description of the new trait</li> <li>Biological motivation</li> <li>Test results</li> <li>Documentation updates</li> </ol>"},{"location":"dev/adding-traits/#next-steps","title":"Next Steps","text":"<ul> <li>Review Testing Guide for comprehensive testing strategies</li> <li>See Code Style for style guidelines</li> <li>Read Architecture for module organization</li> <li>Check Contributing for PR process</li> <li>Explore Trait Reference for existing traits</li> </ul>"},{"location":"dev/architecture/","title":"Architecture","text":"<p>Architecture documentation coming soon.</p>"},{"location":"dev/benchmarking/","title":"Performance Benchmarking Guide","text":"<p>This guide explains how to run, interpret, and add performance benchmarks for sleap-roots trait extraction pipelines.</p>"},{"location":"dev/benchmarking/#overview","title":"Overview","text":"<p>sleap-roots uses pytest-benchmark to measure trait extraction performance. Benchmarks provide:</p> <ul> <li>Statistical rigor: Multiple iterations with mean, stddev, min, max, percentiles</li> <li>Regression detection: Track performance changes over time</li> <li>Optimization guidance: Identify bottlenecks for targeted improvements</li> <li>User expectations: Document actual performance on standard hardware</li> </ul>"},{"location":"dev/benchmarking/#running-benchmarks-locally","title":"Running Benchmarks Locally","text":""},{"location":"dev/benchmarking/#run-all-benchmarks","title":"Run all benchmarks","text":"<pre><code>uv run pytest tests/benchmarks/ --benchmark-only\n</code></pre>"},{"location":"dev/benchmarking/#run-specific-benchmark","title":"Run specific benchmark","text":"<pre><code>uv run pytest tests/benchmarks/test_pipeline_performance.py::TestSinglePlantPipelines::test_dicot_pipeline_performance --benchmark-only\n</code></pre>"},{"location":"dev/benchmarking/#compare-with-previous-run","title":"Compare with previous run","text":"<pre><code># First run - save baseline\nuv run pytest tests/benchmarks/ --benchmark-only --benchmark-save=baseline\n\n# Make code changes...\n\n# Compare against baseline\nuv run pytest tests/benchmarks/ --benchmark-only --benchmark-compare=baseline\n</code></pre>"},{"location":"dev/benchmarking/#generate-histogram","title":"Generate histogram","text":"<pre><code>uv run pytest tests/benchmarks/ --benchmark-only --benchmark-histogram=benchmark_hist\n</code></pre> <p>This creates <code>benchmark_hist.svg</code> showing performance distribution.</p>"},{"location":"dev/benchmarking/#interpreting-results","title":"Interpreting Results","text":""},{"location":"dev/benchmarking/#understanding-the-output","title":"Understanding the output","text":"<pre><code>----------------------------------------- benchmark: 7 tests ----------------------------------------\nName (time in ms)                                    Min       Max      Mean    StdDev    Median\n----------------------------------------------------------------------------------------------------\ntest_dicot_pipeline_performance                  125.32    156.78    138.45      8.23    136.92\ntest_younger_monocot_pipeline_performance        102.45    128.34    115.67      7.12    114.23\ntest_multiple_dicot_pipeline_performance         456.78    523.12    489.34     18.45    487.56\n----------------------------------------------------------------------------------------------------\n</code></pre> <p>Key metrics: - Mean: Average execution time (most important for typical performance) - StdDev: Standard deviation (lower is more consistent) - Min/Max: Best and worst case times - Median: Middle value (less affected by outliers)</p>"},{"location":"dev/benchmarking/#whats-good-performance","title":"What's good performance?","text":"<p>Based on the published paper (Berrigan et al., 2024):</p> Pipeline Type Expected Time Hardware Single plant pipelines 0.1-0.5s per plant GitHub Actions Ubuntu 22.04 Multiple plant pipelines 0.5-2s (varies with plant count) GitHub Actions Ubuntu 22.04 <p>Note: Local performance may vary based on your CPU, available memory, and system load.</p>"},{"location":"dev/benchmarking/#performance-vs-profiling","title":"Performance vs. Profiling","text":"<ul> <li>Benchmarks (what we have): Measure end-to-end execution time with statistical rigor</li> <li>Profiling (different tools): Identify which functions are slow within a benchmark</li> </ul> <p>If a benchmark shows poor performance, use profiling tools to investigate:</p> <pre><code># Profile a slow pipeline\nuv run python -m cProfile -o profile.stats -c \"\nimport sleap_roots as sr\nseries = sr.Series.load('plant', primary_path='primary.slp', lateral_path='lateral.slp')\npipeline = sr.DicotPipeline()\npipeline.fit_series(series)\n\"\n\n# Analyze profile\nuv run python -m pstats profile.stats\n</code></pre>"},{"location":"dev/benchmarking/#adding-new-benchmarks","title":"Adding New Benchmarks","text":""},{"location":"dev/benchmarking/#1-identify-what-to-benchmark","title":"1. Identify what to benchmark","text":"<p>Good candidates: - New pipeline classes - Alternative implementations of existing algorithms - Performance-critical trait computations</p> <p>Don't benchmark: - Individual helper functions (too granular) - I/O operations (data loading - too variable) - Plotting/visualization (not core workflow)</p>"},{"location":"dev/benchmarking/#2-write-the-benchmark","title":"2. Write the benchmark","text":"<p>Add to <code>tests/benchmarks/test_pipeline_performance.py</code>:</p> <pre><code>def test_my_new_pipeline_performance(\n    self,\n    benchmark,\n    test_data_fixture,  # Reuse existing fixtures\n):\n    \"\"\"Benchmark MyNewPipeline.fit_series().\n\n    Dataset: Description of test data\n    Expected: ~X.X-X.Xs per plant on GitHub Actions runners\n    \"\"\"\n    series = sr.Series.load(\n        \"my_test_plant\",\n        primary_path=test_data_fixture,\n    )\n    pipeline = sr.MyNewPipeline()\n\n    # benchmark() calls the function multiple times\n    result = benchmark(pipeline.fit_series, series)\n\n    # Sanity check: ensure it worked\n    assert result is not None\n    assert \"my_expected_trait\" in result\n</code></pre>"},{"location":"dev/benchmarking/#3-run-and-document","title":"3. Run and document","text":"<pre><code># Run your new benchmark\nuv run pytest tests/benchmarks/test_pipeline_performance.py::test_my_new_pipeline_performance --benchmark-only\n\n# Document expected performance in the docstring\n# Update docs/api/core/pipelines.md if it's a new pipeline\n</code></pre>"},{"location":"dev/benchmarking/#ci-integration","title":"CI Integration","text":"<p>Benchmarks run automatically in two contexts:</p>"},{"location":"dev/benchmarking/#1-main-branch-baseline-storage","title":"1. Main Branch (Baseline Storage)","text":"<p>On pushes to <code>main</code> branch:</p> <ol> <li>When: After merging PRs to main</li> <li>Where: Ubuntu 22.04 runners (standardized environment)</li> <li>Output: Baseline stored in <code>.benchmarks/baselines/main.json</code> (committed to repo)</li> <li>Purpose: Create baseline for comparing future PRs</li> <li>History: Results also saved to <code>.benchmarks/history/&lt;date&gt;.json</code> for trends</li> </ol>"},{"location":"dev/benchmarking/#2-pull-requests-regression-detection","title":"2. Pull Requests (Regression Detection)","text":"<p>On all pull requests:</p> <ol> <li>When: Automatically on every PR</li> <li>What: Compares PR benchmarks against main branch baseline</li> <li>Comment: Posts/updates PR comment with comparison table</li> <li>Threshold: Fails CI if any benchmark regresses &gt;15%</li> <li>Artifacts: Uploads <code>benchmark-results.json</code> and <code>benchmark-comparison.md</code> (30-day retention)</li> </ol>"},{"location":"dev/benchmarking/#viewing-ci-benchmark-results","title":"Viewing CI benchmark results","text":"<p>For main branch: 1. Go to GitHub Actions for the commit 2. Find the \"Performance Benchmarks\" job 3. View the \"Display benchmark results\" step for summary 4. Check <code>.benchmarks/baselines/main.json</code> in repo for baseline</p> <p>For pull requests: 1. Check the automated PR comment with benchmark comparison table 2. Review the \"PR Benchmark Comparison\" job status 3. Download artifacts if detailed analysis needed:    <pre><code>gh run list --limit 5\ngh run download &lt;run-id&gt; --name pr-benchmark-results\n</code></pre></p>"},{"location":"dev/benchmarking/#pr-workflow-benchmark-regression-detection","title":"PR Workflow: Benchmark Regression Detection","text":"<p>When you open a PR, benchmarks run automatically and post a comparison comment.</p>"},{"location":"dev/benchmarking/#understanding-the-pr-comment","title":"Understanding the PR Comment","text":"<p>The benchmark bot posts a comment like this:</p> <pre><code>## \ud83d\udcca Benchmark Results\n\n| Benchmark | Main | PR | Change | Status |\n|-----------|------|-----|--------|--------|\n| test_dicot_pipeline_performance | 138.5ms | 142.1ms | +2.6% | \u2705 |\n| test_younger_monocot_pipeline_performance | 115.7ms | 110.3ms | -4.7% | \u2705 |\n| test_lateral_root_pipeline_performance | 202.3ms | 235.8ms | +16.5% | \u26a0\ufe0f |\n</code></pre> <p>Status indicators: - \u2705 OK: Change within acceptable range (&lt;15% regression) - \ud83d\ude80 Improvement: &gt;5% faster than baseline - \u26a0\ufe0f Regression: &gt;15% slower (fails CI) - \ud83c\udd95 New: Benchmark doesn't exist in baseline</p>"},{"location":"dev/benchmarking/#regression-threshold","title":"Regression Threshold","text":"<p>Default: 15% (configurable via <code>BENCHMARK_MAX_REGRESSION</code> env var)</p> <p>Why 15%? - Accounts for CI runner variance (~5-10%) - Catches meaningful regressions - Avoids false positives from noise</p>"},{"location":"dev/benchmarking/#what-to-do-about-regressions","title":"What to do about regressions","text":""},{"location":"dev/benchmarking/#if-your-pr-has-regressions-15","title":"\u26a0\ufe0f If your PR has regressions &gt;15%:","text":"<ol> <li> <p>Understand why:    <pre><code># Checkout your PR branch\ngh pr checkout &lt;number&gt;\n\n# Profile the slow benchmark\nuv run pytest tests/benchmarks/test_pipeline_performance.py::test_lateral_root_pipeline_performance --benchmark-only -v\n</code></pre></p> </li> <li> <p>Determine if justified:</p> </li> <li>Is this expected from your algorithm change?</li> <li>Does accuracy improvement outweigh performance cost?</li> <li> <p>Is this a temporary regression (refactoring in progress)?</p> </li> <li> <p>Options:</p> </li> <li>Fix it: Optimize the code to reduce regression</li> <li>Justify it: Document why regression is acceptable in PR description</li> <li>Split it: Defer optimization to follow-up PR if algorithm change is necessary</li> </ol>"},{"location":"dev/benchmarking/#if-regressions-are-acceptable","title":"\u2705 If regressions are acceptable:","text":"<p>Add explanation to PR description: <pre><code>## Performance Note\n\nThe 16.5% regression in `test_lateral_root_pipeline_performance` is expected because:\n- New validation step adds safety checks for edge cases\n- Accuracy improved from 92% to 98% on test dataset\n- Performance still within acceptable range (235ms vs. 202ms on CI)\n- Optimization tracked in issue #XXX\n</code></pre></p>"},{"location":"dev/benchmarking/#if-you-improved-performance","title":"\ud83d\ude80 If you improved performance:","text":"<p>Great! Note it in the PR description and the bot will highlight it automatically.</p>"},{"location":"dev/benchmarking/#for-reviewers","title":"For Reviewers","text":"<p>When reviewing PRs with benchmark results:</p> <ol> <li>Check the automated comment - It appears shortly after benchmarks run</li> <li>Evaluate regressions - Are they justified or concerning?</li> <li>Review artifacts - Download for detailed analysis if needed:    <pre><code>gh run download &lt;run-id&gt; --name pr-benchmark-results\ncat benchmark-comparison.md\n</code></pre></li> <li>Request optimization - If large unexplained regressions exist</li> </ol> <p>See <code>.claude/commands/review-pr.md</code> for detailed review guidance.</p>"},{"location":"dev/benchmarking/#baseline-management","title":"Baseline Management","text":"<p>Baselines are automatically managed:</p> <ul> <li>Created: When benchmarks run on main branch after PR merge</li> <li>Updated: On every push to main (with <code>[skip ci]</code> to avoid loops)</li> <li>Stored: In <code>.benchmarks/baselines/main.json</code> (committed to repo)</li> <li>Cleaned: Old commit-specific baselines removed after 90 days</li> </ul> <p>Note: The first PR with benchmarks will show \"No baseline\" - this is expected. The baseline is created after merging to main.</p>"},{"location":"dev/benchmarking/#best-practices","title":"Best Practices","text":""},{"location":"dev/benchmarking/#do","title":"DO:","text":"<ul> <li>\u2705 Use real test data (from <code>tests/data/</code>)</li> <li>\u2705 Document expected performance in docstrings</li> <li>\u2705 Include hardware context (GitHub Actions vs. local)</li> <li>\u2705 Focus on end-user-facing operations (<code>fit_series()</code>)</li> <li>\u2705 Run multiple iterations (pytest-benchmark does this automatically)</li> </ul>"},{"location":"dev/benchmarking/#dont","title":"DON'T:","text":"<ul> <li>\u274c Optimize for benchmarks at the expense of correctness</li> <li>\u274c Benchmark unrealistic inputs (edge cases)</li> <li>\u274c Compare benchmarks across different hardware</li> <li>\u274c Expect identical results every run (some variance is normal)</li> <li>\u274c Fail CI on small regressions (runner variance can cause false positives)</li> </ul>"},{"location":"dev/benchmarking/#troubleshooting","title":"Troubleshooting","text":""},{"location":"dev/benchmarking/#benchmarks-are-slow-locally","title":"Benchmarks are slow locally","text":"<pre><code># Reduce iterations for faster feedback\nuv run pytest tests/benchmarks/ --benchmark-only --benchmark-min-rounds=3\n</code></pre>"},{"location":"dev/benchmarking/#high-variance-in-results","title":"High variance in results","text":"<p>Possible causes: - Background processes consuming CPU - Thermal throttling on laptop - Small dataset (noise dominates signal)</p> <p>Solutions: - Close unnecessary applications - Use <code>--benchmark-warmup=on</code> to stabilize - Use larger/more representative test data</p>"},{"location":"dev/benchmarking/#benchmark-fails-but-test-passes","title":"Benchmark fails but test passes","text":"<p>Benchmarks call the same code as regular tests. If a benchmark fails:</p> <ol> <li>Run the regular test: <code>uv run pytest tests/test_trait_pipelines.py::test_dicot_pipeline</code></li> <li>If regular test passes, the benchmark setup might be wrong (fixture issue)</li> <li>Check that benchmark is using correct test data</li> </ol>"},{"location":"dev/benchmarking/#false-positives-ci-fails-but-regression-seems-small","title":"False positives: CI fails but regression seems small","text":"<p>Sometimes CI variance causes borderline failures:</p> <p>Symptoms: - Regression is 15-17% (just over threshold) - Re-running the workflow gives different results - Local benchmarks don't show regression</p> <p>Solutions:</p> <ol> <li>Re-run the workflow: Click \"Re-run jobs\" in GitHub Actions</li> <li> <p>If it passes on second run, it was likely CI variance</p> </li> <li> <p>Check recent main branch runs: Compare against several recent baselines    <pre><code># View recent benchmark results on main\ngit log main --all --grep=\"chore: update benchmark baselines\"\ngit show &lt;commit-sha&gt;:.benchmarks/baselines/main.json\n</code></pre></p> </li> <li> <p>Run locally multiple times: Check consistency    <pre><code># Run 5 times and compare\nfor i in {1..5}; do\n  uv run pytest tests/benchmarks/ --benchmark-only --benchmark-json=run_$i.json\ndone\n</code></pre></p> </li> <li> <p>Request threshold adjustment: If a specific benchmark is consistently noisy</p> </li> <li>Document the variance in an issue</li> <li>Consider per-benchmark thresholds (future feature)</li> </ol>"},{"location":"dev/benchmarking/#ci-baseline-is-missing-or-outdated","title":"CI baseline is missing or outdated","text":"<p>Symptom: PR shows \"No baseline\" even though benchmarks exist on main</p> <p>Causes: - First time benchmarks are running (expected) - Baseline commit failed to push - <code>.benchmarks/</code> directory not in repo</p> <p>Solution: 1. Check if <code>.benchmarks/baselines/main.json</code> exists on main branch 2. If missing, merge any PR to trigger baseline creation 3. The next PR will have a baseline to compare against</p>"},{"location":"dev/benchmarking/#design-rationale","title":"Design Rationale","text":"<p>For the full design rationale behind the benchmark regression detection system, see the OpenSpec proposal.</p> <p>Key design decisions: - 15% threshold: Balances catching real regressions vs. CI variance false positives - Automatic PR comments: Provides immediate visibility without manual artifact downloads - Baseline storage in repo: Ensures deterministic comparisons across CI runs - History tracking: Enables future performance trend analysis and charts</p>"},{"location":"dev/benchmarking/#references","title":"References","text":"<ul> <li>pytest-benchmark documentation</li> <li>Performance testing best practices</li> <li>Berrigan et al. 2024 - Original performance metrics</li> <li>OpenSpec: Benchmark Regression Detection</li> </ul>"},{"location":"dev/code-style/","title":"Code Style","text":"<p>Follow PEP 8 and use Black formatter.</p>"},{"location":"dev/contributing/","title":"Contributing to sleap-roots","text":"<p>Thank you for your interest in contributing to sleap-roots!</p>"},{"location":"dev/contributing/#getting-started","title":"Getting Started","text":"<p>See Development Setup for instructions on setting up your environment.</p>"},{"location":"dev/contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests and linting</li> <li>Submit a pull request</li> </ol>"},{"location":"dev/contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8 (enforced by Black)</li> <li>Use Google-style docstrings</li> <li>Add type hints to function signatures</li> <li>Write tests for new features</li> </ul> <p>See Code Style for details.</p>"},{"location":"dev/contributing/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/\n</code></pre>"},{"location":"dev/contributing/#questions","title":"Questions?","text":"<p>Open a GitHub Discussion or issue.</p>"},{"location":"dev/creating-pipelines/","title":"Creating Custom Pipelines","text":"<p>Pipeline development guide coming soon.</p>"},{"location":"dev/release-process/","title":"Release Process","text":"<p>This guide documents the process for releasing new versions of sleap-roots.</p>"},{"location":"dev/release-process/#overview","title":"Overview","text":"<p>sleap-roots follows semantic versioning (SemVer) and uses automated workflows for building, testing, and publishing releases.</p>"},{"location":"dev/release-process/#version-numbering","title":"Version Numbering","text":""},{"location":"dev/release-process/#semantic-versioning","title":"Semantic Versioning","text":"<p>Format: <code>MAJOR.MINOR.PATCH</code></p> <ul> <li>MAJOR: Breaking API changes</li> <li>MINOR: New features (backward compatible)</li> <li>PATCH: Bug fixes (backward compatible)</li> </ul> <p>Examples: - <code>0.1.0</code> \u2192 <code>0.1.1</code>: Bug fix - <code>0.1.1</code> \u2192 <code>0.2.0</code>: New pipeline added - <code>0.2.0</code> \u2192 <code>1.0.0</code>: Breaking API change</p>"},{"location":"dev/release-process/#pre-release-versions","title":"Pre-release Versions","text":"<ul> <li><code>0.1.0rc1</code>: Release candidate 1</li> <li><code>0.1.0a1</code>: Alpha version</li> <li><code>0.1.0b1</code>: Beta version</li> </ul>"},{"location":"dev/release-process/#release-checklist","title":"Release Checklist","text":""},{"location":"dev/release-process/#pre-release-1-2-weeks-before","title":"Pre-Release (1-2 weeks before)","text":"<ul> <li>[ ] Review open issues and PRs</li> <li>[ ] Merge ready features for the release</li> <li>[ ] Update dependencies if needed</li> <li>[ ] Run full test suite locally</li> <li>[ ] Check CI passes on main branch</li> <li>[ ] Update CHANGELOG.md with new features, fixes, and breaking changes</li> <li>[ ] Review and update documentation</li> </ul>"},{"location":"dev/release-process/#release-day","title":"Release Day","text":"<ul> <li>[ ] Create release branch</li> <li>[ ] Update version number</li> <li>[ ] Update CHANGELOG.md</li> <li>[ ] Create release commit</li> <li>[ ] Push and create PR</li> <li>[ ] Review and merge release PR</li> <li>[ ] Create Git tag</li> <li>[ ] Create GitHub release</li> <li>[ ] Verify PyPI publication</li> <li>[ ] Deploy documentation</li> <li>[ ] Announce release</li> </ul>"},{"location":"dev/release-process/#post-release","title":"Post-Release","text":"<ul> <li>[ ] Monitor for issues</li> <li>[ ] Address critical bugs with patch release if needed</li> <li>[ ] Plan next release features</li> </ul>"},{"location":"dev/release-process/#step-by-step-release-process","title":"Step-by-Step Release Process","text":""},{"location":"dev/release-process/#1-prepare-release-branch","title":"1. Prepare Release Branch","text":"<pre><code># Ensure main is up to date\ngit checkout main\ngit pull origin main\n\n# Create release branch\ngit checkout -b release/v0.2.0\n\n# Or use GitHub CLI\ngh issue create --title \"Release v0.2.0\" --body \"Release tracking issue\"\n</code></pre>"},{"location":"dev/release-process/#2-update-version-number","title":"2. Update Version Number","text":"<p>Update version in <code>sleap_roots/__init__.py</code>:</p> <pre><code># sleap_roots/__init__.py\n\n__version__ = \"0.2.0\"\n</code></pre> <p>Verify version is correct:</p> <pre><code>python -c \"import sleap_roots; print(sleap_roots.__version__)\"\n</code></pre>"},{"location":"dev/release-process/#3-update-changelog","title":"3. Update CHANGELOG","text":"<p>Edit <code>CHANGELOG.md</code> following Keep a Changelog format:</p> <pre><code># Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [0.2.0] - 2024-01-15\n\n### Added\n- New `MultipleDicotPipeline` for multi-plant analysis\n- Root sinuosity trait computation\n- Batch processing utilities\n- Comprehensive tutorials for all pipelines\n\n### Changed\n- Improved performance of length calculations (20% faster)\n- Updated trait reference documentation\n- Migrated to uv for package management\n\n### Fixed\n- Fixed bug in lateral root angle calculation (#123)\n- Corrected convex hull computation for edge cases (#145)\n\n### Deprecated\n- `old_function` will be removed in v0.3.0\n\n## [0.1.4] - 2024-01-01\n\n### Fixed\n- Fixed critical bug in primary root detection\n\n...\n</code></pre>"},{"location":"dev/release-process/#4-run-pre-release-tests","title":"4. Run Pre-Release Tests","text":"<pre><code># Run full test suite\npytest tests/ -v\n\n# Check code style\nblack --check sleap_roots tests\npydocstyle sleap_roots/\n\n# Build documentation locally\nmkdocs build\n\n# Test package build\npython -m build\n</code></pre>"},{"location":"dev/release-process/#5-commit-and-push-release-branch","title":"5. Commit and Push Release Branch","text":"<pre><code># Commit version bump and changelog\ngit add sleap_roots/__init__.py CHANGELOG.md\ngit commit -m \"Bump version to v0.2.0\"\n\n# Push release branch\ngit push origin release/v0.2.0\n</code></pre>"},{"location":"dev/release-process/#6-create-release-pr","title":"6. Create Release PR","text":"<p>Create PR from <code>release/v0.2.0</code> to <code>main</code>:</p> <pre><code># Using GitHub CLI\ngh pr create \\\n  --title \"Release v0.2.0\" \\\n  --body \"$(cat &lt;&lt;EOF\n## Release v0.2.0\n\n### Summary\nThis release includes...\n\n### Changes\n- New MultipleDicotPipeline\n- Performance improvements\n- Bug fixes\n\n### Checklist\n- [x] Version bumped\n- [x] CHANGELOG updated\n- [x] Tests passing\n- [x] Documentation updated\n\nCloses #XX\nEOF\n)\"\n</code></pre> <p>PR Description should include: - Summary of major changes - Link to CHANGELOG section - Breaking changes (if any) - Migration guide (for breaking changes) - Checklist of completed tasks</p>"},{"location":"dev/release-process/#7-review-and-merge","title":"7. Review and Merge","text":"<p>Review checklist: - [ ] Version number is correct - [ ] CHANGELOG is complete and accurate - [ ] All tests pass in CI - [ ] Documentation builds successfully - [ ] No unintended changes</p> <p>Merge the PR after approval.</p>"},{"location":"dev/release-process/#8-create-git-tag","title":"8. Create Git Tag","text":"<pre><code># After merging release PR, checkout main\ngit checkout main\ngit pull origin main\n\n# Create annotated tag\ngit tag -a v0.2.0 -m \"Release version 0.2.0\n\nMajor changes:\n- Added MultipleDicotPipeline\n- Improved performance\n- Bug fixes\n\nSee CHANGELOG.md for details.\"\n\n# Push tag to trigger release workflow\ngit push origin v0.2.0\n</code></pre>"},{"location":"dev/release-process/#9-create-github-release","title":"9. Create GitHub Release","text":"<p>GitHub Actions will automatically create a draft release. Edit and publish it:</p> <ol> <li>Go to Releases</li> <li>Find draft release for <code>v0.2.0</code></li> <li>Edit release notes:</li> </ol> <pre><code>## sleap-roots v0.2.0\n\n### Highlights\n\n\ud83c\udf31 **New Pipeline**: `MultipleDicotPipeline` for analyzing multiple plants simultaneously\n\n\u26a1 **Performance**: 20% faster length calculations\n\n\ud83d\udc1b **Bug Fixes**: Corrected lateral root angle computation\n\n### What's Changed\n\n#### Added\n- MultipleDicotPipeline for multi-plant setups (#150)\n- Root sinuosity trait (#155)\n- Comprehensive pipeline tutorials (#160)\n\n#### Improved\n- Vectorized length computation (#148)\n- Enhanced trait documentation (#152)\n\n#### Fixed\n- Lateral root emergence angle calculation (#123)\n- Convex hull edge case handling (#145)\n\n### Installation\n\n```bash\npip install sleap-roots==0.2.0\n</code></pre>"},{"location":"dev/release-process/#documentation","title":"Documentation","text":"<p>Full documentation: https://talmolab.github.io/sleap-roots/</p>"},{"location":"dev/release-process/#contributors","title":"Contributors","text":"<p>Thanks to @contributor1, @contributor2 for their contributions!</p> <p>Full Changelog: https://github.com/talmolab/sleap-roots/compare/v0.1.4...v0.2.0 <pre><code>4. Check **Set as latest release**\n5. Click **Publish release**\n\n### 10. Verify PyPI Publication\n\nGitHub Actions automatically publishes to PyPI when a release is created.\n\n**Verify publication**:\n\n```bash\n# Wait a few minutes, then check PyPI\npip install sleap-roots==0.2.0\n\n# Verify installation\npython -c \"import sleap_roots; print(sleap_roots.__version__)\"\n# Should print: 0.2.0\n</code></pre></p> <p>If publication fails: 1. Check GitHub Actions 2. Review error logs 3. Fix issues and manually publish if needed:</p> <pre><code># Build package\npython -m build\n\n# Upload to PyPI (requires credentials)\npython -m twine upload dist/sleap_roots-0.2.0*\n</code></pre>"},{"location":"dev/release-process/#11-deploy-documentation","title":"11. Deploy Documentation","text":"<p>Documentation is automatically deployed by GitHub Actions.</p> <p>Verify deployment:</p> <ol> <li>Visit https://talmolab.github.io/sleap-roots/</li> <li>Check version selector shows <code>v0.2.0</code></li> <li>Verify new features are documented</li> </ol> <p>Manual deployment (if automated deployment fails):</p> <pre><code># Install mike for version management\npip install mike\n\n# Deploy documentation for this version\nmike deploy --push --update-aliases 0.2.0 latest\n\n# Set default version\nmike set-default --push latest\n</code></pre>"},{"location":"dev/release-process/#12-announce-release","title":"12. Announce Release","text":"<p>GitHub Discussions: <pre><code>Title: sleap-roots v0.2.0 Released!\n\nWe're excited to announce sleap-roots v0.2.0!\n\n## Highlights\n- \ud83c\udf31 New MultipleDicotPipeline for multi-plant analysis\n- \u26a1 20% performance improvement\n- \ud83d\udc1b Critical bug fixes\n\n## Installation\n```bash\npip install sleap-roots==0.2.0\n</code></pre></p>"},{"location":"dev/release-process/#documentation_1","title":"Documentation","text":"<p>https://talmolab.github.io/sleap-roots/</p>"},{"location":"dev/release-process/#changelog","title":"Changelog","text":"<p>https://github.com/talmolab/sleap-roots/releases/tag/v0.2.0</p> <p>Please report any issues or feedback! <pre><code>**SLEAP Slack** (if applicable):\n- Post announcement in #plant-phenotyping channel\n- Highlight key new features\n- Link to release notes\n\n**Twitter/X** (if applicable):\n</code></pre> \ud83c\udf31 sleap-roots v0.2.0 is out!</p> <p>\u2728 New: MultipleDicotPipeline \u26a1 Faster trait computation \ud83d\udc1b Bug fixes</p> <p>\ud83d\udce6 pip install sleap-roots==0.2.0 \ud83d\udcd6 https://talmolab.github.io/sleap-roots/</p>"},{"location":"dev/release-process/#plantphenotyping-computervision-sleap","title":"plantphenotyping #computervision #sleap","text":"<pre><code>## Hotfix Releases\n\nFor critical bugs that need immediate patching:\n\n### 1. Create Hotfix Branch\n\n```bash\n# Branch from latest release tag\ngit checkout -b hotfix/v0.2.1 v0.2.0\n</code></pre>"},{"location":"dev/release-process/#2-fix-the-bug","title":"2. Fix the Bug","text":"<pre><code># Make minimal changes to fix the bug\ngit add fixed_file.py\ngit commit -m \"Fix critical bug in lateral root detection\"\n</code></pre>"},{"location":"dev/release-process/#3-update-version-and-changelog","title":"3. Update Version and Changelog","text":"<pre><code># sleap_roots/__init__.py\n__version__ = \"0.2.1\"\n</code></pre> <pre><code># CHANGELOG.md\n\n## [0.2.1] - 2024-01-20\n\n### Fixed\n- Critical bug in lateral root detection causing crashes (#170)\n</code></pre>"},{"location":"dev/release-process/#4-release-hotfix","title":"4. Release Hotfix","text":"<pre><code># Commit changes\ngit add sleap_roots/__init__.py CHANGELOG.md\ngit commit -m \"Bump version to v0.2.1 (hotfix)\"\n\n# Merge to main\ngit checkout main\ngit merge --no-ff hotfix/v0.2.1\n\n# Tag and push\ngit tag -a v0.2.1 -m \"Hotfix release v0.2.1\"\ngit push origin main\ngit push origin v0.2.1\n</code></pre>"},{"location":"dev/release-process/#automation","title":"Automation","text":""},{"location":"dev/release-process/#github-actions-workflows","title":"GitHub Actions Workflows","text":""},{"location":"dev/release-process/#githubworkflowsreleaseyml","title":"<code>.github/workflows/release.yml</code>","text":"<pre><code>name: Release\n\non:\n  release:\n    types: [published]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n      - name: Install dependencies\n        run: |\n          pip install build twine\n      - name: Build package\n        run: python -m build\n      - name: Publish to PyPI\n        env:\n          TWINE_USERNAME: __token__\n          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}\n        run: twine upload dist/*\n</code></pre>"},{"location":"dev/release-process/#githubworkflowsdocsyml","title":"<code>.github/workflows/docs.yml</code>","text":"<pre><code>name: Deploy Docs\n\non:\n  push:\n    branches: [main]\n    tags:\n      - 'v*'\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n      - name: Install dependencies\n        run: |\n          pip install mkdocs-material mike\n      - name: Deploy docs\n        run: |\n          mike deploy --push --update-aliases ${{ github.ref_name }} latest\n</code></pre>"},{"location":"dev/release-process/#troubleshooting","title":"Troubleshooting","text":""},{"location":"dev/release-process/#pypi-upload-fails","title":"PyPI Upload Fails","text":"<p>Issue: <code>403 Forbidden</code> error</p> <p>Solution: Verify PyPI API token in repository secrets</p> <ol> <li>Go to PyPI \u2192 Account settings \u2192 API tokens</li> <li>Create token with scope for sleap-roots</li> <li>Add token to GitHub secrets as <code>PYPI_API_TOKEN</code></li> </ol>"},{"location":"dev/release-process/#version-conflict","title":"Version Conflict","text":"<p>Issue: Version already exists on PyPI</p> <p>Solution: Increment patch version</p> <pre><code># Instead of 0.2.0, use 0.2.1\n# Update version and re-release\n</code></pre>"},{"location":"dev/release-process/#documentation-doesnt-deploy","title":"Documentation Doesn't Deploy","text":"<p>Issue: Mike deployment fails</p> <p>Solution: Check GitHub Pages settings</p> <ol> <li>Repository \u2192 Settings \u2192 Pages</li> <li>Source: Deploy from a branch</li> <li>Branch: <code>gh-pages</code> / <code>root</code></li> </ol>"},{"location":"dev/release-process/#release-schedule","title":"Release Schedule","text":"<p>Suggested release cadence:</p> <ul> <li>Major releases (X.0.0): Yearly or when breaking changes accumulate</li> <li>Minor releases (0.X.0): Every 1-2 months with new features</li> <li>Patch releases (0.0.X): As needed for bug fixes</li> </ul> <p>Example timeline: - Jan: v0.2.0 (new pipeline) - Feb: v0.2.1 (hotfix) - Mar: v0.3.0 (new traits) - May: v0.4.0 (performance improvements) - Dec: v1.0.0 (stable API)</p>"},{"location":"dev/release-process/#next-steps","title":"Next Steps","text":"<ul> <li>Review Contributing Guide for development workflow</li> <li>See Testing Guide for test requirements</li> <li>Check Development Setup for environment configuration</li> <li>Read Architecture for understanding codebase structure</li> </ul>"},{"location":"dev/setup/","title":"Development Setup","text":"<p>This guide will help you set up a development environment for contributing to sleap-roots.</p>"},{"location":"dev/setup/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Git (2.0+) \u2013 Version control</li> <li>Git LFS \u2013 For test data (898 MB)</li> <li>Python (3.7-3.11) \u2013 We recommend 3.11</li> <li>uv (recommended) or conda \u2013 Package management</li> </ul>"},{"location":"dev/setup/#quick-setup-with-uv-recommended","title":"Quick Setup with uv (Recommended)","text":"<p>The fastest way to get started is with uv, a modern Python package manager.</p>"},{"location":"dev/setup/#1-install-uv","title":"1. Install uv","text":"<pre><code># macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip/pipx\npip install uv\n</code></pre>"},{"location":"dev/setup/#2-clone-and-setup","title":"2. Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/talmolab/sleap-roots.git\ncd sleap-roots\n\n# Install Git LFS and pull test data\ngit lfs install\ngit lfs pull\n\n# Setup environment (creates .venv, installs all dependencies)\nuv sync\n</code></pre> <p>That's it! You're ready to develop.</p>"},{"location":"dev/setup/#3-verify-setup","title":"3. Verify Setup","text":"<pre><code># Run tests\nuv run pytest tests/\n\n# Check code formatting\nuv run black --check sleap_roots tests\n\n# Check docstrings\nuv run pydocstyle sleap_roots/\n\n# Build documentation\nuv run mkdocs serve\n</code></pre>"},{"location":"dev/setup/#4-development-workflow","title":"4. Development Workflow","text":"<pre><code># Run tests\nuv run pytest tests/ -v\n\n# Run specific test file\nuv run pytest tests/test_pipelines.py\n\n# Run with coverage\nuv run pytest --cov=sleap_roots --cov-report=term-missing tests/\n\n# Format code\nuv run black sleap_roots tests\n\n# Check types (if mypy added)\nuv run mypy sleap_roots\n\n# Build docs locally\nuv run mkdocs serve\n# Visit http://127.0.0.1:8000\n\n# Add new dependency\nuv add package-name\n\n# Add dev dependency\nuv add --dev package-name\n</code></pre> <p>No activation needed</p> <p>With uv, you don't need to activate a virtual environment. Just use <code>uv run</code> before commands, and uv handles everything automatically.</p>"},{"location":"dev/setup/#5-update-dependencies","title":"5. Update Dependencies","text":"<pre><code># Update all dependencies to latest compatible versions\nuv lock --upgrade\n\n# Sync to updated lockfile\nuv sync\n\n# Check for outdated packages\nuv tree\n</code></pre>"},{"location":"dev/setup/#alternative-setup-with-conda","title":"Alternative: Setup with Conda","text":"<p>If you prefer conda or need conda-specific packages:</p>"},{"location":"dev/setup/#1-install-condamamba","title":"1. Install Conda/Mamba","text":"<pre><code># Install mamba (faster than conda)\nconda install -n base -c conda-forge mamba\n</code></pre>"},{"location":"dev/setup/#2-clone-and-setup_1","title":"2. Clone and Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/talmolab/sleap-roots.git\ncd sleap-roots\n\n# Install Git LFS\ngit lfs install\ngit lfs pull\n\n# Create environment from file\nconda env create -f environment.yml\n\n# Activate environment\nconda activate sleap-roots\n</code></pre>"},{"location":"dev/setup/#3-development-workflow","title":"3. Development Workflow","text":"<pre><code># Activate environment\nconda activate sleap-roots\n\n# Run tests\npytest tests/ -v\n\n# Format code\nblack sleap_roots tests\n\n# Check docstrings\npydocstyle sleap_roots/\n\n# Build docs\nmkdocs serve\n</code></pre>"},{"location":"dev/setup/#git-lfs-setup","title":"Git LFS Setup","text":"<p>sleap-roots uses Git LFS for test data (~898 MB). This is required for running tests.</p>"},{"location":"dev/setup/#install-git-lfs","title":"Install Git LFS","text":"<pre><code># macOS\nbrew install git-lfs\n\n# Ubuntu/Debian\nsudo apt-get install git-lfs\n\n# Windows\n# Download from https://git-lfs.github.com/\n\n# Initialize\ngit lfs install\n</code></pre>"},{"location":"dev/setup/#pull-test-data","title":"Pull Test Data","text":"<pre><code># Pull all LFS files\ngit lfs pull\n\n# Verify (should show binary data, not text pointers)\nfile tests/data/*.h5\n# Output: tests/data/example.h5: Hierarchical Data Format (version 5) data\n</code></pre>"},{"location":"dev/setup/#ide-configuration","title":"IDE Configuration","text":""},{"location":"dev/setup/#vs-code","title":"VS Code","text":"<p>Recommended extensions: - Python (Microsoft) - Pylance - Black Formatter - autoDocstring</p> <p>Settings (<code>.vscode/settings.json</code>): <pre><code>{\n  \"python.defaultInterpreterPath\": \".venv/bin/python\",\n  \"python.formatting.provider\": \"black\",\n  \"python.linting.enabled\": true,\n  \"python.linting.pydocstyleEnabled\": true,\n  \"python.testing.pytestEnabled\": true,\n  \"python.testing.pytestArgs\": [\"tests\"],\n  \"editor.formatOnSave\": true\n}\n</code></pre></p>"},{"location":"dev/setup/#pycharm","title":"PyCharm","text":"<ol> <li>Open project in PyCharm</li> <li>File \u2192 Settings \u2192 Project \u2192 Python Interpreter</li> <li>Add interpreter: <code>.venv/bin/python</code></li> <li>Enable Black formatter:</li> <li>File \u2192 Settings \u2192 Tools \u2192 Black</li> <li>Check \"On code reformat\" and \"On save\"</li> <li>Configure pytest:</li> <li>Run \u2192 Edit Configurations \u2192 Add pytest</li> <li>Target: <code>tests/</code></li> </ol>"},{"location":"dev/setup/#running-tests","title":"Running Tests","text":""},{"location":"dev/setup/#full-test-suite","title":"Full Test Suite","text":"<pre><code># Run all tests\nuv run pytest tests/\n\n# With verbose output\nuv run pytest tests/ -v\n\n# With coverage\nuv run pytest --cov=sleap_roots --cov-report=html tests/\n# Open htmlcov/index.html to view coverage report\n</code></pre>"},{"location":"dev/setup/#specific-tests","title":"Specific Tests","text":"<pre><code># Run specific test file\nuv run pytest tests/test_series.py\n\n# Run specific test function\nuv run pytest tests/test_series.py::test_load_series\n\n# Run tests matching pattern\nuv run pytest tests/ -k \"dicot\"\n</code></pre>"},{"location":"dev/setup/#test-markers","title":"Test Markers","text":"<pre><code># Run fast tests only\nuv run pytest -m \"not slow\"\n\n# Run integration tests\nuv run pytest -m integration\n</code></pre>"},{"location":"dev/setup/#code-quality-checks","title":"Code Quality Checks","text":""},{"location":"dev/setup/#formatting","title":"Formatting","text":"<pre><code># Check formatting (no changes)\nuv run black --check sleap_roots tests\n\n# Format code\nuv run black sleap_roots tests\n</code></pre>"},{"location":"dev/setup/#linting","title":"Linting","text":"<pre><code># Check docstrings\nuv run pydocstyle sleap_roots/\n\n# Check for common issues (if ruff/flake8 added)\nuv run ruff check sleap_roots/\n</code></pre>"},{"location":"dev/setup/#pre-commit-hooks-optional","title":"Pre-commit Hooks (Optional)","text":"<pre><code># Install pre-commit\nuv add --dev pre-commit\n\n# Install hooks\nuv run pre-commit install\n\n# Run on all files\nuv run pre-commit run --all-files\n</code></pre>"},{"location":"dev/setup/#building-documentation","title":"Building Documentation","text":""},{"location":"dev/setup/#local-preview","title":"Local Preview","text":"<pre><code># Serve docs with live reload\nuv run mkdocs serve\n\n# Open http://127.0.0.1:8000\n</code></pre>"},{"location":"dev/setup/#build-static-site","title":"Build Static Site","text":"<pre><code># Build production site\nuv run mkdocs build\n\n# Output in site/\n# Test by opening site/index.html\n</code></pre>"},{"location":"dev/setup/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md              # Home page\n\u251c\u2500\u2500 getting-started/      # User installation guides\n\u251c\u2500\u2500 tutorials/            # Pipeline tutorials\n\u251c\u2500\u2500 guides/               # User guides\n\u251c\u2500\u2500 dev/                  # Developer documentation\n\u251c\u2500\u2500 api/                  # API reference\n\u251c\u2500\u2500 cookbook/             # Code recipes\n\u2514\u2500\u2500 changelog.md          # Release history\n</code></pre>"},{"location":"dev/setup/#common-tasks","title":"Common Tasks","text":""},{"location":"dev/setup/#add-a-new-pipeline","title":"Add a New Pipeline","text":"<ol> <li>Create pipeline class in <code>sleap_roots/trait_pipelines.py</code></li> <li>Add tests in <code>tests/test_pipelines.py</code></li> <li>Export in <code>sleap_roots/__init__.py</code></li> <li>Add documentation page in <code>docs/guides/pipelines/</code></li> <li>Add tutorial in <code>docs/tutorials/</code></li> <li>Update <code>mkdocs.yml</code> navigation</li> </ol>"},{"location":"dev/setup/#add-a-new-trait","title":"Add a New Trait","text":"<ol> <li>Create trait function in appropriate module (e.g., <code>sleap_roots/lengths.py</code>)</li> <li>Add to <code>TraitDef</code> in pipeline</li> <li>Add tests in <code>tests/test_&lt;module&gt;.py</code></li> <li>Document in <code>docs/guides/trait-reference.md</code></li> <li>Add example in <code>docs/cookbook/custom-traits.md</code></li> </ol> <p>See Adding Traits for detailed guide.</p>"},{"location":"dev/setup/#release-process","title":"Release Process","text":"<ol> <li>Update version in <code>sleap_roots/__init__.py</code></li> <li>Update <code>docs/changelog.md</code></li> <li>Create release branch: <code>git checkout -b release/v0.x.x</code></li> <li>Run full test suite</li> <li>Create PR to main</li> <li>After merge, tag release: <code>git tag -a v0.x.x</code></li> <li>Push tag: <code>git push origin v0.x.x</code></li> <li>GitHub Actions builds and publishes to PyPI</li> </ol> <p>See Release Process for complete workflow.</p>"},{"location":"dev/setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"dev/setup/#tests-fail-with-filenotfounderror","title":"Tests Fail with \"FileNotFoundError\"","text":"<p>Cause: Git LFS data not pulled</p> <p>Solution: <pre><code>git lfs install\ngit lfs pull\n</code></pre></p>"},{"location":"dev/setup/#import-errors-in-tests","title":"Import Errors in Tests","text":"<p>Cause: Package not installed in editable mode</p> <p>Solution: <pre><code># With uv\nuv sync\n\n# With conda\npip install -e .\n</code></pre></p>"},{"location":"dev/setup/#black-formatting-conflicts","title":"Black Formatting Conflicts","text":"<p>Cause: Different Black versions</p> <p>Solution: <pre><code># Use project-pinned version\nuv run black sleap_roots tests\n\n# Or update Black\nuv add --dev black\n</code></pre></p>"},{"location":"dev/setup/#documentation-build-fails","title":"Documentation Build Fails","text":"<p>Cause: Missing mkdocs dependencies</p> <p>Solution: <pre><code># Install doc dependencies\nuv sync\n\n# Or specifically\nuv add --dev mkdocs mkdocs-material mkdocstrings\n</code></pre></p>"},{"location":"dev/setup/#uv-commands-fail","title":"uv Commands Fail","text":"<p>Cause: uv not in PATH or outdated</p> <p>Solution: <pre><code># Reinstall uv\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Update uv\nuv self update\n\n# Check version\nuv --version\n</code></pre></p>"},{"location":"dev/setup/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: https://talmolab.github.io/sleap-roots/</li> <li>Issues: https://github.com/talmolab/sleap-roots/issues</li> <li>Discussions: https://github.com/talmolab/sleap-roots/discussions</li> <li>SLEAP Community: https://sleap.ai/community</li> </ul>"},{"location":"dev/setup/#next-steps","title":"Next Steps","text":"<ul> <li>Read Contributing Guide for workflow</li> <li>Review Code Style for conventions</li> <li>See Creating Pipelines for pipeline development</li> <li>Check Testing Guide for test best practices</li> </ul>"},{"location":"dev/testing/","title":"Testing","text":"<p>Testing guide coming soon.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#quick-install","title":"Quick Install","text":"<p>The simplest way to install sleap-roots is via pip:</p> <pre><code>pip install sleap-roots\n</code></pre>"},{"location":"getting-started/installation/#recommended-conda-environment","title":"Recommended: Conda Environment","text":"<p>We recommend using conda to manage dependencies and avoid conflicts:</p> <pre><code># Create a new environment with Python 3.11\nconda create -n sleap-roots python=3.11\n\n# Activate the environment\nconda activate sleap-roots\n\n# Install sleap-roots\npip install sleap-roots\n</code></pre> <p>Why Python 3.11?</p> <p>While sleap-roots supports Python 3.7+, we recommend 3.11 for the best performance and compatibility with recent NumPy/Pandas versions.</p>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>If you want to contribute to sleap-roots or run the latest development version, we recommend using uv for the fastest and most modern workflow.</p>"},{"location":"getting-started/installation/#modern-approach-using-uv-recommended","title":"Modern Approach: Using uv (Recommended)","text":"<p>uv is a fast, modern Python package manager that handles dependency management with lockfiles for reproducibility.</p>"},{"location":"getting-started/installation/#1-install-uv","title":"1. Install uv","text":"<pre><code># macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip\npip install uv\n</code></pre>"},{"location":"getting-started/installation/#2-clone-and-setup","title":"2. Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/talmolab/sleap-roots.git\ncd sleap-roots\n\n# Install Git LFS for test data\ngit lfs install\ngit lfs pull\n\n# Create environment and install all dependencies\nuv sync\n\n# This automatically:\n# - Creates a virtual environment (.venv)\n# - Installs runtime dependencies\n# - Installs dev dependencies from [dependency-groups]\n# - Installs sleap-roots in editable mode\n# - Generates/updates uv.lock for reproducibility\n</code></pre>"},{"location":"getting-started/installation/#3-verify-installation","title":"3. Verify Installation","text":"<pre><code># Run tests\nuv run pytest tests/\n\n# Check formatting\nuv run black --check sleap_roots tests\n\n# Check docstrings\nuv run pydocstyle sleap_roots/\n\n# Import the package\nuv run python -c \"import sleap_roots; print(sleap_roots.__version__)\"\n</code></pre> <p>Why uv?</p> <ul> <li>10-100x faster than pip/conda</li> <li>Automatic dependency locking with uv.lock</li> <li>No separate environment activation needed (use <code>uv run</code>)</li> <li>PEP 735 dependency groups for clean dev/prod separation</li> <li>Built-in tool management (no need for separate virtualenv)</li> </ul>"},{"location":"getting-started/installation/#alternative-using-conda","title":"Alternative: Using Conda","text":"<p>If you prefer conda or need conda-specific packages:</p>"},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/talmolab/sleap-roots.git\ncd sleap-roots\n</code></pre>"},{"location":"getting-started/installation/#2-create-environment-from-file","title":"2. Create Environment from File","text":"<pre><code>conda env create -f environment.yml\nconda activate sleap-roots\n</code></pre> <p>This installs:</p> <ul> <li>All runtime dependencies (numpy, pandas, sleap-io, etc.)</li> <li>Dev dependencies (pytest, black, pydocstyle, mkdocs)</li> <li>The package in editable mode</li> </ul>"},{"location":"getting-started/installation/#3-verify-installation_1","title":"3. Verify Installation","text":"<pre><code># Run tests\npytest tests/\n\n# Check formatting\nblack --check sleap_roots tests\n\n# Import the package\npython -c \"import sleap_roots; print(sleap_roots.__version__)\"\n</code></pre>"},{"location":"getting-started/installation/#platform-support","title":"Platform Support","text":"<p>sleap-roots is tested on:</p> Platform Python Versions Status Ubuntu 22.04 3.7, 3.8, 3.9, 3.10, 3.11  Fully supported macOS 3.11  Fully supported Windows 3.11  Fully supported"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>sleap-roots has the following core dependencies:</p> <ul> <li>numpy \u2013 Numerical operations</li> <li>pandas \u2013 Data frames for trait output</li> <li>h5py \u2013 Reading HDF5 video files</li> <li>sleap-io \u2013 Loading SLEAP prediction files (.slp)</li> <li>scikit-image \u2013 Image processing utilities</li> <li>shapely \u2013 Geometric operations</li> <li>matplotlib \u2013 Visualization (optional)</li> <li>seaborn \u2013 Statistical plots (optional)</li> </ul> <p>All dependencies are automatically installed with pip.</p>"},{"location":"getting-started/installation/#git-lfs-for-test-data","title":"Git LFS for Test Data","text":"<p>If you're developing or running tests, you'll need Git LFS to download test data:</p> <pre><code># Install Git LFS\n# macOS\nbrew install git-lfs\n\n# Ubuntu\nsudo apt-get install git-lfs\n\n# Initialize Git LFS\ngit lfs install\n\n# Pull test data (898 MB)\ngit lfs pull\n</code></pre> <p>Without Git LFS, test data files will be pointer files (~130 bytes) instead of the actual data, and tests will fail.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#modulenotfounderror-no-module-named-sleap_roots","title":"\"ModuleNotFoundError: No module named 'sleap_roots'\"","text":"<p>Make sure the conda environment is activated:</p> <pre><code>conda activate sleap-roots\n</code></pre>"},{"location":"getting-started/installation/#filenotfounderror-in-tests","title":"\"FileNotFoundError\" in Tests","text":"<p>Pull Git LFS data:</p> <pre><code>git lfs install\ngit lfs pull\n</code></pre>"},{"location":"getting-started/installation/#conda-environment-creation-is-slow","title":"Conda Environment Creation is Slow","text":"<p>Use mamba (much faster than conda):</p> <pre><code>conda install -n base -c conda-forge mamba\nmamba env create -f environment.yml\n</code></pre>"},{"location":"getting-started/installation/#import-errors-with-sleap-io","title":"Import Errors with sleap-io","text":"<p>Upgrade to the latest version:</p> <pre><code>pip install --upgrade sleap-io\n</code></pre>"},{"location":"getting-started/installation/#verifying-your-installation","title":"Verifying Your Installation","text":"<p>Run the environment validation command to check everything is set up correctly:</p> <pre><code># If using Claude commands\n/validate-env\n</code></pre> <p>Or manually check:</p> <pre><code>import sleap_roots as sr\nfrom sleap_roots import DicotPipeline\n\n# Check version\nprint(f\"sleap-roots version: {sr.__version__}\")\n\n# Instantiate a pipeline\npipeline = DicotPipeline()\nprint(\"\u2705 Installation successful!\")\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Tutorial \u2013 Learn the basics</li> <li>What is SLEAP? \u2013 Understand the underlying technology</li> <li>Pipeline Guide \u2013 Choose a pipeline for your data</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will walk you through the basic workflow of using sleap-roots to extract morphological traits from plant root images.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before starting, make sure you have:</p> <ol> <li>Installed sleap-roots \u2013 See Installation</li> <li>SLEAP prediction files \u2013 <code>.slp</code> files generated by SLEAP</li> <li>Optional: Video files \u2013 <code>.h5</code> or <code>.mp4</code> files (for frame-by-frame analysis)</li> </ol> <p>Don't have SLEAP predictions?</p> <p>You can use the test data included in the repository: <pre><code>git clone https://github.com/talmolab/sleap-roots.git\ncd sleap-roots\ngit lfs pull  # Download test data\n</code></pre></p>"},{"location":"getting-started/quickstart/#basic-workflow","title":"Basic Workflow","text":"<p>The typical sleap-roots workflow has three steps:</p> <ol> <li>Load SLEAP predictions into a <code>Series</code> object</li> <li>Choose a pipeline appropriate for your plant type</li> <li>Compute traits and export to CSV</li> </ol>"},{"location":"getting-started/quickstart/#example-1-single-plant-analysis","title":"Example 1: Single Plant Analysis","text":"<p>Let's analyze a single dicot plant (e.g., soy or canola) with primary and lateral roots:</p> <pre><code>import sleap_roots as sr\n\n# Step 1: Load SLEAP predictions\nseries = sr.Series.load(\n    series_name=\"919QDUH\",\n    h5_path=\"tests/data/canola_7do/919QDUH.h5\",\n    primary_path=\"tests/data/canola_7do/919QDUH.primary.slp\",\n    lateral_path=\"tests/data/canola_7do/919QDUH.lateral.slp\"\n)\n\n# Step 2: Create a pipeline\npipeline = sr.DicotPipeline()\n\n# Step 3: Compute traits\ntraits_df = pipeline.compute_plant_traits(series, write_csv=True)\n\n# View results\nprint(traits_df.head())\n</code></pre> <p>This will:</p> <ul> <li>Load predictions for primary and lateral roots</li> <li>Compute 40+ morphological traits</li> <li>Save results to <code>919QDUH_traits.csv</code></li> </ul>"},{"location":"getting-started/quickstart/#example-2-batch-processing","title":"Example 2: Batch Processing","text":"<p>For high-throughput experiments, process multiple plants at once:</p> <pre><code>import sleap_roots as sr\n\n# Step 1: Find all SLEAP files in a directory\npaths = sr.find_all_slp_paths(\"tests/data/soy_6do\")\n\n# Step 2: Load all plants\nplants = sr.load_series_from_slps(paths, h5s=True)\n\n# Step 3: Create pipeline and compute batch traits\npipeline = sr.DicotPipeline()\nbatch_df = pipeline.compute_batch_traits(plants, write_csv=True)\n\n# View summary\nprint(f\"Processed {len(batch_df)} plant frames\")\nprint(batch_df[['plant', 'frame_idx', 'primary_length', 'lateral_count']].head())\n</code></pre> <p>The batch CSV will contain all plants with columns:</p> <ul> <li><code>plant</code> \u2013 Plant identifier</li> <li><code>frame_idx</code> \u2013 Frame number (for time-series)</li> <li>Individual trait columns</li> </ul>"},{"location":"getting-started/quickstart/#example-3-using-individual-trait-functions","title":"Example 3: Using Individual Trait Functions","text":"<p>You can also use modular utility functions for custom analyses:</p> <pre><code>from sleap_roots.lengths import get_root_lengths\nfrom sleap_roots.angles import get_primary_angle\nimport sleap_roots as sr\n\n# Load data\nseries = sr.Series.load(\n    series_name=\"my_plant\",\n    primary_path=\"primary_roots.slp\"\n)\n\n# Get points for frame 0\npts = series.get_primary_points(frame_idx=0)\n\n# Compute specific traits\nlength = get_root_lengths(pts)\nangle = get_primary_angle(pts)\n\nprint(f\"Primary root length: {length:.2f} pixels\")\nprint(f\"Primary root angle: {angle:.2f} degrees\")\n</code></pre>"},{"location":"getting-started/quickstart/#available-pipelines","title":"Available Pipelines","text":"<p>Choose a pipeline based on your plant type and root system:</p> Pipeline Use Case Root Types DicotPipeline Dicots with primary + laterals Primary, Lateral YoungerMonocotPipeline Young monocots Primary, Crown OlderMonocotPipeline Mature monocots (no primary) Crown MultipleDicotPipeline Multi-plant images Primary, Lateral PrimaryRootPipeline Primary root only Primary LateralRootPipeline Lateral roots only Lateral <p>See the Pipeline Guide for detailed information about each pipeline.</p>"},{"location":"getting-started/quickstart/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"getting-started/quickstart/#trait-dataframe-structure","title":"Trait DataFrame Structure","text":"<p>The output DataFrame has one row per frame (or plant-frame for batch processing):</p> <pre><code># Example output\n     plant  frame_idx  primary_length  lateral_count  primary_angle\n0  919QDUH          0          523.45             12          87.32\n1  919QDUH          1          541.23             13          86.91\n2  919QDUH          2          558.91             14          85.77\n</code></pre>"},{"location":"getting-started/quickstart/#common-traits","title":"Common Traits","text":"<p>Here are some commonly used traits:</p> <ul> <li>Length traits \u2013 <code>primary_length</code>, <code>lateral_length_total</code>, <code>lateral_length_avg</code></li> <li>Count traits \u2013 <code>lateral_count</code>, <code>primary_tip_count</code>, <code>crown_count</code></li> <li>Angle traits \u2013 <code>primary_angle</code>, <code>lateral_angle_avg</code>, <code>crown_angle_avg</code></li> <li>Topology traits \u2013 <code>convex_hull_area</code>, <code>network_distribution_ratio</code></li> </ul> <p>See the Trait Reference for the full list with descriptions.</p>"},{"location":"getting-started/quickstart/#working-with-csv-output","title":"Working with CSV Output","text":"<p>The CSV files are compatible with any statistical analysis tool:</p>"},{"location":"getting-started/quickstart/#python-pandas","title":"Python (pandas)","text":"<pre><code>import pandas as pd\n\ndf = pd.read_csv(\"919QDUH_traits.csv\")\nprint(df['primary_length'].describe())\n</code></pre>"},{"location":"getting-started/quickstart/#r","title":"R","text":"<pre><code>df &lt;- read.csv(\"919QDUH_traits.csv\")\nsummary(df$primary_length)\n</code></pre>"},{"location":"getting-started/quickstart/#excel","title":"Excel","text":"<p>Simply open the CSV file in Excel or Google Sheets.</p>"},{"location":"getting-started/quickstart/#visualizing-results","title":"Visualizing Results","text":"<pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load results\ndf = pd.read_csv(\"919QDUH_traits.csv\")\n\n# Plot length over time\nplt.figure(figsize=(10, 6))\nplt.plot(df['frame_idx'], df['primary_length'], label='Primary Root')\nplt.plot(df['frame_idx'], df['lateral_length_total'], label='Total Lateral Length')\nplt.xlabel('Frame')\nplt.ylabel('Length (pixels)')\nplt.title('Root Growth Over Time')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"getting-started/quickstart/#converting-pixels-to-real-units","title":"Converting Pixels to Real Units","text":"<p>SLEAP predictions are in pixels. To convert to real-world units (mm, cm):</p> <pre><code># Define scale (e.g., 100 pixels = 1 cm)\npixels_per_cm = 100\n\n# Convert traits\ndf['primary_length_cm'] = df['primary_length'] / pixels_per_cm\ndf['lateral_length_total_cm'] = df['lateral_length_total'] / pixels_per_cm\n</code></pre> <p>Determine your scale by:</p> <ol> <li>Including a ruler or reference object in images</li> <li>Measuring known distances in pixels</li> <li>Calculating pixels per unit</li> </ol>"},{"location":"getting-started/quickstart/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/quickstart/#no-module-named-sleap_roots","title":"\"No module named 'sleap_roots'\"","text":"<p>Activate your conda environment: <pre><code>conda activate sleap-roots\n</code></pre></p>"},{"location":"getting-started/quickstart/#filenotfounderror-predictionsslp","title":"\"FileNotFoundError: predictions.slp\"","text":"<p>Check that file paths are correct and files exist: <pre><code>from pathlib import Path\nassert Path(\"primary_roots.slp\").exists()\n</code></pre></p>"},{"location":"getting-started/quickstart/#empty-or-nan-traits","title":"Empty or NaN traits","text":"<p>This can happen if:</p> <ul> <li>SLEAP predictions are missing for some frames</li> <li>Root landmarks weren't detected</li> <li>Coordinate systems are misaligned</li> </ul> <p>Check your SLEAP predictions in the SLEAP GUI to verify quality.</p>"},{"location":"getting-started/quickstart/#keyerror-primary_pts","title":"\"KeyError: 'primary_pts'\"","text":"<p>Make sure you're using the correct pipeline for your data:</p> <ul> <li>Use <code>DicotPipeline</code> for primary + lateral roots</li> <li>Use <code>MonocotPipeline</code> for crown roots</li> <li>Check that you're loading the correct <code>.slp</code> files</li> </ul>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about SLEAP \u2013 Understand the prediction workflow</li> <li>Pipeline Guide \u2013 Deep dive into each pipeline</li> <li>Trait Reference \u2013 Full list of computed traits</li> <li>Batch Processing \u2013 Advanced batch workflows</li> <li>API Reference \u2013 Complete function documentation</li> </ul>"},{"location":"getting-started/what-is-sleap/","title":"What is SLEAP?","text":"<p>SLEAP (Social LEAP Estimates Animal Poses) is a deep learning framework for multi-animal pose estimation. While designed for tracking animal body parts, SLEAP works exceptionally well for plant root phenotyping.</p>"},{"location":"getting-started/what-is-sleap/#why-sleap-for-roots","title":"Why SLEAP for Roots?","text":"<p>SLEAP excels at tracking complex, branching structures over time \u2013 exactly what plant roots are!</p>"},{"location":"getting-started/what-is-sleap/#key-advantages","title":"Key Advantages","text":"<ul> <li>Multi-instance tracking \u2013 Track multiple roots simultaneously</li> <li>Temporal consistency \u2013 Associate landmarks across frames/time-points</li> <li>Flexible skeletons \u2013 Define custom root architectures (primary, lateral, crown)</li> <li>Active learning \u2013 Iteratively improve models with minimal labeling</li> <li>Fast inference \u2013 GPU-accelerated prediction on large datasets</li> </ul>"},{"location":"getting-started/what-is-sleap/#sleap-workflow","title":"SLEAP Workflow","text":"<p>The typical SLEAP workflow for root phenotyping:</p> <pre><code>graph LR\n    A[Root Images] --&gt; B[Label Landmarks]\n    B --&gt; C[Train Model]\n    C --&gt; D[Run Inference]\n    D --&gt; E[SLEAP Predictions .slp]\n    E --&gt; F[sleap-roots Analysis]\n    F --&gt; G[Trait CSV]</code></pre> <ol> <li>Collect images \u2013 Time-lapse or single time-point root images</li> <li>Label landmarks \u2013 Annotate key points (tips, bases, nodes) in SLEAP GUI</li> <li>Train model \u2013 Use SLEAP to train a pose estimation model</li> <li>Run inference \u2013 Generate predictions (<code>.slp</code> files) for all images</li> <li>Analyze with sleap-roots \u2013 Extract morphological traits from predictions</li> </ol>"},{"location":"getting-started/what-is-sleap/#root-skeleton-design","title":"Root Skeleton Design","text":"<p>A SLEAP skeleton defines the structure of landmarks to track. For roots, we typically use:</p>"},{"location":"getting-started/what-is-sleap/#dicot-skeleton-primary-lateral-roots","title":"Dicot Skeleton (Primary + Lateral Roots)","text":"<pre><code>Primary Root:\n  base \u2192 node1 \u2192 node2 \u2192 ... \u2192 tip\n\nLateral Roots (multiple instances):\n  base \u2192 node1 \u2192 node2 \u2192 ... \u2192 tip\n</code></pre>"},{"location":"getting-started/what-is-sleap/#monocot-skeleton-crown-roots","title":"Monocot Skeleton (Crown Roots)","text":"<pre><code>Crown Roots (multiple instances):\n  base \u2192 node1 \u2192 node2 \u2192 ... \u2192 tip\n</code></pre> <p>Each root is a connected chain of landmarks from base to tip.</p>"},{"location":"getting-started/what-is-sleap/#prediction-files-slp","title":"Prediction Files (.slp)","text":"<p>SLEAP generates <code>.slp</code> files containing:</p> <ul> <li>Landmark coordinates (x, y) for each point</li> <li>Instance tracks \u2013 Which points belong to which root</li> <li>Confidence scores \u2013 Model certainty for each prediction</li> <li>Frame associations \u2013 Temporal tracking across frames</li> </ul> <p>sleap-roots uses the sleap-io library to load and parse these files.</p>"},{"location":"getting-started/what-is-sleap/#example-loading-sleap-predictions","title":"Example: Loading SLEAP Predictions","text":"<pre><code>import sleap_io as sio\n\n# Load predictions\nlabels = sio.load_slp(\"primary_roots.slp\")\n\n# Access first frame\nframe = labels.labeled_frames[0]\n\n# Get first instance (root)\ninstance = frame.instances[0]\n\n# Get landmark points\nfor node, point in instance.points.items():\n    print(f\"{node.name}: ({point.x:.1f}, {point.y:.1f})\")\n</code></pre> <p>Output: <pre><code>base: (245.3, 189.2)\nnode1: (247.1, 210.5)\nnode2: (248.9, 231.8)\n...\ntip: (256.4, 523.7)\n</code></pre></p>"},{"location":"getting-started/what-is-sleap/#from-sleap-to-traits","title":"From SLEAP to Traits","text":"<p>sleap-roots converts SLEAP predictions into trait measurements:</p> <pre><code>import sleap_roots as sr\n\n# Load SLEAP predictions\nseries = sr.Series.load(\n    series_name=\"my_plant\",\n    primary_path=\"primary_roots.slp\",\n    lateral_path=\"lateral_roots.slp\"\n)\n\n# Extract points for a frame\npts = series.get_primary_points(frame_idx=0)\n# pts is a (n_points, 2) numpy array of (x, y) coordinates\n\n# Compute length from points\nfrom sleap_roots.lengths import get_root_lengths\nlength = get_root_lengths(pts)\n</code></pre> <p>The <code>Series</code> class handles loading, organizing, and extracting point data from SLEAP files.</p>"},{"location":"getting-started/what-is-sleap/#data-organization","title":"Data Organization","text":""},{"location":"getting-started/what-is-sleap/#single-root-type","title":"Single Root Type","text":"<p>For experiments with only one root type (e.g., primary only):</p> <pre><code>my_plant.slp  # SLEAP predictions\nmy_plant.h5   # Optional: original video\n</code></pre> <p>Load with: <pre><code>series = sr.Series.load(\n    series_name=\"my_plant\",\n    primary_path=\"my_plant.slp\",\n    h5_path=\"my_plant.h5\"  # Optional\n)\n</code></pre></p>"},{"location":"getting-started/what-is-sleap/#multiple-root-types","title":"Multiple Root Types","text":"<p>For dicots (primary + lateral) or monocots (primary + crown):</p> <pre><code>my_plant.primary.slp  # Primary root predictions\nmy_plant.lateral.slp  # Lateral root predictions\nmy_plant.h5           # Optional: video\n</code></pre> <p>Load with: <pre><code>series = sr.Series.load(\n    series_name=\"my_plant\",\n    primary_path=\"my_plant.primary.slp\",\n    lateral_path=\"my_plant.lateral.slp\",\n    h5_path=\"my_plant.h5\"\n)\n</code></pre></p>"},{"location":"getting-started/what-is-sleap/#batch-experiments","title":"Batch Experiments","text":"<p>For high-throughput experiments:</p> <pre><code>experiment/\n  plant1.primary.slp\n  plant1.lateral.slp\n  plant1.h5\n  plant2.primary.slp\n  plant2.lateral.slp\n  plant2.h5\n  ...\n</code></pre> <p>Use auto-discovery: <pre><code>paths = sr.find_all_slp_paths(\"experiment/\")\nplants = sr.load_series_from_slps(paths, h5s=True)\n</code></pre></p>"},{"location":"getting-started/what-is-sleap/#sleap-vs-sleap-roots","title":"SLEAP vs sleap-roots","text":"Tool Purpose Output SLEAP Pose estimation Landmark coordinates (.slp) sleap-roots Trait extraction Morphological measurements (CSV) <p>SLEAP is upstream \u2013 it detects and tracks root landmarks. sleap-roots is downstream \u2013 it computes biological traits from those landmarks.</p>"},{"location":"getting-started/what-is-sleap/#learning-sleap","title":"Learning SLEAP","text":"<p>To get started with SLEAP for root phenotyping:</p> <ol> <li>Official SLEAP Docs \u2013 https://sleap.ai/tutorials/</li> <li>Video Tutorial \u2013 SLEAP GUI walkthrough on YouTube</li> <li>Example Projects \u2013 Use sleap-roots test data as reference</li> <li>Community \u2013 SLEAP Discussions</li> </ol>"},{"location":"getting-started/what-is-sleap/#best-practices-for-root-labeling","title":"Best Practices for Root Labeling","text":"<p>When creating SLEAP training data:</p> <ul> <li>Label consistently \u2013 Always start at base, end at tip</li> <li>Label enough frames \u2013 50-100 frames is usually sufficient</li> <li>Use suggestion mode \u2013 Let SLEAP's active learning guide labeling</li> <li>Label all instances \u2013 Include all roots in each frame</li> <li>Verify predictions \u2013 Check inference quality before large-scale runs</li> </ul>"},{"location":"getting-started/what-is-sleap/#coordinate-systems","title":"Coordinate Systems","text":"<p>SLEAP predictions use image coordinates:</p> <ul> <li>Origin (0, 0) is top-left corner</li> <li>X-axis increases rightward</li> <li>Y-axis increases downward</li> </ul> <p>sleap-roots respects this coordinate system. For angle calculations, we account for the inverted Y-axis.</p>"},{"location":"getting-started/what-is-sleap/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start \u2013 Start analyzing SLEAP predictions</li> <li>Pipeline Guide \u2013 Choose the right pipeline</li> <li>Batch Processing \u2013 Process multiple plants</li> <li>Trait Reference \u2013 See all computed traits</li> </ul>"},{"location":"guides/","title":"Pipeline Guide","text":"<p>sleap-roots provides pre-built pipelines for different root system architectures. Choose the pipeline that matches your plant type and experimental setup.</p>"},{"location":"guides/#available-pipelines","title":"Available Pipelines","text":""},{"location":"guides/#dicot-pipelines","title":"Dicot Pipelines","text":"<ul> <li> <p>DicotPipeline</p> <p>For dicots with primary and lateral roots.</p> <p>Best for: Soy, canola, arabidopsis</p> <p>Root types: Primary + Lateral</p> <p>Traits: 40+ including lengths, angles, counts, topology</p> <p> Learn more</p> </li> <li> <p>MultipleDicotPipeline</p> <p>For multi-plant dicot setups (batch from single image).</p> <p>Best for: Multi-plant imaging systems</p> <p>Root types: Primary + Lateral (multiple plants)</p> <p>Traits: Same as DicotPipeline, per plant</p> <p> Learn more</p> </li> </ul>"},{"location":"guides/#monocot-pipelines","title":"Monocot Pipelines","text":"<ul> <li> <p>YoungerMonocotPipeline</p> <p>For young monocots with primary and crown roots.</p> <p>Best for: Early-stage rice, maize</p> <p>Root types: Primary + Crown</p> <p>Traits: 35+ including crown root metrics</p> <p> Learn more</p> </li> <li> <p>OlderMonocotPipeline</p> <p>For mature monocots (crown roots only, no primary).</p> <p>Best for: Later-stage rice, maize</p> <p>Root types: Crown only</p> <p>Traits: 25+ focused on crown root architecture</p> <p> Learn more</p> </li> </ul>"},{"location":"guides/#specialized-pipelines","title":"Specialized Pipelines","text":"<ul> <li> <p>MultiplePrimaryRootPipeline</p> <p>For plants with multiple primary roots.</p> <p>Best for: Specialized root architectures</p> <p>Root types: Multiple primary roots</p> <p>Traits: 30+ focused on multi-primary systems</p> <p> Learn more</p> </li> <li> <p>LateralRootPipeline</p> <p>For lateral root analysis only.</p> <p>Best for: Focused lateral root studies</p> <p>Root types: Lateral only</p> <p>Traits: 20+ lateral-specific traits</p> <p> Learn more</p> </li> </ul>"},{"location":"guides/#choosing-a-pipeline","title":"Choosing a Pipeline","text":"<p>Use this decision tree to select the appropriate pipeline:</p> <pre><code>graph TD\n    A[What plant type?] --&gt; B[Dicot]\n    A --&gt; C[Monocot]\n\n    B --&gt; D[Single or multiple plants?]\n    D --&gt; E[Single plant] --&gt; F[DicotPipeline]\n    D --&gt; G[Multiple plants] --&gt; H[MultipleDicotPipeline]\n\n    C --&gt; I[Does it have a primary root?]\n    I --&gt; J[Yes - young plant] --&gt; K[YoungerMonocotPipeline]\n    I --&gt; L[No - mature plant] --&gt; M[OlderMonocotPipeline]</code></pre>"},{"location":"guides/#quick-reference","title":"Quick Reference","text":"Plant Type Growth Stage Root Types Pipeline Soy, canola, arabidopsis Any Primary + Lateral <code>DicotPipeline</code> Rice, maize, wheat Early (\u22647 days) Primary + Crown <code>YoungerMonocotPipeline</code> Rice, maize, wheat Late (&gt;7 days) Crown only <code>OlderMonocotPipeline</code> Multiple dicots Any Primary + Lateral <code>MultipleDicotPipeline</code> Special architecture Any Multiple primary <code>MultiplePrimaryRootPipeline</code> Lateral root focus Any Lateral only <code>LateralRootPipeline</code>"},{"location":"guides/#pipeline-components","title":"Pipeline Components","text":"<p>All pipelines share a common structure:</p>"},{"location":"guides/#1-series-loading","title":"1. Series Loading","text":"<p>Load SLEAP predictions into a <code>Series</code> object:</p> <pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    series_name=\"my_plant\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\",  # Optional, depending on pipeline\n    h5_path=\"video.h5\"  # Optional\n)\n</code></pre>"},{"location":"guides/#2-pipeline-instantiation","title":"2. Pipeline Instantiation","text":"<p>Create a pipeline instance:</p> <pre><code>pipeline = sr.DicotPipeline()\n</code></pre>"},{"location":"guides/#3-trait-computation","title":"3. Trait Computation","text":"<p>Compute traits for single plant or batch:</p> <pre><code># Single plant\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\n# Batch processing\nplants = sr.load_series_from_slps(paths, h5s=True)\nbatch_traits = pipeline.compute_batch_traits(plants, write_csv=True)\n</code></pre>"},{"location":"guides/#common-workflows","title":"Common Workflows","text":""},{"location":"guides/#time-series-analysis","title":"Time-Series Analysis","text":"<p>For plants imaged over time:</p> <pre><code>import sleap_roots as sr\n\n# Load time-series data\nseries = sr.Series.load(\n    series_name=\"plant_growth\",\n    primary_path=\"timeseries.primary.slp\",\n    lateral_path=\"timeseries.lateral.slp\"\n)\n\n# Compute traits for each frame\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\n# traits will have one row per frame\n# Analyze growth over time\nimport matplotlib.pyplot as plt\nplt.plot(traits['frame_idx'], traits['primary_length'])\nplt.xlabel('Frame')\nplt.ylabel('Primary Root Length (pixels)')\nplt.show()\n</code></pre>"},{"location":"guides/#multi-plant-batch-processing","title":"Multi-Plant Batch Processing","text":"<p>For high-throughput experiments:</p> <pre><code>import sleap_roots as sr\n\n# Auto-discover all SLEAP files\npaths = sr.find_all_slp_paths(\"experiment_data/\")\n\n# Load all plants\nplants = sr.load_series_from_slps(paths, h5s=True)\n\n# Process batch\npipeline = sr.DicotPipeline()\nbatch_df = pipeline.compute_batch_traits(plants, write_csv=True)\n\n# Analyze population statistics\nprint(batch_df.groupby('plant')['primary_length'].mean())\n</code></pre>"},{"location":"guides/#custom-trait-selection","title":"Custom Trait Selection","text":"<p>Use individual trait functions for custom analyses:</p> <pre><code>from sleap_roots.lengths import get_root_lengths\nfrom sleap_roots.angles import get_primary_angle\nimport sleap_roots as sr\n\nseries = sr.Series.load(series_name=\"my_plant\", primary_path=\"primary.slp\")\n\n# Compute only specific traits\npts = series.get_primary_points(frame_idx=0)\nlength = get_root_lengths(pts)\nangle = get_primary_angle(pts)\n\nprint(f\"Length: {length:.2f}, Angle: {angle:.2f}\")\n</code></pre>"},{"location":"guides/#customizing-pipelines","title":"Customizing Pipelines","text":"<p>You can create custom pipelines by extending existing ones:</p> <pre><code>from sleap_roots import DicotPipeline, TraitDef\n\nclass MyCustomPipeline(DicotPipeline):\n    def get_trait_definitions(self):\n        # Get base traits\n        base_traits = super().get_trait_definitions()\n\n        # Add custom trait\n        custom_trait = TraitDef(\n            name=\"my_custom_trait\",\n            description=\"My custom measurement\",\n            compute_fn=lambda s, f: self._compute_custom(s, f)\n        )\n\n        return base_traits + [custom_trait]\n\n    def _compute_custom(self, series, frame_idx):\n        # Your custom logic here\n        return 42.0\n\n# Use custom pipeline\npipeline = MyCustomPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n</code></pre> <p>See Creating Pipelines for more details.</p>"},{"location":"guides/#output-format","title":"Output Format","text":"<p>All pipelines output CSV files with consistent structure:</p> Column Description Type <code>plant</code> Plant identifier str <code>frame_idx</code> Frame number int <code>primary_length</code> Primary root length float <code>lateral_count</code> Number of lateral roots int ... Other traits float/int <p>See Trait Reference for complete trait descriptions.</p>"},{"location":"guides/#next-steps","title":"Next Steps","text":"<ul> <li>Explore detailed pipeline documentation in the Pipelines section</li> <li>See the Trait Reference for all computed traits</li> <li>Learn about Batch Processing for high-throughput workflows</li> <li>Check the API Reference for detailed function documentation</li> </ul>"},{"location":"guides/batch-processing/","title":"Batch Processing","text":"<p>Documentation for batch processing workflows coming soon.</p>"},{"location":"guides/custom-pipelines/","title":"Creating Custom Pipelines","text":"<p>This guide explains how to create custom trait computation pipelines for specialized root system architectures or research questions.</p>"},{"location":"guides/custom-pipelines/#overview","title":"Overview","text":"<p>sleap-roots provides pre-built pipelines for common root types (dicots, monocots, etc.), but you may need a custom pipeline for:</p> <ul> <li>Novel root architectures</li> <li>Specialized trait combinations</li> <li>Research-specific metrics</li> <li>Custom preprocessing steps</li> <li>Integration with external tools</li> </ul>"},{"location":"guides/custom-pipelines/#pipeline-architecture","title":"Pipeline Architecture","text":""},{"location":"guides/custom-pipelines/#base-components","title":"Base Components","text":"<p>All pipelines inherit from a common base and implement:</p> <pre><code>class BasePipeline:\n    \"\"\"Base class for trait computation pipelines.\"\"\"\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute traits for a single plant.\"\"\"\n        pass\n\n    def get_trait_definitions(self):\n        \"\"\"Return metadata about computed traits.\"\"\"\n        pass\n</code></pre>"},{"location":"guides/custom-pipelines/#pipeline-flow","title":"Pipeline Flow","text":"<pre><code>graph TD\n    A[Series Object] --&gt; B[Get Root Landmarks]\n    B --&gt; C[Compute Primary Traits]\n    B --&gt; D[Compute Secondary Traits]\n    C --&gt; E[Compute Network Traits]\n    D --&gt; E\n    E --&gt; F[Aggregate Results]\n    F --&gt; G[Export to DataFrame]</code></pre>"},{"location":"guides/custom-pipelines/#creating-a-simple-custom-pipeline","title":"Creating a Simple Custom Pipeline","text":""},{"location":"guides/custom-pipelines/#step-1-define-pipeline-class","title":"Step 1: Define Pipeline Class","text":"<pre><code>import sleap_roots as sr\nimport pandas as pd\nfrom typing import Optional\n\nclass MyCustomPipeline:\n    \"\"\"Custom pipeline for my specific research question.\"\"\"\n\n    def __init__(self, primary_name: str = \"base\", lateral_name: str = \"lateral\"):\n        \"\"\"\n        Initialize pipeline with custom parameters.\n\n        Args:\n            primary_name: Node name for primary root base.\n            lateral_name: Node name for lateral root bases.\n        \"\"\"\n        self.primary_name = primary_name\n        self.lateral_name = lateral_name\n\n    def compute_plant_traits(\n        self,\n        series: sr.Series,\n        write_csv: bool = False,\n        csv_path: Optional[str] = None\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Compute custom traits for a plant.\n\n        Args:\n            series: Series object with SLEAP predictions.\n            write_csv: Whether to write results to CSV.\n            csv_path: Optional path for CSV output.\n\n        Returns:\n            DataFrame with computed traits.\n        \"\"\"\n        traits = {}\n\n        # Get root landmarks\n        primary_pts = series.get_primary_root_points()\n        lateral_pts_list = series.get_lateral_root_points()\n\n        # Compute your custom traits\n        traits['my_custom_length'] = self._compute_custom_length(primary_pts)\n        traits['my_custom_angle'] = self._compute_custom_angle(primary_pts)\n        traits['my_lateral_metric'] = self._compute_lateral_metric(lateral_pts_list)\n\n        # Convert to DataFrame\n        df = pd.DataFrame([traits])\n\n        # Optionally write to CSV\n        if write_csv:\n            output_path = csv_path or f\"{series.series_name}_traits.csv\"\n            df.to_csv(output_path, index=False)\n\n        return df\n\n    def _compute_custom_length(self, pts):\n        \"\"\"Compute a custom length metric.\"\"\"\n        # Your custom logic here\n        return sr.lengths.get_root_lengths([pts])[0]\n\n    def _compute_custom_angle(self, pts):\n        \"\"\"Compute a custom angle metric.\"\"\"\n        # Your custom logic here\n        return sr.angles.get_root_angle(pts, gravity_vector=(0, 1))\n\n    def _compute_lateral_metric(self, lateral_pts_list):\n        \"\"\"Compute a custom lateral root metric.\"\"\"\n        # Your custom logic here\n        return len(lateral_pts_list)\n</code></pre>"},{"location":"guides/custom-pipelines/#step-2-use-your-pipeline","title":"Step 2: Use Your Pipeline","text":"<pre><code># Load data\nseries = sr.Series.load(\n    \"my_plant\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Apply custom pipeline\npipeline = MyCustomPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\nprint(traits)\n</code></pre>"},{"location":"guides/custom-pipelines/#advanced-extending-existing-pipelines","title":"Advanced: Extending Existing Pipelines","text":""},{"location":"guides/custom-pipelines/#inherit-from-dicotpipeline","title":"Inherit from DicotPipeline","text":"<p>Instead of building from scratch, extend an existing pipeline:</p> <pre><code>class EnhancedDicotPipeline(sr.DicotPipeline):\n    \"\"\"DicotPipeline with additional custom traits.\"\"\"\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute standard dicot traits plus custom ones.\"\"\"\n\n        # Get standard dicot traits\n        traits = super().compute_plant_traits(series, write_csv=False)\n\n        # Add custom traits\n        primary_pts = series.get_primary_root_points()\n        traits['my_custom_metric'] = self._my_custom_computation(primary_pts)\n\n        # Write to CSV if requested\n        if write_csv:\n            output_path = csv_path or f\"{series.series_name}_enhanced_traits.csv\"\n            traits.to_csv(output_path, index=False)\n\n        return traits\n\n    def _my_custom_computation(self, pts):\n        \"\"\"Your custom trait computation.\"\"\"\n        # Example: compute tortuosity\n        path_length = sr.lengths.get_root_lengths([pts])[0]\n        euclidean_length = np.linalg.norm(pts[-1] - pts[0])\n        return path_length / euclidean_length if euclidean_length &gt; 0 else 1.0\n</code></pre>"},{"location":"guides/custom-pipelines/#trait-computation-utilities","title":"Trait Computation Utilities","text":""},{"location":"guides/custom-pipelines/#available-modules","title":"Available Modules","text":"<p>sleap-roots provides utility modules for common computations:</p>"},{"location":"guides/custom-pipelines/#length-calculations","title":"Length Calculations","text":"<pre><code>from sleap_roots import lengths\n\n# Total path length\nroot_length = lengths.get_root_lengths([pts])[0]\n\n# Smoothed length (reduces noise)\nsmooth_length = lengths.get_root_lengths_with_smoothing([pts], sigma=2)[0]\n\n# Maximum length points (useful for skeletonization)\nmax_pts = lengths.get_max_length_pts(pts)\n</code></pre>"},{"location":"guides/custom-pipelines/#angle-measurements","title":"Angle Measurements","text":"<pre><code>from sleap_roots import angles\n\n# Tip angle relative to gravity\ntip_angle = angles.get_root_angle(pts, gravity_vector=(0, 1))\n\n# Emergence angle for lateral roots\nemergence_angle = angles.get_lateral_root_angle(\n    primary_pt=base_point,\n    lateral_pts=lateral_root_pts\n)\n</code></pre>"},{"location":"guides/custom-pipelines/#tip-detection","title":"Tip Detection","text":"<pre><code>from sleap_roots import tips\n\n# Get root tip coordinates\ntip_coords = tips.get_root_tips([pts])\n\n# Tip angle using local tangent\ntip_angle = tips.get_tip_angle(pts, window_size=5)\n</code></pre>"},{"location":"guides/custom-pipelines/#base-detection","title":"Base Detection","text":"<pre><code>from sleap_roots import bases\n\n# Count lateral root bases\nbase_count = bases.count_root_bases(lateral_pts_list)\n\n# Get base positions\nbase_positions = bases.get_root_base_positions(primary_pts, lateral_pts_list)\n</code></pre>"},{"location":"guides/custom-pipelines/#network-analysis","title":"Network Analysis","text":"<pre><code>from sleap_roots import networklength\n\n# Total network length\ntotal_length = networklength.get_network_length(primary_pts, lateral_pts_list)\n\n# Network distribution metrics\nmetrics = networklength.get_network_distribution(primary_pts, lateral_pts_list)\n</code></pre>"},{"location":"guides/custom-pipelines/#morphology-metrics","title":"Morphology Metrics","text":"<pre><code>from sleap_roots import convhull\n\n# Convex hull area\nhull_area = convhull.get_convhull_area(pts_list)\n\n# Perimeter\nhull_perimeter = convhull.get_convhull_perimeter(pts_list)\n</code></pre>"},{"location":"guides/custom-pipelines/#complex-example-multi-root-architecture","title":"Complex Example: Multi-Root Architecture","text":"<p>Here's a complete example for a custom architecture with multiple root types:</p> <pre><code>import sleap_roots as sr\nimport pandas as pd\nimport numpy as np\n\nclass TripleRootPipeline:\n    \"\"\"Pipeline for plants with primary, lateral, and adventitious roots.\"\"\"\n\n    def __init__(self):\n        self.primary_name = \"primary_base\"\n        self.lateral_name = \"lateral_base\"\n        self.adventitious_name = \"adventitious_base\"\n\n    def compute_plant_traits(self, series, write_csv=False, csv_path=None):\n        \"\"\"Compute traits for three root types.\"\"\"\n        traits = {}\n\n        # Get all three root types\n        primary_pts = series.get_primary_root_points()\n        lateral_pts_list = series.get_lateral_root_points()\n        adventitious_pts_list = self._get_adventitious_points(series)\n\n        # Primary root traits\n        traits.update(self._compute_primary_traits(primary_pts))\n\n        # Lateral root traits\n        traits.update(self._compute_lateral_traits(lateral_pts_list))\n\n        # Adventitious root traits\n        traits.update(self._compute_adventitious_traits(adventitious_pts_list))\n\n        # Combined network traits\n        traits.update(self._compute_network_traits(\n            primary_pts, lateral_pts_list, adventitious_pts_list\n        ))\n\n        df = pd.DataFrame([traits])\n\n        if write_csv:\n            output_path = csv_path or f\"{series.series_name}_triple_traits.csv\"\n            df.to_csv(output_path, index=False)\n\n        return df\n\n    def _get_adventitious_points(self, series):\n        \"\"\"Extract adventitious root points from series.\"\"\"\n        # Custom logic to get adventitious roots\n        # This depends on how they're stored in your SLEAP data\n        return series.get_root_points_by_type(self.adventitious_name)\n\n    def _compute_primary_traits(self, pts):\n        \"\"\"Compute primary root traits.\"\"\"\n        return {\n            'primary_length': sr.lengths.get_root_lengths([pts])[0],\n            'primary_angle': sr.angles.get_root_angle(pts, (0, 1))\n        }\n\n    def _compute_lateral_traits(self, lateral_pts_list):\n        \"\"\"Compute lateral root traits.\"\"\"\n        lengths_array = sr.lengths.get_root_lengths(lateral_pts_list)\n        return {\n            'lateral_count': len(lateral_pts_list),\n            'lateral_total_length': np.sum(lengths_array),\n            'lateral_mean_length': np.mean(lengths_array) if len(lengths_array) &gt; 0 else 0\n        }\n\n    def _compute_adventitious_traits(self, adventitious_pts_list):\n        \"\"\"Compute adventitious root traits.\"\"\"\n        lengths_array = sr.lengths.get_root_lengths(adventitious_pts_list)\n        return {\n            'adventitious_count': len(adventitious_pts_list),\n            'adventitious_total_length': np.sum(lengths_array),\n            'adventitious_mean_length': np.mean(lengths_array) if len(lengths_array) &gt; 0 else 0\n        }\n\n    def _compute_network_traits(self, primary_pts, lateral_pts_list, adventitious_pts_list):\n        \"\"\"Compute whole-system network traits.\"\"\"\n        all_roots = [primary_pts] + lateral_pts_list + adventitious_pts_list\n        all_lengths = sr.lengths.get_root_lengths(all_roots)\n\n        return {\n            'total_root_count': len(all_roots),\n            'total_system_length': np.sum(all_lengths),\n            'convex_hull_area': sr.convhull.get_convhull_area(all_roots)\n        }\n</code></pre>"},{"location":"guides/custom-pipelines/#trait-definition-metadata","title":"Trait Definition Metadata","text":"<p>Document your pipeline's traits for users:</p> <pre><code>class MyCustomPipeline:\n    def get_trait_definitions(self):\n        \"\"\"Return metadata about computed traits.\"\"\"\n        return {\n            'my_custom_length': {\n                'description': 'Custom length metric accounting for...',\n                'units': 'pixels',\n                'formula': 'sum(segment_lengths) * custom_factor'\n            },\n            'my_custom_angle': {\n                'description': 'Angle measured from...',\n                'units': 'degrees',\n                'range': '0-360'\n            }\n        }\n</code></pre>"},{"location":"guides/custom-pipelines/#testing-your-pipeline","title":"Testing Your Pipeline","text":""},{"location":"guides/custom-pipelines/#unit-tests","title":"Unit Tests","text":"<pre><code>import pytest\nimport sleap_roots as sr\n\ndef test_custom_pipeline():\n    \"\"\"Test custom pipeline on example data.\"\"\"\n    # Load test data\n    series = sr.Series.load(\n        \"test_plant\",\n        h5_path=\"tests/data/test.h5\",\n        primary_path=\"tests/data/test_primary.slp\"\n    )\n\n    # Run pipeline\n    pipeline = MyCustomPipeline()\n    traits = pipeline.compute_plant_traits(series)\n\n    # Assertions\n    assert 'my_custom_length' in traits.columns\n    assert traits['my_custom_length'].iloc[0] &gt; 0\n    assert not traits.isnull().any().any()\n\ndef test_custom_trait_computation():\n    \"\"\"Test individual trait computation method.\"\"\"\n    pipeline = MyCustomPipeline()\n\n    # Mock data\n    pts = np.array([[0, 0], [1, 1], [2, 2]])\n\n    # Test computation\n    result = pipeline._compute_custom_length(pts)\n\n    assert isinstance(result, float)\n    assert result &gt; 0\n</code></pre>"},{"location":"guides/custom-pipelines/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_pipeline_end_to_end():\n    \"\"\"Test complete pipeline workflow.\"\"\"\n    # Load real data\n    series = sr.Series.load(\n        \"real_plant\",\n        h5_path=\"data/predictions.h5\",\n        primary_path=\"data/primary.slp\",\n        lateral_path=\"data/lateral.slp\"\n    )\n\n    # Run pipeline\n    pipeline = MyCustomPipeline()\n    traits = pipeline.compute_plant_traits(series, write_csv=True)\n\n    # Verify output\n    assert traits.shape[0] &gt; 0  # Has rows\n    assert traits.shape[1] &gt; 0  # Has columns\n    assert Path(f\"{series.series_name}_traits.csv\").exists()\n</code></pre>"},{"location":"guides/custom-pipelines/#best-practices","title":"Best Practices","text":""},{"location":"guides/custom-pipelines/#1-modular-design","title":"1. Modular Design","text":"<p>Break computations into small, testable functions:</p> <pre><code>def _compute_trait_a(self, pts):\n    \"\"\"Single responsibility: compute trait A.\"\"\"\n    pass\n\ndef _compute_trait_b(self, pts):\n    \"\"\"Single responsibility: compute trait B.\"\"\"\n    pass\n</code></pre>"},{"location":"guides/custom-pipelines/#2-error-handling","title":"2. Error Handling","text":"<p>Handle edge cases gracefully:</p> <pre><code>def _compute_custom_metric(self, pts):\n    \"\"\"Compute metric with error handling.\"\"\"\n    if len(pts) &lt; 2:\n        return np.nan  # Not enough points\n\n    try:\n        result = complex_computation(pts)\n    except Exception as e:\n        print(f\"Warning: Computation failed - {e}\")\n        return np.nan\n\n    return result\n</code></pre>"},{"location":"guides/custom-pipelines/#3-documentation","title":"3. Documentation","text":"<p>Document your pipeline thoroughly:</p> <pre><code>class MyCustomPipeline:\n    \"\"\"\n    Custom pipeline for [specific research application].\n\n    This pipeline computes traits for [root architecture description],\n    specifically designed for [use case].\n\n    Attributes:\n        param1: Description of parameter 1.\n        param2: Description of parameter 2.\n\n    Example:\n        &gt;&gt;&gt; series = sr.Series.load(...)\n        &gt;&gt;&gt; pipeline = MyCustomPipeline(param1=value1)\n        &gt;&gt;&gt; traits = pipeline.compute_plant_traits(series)\n    \"\"\"\n</code></pre>"},{"location":"guides/custom-pipelines/#4-reusable-components","title":"4. Reusable Components","text":"<p>Use existing utilities when possible:</p> <pre><code># Good: reuse existing utilities\nfrom sleap_roots import lengths, angles\n\nlength = lengths.get_root_lengths([pts])[0]\nangle = angles.get_root_angle(pts, (0, 1))\n\n# Avoid: reimplementing common functions\n# length = np.sum(np.linalg.norm(np.diff(pts, axis=0), axis=1))  # Don't do this\n</code></pre>"},{"location":"guides/custom-pipelines/#sharing-your-pipeline","title":"Sharing Your Pipeline","text":"<p>To share your custom pipeline:</p> <ol> <li> <p>Package it: <pre><code># my_custom_pipeline.py\nimport sleap_roots as sr\n\nclass MyCustomPipeline:\n    # Your implementation\n    pass\n</code></pre></p> </li> <li> <p>Document it: Create a README explaining:</p> </li> <li>What root architecture it targets</li> <li>What traits it computes</li> <li>How to use it</li> <li> <p>Example data</p> </li> <li> <p>Test it: Include unit tests demonstrating correctness</p> </li> <li> <p>Share it:</p> </li> <li>Create a GitHub repository</li> <li>Publish to PyPI (optional)</li> <li>Share with sleap-roots community</li> </ol>"},{"location":"guides/custom-pipelines/#next-steps","title":"Next Steps","text":"<ul> <li>Review Architecture for pipeline design patterns</li> <li>See Testing Guide for testing strategies</li> <li>Check API Reference for existing pipeline implementations</li> <li>Explore Trait Reference for trait computation details</li> <li>Read Adding Traits for contributing new trait computations</li> </ul>"},{"location":"guides/trait-reference/","title":"Trait Reference","text":"<p>Comprehensive reference for all traits computed by sleap-roots pipelines.</p>"},{"location":"guides/trait-reference/#coming-soon","title":"Coming Soon","text":"<p>Full trait reference documentation will be auto-generated from TraitDef objects.</p> <p>For now, see individual pipeline documentation or the API reference.</p>"},{"location":"guides/troubleshooting/","title":"Troubleshooting","text":"<p>This guide addresses common issues when using sleap-roots and provides solutions.</p>"},{"location":"guides/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"guides/troubleshooting/#git-lfs-data-not-downloaded","title":"Git LFS Data Not Downloaded","text":"<p>Problem: Example data files are missing or show as text pointers</p> <pre><code>Error: cannot load file 'test_data.h5'\n</code></pre> <p>Solution: <pre><code># Install Git LFS\ngit lfs install\n\n# Pull LFS data\ngit lfs pull\n\n# Verify files are binary (not text pointers)\nfile tests/data/*.h5  # Should show \"HDF5 data file\"\n</code></pre></p>"},{"location":"guides/troubleshooting/#import-errors","title":"Import Errors","text":"<p>Problem: <code>ModuleNotFoundError: No module named 'sleap_roots'</code></p> <p>Solution: <pre><code># Install in editable mode for development\npip install -e .\n\n# Or install normally\npip install sleap-roots\n\n# Verify installation\npython -c \"import sleap_roots; print(sleap_roots.__version__)\"\n</code></pre></p>"},{"location":"guides/troubleshooting/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>Problem: Version conflicts with other packages</p> <p>Solution: <pre><code># Create fresh environment\nconda create -n sleap-roots-env python=3.11\nconda activate sleap-roots-env\n\n# Install sleap-roots\npip install sleap-roots\n\n# Or use uv (faster)\npip install uv\nuv pip install sleap-roots\n</code></pre></p>"},{"location":"guides/troubleshooting/#data-loading-issues","title":"Data Loading Issues","text":""},{"location":"guides/troubleshooting/#cannot-load-h5-file","title":"Cannot Load H5 File","text":"<p>Problem: <code>OSError: Unable to open file</code></p> <p>Causes and solutions:</p> <ol> <li> <p>File doesn't exist: <pre><code>from pathlib import Path\nassert Path(\"predictions.h5\").exists(), \"H5 file not found\"\n</code></pre></p> </li> <li> <p>File is corrupted: <pre><code># Check file integrity\nh5ls predictions.h5  # Should list datasets\n\n# Try opening in Python\nimport h5py\nwith h5py.File(\"predictions.h5\", \"r\") as f:\n    print(list(f.keys()))\n</code></pre></p> </li> <li> <p>Wrong file format: Ensure file is exported from SLEAP, not a raw labels file: <pre><code># Export from SLEAP\nsleap-convert predictions.slp --format analysis --output predictions.h5\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#cannot-load-slp-file","title":"Cannot Load SLP File","text":"<p>Problem: <code>ValueError: Cannot load SLEAP file</code></p> <p>Solution: <pre><code># Verify SLP file is valid\nimport sleap_io as sio\n\nlabels = sio.load_slp(\"predictions.slp\")\nprint(f\"Loaded {len(labels)} frames\")\nprint(f\"Skeleton: {labels.skeleton.node_names}\")\n</code></pre></p>"},{"location":"guides/troubleshooting/#missing-predictions","title":"Missing Predictions","text":"<p>Problem: Empty or sparse predictions in H5/SLP files</p> <p>Solution: 1. Check SLEAP tracking quality 2. Lower confidence threshold in SLEAP 3. Review frames with missing tracks in SLEAP GUI</p>"},{"location":"guides/troubleshooting/#trait-computation-issues","title":"Trait Computation Issues","text":""},{"location":"guides/troubleshooting/#nan-values-in-traits","title":"NaN Values in Traits","text":"<p>Problem: Computed traits contain <code>NaN</code> values</p> <p>Common causes:</p> <ol> <li> <p>Insufficient tracking points: <pre><code># Check point count\nfor i, pts in enumerate(series.primary_pts):\n    if len(pts) &lt; 5:\n        print(f\"Frame {i}: only {len(pts)} points (need at least 5)\")\n</code></pre></p> </li> <li> <p>Empty root arrays: <pre><code># Check for empty roots\nif len(series.primary_pts) == 0:\n    print(\"No primary root points found\")\nif len(series.lateral_pts) == 0:\n    print(\"No lateral root points found\")\n</code></pre></p> </li> <li> <p>Division by zero: Handle edge cases in custom computations: <pre><code>def safe_ratio(numerator, denominator):\n    \"\"\"Compute ratio with NaN for zero denominator.\"\"\"\n    return numerator / denominator if denominator != 0 else np.nan\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#incorrect-trait-values","title":"Incorrect Trait Values","text":"<p>Problem: Trait values seem wrong or unexpected</p> <p>Debugging steps:</p> <ol> <li> <p>Visualize the data: <pre><code>import matplotlib.pyplot as plt\n\n# Plot root points\npts = series.primary_pts[0]\nplt.plot(pts[:, 0], pts[:, 1], 'o-')\nplt.title(\"Primary Root Points\")\nplt.gca().invert_yaxis()  # Match image coordinates\nplt.show()\n</code></pre></p> </li> <li> <p>Check intermediate values: <pre><code># Debug trait computation\npts = series.primary_pts[0]\nlength = sr.lengths.get_root_lengths([pts])[0]\nprint(f\"Computed length: {length:.2f} pixels\")\nprint(f\"Expected range: ~100-500 pixels\")\n</code></pre></p> </li> <li> <p>Verify pixel scaling: If physical units are needed: <pre><code># Convert pixels to mm\npixels_per_mm = 10  # Calibrate from your setup\nlength_mm = length_pixels / pixels_per_mm\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#missing-lateral-roots","title":"Missing Lateral Roots","text":"<p>Problem: Lateral root count is lower than expected</p> <p>Solutions:</p> <ol> <li>Check SLEAP tracking:</li> <li>Open <code>lateral.slp</code> in SLEAP GUI</li> <li>Verify all laterals are tracked</li> <li> <p>Check for broken tracks</p> </li> <li> <p>Verify node names: <pre><code># Check skeleton structure\nlabels = sio.load_slp(\"lateral.slp\")\nprint(\"Lateral root nodes:\", labels.skeleton.node_names)\n# Should include \"base\" or \"lateral\" node\n</code></pre></p> </li> <li> <p>Lower confidence threshold: <pre><code># When loading series, use lower threshold\nseries = sr.Series.load(\n    \"plant\",\n    h5_path=\"pred.h5\",\n    lateral_path=\"lateral.slp\",\n    confidence_threshold=0.3  # Lower threshold\n)\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#pipeline-specific-issues","title":"Pipeline-Specific Issues","text":""},{"location":"guides/troubleshooting/#dicotpipeline","title":"DicotPipeline","text":"<p>Problem: Primary-lateral connections incorrect</p> <p>Solution: <pre><code># Verify primary and lateral bases align\nprimary_pts = series.primary_pts[0]\nlateral_pts_list = series.lateral_pts[0]\n\n# Primary base should be near (0,0) in root coordinates\nprint(f\"Primary base: {primary_pts[0]}\")\n\n# Each lateral should start near primary\nfor i, lateral_pts in enumerate(lateral_pts_list):\n    print(f\"Lateral {i} base: {lateral_pts[0]}\")\n</code></pre></p>"},{"location":"guides/troubleshooting/#monocotpipeline","title":"MonocotPipeline","text":"<p>Problem: Crown roots not detected</p> <p>Solution: 1. Ensure crown roots are in separate file from primary 2. Check that crown root bases are labeled correctly 3. Verify SLEAP model detects all crown roots</p> <pre><code># Check crown root data\ncrown_pts_list = series.crown_pts[0]  # For monocot pipelines\nprint(f\"Crown root count: {len(crown_pts_list)}\")\n</code></pre>"},{"location":"guides/troubleshooting/#multiplepipeline","title":"MultiplePipeline","text":"<p>Problem: Plants not separated correctly</p> <p>Solution: <pre><code># Check track IDs\nlabels = sio.load_slp(\"predictions.slp\")\ntrack_ids = set()\nfor frame in labels:\n    for instance in frame:\n        if instance.track is not None:\n            track_ids.add(instance.track.name)\n\nprint(f\"Found {len(track_ids)} unique tracks: {track_ids}\")\n# Should match expected plant count\n</code></pre></p>"},{"location":"guides/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"guides/troubleshooting/#slow-computation","title":"Slow Computation","text":"<p>Problem: Trait computation takes too long</p> <p>Solutions:</p> <ol> <li> <p>Use vectorized operations: <pre><code># Fast: vectorized\nlengths = sr.lengths.get_root_lengths(all_roots)\n\n# Slow: iterative\nlengths = [sr.lengths.get_root_lengths([root])[0] for root in all_roots]\n</code></pre></p> </li> <li> <p>Process in parallel: <pre><code>from concurrent.futures import ProcessPoolExecutor\n\ndef process_plant(series):\n    pipeline = sr.DicotPipeline()\n    return pipeline.compute_plant_traits(series)\n\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    results = list(executor.map(process_plant, series_list))\n</code></pre></p> </li> <li> <p>Reduce temporal resolution: <pre><code># Sample every Nth frame instead of all frames\nseries_subsampled = series[::5]  # Every 5th frame\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Problem: Out of memory errors</p> <p>Solutions:</p> <ol> <li> <p>Process in batches: <pre><code># Process plants in batches\nbatch_size = 10\nfor i in range(0, len(series_list), batch_size):\n    batch = series_list[i:i+batch_size]\n    traits = pipeline.compute_multi_plant_traits(batch)\n    traits.to_csv(f\"traits_batch_{i}.csv\")\n</code></pre></p> </li> <li> <p>Clear unused data: <pre><code>import gc\n\nfor series in series_list:\n    traits = pipeline.compute_plant_traits(series)\n    # Process traits...\n    del series  # Free memory\n    gc.collect()\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#visualization-issues","title":"Visualization Issues","text":""},{"location":"guides/troubleshooting/#plots-not-showing","title":"Plots Not Showing","text":"<p>Problem: <code>plt.show()</code> doesn't display plots</p> <p>Solutions:</p> <ol> <li> <p>Use interactive backend: <pre><code>import matplotlib\nmatplotlib.use('TkAgg')  # or 'Qt5Agg'\nimport matplotlib.pyplot as plt\n</code></pre></p> </li> <li> <p>For Jupyter notebooks: <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\n</code></pre></p> </li> <li> <p>Save to file instead: <pre><code>plt.savefig('plot.png', dpi=300, bbox_inches='tight')\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#coordinate-system-issues","title":"Coordinate System Issues","text":"<p>Problem: Plots appear flipped or rotated</p> <p>Solution: <pre><code># Image coordinates: origin at top-left\nplt.plot(pts[:, 0], pts[:, 1], 'o-')\nplt.gca().invert_yaxis()  # Flip y-axis to match image\nplt.axis('equal')  # Equal aspect ratio\n</code></pre></p>"},{"location":"guides/troubleshooting/#export-issues","title":"Export Issues","text":""},{"location":"guides/troubleshooting/#csv-not-created","title":"CSV Not Created","text":"<p>Problem: <code>write_csv=True</code> but no file appears</p> <p>Solutions:</p> <ol> <li> <p>Check file permissions: <pre><code>import os\noutput_dir = \"output/\"\nos.makedirs(output_dir, exist_ok=True)\ntraits = pipeline.compute_plant_traits(series, write_csv=True,\n                                      csv_path=f\"{output_dir}/traits.csv\")\n</code></pre></p> </li> <li> <p>Verify write succeeded: <pre><code>from pathlib import Path\n\ncsv_path = \"traits.csv\"\ntraits = pipeline.compute_plant_traits(series, write_csv=True, csv_path=csv_path)\n\nif Path(csv_path).exists():\n    print(f\"CSV written successfully: {Path(csv_path).absolute()}\")\nelse:\n    print(\"CSV write failed!\")\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#csv-encoding-issues","title":"CSV Encoding Issues","text":"<p>Problem: Special characters garbled in CSV</p> <p>Solution: <pre><code># Specify UTF-8 encoding\ntraits.to_csv(\"traits.csv\", index=False, encoding='utf-8')\n</code></pre></p>"},{"location":"guides/troubleshooting/#testing-issues","title":"Testing Issues","text":""},{"location":"guides/troubleshooting/#tests-fail-locally","title":"Tests Fail Locally","text":"<p>Problem: Tests pass in CI but fail locally</p> <p>Solutions:</p> <ol> <li> <p>Check Git LFS data: <pre><code>git lfs pull\npytest tests/ -v\n</code></pre></p> </li> <li> <p>Verify environment: <pre><code>python --version  # Should match CI (3.11+)\npip list | grep sleap  # Check versions\n</code></pre></p> </li> <li> <p>Run specific test: <pre><code>pytest tests/test_pipelines.py::test_dicot_pipeline -v\n</code></pre></p> </li> </ol>"},{"location":"guides/troubleshooting/#import-errors-in-tests","title":"Import Errors in Tests","text":"<p>Problem: <code>ModuleNotFoundError</code> when running tests</p> <p>Solution: <pre><code># Install package in editable mode\npip install -e .\n\n# Run tests from repo root\npytest tests/\n</code></pre></p>"},{"location":"guides/troubleshooting/#platform-specific-issues","title":"Platform-Specific Issues","text":""},{"location":"guides/troubleshooting/#windows","title":"Windows","text":"<p>Path separators: <pre><code>from pathlib import Path\n\n# Good: platform-independent\npath = Path(\"data\") / \"predictions.h5\"\n\n# Avoid: hardcoded separators\n# path = \"data/predictions.h5\"  # May fail on Windows\n</code></pre></p> <p>Long paths: Enable long path support in Windows or use shorter paths</p>"},{"location":"guides/troubleshooting/#macos","title":"macOS","text":"<p>File permissions: <pre><code># Fix permissions if needed\nchmod +x scripts/process_data.sh\n</code></pre></p>"},{"location":"guides/troubleshooting/#linux","title":"Linux","text":"<p>Display issues: <pre><code># Set display for headless systems\nexport DISPLAY=:0\n</code></pre></p>"},{"location":"guides/troubleshooting/#common-error-messages","title":"Common Error Messages","text":""},{"location":"guides/troubleshooting/#keyerror-primary_root","title":"<code>KeyError: 'primary_root'</code>","text":"<p>Cause: Node name mismatch</p> <p>Solution: <pre><code># Check actual node names\nlabels = sio.load_slp(\"primary.slp\")\nprint(\"Available nodes:\", labels.skeleton.node_names)\n\n# Pass correct names to pipeline\npipeline = sr.DicotPipeline(primary_name=\"actual_node_name\")\n</code></pre></p>"},{"location":"guides/troubleshooting/#indexerror-list-index-out-of-range","title":"<code>IndexError: list index out of range</code>","text":"<p>Cause: Empty tracking results</p> <p>Solution: <pre><code># Check for empty frames\nfor i, frame_pts in enumerate(series.primary_pts):\n    if len(frame_pts) == 0:\n        print(f\"Frame {i} has no points\")\n</code></pre></p>"},{"location":"guides/troubleshooting/#valueerror-array-size-must-be-at-least-2","title":"<code>ValueError: array size must be at least 2</code>","text":"<p>Cause: Too few points for computation</p> <p>Solution: <pre><code># Filter frames with sufficient points\ndef has_enough_points(pts, min_points=5):\n    return len(pts) &gt;= min_points\n\nvalid_frames = [i for i, pts in enumerate(series.primary_pts)\n                if has_enough_points(pts)]\n</code></pre></p>"},{"location":"guides/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still stuck:</p> <ol> <li> <p>Check existing issues: GitHub Issues</p> </li> <li> <p>Search documentation: Use search bar (top of page)</p> </li> <li> <p>Create a minimal example: <pre><code>import sleap_roots as sr\n\n# Minimal code that reproduces the issue\nseries = sr.Series.load(...)\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series)\n# Error occurs here\n</code></pre></p> </li> <li> <p>Open an issue: Include:</p> </li> <li>Error message and full traceback</li> <li>Minimal reproducible example</li> <li>sleap-roots version: <code>import sleap_roots; print(sleap_roots.__version__)</code></li> <li>Python version: <code>python --version</code></li> <li> <p>Operating system</p> </li> <li> <p>Community support:</p> </li> <li>GitHub Discussions</li> <li>SLEAP Slack workspace</li> </ol>"},{"location":"guides/troubleshooting/#best-practices-for-avoiding-issues","title":"Best Practices for Avoiding Issues","text":""},{"location":"guides/troubleshooting/#1-validate-data-early","title":"1. Validate Data Early","text":"<pre><code>def validate_series(series):\n    \"\"\"Check series has required data.\"\"\"\n    assert len(series.primary_pts) &gt; 0, \"No primary root data\"\n    assert all(len(pts) &gt;= 2 for pts in series.primary_pts), \"Insufficient points\"\n    print(\"Series validation passed!\")\n\nvalidate_series(series)\n</code></pre>"},{"location":"guides/troubleshooting/#2-use-try-except-blocks","title":"2. Use Try-Except Blocks","text":"<pre><code>try:\n    traits = pipeline.compute_plant_traits(series)\nexcept Exception as e:\n    print(f\"Error processing {series.series_name}: {e}\")\n    # Log error and continue with next plant\n    continue\n</code></pre>"},{"location":"guides/troubleshooting/#3-log-intermediate-results","title":"3. Log Intermediate Results","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nlogger.info(f\"Processing {series.series_name}\")\ntraits = pipeline.compute_plant_traits(series)\nlogger.info(f\"Computed {len(traits.columns)} traits\")\n</code></pre>"},{"location":"guides/troubleshooting/#4-test-on-small-subset-first","title":"4. Test on Small Subset First","text":"<pre><code># Test on first 3 plants before processing all 100\ntest_series = series_list[:3]\nfor series in test_series:\n    traits = pipeline.compute_plant_traits(series)\n    print(f\"{series.series_name}: OK\")\n\n# If tests pass, process all\nall_traits = pipeline.compute_multi_plant_traits(series_list)\n</code></pre>"},{"location":"guides/troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Review Quick Start for basic usage</li> <li>Read Pipeline Guides for pipeline-specific details</li> <li>Check Trait Reference for trait definitions</li> <li>See Batch Processing for large-scale workflows</li> </ul>"},{"location":"guides/data-formats/csv-traits/","title":"CSV Traits","text":"<p>Documentation coming soon.</p>"},{"location":"guides/data-formats/hdf5/","title":"HDF5 Output","text":"<p>Documentation coming soon.</p>"},{"location":"guides/data-formats/sleap-files/","title":"SLEAP Files (.slp)","text":"<p>Documentation coming soon.</p>"},{"location":"guides/pipelines/dicot/","title":"DicotPipeline","text":"<p>Pipeline for analyzing dicot plants with primary and lateral roots.</p>"},{"location":"guides/pipelines/dicot/#overview","title":"Overview","text":"<p>DicotPipeline is designed for dicot species (e.g., soy, canola, arabidopsis) that have a single primary root with branching lateral roots.</p> <p>Root types required:</p> <ul> <li>Primary root (1 instance)</li> <li>Lateral roots (multiple instances)</li> </ul> <p>Computed traits: 40+ morphological measurements</p>"},{"location":"guides/pipelines/dicot/#quick-start","title":"Quick Start","text":"<pre><code>import sleap_roots as sr\n\n# Load SLEAP predictions\nseries = sr.Series.load(\n    series_name=\"919QDUH\",\n    h5_path=\"919QDUH.h5\",\n    primary_path=\"919QDUH.primary.slp\",\n    lateral_path=\"919QDUH.lateral.slp\"\n)\n\n# Create pipeline and compute traits\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\nprint(traits[['frame_idx', 'primary_length', 'lateral_count']].head())\n</code></pre>"},{"location":"guides/pipelines/dicot/#trait-categories","title":"Trait Categories","text":""},{"location":"guides/pipelines/dicot/#length-traits","title":"Length Traits","text":"<ul> <li><code>primary_length</code> \u2013 Total length of primary root</li> <li><code>lateral_length_total</code> \u2013 Sum of all lateral root lengths</li> <li><code>lateral_length_avg</code> \u2013 Average lateral root length</li> <li><code>lateral_length_max</code> \u2013 Maximum lateral root length</li> <li><code>lateral_length_min</code> \u2013 Minimum lateral root length</li> </ul>"},{"location":"guides/pipelines/dicot/#count-traits","title":"Count Traits","text":"<ul> <li><code>lateral_count</code> \u2013 Number of lateral roots detected</li> <li><code>primary_tip_count</code> \u2013 Number of primary root tips</li> </ul>"},{"location":"guides/pipelines/dicot/#angle-traits","title":"Angle Traits","text":"<ul> <li><code>primary_angle</code> \u2013 Angle of primary root from vertical</li> <li><code>lateral_angle_avg</code> \u2013 Average emergence angle of laterals</li> <li><code>lateral_angle_min</code> \u2013 Minimum lateral emergence angle</li> <li><code>lateral_angle_max</code> \u2013 Maximum lateral emergence angle</li> </ul>"},{"location":"guides/pipelines/dicot/#topology-traits","title":"Topology Traits","text":"<ul> <li><code>convex_hull_area</code> \u2013 Area of convex hull around all roots</li> <li><code>network_distribution_ratio</code> \u2013 Spatial distribution metric</li> <li><code>network_solidity</code> \u2013 Compactness of root network</li> </ul>"},{"location":"guides/pipelines/dicot/#data-requirements","title":"Data Requirements","text":""},{"location":"guides/pipelines/dicot/#sleap-skeleton","title":"SLEAP Skeleton","text":"<p>Primary root skeleton: <pre><code>base \u2192 node1 \u2192 node2 \u2192 ... \u2192 tip\n</code></pre></p> <p>Lateral root skeleton (multiple instances): <pre><code>base \u2192 node1 \u2192 node2 \u2192 ... \u2192 tip\n</code></pre></p>"},{"location":"guides/pipelines/dicot/#file-organization","title":"File Organization","text":"<p>Single time-point: <pre><code>plant_name.primary.slp  # Primary root predictions\nplant_name.lateral.slp  # Lateral root predictions\nplant_name.h5           # Optional: video file\n</code></pre></p>"},{"location":"guides/pipelines/dicot/#example-datasets","title":"Example Datasets","text":"<p>The test data includes dicot examples:</p> <ul> <li>Canola (7 days old): <code>tests/data/canola_7do/</code></li> <li>Soy (6 days old): <code>tests/data/soy_6do/</code></li> </ul>"},{"location":"guides/pipelines/dicot/#best-practices","title":"Best Practices","text":"<ul> <li>Ensure lateral roots are tracked separately from primary</li> <li>Label lateral root bases near primary root</li> <li>Use consistent skeleton structure across plants</li> <li>Verify SLEAP predictions before batch processing</li> </ul>"},{"location":"guides/pipelines/dicot/#see-also","title":"See Also","text":"<ul> <li>MultipleDicotPipeline \u2013 For multi-plant setups</li> <li>Trait Reference \u2013 Full trait descriptions</li> <li>API Reference \u2013 Detailed class documentation</li> </ul>"},{"location":"guides/pipelines/lateral-root/","title":"Lateral Root Pipeline","text":"<p>Documentation coming soon.</p>"},{"location":"guides/pipelines/multiple-dicot/","title":"Multiple Dicot Pipeline","text":"<p>Documentation coming soon.</p>"},{"location":"guides/pipelines/multiple-primary/","title":"Multiple Primary Root Pipeline","text":"<p>Documentation coming soon.</p>"},{"location":"guides/pipelines/older-monocot/","title":"Older Monocot Pipeline","text":"<p>Documentation coming soon.</p>"},{"location":"guides/pipelines/primary-root/","title":"Primary Root Pipeline","text":"<p>Documentation coming soon.</p>"},{"location":"guides/pipelines/younger-monocot/","title":"Younger Monocot Pipeline","text":"<p>Documentation coming soon.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>sleap_roots<ul> <li>angle</li> <li>bases</li> <li>convhull</li> <li>ellipse</li> <li>lengths</li> <li>networklength</li> <li>points</li> <li>scanline</li> <li>series</li> <li>summary</li> <li>tips</li> <li>trait_pipelines</li> </ul> </li> </ul>"},{"location":"reference/sleap_roots/","title":"Index","text":""},{"location":"reference/sleap_roots/#sleap_roots","title":"sleap_roots","text":"<p>High-level imports.</p>"},{"location":"reference/sleap_roots/angle/","title":"Angle","text":""},{"location":"reference/sleap_roots/angle/#sleap_roots.angle","title":"angle","text":"<p>Get angle of each root.</p>"},{"location":"reference/sleap_roots/angle/#sleap_roots.angle.get_node_ind","title":"get_node_ind","text":"<pre><code>get_node_ind(\n    pts: ndarray, proximal: bool = True\n) -&gt; ndarray\n</code></pre> <p>Find proximal/distal node index.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Numpy array of points of shape (instances, nodes, 2) or (nodes, 2).</p> required <code>proximal</code> <code>bool</code> <p>Boolean value, where true is proximal (default), false is distal.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of shape (instances,) of proximal or distal node indices.</p> <code>ndarray</code> <p>The proximal node is the first non-NaN node in the first half of the root.</p> <code>ndarray</code> <p>The distal node is the last non-NaN node in the last half of the root.</p> <code>ndarray</code> <p>If all nodes (or all nodes in the half of the root) are NaN, then zero is</p> <code>ndarray</code> <p>returned.</p> Source code in <code>sleap_roots/angle.py</code> <pre><code>def get_node_ind(pts: np.ndarray, proximal: bool = True) -&gt; np.ndarray:\n    \"\"\"Find proximal/distal node index.\n\n    Args:\n        pts: Numpy array of points of shape (instances, nodes, 2) or (nodes, 2).\n        proximal: Boolean value, where true is proximal (default), false is distal.\n\n    Returns:\n        An array of shape (instances,) of proximal or distal node indices.\n\n        The proximal node is the first non-NaN node in the first half of the root.\n\n        The distal node is the last non-NaN node in the last half of the root.\n\n        If all nodes (or all nodes in the half of the root) are NaN, then zero is\n        returned.\n    \"\"\"\n    # Check if pts is 2D, if so, reshape to 3D\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    n_instances, n_nodes, _ = pts.shape\n\n    # Identify where NaN values exist\n    is_nan = np.isnan(pts).any(axis=-1)  # (n_instances, n_nodes)\n\n    # If only NaN values, return NaN\n    if is_nan.all():\n        return np.zeros((n_instances,))\n\n    if proximal:\n        # Proximal nodes are in the first half of the root.\n        is_nan = is_nan[:, 1 : (n_nodes + 1) // 2]\n        node_ind = np.argmax(~is_nan, axis=-1) + 1\n    else:\n        # Distal nodes are in the last half of the root.\n        is_nan = is_nan[:, (n_nodes + 1) // 2 :]\n        node_ind = np.argmax(~is_nan[:, ::-1], axis=-1)\n        node_ind = n_nodes - node_ind - 1\n\n    # If the selected index is missing originally, return 0.\n    node_ind = np.where(is_nan.all(axis=-1), 0, node_ind)\n\n    return node_ind\n</code></pre>"},{"location":"reference/sleap_roots/angle/#sleap_roots.angle.get_root_angle","title":"get_root_angle","text":"<pre><code>get_root_angle(\n    pts: ndarray,\n    node_ind: ndarray,\n    proximal: bool = True,\n    base_ind: int = 0,\n) -&gt; ndarray\n</code></pre> <p>Find angles for each root.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Numpy array of points of shape (instances, nodes, 2).</p> required <code>node_ind</code> <code>ndarray</code> <p>Primary or lateral root node index.</p> required <code>proximal</code> <code>bool</code> <p>Boolean value, where true is proximal (default), false is distal.</p> <code>True</code> <code>base_ind</code> <code>int</code> <p>Index of base node in the skeleton (default: 0).</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of shape (instances,) of angles in degrees, modulo 360.</p> Source code in <code>sleap_roots/angle.py</code> <pre><code>def get_root_angle(\n    pts: np.ndarray, node_ind: np.ndarray, proximal: bool = True, base_ind: int = 0\n) -&gt; np.ndarray:\n    \"\"\"Find angles for each root.\n\n    Args:\n        pts: Numpy array of points of shape (instances, nodes, 2).\n        node_ind: Primary or lateral root node index.\n        proximal: Boolean value, where true is proximal (default), false is distal.\n        base_ind: Index of base node in the skeleton (default: 0).\n\n    Returns:\n        An array of shape (instances,) of angles in degrees, modulo 360.\n    \"\"\"\n    # if node_ind is a single  int value, make it as array to keep consistent\n    if not isinstance(node_ind, np.ndarray):\n        node_ind = [node_ind]\n\n    if np.isnan(node_ind).all():\n        return np.nan\n\n    if pts.ndim == 2:\n        pts = np.expand_dims(pts, axis=0)\n\n    angs_root = []\n    # Calculate the angle for each instance\n    for i in range(pts.shape[0]):\n        # if the node_ind is 0, do NOT calculate angs\n        if node_ind[i] == 0:\n            angs = np.nan\n        else:\n            xy = pts[i, node_ind[i], :] - pts[i, base_ind, :]  # center on base node\n            # calculate the angle and convert to the start with gravity direction\n            ang = np.arctan2(-xy[1], xy[0]) * 180 / np.pi\n            angs = abs(ang + 90) if ang &lt; 90 else abs(-(360 - 90 - ang))\n        angs_root.append(angs)\n    angs_root = np.array(angs_root)\n\n    # If only one root, return a scalar instead of a single-element array\n    if angs_root.shape[0] == 1:\n        return angs_root[0]\n    return angs_root\n</code></pre>"},{"location":"reference/sleap_roots/angle/#sleap_roots.angle.get_vector_angles_from_gravity","title":"get_vector_angles_from_gravity","text":"<pre><code>get_vector_angles_from_gravity(vectors: ndarray) -&gt; ndarray\n</code></pre> <p>Calculate the angle of given vectors from the gravity vector.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>ndarray</code> <p>An array of vectorss with shape (instances, 2), each representing a vector     from start to end in an instance.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of angles in degrees with shape (instances,), representing the angle</p> <code>ndarray</code> <p>between each vector and the downward-pointing gravity vector.</p> Source code in <code>sleap_roots/angle.py</code> <pre><code>def get_vector_angles_from_gravity(vectors: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Calculate the angle of given vectors from the gravity vector.\n\n    Args:\n        vectors: An array of vectorss with shape (instances, 2), each representing a vector\n                from start to end in an instance.\n\n    Returns:\n        An array of angles in degrees with shape (instances,), representing the angle\n        between each vector and the downward-pointing gravity vector.\n    \"\"\"\n    gravity_vector = np.array([0, 1])  # Downwards along the positive y-axis\n    # Calculate the angle between the vectors and the gravity vectors\n    angles = np.arctan2(vectors[:, 1], vectors[:, 0]) - np.arctan2(\n        gravity_vector[1], gravity_vector[0]\n    )\n    angles = np.degrees(angles)\n    # Normalize angles to the range [0, 180] since direction doesn't matter\n    angles = np.abs(angles)\n    angles[angles &gt; 180] = 360 - angles[angles &gt; 180]\n\n    # If only one root, return a scalar instead of a single-element array\n    if angles.shape[0] == 1:\n        return angles[0]\n    return angles\n</code></pre>"},{"location":"reference/sleap_roots/bases/","title":"Bases","text":""},{"location":"reference/sleap_roots/bases/#sleap_roots.bases","title":"bases","text":"<p>Trait calculations that rely on bases.</p>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_bases","title":"get_bases","text":"<pre><code>get_bases(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Return bases (r1) from each root.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of bases <code>(instances, (x, y))</code>. If the input is <code>(nodes, 2)</code>, an array of shape <code>(2,)</code> will be returned.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_bases(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return bases (r1) from each root.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        Array of bases `(instances, (x, y))`. If the input is `(nodes, 2)`, an array of\n            shape `(2,)` will be returned.\n    \"\"\"\n    # If the input has shape `(nodes, 2)`, reshape it for consistency\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    # Get the first point of each instance\n    base_pts = pts[:, 0]  # Shape is `(instances, 2)`\n\n    # If the input was `(nodes, 2)`, return an array of shape `(2,)` instead of `(1, 2)`\n    if base_pts.shape[0] == 1:\n        return base_pts[0]\n\n    return base_pts\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_tip_dist","title":"get_base_tip_dist","text":"<pre><code>get_base_tip_dist(\n    base_pts: ndarray, tip_pts: ndarray\n) -&gt; Union[ndarray, float]\n</code></pre> <p>Calculate the straight-line distance(s) from the base(s) to the tip(s).</p> <p>Parameters:</p> Name Type Description Default <code>base_pts</code> <code>ndarray</code> <p>The x and y coordinates of the base point(s) of the root(s). Shape can be either <code>(2,)</code> for a single point or <code>(instances, 2)</code> for multiple instances.</p> required <code>tip_pts</code> <code>ndarray</code> <p>The x and y coordinates of the tip point(s) of the root(s). Shape should match that of <code>base_pts</code>.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, float]</code> <p>Distance(s) from the base(s) to the tip(s) of the root(s). If there's only one distance (i.e., shape is <code>(1,)</code>), a scalar is returned. Otherwise, an array matching the first dimension of the input arrays is returned.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_tip_dist(\n    base_pts: np.ndarray, tip_pts: np.ndarray\n) -&gt; Union[np.ndarray, float]:\n    \"\"\"Calculate the straight-line distance(s) from the base(s) to the tip(s).\n\n    Args:\n        base_pts: The x and y coordinates of the base point(s) of the root(s). Shape can\n            be either `(2,)` for a single point or `(instances, 2)` for multiple\n            instances.\n        tip_pts: The x and y coordinates of the tip point(s) of the root(s). Shape\n            should match that of `base_pts`.\n\n    Returns:\n        Distance(s) from the base(s) to the tip(s) of the root(s). If there's only one\n            distance (i.e., shape is `(1,)`), a scalar is returned. Otherwise, an array\n            matching the first dimension of the input arrays is returned.\n    \"\"\"\n    # Check if the shapes of the two input arrays match\n    if base_pts.shape != tip_pts.shape:\n        raise ValueError(\"The shapes of base_pts and tip_pts must match.\")\n\n    # Compute the Euclidean distance(s) between the point(s)\n    distances = np.linalg.norm(base_pts - tip_pts, axis=-1)\n\n    # If distances is a scalar, check if either base_pts or tip_pts is NaN, and\n    # return NaN if true\n    if np.isscalar(distances):\n        if np.isnan(base_pts).any() or np.isnan(tip_pts).any():\n            return np.nan\n        return distances\n\n    # If distances is an array, create and apply the nan_mask\n    nan_mask = np.isnan(base_pts).any(axis=-1) | np.isnan(tip_pts).any(axis=-1)\n    distances[nan_mask] = np.nan\n\n    return distances\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_xs","title":"get_base_xs","text":"<pre><code>get_base_xs(base_pts: ndarray) -&gt; ndarray | floating\n</code></pre> <p>Get x coordinates of the base of each lateral root.</p> <p>Parameters:</p> Name Type Description Default <code>base_pts</code> <code>ndarray</code> <p>root bases as array of shape <code>(instances, 2)</code> or <code>(2)</code> when there is only one root, as is the case for primary roots.</p> required Return <p>An array of base x-coordinates (instances,) or a scalar when there is only one root.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_xs(base_pts: np.ndarray) -&gt; np.ndarray | np.floating:\n    \"\"\"Get x coordinates of the base of each lateral root.\n\n    Args:\n        base_pts: root bases as array of shape `(instances, 2)` or `(2)` when there is\n            only one root, as is the case for primary roots.\n\n    Return:\n        An array of base x-coordinates (instances,) or a scalar when there is only one root.\n    \"\"\"\n    # Check for the 2D shape of the input array\n    if base_pts.ndim == 1:\n        # If shape is `(2,)`, then reshape it to `(1, 2)` for consistency\n        base_pts = base_pts.reshape(1, 2)\n    elif base_pts.ndim != 2:\n        raise ValueError(\"Input array must be of shape `(instances, 2)` or `(2, )`.\")\n\n    # At this point, `base_pts` should be of shape `(instances, 2)`.\n    # Get the base x-value\n    base_xs = base_pts[:, 0]\n\n    # For a single array of 1 item, return the value.\n    if base_xs.shape == (1,):\n        # Return a scalar\n        return base_xs[0]\n\n    return base_xs\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_ys","title":"get_base_ys","text":"<pre><code>get_base_ys(base_pts: ndarray) -&gt; ndarray | floating\n</code></pre> <p>Get y coordinates of the base of each root.</p> <p>Parameters:</p> Name Type Description Default <code>base_pts</code> <code>ndarray</code> <p>root bases as array of shape <code>(instances, 2)</code> or <code>(2)</code> when there is only one root, as is the case for primary roots.</p> required Return <p>An array of the y-coordinates of bases (instances,) or a scalar when there is only one root.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_ys(base_pts: np.ndarray) -&gt; np.ndarray | np.floating:\n    \"\"\"Get y coordinates of the base of each root.\n\n    Args:\n        base_pts: root bases as array of shape `(instances, 2)` or `(2)`\n            when there is only one root, as is the case for primary roots.\n\n    Return:\n        An array of the y-coordinates of bases (instances,) or a scalar when there is only one root.\n    \"\"\"\n    # Check for the 2D shape of the input array\n    if base_pts.ndim == 1:\n        # If shape is `(2,)`, then reshape it to `(1, 2)` for consistency\n        base_pts = base_pts.reshape(1, 2)\n    elif base_pts.ndim != 2:\n        raise ValueError(\"Input array must be of shape `(instances, 2)` or `(2, )`.\")\n\n    # At this point, `base_pts` should be of shape `(instances, 2)`.\n    # Get the base y-value\n    base_ys = base_pts[:, 1]\n    # Now it has shape `(instances,)`\n    if base_ys.shape == (1,):\n        # Return a scalar\n        return base_ys[0]\n\n    return base_ys\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_length","title":"get_base_length","text":"<pre><code>get_base_length(lateral_base_ys: ndarray) -&gt; float\n</code></pre> <p>Get the y-axis difference from the top lateral base to the bottom lateral base.</p> <p>Parameters:</p> Name Type Description Default <code>lateral_base_ys</code> <code>ndarray</code> <p>y-coordinates of the base points of lateral roots of shape <code>(instances,)</code>.</p> required Return <p>The distance between the top base y-coordinate and the deepest base y-coordinate.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_length(lateral_base_ys: np.ndarray) -&gt; float:\n    \"\"\"Get the y-axis difference from the top lateral base to the bottom lateral base.\n\n    Args:\n        lateral_base_ys: y-coordinates of the base points of lateral roots of shape\n            `(instances,)`.\n\n    Return:\n        The distance between the top base y-coordinate and the deepest\n        base y-coordinate.\n    \"\"\"\n    # Compute the difference between the maximum and minimum y-coordinates\n    base_length = np.nanmax(lateral_base_ys) - np.nanmin(lateral_base_ys)\n    return base_length\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_ct_density","title":"get_base_ct_density","text":"<pre><code>get_base_ct_density(\n    primary_length_max: float, lateral_base_pts: ndarray\n) -&gt; float\n</code></pre> <p>Get a ratio of the number of base points to maximum primary root length.</p> <p>Parameters:</p> Name Type Description Default <code>primary_length_max</code> <code>float</code> <p>Scalar of maximum primary root length.</p> required <code>lateral_base_pts</code> <code>ndarray</code> <p>Base points of lateral roots as returned by <code>get_bases</code>, shape <code>(instances, 2)</code> or <code>(2,)</code>.</p> required Return <p>Scalar of base count density.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_ct_density(\n    primary_length_max: float, lateral_base_pts: np.ndarray\n) -&gt; float:\n    \"\"\"Get a ratio of the number of base points to maximum primary root length.\n\n    Args:\n        primary_length_max: Scalar of maximum primary root length.\n        lateral_base_pts: Base points of lateral roots as returned by `get_bases`,\n            shape `(instances, 2)` or `(2,)`.\n\n    Return:\n        Scalar of base count density.\n    \"\"\"\n    # Check if the input is valid for lateral_base_pts\n    if (\n        isinstance(lateral_base_pts, (np.floating, float, np.integer, int))\n        or np.isnan(lateral_base_pts).all()\n    ):\n        return np.nan\n\n    # Handle the case where lateral_base_pts has shape `(2,)`\n    if lateral_base_pts.ndim == 1 and lateral_base_pts.shape[0] == 2:\n        base_ct = 1  # Only one base point in this case\n\n    # Handle the case where lateral_base_pts has shape `(instances, 2)`\n    else:\n        base_ct = len(lateral_base_pts[~np.isnan(lateral_base_pts[:, 0])])\n\n    # Handle cases where maximum primary length is zero or NaN to avoid division by zero\n    if primary_length_max == 0 or np.isnan(primary_length_max):\n        return np.nan\n\n    # Calculate base_ct_density\n    base_ct_density = base_ct / primary_length_max\n\n    return base_ct_density\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_length_ratio","title":"get_base_length_ratio","text":"<pre><code>get_base_length_ratio(\n    primary_length: float, base_length: float\n) -&gt; float\n</code></pre> <p>Calculate the ratio of the length of the bases to the primary root length.</p> <p>Parameters:</p> Name Type Description Default <code>primary_length</code> <code>float</code> <p>Length of the primary root.</p> required <code>base_length</code> <code>float</code> <p>Length of the bases along the primary root.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Ratio of the length of the bases along the primary root to the primary root length.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_length_ratio(primary_length: float, base_length: float) -&gt; float:\n    \"\"\"Calculate the ratio of the length of the bases to the primary root length.\n\n    Args:\n        primary_length (float): Length of the primary root.\n        base_length (float): Length of the bases along the primary root.\n\n    Returns:\n        Ratio of the length of the bases along the primary root to the primary root\n            length.\n    \"\"\"\n    # If either of the lengths are NaN, return NaN\n    if np.isnan(primary_length) or np.isnan(base_length):\n        return np.nan\n\n    # Handle case where primary length is zero to avoid division by zero\n    if primary_length == 0:\n        return np.nan\n\n    # Compute and return the base length ratio\n    base_length_ratio = base_length / primary_length\n    return base_length_ratio\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_base_median_ratio","title":"get_base_median_ratio","text":"<pre><code>get_base_median_ratio(lateral_base_ys, primary_tip_pt_y)\n</code></pre> <p>Get ratio of median value in all base points to tip of primary root in y axis.</p> <p>Parameters:</p> Name Type Description Default <code>lateral_base_ys</code> <p>Y-coordinates of the base points of lateral roots of shape <code>(instances,)</code>.</p> required <code>primary_tip_pt_y</code> <p>Y-coordinate of the tip point of the primary root of shape <code>(1)</code> or a scalar.</p> required Return <p>Scalar of base median ratio. If all y-coordinates of the lateral root bases are     NaN, the function returns NaN.</p> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_base_median_ratio(lateral_base_ys, primary_tip_pt_y):\n    \"\"\"Get ratio of median value in all base points to tip of primary root in y axis.\n\n    Args:\n        lateral_base_ys: Y-coordinates of the base points of lateral roots of shape\n            `(instances,)`.\n        primary_tip_pt_y: Y-coordinate of the tip point of the primary root of shape\n            `(1)` or a scalar.\n\n    Return:\n        Scalar of base median ratio. If all y-coordinates of the lateral root bases are\n            NaN, the function returns NaN.\n    \"\"\"\n    # Check if all y-coordinates of lateral root bases are NaN, if so return NaN\n    if np.isnan(lateral_base_ys).all():\n        return np.nan\n\n    # Calculate the median of all y-coordinates of lateral root bases\n    median_base_y = np.nanmedian(lateral_base_ys)\n\n    # If primary_tip_pt_y is an array of shape (1), extract the scalar value\n    if isinstance(primary_tip_pt_y, np.ndarray) and primary_tip_pt_y.shape == (1,):\n        primary_tip_pt_y = primary_tip_pt_y[0]\n\n    # Compute the ratio of the median y-coordinate of lateral root bases to the\n    # y-coordinate of the primary root tip\n    base_median_ratio = median_base_y / primary_tip_pt_y\n\n    return base_median_ratio\n</code></pre>"},{"location":"reference/sleap_roots/bases/#sleap_roots.bases.get_root_widths","title":"get_root_widths","text":"<pre><code>get_root_widths(\n    primary_max_length_pts: ndarray,\n    lateral_pts: ndarray,\n    tolerance: float = 0.02,\n    return_inds: bool = False,\n) -&gt; Tuple[ndarray, list, ndarray, ndarray]\n</code></pre> <p>Estimate root width using bases of lateral roots.</p> <p>Parameters:</p> Name Type Description Default <code>primary_max_length_pts</code> <code>ndarray</code> <p>Longest primary root, represented as a 2D array of shape (nodes, 2).</p> required <code>lateral_pts</code> <code>ndarray</code> <p>Lateral roots, represented as a 3D array of shape (n, nodes, 2).</p> required <code>tolerance</code> <code>float</code> <p>Tolerance level for the projection difference between matched roots. Defaults to 0.02.</p> <code>0.02</code> <code>return_inds</code> <code>bool</code> <p>Flag to indicate whether to return matched indices along with distances. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <ul> <li>If <code>return_inds</code> is False (default): Returns an array of distances between the bases of matched roots. If no matched indices are found, NaN is returned.</li> </ul> <code>list</code> <ul> <li>If <code>return_inds</code> is True: Returns a tuple containing the following four elements:<ul> <li>matched_dists: Distances between the bases of matched roots. If no     matched indices are found, NaN is returned.</li> <li>matched_indices: List of tuples, each containing the indices     of matched roots on the left and right sides. A list containing a     tuple of NaNs is returned if no matched indices are found.</li> <li>left_bases_final: (n, 2) array containing the (x, y)     coordinates of the left bases of the matched roots. An array of     NaNs is returned if no matched indices are found.</li> <li>right_bases_final: (n, 2) array containing the (x, y)     coordinates of the right bases of the matched roots. An array of     NaNs is returned if no matched indices are found.</li> </ul> </li> </ul> Source code in <code>sleap_roots/bases.py</code> <pre><code>def get_root_widths(\n    primary_max_length_pts: np.ndarray,\n    lateral_pts: np.ndarray,\n    tolerance: float = 0.02,\n    return_inds: bool = False,\n) -&gt; Tuple[np.ndarray, list, np.ndarray, np.ndarray]:\n    \"\"\"Estimate root width using bases of lateral roots.\n\n    Args:\n        primary_max_length_pts: Longest primary root, represented\n            as a 2D array of shape (nodes, 2).\n        lateral_pts: Lateral roots, represented as a 3D array of\n            shape (n, nodes, 2).\n        tolerance: Tolerance level for the projection difference between matched roots.\n            Defaults to 0.02.\n        return_inds: Flag to indicate whether to return matched indices along with\n            distances. Defaults to False.\n\n    Returns:\n        - If `return_inds` is False (default):\n            Returns an array of distances between the bases of matched roots. If no\n            matched indices are found, NaN is returned.\n\n        - If `return_inds` is True:\n            Returns a tuple containing the following four elements:\n                - matched_dists: Distances between the bases of matched roots. If no\n                    matched indices are found, NaN is returned.\n                - matched_indices: List of tuples, each containing the indices\n                    of matched roots on the left and right sides. A list containing a\n                    tuple of NaNs is returned if no matched indices are found.\n                - left_bases_final: (n, 2) array containing the (x, y)\n                    coordinates of the left bases of the matched roots. An array of\n                    NaNs is returned if no matched indices are found.\n                - right_bases_final: (n, 2) array containing the (x, y)\n                    coordinates of the right bases of the matched roots. An array of\n                    NaNs is returned if no matched indices are found.\n    \"\"\"\n    # Validate tolerance\n    if tolerance &lt;= 0:\n        raise ValueError(\"Tolerance should be a positive number\")\n\n    # Check array dimensions\n    if primary_max_length_pts.ndim != 2 or lateral_pts.ndim != 3:\n        raise ValueError(\"Input arrays should be 2-dimensional and 3-dimensional\")\n\n    # Check the shape of the last dimensions\n    if primary_max_length_pts.shape[1] != 2 or lateral_pts.shape[2] != 2:\n        raise ValueError(\"The last dimension should contain x and y coordinates\")\n\n    # Initialize default return values\n    default_dists = np.nan\n    default_indices = [(np.nan, np.nan)]  # List of tuples with NaN values\n    default_left_bases = np.full((1, 2), np.nan)  # 2D array filled with NaN values\n    default_right_bases = np.full((1, 2), np.nan)  # 2D array filled with NaN values\n\n    # Check for minimum length, or all NaNs in arrays\n    if (\n        len(primary_max_length_pts) &lt; 2\n        or len(lateral_pts) &lt; 2\n        or np.isnan(primary_max_length_pts).all()\n        or np.isnan(lateral_pts).all()\n    ):\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Filter out any NaN points from the primary root points\n    primary_pts_filtered = primary_max_length_pts[\n        ~np.isnan(primary_max_length_pts).any(axis=-1)\n    ]\n    # Create a LineString object for the primary root\n    primary_line = LineString(primary_pts_filtered)\n\n    # Identify lateral roots that have a defined base (not NaN)\n    has_base = ~np.isnan(lateral_pts[:, 0, 0])\n    # Filter the lateral roots based on the valid base points\n    lateral_pts = lateral_pts[has_base]\n\n    # Determine if the base of each lateral root is to the left or right of the rest of\n    # the root\n    is_left = lateral_pts[:, 0, 0] &gt; np.nanmin(lateral_pts[:, 1:, 0], axis=1)\n\n    # If all lateral roots are on the same side, return default values\n    if is_left.all() or (~is_left).all():\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Split lateral roots into left and right bases\n    left_bases, right_bases = lateral_pts[is_left, 0], lateral_pts[~is_left, 0]\n\n    # Find the nearest points on the primary root for each right base\n    nearest_primary_right = [\n        nearest_points(primary_line, Point(right_base))[0] for right_base in right_bases\n    ]\n\n    # Find the nearest points on the primary root for each left base\n    nearest_primary_left = [\n        nearest_points(primary_line, Point(left_base))[0] for left_base in left_bases\n    ]\n\n    # Calculate the normalized projection of each nearest point on the primary root\n    # (right side)\n    nearest_primary_norm_right = np.array(\n        [primary_line.project(pt, normalized=True) for pt in nearest_primary_right]\n    )\n\n    # Calculate the normalized projection of each nearest point on the primary root\n    # (left side)\n    nearest_primary_norm_left = np.array(\n        [primary_line.project(pt, normalized=True) for pt in nearest_primary_left]\n    )\n\n    # Create a cost matrix based on the differences in projections between left and\n    # right bases\n    cost_matrix = np.abs(\n        nearest_primary_norm_left.reshape(-1, 1)\n        - nearest_primary_norm_right.reshape(1, -1)\n    )\n\n    # Use the Hungarian algorithm to find an optimal pairing that minimizes the sum of\n    # projection differences\n    left_inds, right_inds = linear_sum_assignment(cost_matrix)\n\n    # Filter out pairs where the projection difference exceeds the given tolerance\n    valid_pairs = cost_matrix[left_inds, right_inds] &lt;= tolerance\n    left_inds = left_inds[valid_pairs]\n    right_inds = right_inds[valid_pairs]\n\n    # If no valid pairs remain, return default values\n    if len(left_inds) == 0 or len(right_inds) == 0:\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Filter out pairs that do not intersect the primary root\n    is_intersecting = np.array(\n        [\n            primary_line.intersects(\n                LineString([left_bases[left_ind], right_bases[right_ind]])\n            )\n            for left_ind, right_ind in zip(left_inds, right_inds)\n        ]\n    )\n    left_inds = left_inds[is_intersecting]\n    right_inds = right_inds[is_intersecting]\n\n    # If no valid pairs remain, return default values\n    if len(left_inds) == 0 or len(right_inds) == 0:\n        if return_inds:\n            # Return the distances, matched indices, and the final left and right bases\n            return (\n                default_dists,\n                default_indices,\n                default_left_bases,\n                default_right_bases,\n            )\n        else:\n            # Default: Return the distances\n            return default_dists\n\n    # Update the left and right bases of the final paired coordinates\n    left_bases_final = left_bases[left_inds]\n    right_bases_final = right_bases[right_inds]\n\n    # Calculate the Euclidean distance between the bases of the valid pairs\n    match_dists = np.linalg.norm(\n        left_bases[left_inds] - right_bases[right_inds],\n        axis=-1,\n    )\n\n    # Create a list of tuples representing the indices of the matched pairs\n    matched_indices = list(zip(left_inds, right_inds))\n\n    if return_inds:\n        # Return the distances, matched indices, and the final left and right bases\n        return match_dists, matched_indices, left_bases_final, right_bases_final\n    else:\n        # Default: Return the distances\n        return match_dists\n</code></pre>"},{"location":"reference/sleap_roots/convhull/","title":"Convhull","text":""},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull","title":"convhull","text":"<p>Convex hull fitting and derived trait calculation.</p>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_convhull","title":"get_convhull","text":"<pre><code>get_convhull(pts: ndarray) -&gt; Optional[ConvexHull]\n</code></pre> <p>Compute the convex hull for the points per frame.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as an array of shape (..., 2).</p> required <p>Returns:</p> Type Description <code>Optional[ConvexHull]</code> <p>An object representing the convex hull or None if a hull can't be formed.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_convhull(pts: np.ndarray) -&gt; Optional[ConvexHull]:\n    \"\"\"Compute the convex hull for the points per frame.\n\n    Args:\n        pts: Root landmarks as an array of shape (..., 2).\n\n    Returns:\n        An object representing the convex hull or None if a hull can't be formed.\n    \"\"\"\n    # Ensure the input is an array of shape (..., 2)\n    if pts.ndim &lt; 2 or pts.shape[-1] != 2:\n        raise ValueError(\"Input points should be of shape (..., 2).\")\n\n    # Reshape and filter out NaN values\n    pts = pts.reshape(-1, 2)\n    pts = pts[~np.isnan(pts).any(axis=-1)]\n\n    # Check for infinite values\n    if np.isinf(pts).any():\n        logging.info(\"Cannot compute convex hull: input contains infinite values.\")\n        return None\n\n    # Ensure there are at least 3 unique non-collinear points\n    unique_pts = np.unique(pts, axis=0)\n    if len(unique_pts) &lt; 3:\n        logging.info(\"Cannot compute convex hull: not enough unique points.\")\n        return None\n\n    try:\n        # Compute and return the convex hull\n        return ConvexHull(unique_pts)\n    except Exception as e:\n        logging.info(f\"Cannot compute convex hull: {e}\")\n        return None\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_perimeter","title":"get_chull_perimeter","text":"<pre><code>get_chull_perimeter(\n    hull: Union[ndarray, ConvexHull, None],\n) -&gt; float\n</code></pre> <p>Calculate the perimeter of the convex hull formed by the given points.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull, None]</code> <p>Either an array of landmark points, a pre-computed convex hull, or None.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Scalar value representing the perimeter of the convex hull. Returns NaN if</p> <code>float</code> <p>unable to compute the convex hull or if the input is None.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_perimeter(hull: Union[np.ndarray, ConvexHull, None]) -&gt; float:\n    \"\"\"Calculate the perimeter of the convex hull formed by the given points.\n\n    Args:\n        hull: Either an array of landmark points, a pre-computed convex hull, or None.\n\n    Returns:\n        Scalar value representing the perimeter of the convex hull. Returns NaN if\n        unable to compute the convex hull or if the input is None.\n    \"\"\"\n    # If the input hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # If the input is an array, compute its convex hull\n    if isinstance(hull, np.ndarray):\n        hull = get_convhull(hull)\n\n    # If hull becomes None after attempting to compute the convex hull, return NaN\n    if hull is None:\n        return np.nan\n\n    # Ensure that the hull is of type ConvexHull\n    if not isinstance(hull, ConvexHull):\n        raise TypeError(\"After processing, the input must be a ConvexHull object.\")\n\n    # Compute the perimeter of the convex hull\n    return hull.area\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_area","title":"get_chull_area","text":"<pre><code>get_chull_area(hull: Union[ndarray, ConvexHull]) -&gt; float\n</code></pre> <p>Calculate the area of the convex hull formed by the given points.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull]</code> <p>Either an array of landmark points or a pre-computed convex hull.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Scalar value representing the area of the convex hull. Returns NaN if unable</p> <code>float</code> <p>to compute the convex hull.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_area(hull: Union[np.ndarray, ConvexHull]) -&gt; float:\n    \"\"\"Calculate the area of the convex hull formed by the given points.\n\n    Args:\n        hull: Either an array of landmark points or a pre-computed convex hull.\n\n    Returns:\n        Scalar value representing the area of the convex hull. Returns NaN if unable\n        to compute the convex hull.\n    \"\"\"\n    # If the input hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # If the input is an array, compute its convex hull\n    if isinstance(hull, np.ndarray):\n        hull = get_convhull(hull)\n\n    # If hull becomes None after attempting to compute the convex hull, return NaN\n    if hull is None:\n        return np.nan\n\n    # Ensure that the hull is of type ConvexHull\n    if not isinstance(hull, ConvexHull):\n        raise TypeError(\"After processing, the input must be a ConvexHull object.\")\n\n    # If hull couldn't be formed, return NaN\n    if hull is None:\n        return np.nan\n\n    # Return the area of the convex hull\n    return hull.volume\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_max_width","title":"get_chull_max_width","text":"<pre><code>get_chull_max_width(\n    hull: Union[ndarray, ConvexHull],\n) -&gt; float\n</code></pre> <p>Calculate the maximum width (in the x-axis direction) of the convex hull.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull]</code> <p>Either an array of landmark points or a pre-computed convex hull.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Scalar value representing the maximum width of the convex hull. Returns NaN if unable to compute the convex hull.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_max_width(hull: Union[np.ndarray, ConvexHull]) -&gt; float:\n    \"\"\"Calculate the maximum width (in the x-axis direction) of the convex hull.\n\n    Args:\n        hull: Either an array of landmark points or a pre-computed convex hull.\n\n    Returns:\n        Scalar value representing the maximum width of the convex hull. Returns NaN if\n            unable to compute the convex hull.\n    \"\"\"\n    # If hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # If the input is an array, compute its convex hull\n    if isinstance(hull, np.ndarray):\n        hull = get_convhull(hull)\n        if hull is None:\n            return np.nan\n        # Extract the convex hull points\n        hull_pts = hull.points[hull.vertices]\n    elif isinstance(hull, ConvexHull):\n        hull_pts = hull.points[hull.vertices]\n    else:\n        raise TypeError(\n            \"Input must be either an array of points or a ConvexHull object.\"\n        )\n\n    # Calculate the maximum width (difference in x-coordinates)\n    max_width = np.nanmax(hull_pts[:, 0]) - np.nanmin(hull_pts[:, 0])\n\n    return max_width\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_max_height","title":"get_chull_max_height","text":"<pre><code>get_chull_max_height(\n    hull: Union[ndarray, ConvexHull],\n) -&gt; float\n</code></pre> <p>Get maximum height of convex hull.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull]</code> <p>landmark points or a precomputed convex hull.</p> required Return <p>Scalar of convex hull maximum height. If the hull cannot be computed (e.g., insufficient valid points), NaN is returned.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_max_height(hull: Union[np.ndarray, ConvexHull]) -&gt; float:\n    \"\"\"Get maximum height of convex hull.\n\n    Args:\n        hull: landmark points or a precomputed convex hull.\n\n    Return:\n        Scalar of convex hull maximum height. If the hull cannot be computed (e.g.,\n        insufficient valid points), NaN is returned.\n    \"\"\"\n    # If hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # If the input is a ConvexHull object, use it directly\n    if isinstance(hull, ConvexHull):\n        hull = hull\n    else:\n        # Otherwise, compute the convex hull\n        hull = get_convhull(hull)\n\n    # If no valid convex hull could be computed, return NaN\n    if hull is None:\n        return np.nan\n\n    # Use the convex hull's vertices to compute the maximum height\n    max_height = np.nanmax(hull.points[hull.vertices, 1]) - np.nanmin(\n        hull.points[hull.vertices, 1]\n    )\n\n    return max_height\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_line_lengths","title":"get_chull_line_lengths","text":"<pre><code>get_chull_line_lengths(\n    hull: Union[ndarray, ConvexHull],\n) -&gt; ndarray\n</code></pre> <p>Get the pairwise distances between all vertices of the convex hull.</p> <p>Parameters:</p> Name Type Description Default <code>hull</code> <code>Union[ndarray, ConvexHull]</code> <p>Root landmarks as array of shape (..., 2) or a ConvexHull object.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array containing the pairwise distances between all vertices of the convex hull. If the convex hull fitting fails, an empty array is returned.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_line_lengths(hull: Union[np.ndarray, ConvexHull]) -&gt; np.ndarray:\n    \"\"\"Get the pairwise distances between all vertices of the convex hull.\n\n    Args:\n        hull: Root landmarks as array of shape (..., 2) or a ConvexHull object.\n\n    Returns:\n        An array containing the pairwise distances between all vertices of the convex\n            hull. If the convex hull fitting fails, an empty array is returned.\n    \"\"\"\n    # If hull is None, return NaN\n    if hull is None:\n        return np.nan\n\n    # Ensure pts is a ConvexHull object, otherwise get the convex hull\n    hull = hull if isinstance(hull, ConvexHull) else get_convhull(hull)\n\n    if hull is None:\n        return np.array([])\n\n    # Compute the pairwise distances between all vertices of the convex hull\n    chull_line_lengths = pdist(hull.points[hull.vertices], \"euclidean\")\n\n    return chull_line_lengths\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_division_areas","title":"get_chull_division_areas","text":"<pre><code>get_chull_division_areas(\n    rn_pts: ndarray, pts: ndarray, hull: ConvexHull\n) -&gt; Tuple[float, float]\n</code></pre> <p>Get areas above and below the line formed by the leftmost and rightmost rn nodes.</p> <p>Parameters:</p> Name Type Description Default <code>rn_pts</code> <code>ndarray</code> <p>The nth root nodes when indexing from 0. Shape is (instances, 2).</p> required <code>pts</code> <code>ndarray</code> <p>Numpy array of points with shape (instances, nodes, 2).</p> required <code>hull</code> <code>ConvexHull</code> <p>A ConvexHull object computed from pts.</p> required <p>Returns:</p> Type Description <code>float</code> <p>A tuple containing the areas of the convex hull of the points above and below</p> <code>float</code> <p>the line, respectively, where the line is formed by the leftmost and rightmost</p> <code>Tuple[float, float]</code> <p>rn nodes and the y-axis increases downward in image coordinates. Returns</p> <code>Tuple[float, float]</code> <p>(np.nan, np.nan) if the area cannot be calculated.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If pts does not have the expected shape, or if hull is not a valid</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_division_areas(\n    rn_pts: np.ndarray, pts: np.ndarray, hull: ConvexHull\n) -&gt; Tuple[float, float]:\n    \"\"\"Get areas above and below the line formed by the leftmost and rightmost rn nodes.\n\n    Args:\n        rn_pts: The nth root nodes when indexing from 0. Shape is (instances, 2).\n        pts: Numpy array of points with shape (instances, nodes, 2).\n        hull: A ConvexHull object computed from pts.\n\n    Returns:\n        A tuple containing the areas of the convex hull of the points above and below\n        the line, respectively, where the line is formed by the leftmost and rightmost\n        rn nodes and the y-axis increases downward in image coordinates. Returns\n        (np.nan, np.nan) if the area cannot be calculated.\n\n    Raises:\n        ValueError: If pts does not have the expected shape, or if hull is not a valid\n        ConvexHull object.\n    \"\"\"\n    if not isinstance(pts, np.ndarray) or pts.ndim != 3 or pts.shape[-1] != 2:\n        raise ValueError(\"pts must be a numpy array of shape (instances, nodes, 2).\")\n    if not isinstance(hull, ConvexHull):\n        raise ValueError(\"hull must be a ConvexHull object.\")\n\n    # There must be at least 3 unique non-collinear points to form a convex hull\n    # Flatten pts to 2D array and check for at least 3 unique points\n    flattened_pts = pts.reshape(-1, 2)\n    unique_pts = np.unique(flattened_pts, axis=0)\n    if len(unique_pts) &lt; 3:\n        return np.nan, np.nan\n\n    # Attempt to get the line equation between the leftmost and rightmost r1 nodes\n    try:\n        leftmost_rn = rn_pts[np.argmin(rn_pts[:, 0])]\n        rightmost_rn = rn_pts[np.argmax(rn_pts[:, 0])]\n        m, b = get_line_equation_from_points(leftmost_rn, rightmost_rn)\n    except Exception:\n        # If line equation cannot be found, return NaNs\n        return np.nan, np.nan\n\n    # Initialize lists to hold points above/on and below the line\n    above_or_on_line = []\n    below_line = []\n    # Classify each point as being above or below the line\n    for point in flattened_pts:\n        if (\n            point[1] &lt;= m * point[0] + b\n        ):  # y &lt;= mx + b (y increases downward in image coordinates)\n            above_or_on_line.append(point)\n        else:\n            below_line.append(point)\n\n    # Calculate areas using get_chull_area, return np.nan if no points satisfy the condition\n    area_above_line = (\n        get_chull_area(np.array(above_or_on_line)) if above_or_on_line else np.nan\n    )\n    area_below_line = get_chull_area(np.array(below_line)) if below_line else np.nan\n\n    return area_above_line, area_below_line\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_division_areas_above","title":"get_chull_division_areas_above","text":"<pre><code>get_chull_division_areas_above(\n    areas: Tuple[float, float],\n) -&gt; float\n</code></pre> <p>Get the chull area of the points above the line from <code>get_chull_division_areas</code>.</p> <p>Parameters:</p> Name Type Description Default <code>areas</code> <code>Tuple[float, float]</code> <p>Tuple containing two float objects: - The first is the area of the convex hull of the points above the line formed by the leftmost and rightmost rn nodes. - The second is the area of the convex hull of the points below the line formed by the leftmost and rightmost rn nodes.</p> required <p>Returns:</p> Name Type Description <code>area_above_line</code> <code>float</code> <p>the area of the convex hull of the points above the line, formed by the leftmost and rightmost rn nodes.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_division_areas_above(areas: Tuple[float, float]) -&gt; float:\n    \"\"\"Get the chull area of the points above the line from `get_chull_division_areas`.\n\n    Args:\n        areas: Tuple containing two float objects:\n            - The first is the area of the convex hull of the points above the line\n            formed by the leftmost and rightmost rn nodes.\n            - The second is the area of the convex hull of the points below the line\n            formed by the leftmost and rightmost rn nodes.\n\n    Returns:\n        area_above_line: the area of the convex hull of the points above the line,\n            formed by the leftmost and rightmost rn nodes.\n    \"\"\"\n    return areas[0]\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_division_areas_below","title":"get_chull_division_areas_below","text":"<pre><code>get_chull_division_areas_below(\n    areas: Tuple[float, float],\n) -&gt; float\n</code></pre> <p>Get the chull area of the points below the line from <code>get_chull_division_areas</code>.</p> <p>Parameters:</p> Name Type Description Default <code>areas</code> <code>Tuple[float, float]</code> <p>Tuple containing two float objects: - The first is the area of the convex hull of the points above the line formed by the leftmost and rightmost rn nodes. - The second is the area of the convex hull of the points below the line formed by the leftmost and rightmost rn nodes.</p> required <p>Returns:</p> Name Type Description <code>area_below_line</code> <code>float</code> <p>the area of the convex hull of the points below the line, formed by the leftmost and rightmost rn nodes.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_division_areas_below(areas: Tuple[float, float]) -&gt; float:\n    \"\"\"Get the chull area of the points below the line from `get_chull_division_areas`.\n\n    Args:\n        areas: Tuple containing two float objects:\n            - The first is the area of the convex hull of the points above the line\n            formed by the leftmost and rightmost rn nodes.\n            - The second is the area of the convex hull of the points below the line\n            formed by the leftmost and rightmost rn nodes.\n\n    Returns:\n        area_below_line: the area of the convex hull of the points below the line,\n            formed by the leftmost and rightmost rn nodes.\n    \"\"\"\n    return areas[1]\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_areas_via_intersection","title":"get_chull_areas_via_intersection","text":"<pre><code>get_chull_areas_via_intersection(\n    rn_pts: ndarray,\n    pts: ndarray,\n    hull: Optional[ConvexHull],\n) -&gt; Tuple[float, float]\n</code></pre> <p>Get convex hull areas above and below the intersecting line.</p> <p>Parameters:</p> Name Type Description Default <code>rn_pts</code> <code>ndarray</code> <p>The nth root nodes when indexing from 0. Shape is (instances, 2).</p> required <code>pts</code> <code>ndarray</code> <p>Numpy array of points with shape (instances, nodes, 2).</p> required <code>hull</code> <code>Optional[ConvexHull]</code> <p>A ConvexHull object computed from pts, or None if a convex hull couldn't be formed.</p> required <p>Returns:</p> Type Description <code>float</code> <p>A tuple containing the areas of the convex hull above and below</p> <code>float</code> <p>the line, respectively, where the line is formed by the leftmost and rightmost</p> <code>Tuple[float, float]</code> <p>rn nodes and the y-axis increases downward in image coordinates. Returns</p> <code>Tuple[float, float]</code> <p>(np.nan, np.nan) if the area cannot be calculated.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If pts does not have the expected shape.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_areas_via_intersection(\n    rn_pts: np.ndarray, pts: np.ndarray, hull: Optional[ConvexHull]\n) -&gt; Tuple[float, float]:\n    \"\"\"Get convex hull areas above and below the intersecting line.\n\n    Args:\n        rn_pts: The nth root nodes when indexing from 0. Shape is (instances, 2).\n        pts: Numpy array of points with shape (instances, nodes, 2).\n        hull: A ConvexHull object computed from pts, or None if a convex hull couldn't be formed.\n\n    Returns:\n        A tuple containing the areas of the convex hull above and below\n        the line, respectively, where the line is formed by the leftmost and rightmost\n        rn nodes and the y-axis increases downward in image coordinates. Returns\n        (np.nan, np.nan) if the area cannot be calculated.\n\n    Raises:\n        ValueError: If pts does not have the expected shape.\n    \"\"\"\n    # Check for valid pts input\n    if not isinstance(pts, np.ndarray) or pts.ndim != 3 or pts.shape[-1] != 2:\n        raise ValueError(\"pts must be a numpy array of shape (instances, nodes, 2).\")\n\n    # Flatten pts to 2D array and remove NaN values\n    flattened_pts = pts.reshape(-1, 2)\n    valid_pts = flattened_pts[~np.isnan(flattened_pts).any(axis=1)]\n    # Get unique points\n    unique_pts = np.unique(valid_pts, axis=0)\n\n    # Check for a valid or existing convex hull\n    if hull is None or len(unique_pts) &lt; 3:\n        return np.nan, np.nan\n\n    # Ensure rn_pts does not contain NaN values\n    rn_pts_valid = rn_pts[~np.isnan(rn_pts).any(axis=1)]\n    # Need at least two points to define a line\n    if len(rn_pts_valid) &lt; 2:\n        return np.nan, np.nan\n\n    # Attempt to get the line equation between the leftmost and rightmost rn nodes\n    try:\n        leftmost_rn = rn_pts[np.argmin(rn_pts[:, 0])]\n        rightmost_rn = rn_pts[np.argmax(rn_pts[:, 0])]\n        m, b = get_line_equation_from_points(leftmost_rn, rightmost_rn)\n    except Exception:\n        # If line equation cannot be found, return NaNs\n        return np.nan, np.nan\n\n    # Initialize lists to hold points above/on and below the line\n    above_line = []\n    below_line = []\n    # Classify each point as being above or below the line\n    for point in unique_pts:\n        if (\n            point[1] &lt;= m * point[0] + b\n        ):  # y &lt;= mx + b (y increases downward in image coordinates)\n            above_line.append(point)\n        if point[1] &gt;= m * point[0] + b:\n            below_line.append(point)\n\n    # Find the leftmost and rightmost points\n    leftmost_pt = np.nanmin(unique_pts[:, 0])\n    rightmost_pt = np.nanmax(unique_pts[:, 0])\n\n    # Define how far to extend the line in terms of x\n    x_min_extended = leftmost_pt  # Far left point\n    x_max_extended = rightmost_pt  # Far right point\n\n    # Calculate the corresponding y-values using the line equation\n    y_min_extended = m * x_min_extended + b\n    y_max_extended = m * x_max_extended + b\n\n    # Create the extended line\n    extended_line = LineString(\n        [(x_min_extended, y_min_extended), (x_max_extended, y_max_extended)]\n    )\n\n    # Create a LineString that represents the perimeter of the convex hull\n    hull_perimeter = LineString(\n        hull.points[hull.vertices].tolist() + [hull.points[hull.vertices[0]].tolist()]\n    )\n\n    # Find the intersection between the hull perimeter and the extended line\n    intersection = extended_line.intersection(hull_perimeter)\n    logging.debug(f\"Intersection: {intersection}\")\n\n    # Compute the intersection points and add to lists\n    if intersection and not intersection.is_empty:\n        logging.debug(\"Intersection points found between the convex hull and the line.\")\n        intersect_points = extract_points_from_geometry(intersection)\n        if not intersect_points:  # Ensure it's not an empty list\n            return np.nan, np.nan\n    else:\n        logging.debug(\n            \"No intersection points found between the convex hull and the line.\"\n        )\n        return np.nan, np.nan\n\n    # Add intersection points to the lists\n    above_line.extend(intersect_points)\n    below_line.extend(intersect_points)\n\n    # Calculate areas using get_chull_area\n    area_above_line = get_chull_area(np.array(above_line)) if above_line else np.nan\n    area_below_line = get_chull_area(np.array(below_line)) if below_line else np.nan\n\n    return area_above_line, area_below_line\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_area_via_intersection_above","title":"get_chull_area_via_intersection_above","text":"<pre><code>get_chull_area_via_intersection_above(\n    areas: Tuple[float, float],\n) -&gt; float\n</code></pre> <p>Get the chull area above the line from <code>get_chull_area_via_intersection</code>.</p> <p>Parameters:</p> Name Type Description Default <code>areas</code> <code>Tuple[float, float]</code> <p>Tuple containing two float objects: - The first is the area of the convex hull above the line formed by the leftmost and rightmost rn nodes. - The second is the area of the convex hull below the line formed by the leftmost and rightmost rn nodes.</p> required <p>Returns:</p> Name Type Description <code>area_above_line</code> <code>float</code> <p>the area of the convex hull above the line, formed by the leftmost and rightmost rn nodes.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_area_via_intersection_above(areas: Tuple[float, float]) -&gt; float:\n    \"\"\"Get the chull area above the line from `get_chull_area_via_intersection`.\n\n    Args:\n        areas: Tuple containing two float objects:\n            - The first is the area of the convex hull above the line\n            formed by the leftmost and rightmost rn nodes.\n            - The second is the area of the convex hull below the line\n            formed by the leftmost and rightmost rn nodes.\n\n    Returns:\n        area_above_line: the area of the convex hull above the line,\n            formed by the leftmost and rightmost rn nodes.\n    \"\"\"\n    return areas[0]\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_area_via_intersection_below","title":"get_chull_area_via_intersection_below","text":"<pre><code>get_chull_area_via_intersection_below(\n    areas: Tuple[float, float],\n) -&gt; float\n</code></pre> <p>Get the chull area below the line from <code>get_chull_area_via_intersection</code>.</p> <p>Parameters:</p> Name Type Description Default <code>areas</code> <code>Tuple[float, float]</code> <p>Tuple containing two float objects: - The first is the area of the convex hull above the line formed by the leftmost and rightmost rn nodes. - The second is the area of the convex hull below the line formed by the leftmost and rightmost rn nodes.</p> required <p>Returns:</p> Name Type Description <code>area_below_line</code> <code>float</code> <p>the area of the convex hull below the line, formed by the leftmost and rightmost rn nodes.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_area_via_intersection_below(areas: Tuple[float, float]) -&gt; float:\n    \"\"\"Get the chull area below the line from `get_chull_area_via_intersection`.\n\n    Args:\n        areas: Tuple containing two float objects:\n            - The first is the area of the convex hull above the line\n            formed by the leftmost and rightmost rn nodes.\n            - The second is the area of the convex hull below the line\n            formed by the leftmost and rightmost rn nodes.\n\n    Returns:\n        area_below_line: the area of the convex hull below the line,\n            formed by the leftmost and rightmost rn nodes.\n    \"\"\"\n    return areas[1]\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_intersection_vectors","title":"get_chull_intersection_vectors","text":"<pre><code>get_chull_intersection_vectors(\n    r0_pts: ndarray,\n    rn_pts: ndarray,\n    pts: ndarray,\n    hull: Optional[ConvexHull],\n) -&gt; Tuple[ndarray, ndarray]\n</code></pre> <p>Get vectors from top left and top right to intersection on convex hull.</p> <p>Parameters:</p> Name Type Description Default <code>r0_pts</code> <code>ndarray</code> <p>The 0th root nodes when indexing from 0. Shape is (instances, 2).</p> required <code>rn_pts</code> <code>ndarray</code> <p>The nth root nodes when indexing from 0. Shape is (instances, 2).</p> required <code>pts</code> <code>ndarray</code> <p>Numpy array of points with shape (instances, nodes, 2).</p> required <code>hull</code> <code>Optional[ConvexHull]</code> <p>A ConvexHull object computed from pts, or None if a convex hull couldn't be formed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A tuple containing vectors from the top left point to the left intersection point, and from</p> <code>ndarray</code> <p>the top right point to the right intersection point with the convex hull. Returns two vectors</p> <code>Tuple[ndarray, ndarray]</code> <p>of NaNs if the vectors can't be calculated. Vectors are of shape (1, 2).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If pts does not have the expected shape.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_intersection_vectors(\n    r0_pts: np.ndarray, rn_pts: np.ndarray, pts: np.ndarray, hull: Optional[ConvexHull]\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Get vectors from top left and top right to intersection on convex hull.\n\n    Args:\n        r0_pts: The 0th root nodes when indexing from 0. Shape is (instances, 2).\n        rn_pts: The nth root nodes when indexing from 0. Shape is (instances, 2).\n        pts: Numpy array of points with shape (instances, nodes, 2).\n        hull: A ConvexHull object computed from pts, or None if a convex hull couldn't be formed.\n\n    Returns:\n        A tuple containing vectors from the top left point to the left intersection point, and from\n        the top right point to the right intersection point with the convex hull. Returns two vectors\n        of NaNs if the vectors can't be calculated. Vectors are of shape (1, 2).\n\n    Raises:\n        ValueError: If pts does not have the expected shape.\n    \"\"\"\n    if r0_pts.ndim == 1 or rn_pts.ndim == 1 or pts.ndim == 2:\n        print(\n            \"Not enough instances or incorrect format to compute convex hull intersections.\"\n        )\n        return (np.array([[np.nan, np.nan]]), np.array([[np.nan, np.nan]]))\n\n    # Check for valid pts input\n    if not isinstance(pts, np.ndarray) or pts.ndim != 3 or pts.shape[-1] != 2:\n        raise ValueError(\"pts must be a numpy array of shape (instances, nodes, 2).\")\n    # Ensure rn_pts is a numpy array of shape (instances, 2)\n    if not isinstance(rn_pts, np.ndarray) or rn_pts.ndim != 2 or rn_pts.shape[-1] != 2:\n        raise ValueError(\"rn_pts must be a numpy array of shape (instances, 2).\")\n    # Ensure r0_pts is a numpy array of shape (instances, 2)\n    if not isinstance(r0_pts, np.ndarray) or r0_pts.ndim != 2 or r0_pts.shape[-1] != 2:\n        raise ValueError(f\"r0_pts must be a numpy array of shape (instances, 2).\")\n\n    # Flatten pts to 2D array and remove NaN values\n    flattened_pts = pts.reshape(-1, 2)\n    valid_pts = flattened_pts[~np.isnan(flattened_pts).any(axis=1)]\n    # Get unique points\n    unique_pts = np.unique(valid_pts, axis=0)\n\n    # Check for a valid or existing convex hull\n    if hull is None or len(unique_pts) &lt; 3:\n        logging.debug(\"Not enough unique points to compute convex hull intersections.\")\n        # Return two vectors of NaNs if not valid hull\n        return (np.array([[np.nan, np.nan]]), np.array([[np.nan, np.nan]]))\n\n    # Ensure rn_pts does not contain NaN values\n    rn_pts_valid = rn_pts[~np.isnan(rn_pts).any(axis=1)]\n    # Need at least two points to define a line\n    if len(rn_pts_valid) &lt; 2:\n        logging.debug(\n            \"Not enough valid rn points to compute convex hull intersections.\"\n        )\n        return (np.array([[np.nan, np.nan]]), np.array([[np.nan, np.nan]]))\n\n    # Ensuring r0_pts does not contain NaN values\n    r0_pts_valid = r0_pts[~np.isnan(r0_pts).any(axis=1)]\n    # Expect two vectors in the end\n    if len(r0_pts_valid) &lt; 2:\n        logging.debug(\n            \"Not enough valid r0 points to compute convex hull intersections.\"\n        )\n        return (np.array([[np.nan, np.nan]]), np.array([[np.nan, np.nan]]))\n\n    # Get the vertices of the convex hull\n    hull_vertices = hull.points[hull.vertices]\n\n    # Find the leftmost and rightmost r0 point\n    leftmost_r0 = r0_pts_valid[np.argmin(r0_pts_valid[:, 0])]\n    rightmost_r0 = r0_pts_valid[np.argmax(r0_pts_valid[:, 0])]\n\n    # Check if these points are on the convex hull\n    is_leftmost_on_hull = any(\n        np.array_equal(leftmost_r0, vertex) for vertex in hull_vertices\n    )\n    is_rightmost_on_hull = any(\n        np.array_equal(rightmost_r0, vertex) for vertex in hull_vertices\n    )\n\n    # Initialize vectors\n    leftmost_vector = np.array([[np.nan, np.nan]])\n    rightmost_vector = np.array([[np.nan, np.nan]])\n    if not is_leftmost_on_hull and not is_rightmost_on_hull:\n        logging.debug(\"Leftmost and rightmost r0 points are not on the convex hull.\")\n        # If leftmost and rightmost r0 points are not on the convex hull return NaNs\n        return leftmost_vector, rightmost_vector\n\n    # Attempt to get the line equation between the leftmost and rightmost rn nodes\n    try:\n        leftmost_rn = rn_pts[np.argmin(rn_pts[:, 0])]\n        rightmost_rn = rn_pts[np.argmax(rn_pts[:, 0])]\n        m, b = get_line_equation_from_points(leftmost_rn, rightmost_rn)\n    except Exception:\n        logging.debug(\n            \"Could not find line equation between leftmost and rightmost rn points.\"\n        )\n        # If line equation cannot be found, return NaNs\n        return leftmost_vector, rightmost_vector\n\n    # Find the leftmost and rightmost points\n    leftmost_pt = np.nanmin(unique_pts[:, 0])\n    rightmost_pt = np.nanmax(unique_pts[:, 0])\n\n    # Define how far to extend the line in terms of x\n    x_min_extended = leftmost_pt  # Far left point\n    x_max_extended = rightmost_pt  # Far right point\n\n    # Calculate the corresponding y-values using the line equation\n    y_min_extended = m * x_min_extended + b\n    y_max_extended = m * x_max_extended + b\n\n    # Create the extended line\n    extended_line = LineString(\n        [(x_min_extended, y_min_extended), (x_max_extended, y_max_extended)]\n    )\n\n    # Create a LineString that represents the perimeter of the convex hull\n    hull_perimeter = LineString(\n        hull.points[hull.vertices].tolist() + [hull.points[hull.vertices[0]].tolist()]\n    )\n\n    # Find the intersection between the hull perimeter and the extended line\n    intersection = extended_line.intersection(hull_perimeter)\n    logging.debug(f\"Intersection: {intersection}\")\n\n    # Get the intersection points\n    if intersection and not intersection.is_empty:\n        logging.debug(\n            f\"Intersection points found between the convex hull and the line: {intersection}.\"\n        )\n        intersect_points = extract_points_from_geometry(intersection)\n        if not intersect_points:  # Ensure it's not an empty list\n            logging.debug(\"No intersection points found after extraction.\")\n            return leftmost_vector, rightmost_vector\n    else:\n        logging.debug(\n            \"No intersection points found between the convex hull and the line.\"\n        )\n        # Return two vectors of NaNs if there is no intersection\n        return leftmost_vector, rightmost_vector\n\n    # Convert the list of NumPy arrays to a 2D NumPy array\n    intersection_points_array = np.vstack(intersect_points)\n\n    # Find the leftmost and rightmost intersection points\n    leftmost_intersect = intersection_points_array[\n        np.argmin(intersection_points_array[:, 0])\n    ]\n    rightmost_intersect = intersection_points_array[\n        np.argmax(intersection_points_array[:, 0])\n    ]\n\n    # Make a vector from the leftmost r0 point to the leftmost intersection point\n    leftmost_vector = (leftmost_intersect - leftmost_r0).reshape(1, -1)\n\n    # Make a vector from the rightmost r0 point to the rightmost intersection point\n    rightmost_vector = (rightmost_intersect - rightmost_r0).reshape(1, -1)\n\n    return leftmost_vector, rightmost_vector\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_intersection_vectors_left","title":"get_chull_intersection_vectors_left","text":"<pre><code>get_chull_intersection_vectors_left(\n    vectors: Tuple[ndarray, ndarray],\n) -&gt; ndarray\n</code></pre> <p>Get the vector from the top left point to the left intersection point.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>Tuple[ndarray, ndarray]</code> <p>Tuple containing two numpy arrays: - The first is the vector from the top left point to the left intersection point. - The second is the vector from the top right point to the right intersection point.</p> required <p>Returns:</p> Name Type Description <code>leftmost_vector</code> <code>ndarray</code> <p>the vector from the top left point to the left intersection point.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_intersection_vectors_left(\n    vectors: Tuple[np.ndarray, np.ndarray],\n) -&gt; np.ndarray:\n    \"\"\"Get the vector from the top left point to the left intersection point.\n\n    Args:\n        vectors: Tuple containing two numpy arrays:\n            - The first is the vector from the top left point to the left intersection point.\n            - The second is the vector from the top right point to the right intersection point.\n\n    Returns:\n        leftmost_vector: the vector from the top left point to the left intersection point.\n    \"\"\"\n    return vectors[0]\n</code></pre>"},{"location":"reference/sleap_roots/convhull/#sleap_roots.convhull.get_chull_intersection_vectors_right","title":"get_chull_intersection_vectors_right","text":"<pre><code>get_chull_intersection_vectors_right(\n    vectors: Tuple[ndarray, ndarray],\n) -&gt; ndarray\n</code></pre> <p>Get the vector from the top right point to the right intersection point.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>Tuple[ndarray, ndarray]</code> <p>Tuple containing two numpy arrays: - The first is the vector from the top left point to the left intersection point. - The second is the vector from the top right point to the right intersection point.</p> required <p>Returns:</p> Name Type Description <code>rightmost_vector</code> <code>ndarray</code> <p>the vector from the top right point to the right intersection point.</p> Source code in <code>sleap_roots/convhull.py</code> <pre><code>def get_chull_intersection_vectors_right(\n    vectors: Tuple[np.ndarray, np.ndarray],\n) -&gt; np.ndarray:\n    \"\"\"Get the vector from the top right point to the right intersection point.\n\n    Args:\n        vectors: Tuple containing two numpy arrays:\n            - The first is the vector from the top left point to the left intersection point.\n            - The second is the vector from the top right point to the right intersection point.\n\n    Returns:\n        rightmost_vector: the vector from the top right point to the right intersection point.\n    \"\"\"\n    return vectors[1]\n</code></pre>"},{"location":"reference/sleap_roots/ellipse/","title":"Ellipse","text":""},{"location":"reference/sleap_roots/ellipse/#sleap_roots.ellipse","title":"ellipse","text":"<p>Ellipse fitting and derived trait calculation.</p>"},{"location":"reference/sleap_roots/ellipse/#sleap_roots.ellipse.fit_ellipse","title":"fit_ellipse","text":"<pre><code>fit_ellipse(pts: ndarray) -&gt; Tuple[float, float, float]\n</code></pre> <p>Find a best fit ellipse for the points per frame.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape (..., 2).</p> required <p>Returns:</p> Type Description <code>float</code> <p>A tuple of (a, b, ratio) containing the semi-major axis length,</p> <code>float</code> <p>semi-minor axis length, and the ratio of the major to minor lengths.</p> <code>float</code> <p>If the ellipse fitting fails, NaNs are returned.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def fit_ellipse(pts: np.ndarray) -&gt; Tuple[float, float, float]:\n    \"\"\"Find a best fit ellipse for the points per frame.\n\n    Args:\n        pts: Root landmarks as array of shape (..., 2).\n\n    Returns:\n        A tuple of (a, b, ratio) containing the semi-major axis length,\n        semi-minor axis length, and the ratio of the major to minor lengths.\n\n        If the ellipse fitting fails, NaNs are returned.\n    \"\"\"\n    # Reshape the input array and filter out rows containing NaNs\n    pts = pts.reshape(-1, 2)\n    pts = pts[~(np.isnan(pts).all(axis=-1))]\n\n    # Check for a minimum number of points to fit an ellipse\n    if len(pts) &lt; 5:\n        return np.nan, np.nan, np.nan\n\n    # Initialize the ellipse model\n    ell = EllipseModel()\n\n    # Try to estimate the ellipse parameters\n    try:\n        success = ell.estimate(pts)\n    except TypeError as e:\n        # If the estimation fails, return NaNs\n        return np.nan, np.nan, np.nan\n\n    # Check if the estimation was successful\n    if success:\n        # Extract the ellipse parameters.\n        xc, yc, a_f, b_f, theta = ell.params\n\n        # Check for complex numbers in the parameters.\n        if np.iscomplex([xc, yc, a_f, b_f, theta]).any():\n            return np.nan, np.nan, np.nan\n\n        # Check for invalid (zero or NaN) major or minor axes.\n        if np.isnan(a_f) or np.isnan(b_f) or a_f == 0 or b_f == 0:\n            return np.nan, np.nan, np.nan\n\n        # Ensure a_f is the semi-major axis and b_f is the semi-minor axis.\n        a_f, b_f = np.maximum(a_f, b_f), np.minimum(a_f, b_f)\n\n        # Calculate the ratio of the major to minor axis.\n        ratio_ba_f = a_f / b_f\n\n        return a_f, b_f, ratio_ba_f\n\n    else:\n        # Return NaNs if the ellipse fitting was not successful.\n        return np.nan, np.nan, np.nan\n</code></pre>"},{"location":"reference/sleap_roots/ellipse/#sleap_roots.ellipse.get_ellipse_a","title":"get_ellipse_a","text":"<pre><code>get_ellipse_a(\n    pts_all_array: Union[\n        ndarray, Tuple[float, float, float]\n    ],\n)\n</code></pre> <p>Get semi-major axis length of the fitted ellipse.</p> <p>Parameters:</p> Name Type Description Default <code>pts_all_array</code> <code>Union[ndarray, Tuple[float, float, float]]</code> <p>landmark points or tuple of ellipse restults.</p> required Return <p>Scalar of semi-major axis length.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def get_ellipse_a(pts_all_array: Union[np.ndarray, Tuple[float, float, float]]):\n    \"\"\"Get semi-major axis length of the fitted ellipse.\n\n    Args:\n        pts_all_array: landmark points or tuple of ellipse restults.\n\n    Return:\n        Scalar of semi-major axis length.\n    \"\"\"\n    if type(pts_all_array) == tuple:\n        ellipse_a = pts_all_array[0]\n    else:\n        ellipse_features = fit_ellipse(pts_all_array)\n        ellipse_a = ellipse_features[0]\n    return ellipse_a\n</code></pre>"},{"location":"reference/sleap_roots/ellipse/#sleap_roots.ellipse.get_ellipse_b","title":"get_ellipse_b","text":"<pre><code>get_ellipse_b(\n    pts_all_array: Union[\n        ndarray, Tuple[float, float, float]\n    ],\n)\n</code></pre> <p>Get semi-minor axis length of the fitted ellipse.</p> <p>Parameters:</p> Name Type Description Default <code>pts_all_array</code> <code>Union[ndarray, Tuple[float, float, float]]</code> <p>landmark points or tuple of ellipse restults.</p> required Return <p>Scalar of semi-minor axis length.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def get_ellipse_b(pts_all_array: Union[np.ndarray, Tuple[float, float, float]]):\n    \"\"\"Get semi-minor axis length of the fitted ellipse.\n\n    Args:\n        pts_all_array: landmark points or tuple of ellipse restults.\n\n    Return:\n        Scalar of semi-minor axis length.\n    \"\"\"\n    if type(pts_all_array) == tuple:\n        ellipse_b = pts_all_array[1]\n    else:\n        ellipse_features = fit_ellipse(pts_all_array)\n        ellipse_b = ellipse_features[1]\n    return ellipse_b\n</code></pre>"},{"location":"reference/sleap_roots/ellipse/#sleap_roots.ellipse.get_ellipse_ratio","title":"get_ellipse_ratio","text":"<pre><code>get_ellipse_ratio(\n    pts_all_array: Union[\n        ndarray, Tuple[float, float, float]\n    ],\n)\n</code></pre> <p>Get ratio of the minor to major lengths of the fitted ellipse.</p> <p>Parameters:</p> Name Type Description Default <code>pts_all_array</code> <code>Union[ndarray, Tuple[float, float, float]]</code> <p>landmark points or tuple of ellipse restults.</p> required Return <p>Scalar of ratio of the minor to major lengths.</p> Source code in <code>sleap_roots/ellipse.py</code> <pre><code>def get_ellipse_ratio(pts_all_array: Union[np.ndarray, Tuple[float, float, float]]):\n    \"\"\"Get ratio of the minor to major lengths of the fitted ellipse.\n\n    Args:\n        pts_all_array: landmark points or tuple of ellipse restults.\n\n    Return:\n        Scalar of ratio of the minor to major lengths.\n    \"\"\"\n    if type(pts_all_array) == tuple:\n        ellipse_ratio = pts_all_array[2]\n    else:\n        ellipse_features = fit_ellipse(pts_all_array)\n        ellipse_ratio = ellipse_features[2]\n    return ellipse_ratio\n</code></pre>"},{"location":"reference/sleap_roots/lengths/","title":"Lengths","text":""},{"location":"reference/sleap_roots/lengths/#sleap_roots.lengths","title":"lengths","text":"<p>Get length-related traits.</p>"},{"location":"reference/sleap_roots/lengths/#sleap_roots.lengths.get_max_length_pts","title":"get_max_length_pts","text":"<pre><code>get_max_length_pts(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Points of the root with maximum length (intended for primary root traits).</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of points with shape <code>(nodes, 2)</code> from the root with maximum</p> <code>ndarray</code> <p>length, or the input array unchanged if its shape is <code>(nodes, 2)</code>.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_max_length_pts(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Points of the root with maximum length (intended for primary root traits).\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        np.ndarray: Array of points with shape `(nodes, 2)` from the root with maximum\n        length, or the input array unchanged if its shape is `(nodes, 2)`.\n    \"\"\"\n    # Return the input array unchanged if its shape is (nodes, 2)\n    if pts.ndim == 2 and pts.shape[1] == 2:\n        return pts\n\n    # Return NaN points if the input array is empty\n    if len(pts) == 0:\n        return np.array([[np.nan, np.nan]])\n\n    # Check if pts has the correct shape for processing multiple instances\n    if pts.ndim != 3 or pts.shape[2] != 2:\n        raise ValueError(\n            \"Input array should have shape (instances, nodes, 2) for multiple instances\"\n        )\n\n    # Calculate the differences between consecutive points in each root\n    segment_diffs = np.diff(pts, axis=1)\n\n    # Calculate the length of each segment\n    segment_lengths = np.linalg.norm(segment_diffs, axis=-1)\n\n    # Sum the lengths of the segments for each root\n    total_lengths = np.nansum(segment_lengths, axis=-1)\n\n    # Handle roots where all segment lengths are NaN,\n    # recording NaN in place of the total length for these roots\n    total_lengths[np.isnan(segment_lengths).all(axis=-1)] = np.nan\n\n    # Return NaN points if all total lengths are NaN\n    if np.isnan(total_lengths).all():\n        return np.array([[np.nan, np.nan]])\n\n    # Find the index of the root with the maximum total length\n    max_length_idx = np.nanargmax(total_lengths)\n\n    # Return the points of the root with this index\n    return pts[max_length_idx]\n</code></pre>"},{"location":"reference/sleap_roots/lengths/#sleap_roots.lengths.get_root_lengths","title":"get_root_lengths","text":"<pre><code>get_root_lengths(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Return root lengths for all roots in a frame.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of root lengths of shape <code>(instances,)</code>. If there is no root, or the root</p> <code>ndarray</code> <p>is one point only (all of the rest of the points are NaNs), an array of NaNs</p> <code>ndarray</code> <p>with shape (len(pts),) is returned. This is also the case for non-contiguous</p> <code>ndarray</code> <p>points.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_root_lengths(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return root lengths for all roots in a frame.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        Array of root lengths of shape `(instances,)`. If there is no root, or the root\n        is one point only (all of the rest of the points are NaNs), an array of NaNs\n        with shape (len(pts),) is returned. This is also the case for non-contiguous\n        points.\n    \"\"\"\n    # If the input has shape `(nodes, 2)`, reshape it for consistency\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    # Get the (x,y) differences of segments for each instance\n    segment_diffs = np.diff(pts, axis=1)\n    # Get the lengths of each segment by taking the norm\n    segment_lengths = np.linalg.norm(segment_diffs, axis=-1)\n    # Add the segments together to get the total length using nansum\n    total_lengths = np.nansum(segment_lengths, axis=-1)\n    # Find the NaN segment lengths and record NaN in place of 0 when finding the total\n    # length\n    total_lengths[np.isnan(segment_lengths).all(axis=-1)] = np.nan\n\n    # If there is 1 instance, return a scalar instead of an array of length 1\n    if len(total_lengths) == 1:\n        return total_lengths[0]\n\n    return total_lengths\n</code></pre>"},{"location":"reference/sleap_roots/lengths/#sleap_roots.lengths.get_curve_index","title":"get_curve_index","text":"<pre><code>get_curve_index(\n    lengths: Union[float, ndarray],\n    base_tip_dists: Union[float, ndarray],\n) -&gt; Union[float, ndarray]\n</code></pre> <p>Calculate the curvature index of a root.</p> <p>The curvature index quantifies the curviness of the root's growth. A higher curvature index indicates a curvier root (less responsive to gravity), while a lower index indicates a straighter root (more responsive to gravity). The index is computed as the difference between the maximum root length and straight-line distance from the base to the tip of the root, normalized by the root length.</p> <p>Parameters:</p> Name Type Description Default <code>lengths</code> <code>Union[float, ndarray]</code> <p>Maximum length of the root(s). Can be a scalar or a 1D numpy array of shape <code>(instances,)</code>.</p> required <code>base_tip_dists</code> <code>Union[float, ndarray]</code> <p>The straight-line distance from the base to the tip of the root(s). Can be a scalar or a 1D numpy array of shape <code>(instances,)</code>.</p> required <p>Returns:</p> Type Description <code>Union[float, ndarray]</code> <p>Curvature index of the root(s), quantifying its/their curviness. Will be a   scalar if input is scalar, or a 1D numpy array of shape <code>(instances,)</code>   otherwise.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_curve_index(\n    lengths: Union[float, np.ndarray], base_tip_dists: Union[float, np.ndarray]\n) -&gt; Union[float, np.ndarray]:\n    \"\"\"Calculate the curvature index of a root.\n\n    The curvature index quantifies the curviness of the root's growth. A higher\n    curvature index indicates a curvier root (less responsive to gravity), while a\n    lower index indicates a straighter root (more responsive to gravity). The index is\n    computed as the difference between the maximum root length and straight-line\n    distance from the base to the tip of the root, normalized by the root length.\n\n    Args:\n        lengths: Maximum length of the root(s). Can be a scalar or a 1D numpy array\n            of shape `(instances,)`.\n        base_tip_dists: The straight-line distance from the base to the tip of the\n            root(s). Can be a scalar or a 1D numpy array of shape `(instances,)`.\n\n    Returns:\n       Curvature index of the root(s), quantifying its/their curviness. Will be a\n            scalar if input is scalar, or a 1D numpy array of shape `(instances,)`\n            otherwise.\n    \"\"\"\n    # Check if the input is scalar or array\n    is_scalar_input = np.isscalar(lengths) and np.isscalar(base_tip_dists)\n\n    # Convert scalars to numpy arrays for uniform handling\n    lengths = np.atleast_1d(np.asarray(lengths, dtype=float))\n    base_tip_dists = np.atleast_1d(np.asarray(base_tip_dists, dtype=float))\n\n    # Check for shape mismatch\n    if lengths.shape != base_tip_dists.shape:\n        raise ValueError(\"The shapes of lengths and base_tip_dists must match.\")\n\n    # Calculate the curvature index where possible\n    curve_index = np.where(\n        (~np.isnan(lengths))\n        &amp; (~np.isnan(base_tip_dists))\n        &amp; (lengths &gt; 0)\n        &amp; (lengths &gt;= base_tip_dists),\n        (lengths - base_tip_dists) / np.where(lengths != 0, lengths, np.nan),\n        np.nan,\n    )\n\n    # Return scalar or array based on the input type\n    if is_scalar_input:\n        return curve_index.item()\n    else:\n        return curve_index\n</code></pre>"},{"location":"reference/sleap_roots/lengths/#sleap_roots.lengths.get_min_distance_line_to_line","title":"get_min_distance_line_to_line","text":"<pre><code>get_min_distance_line_to_line(\n    line1: LineString, line2: LineString\n) -&gt; float\n</code></pre> <p>Calculate the minimum distance between two LineString objects.</p> <p>This function computes the shortest distance between any two points on the first line segment and the second line segment. If the lines intersect, the minimum distance is zero. The distance is calculated in the same units as the coordinates of the LineStrings.</p> <p>Args: line1: The first LineString object representing a line segment. line2: The second LineString object representing a line segment.</p> <p>Returns: The minimum distance between the two line segments.</p> Source code in <code>sleap_roots/lengths.py</code> <pre><code>def get_min_distance_line_to_line(line1: LineString, line2: LineString) -&gt; float:\n    \"\"\"Calculate the minimum distance between two LineString objects.\n\n    This function computes the shortest distance between any two points on the first\n    line segment and the second line segment. If the lines intersect, the minimum\n    distance is zero. The distance is calculated in the same units as the coordinates\n    of the LineStrings.\n\n    Args:\n    line1: The first LineString object representing a line segment.\n    line2: The second LineString object representing a line segment.\n\n    Returns:\n    The minimum distance between the two line segments.\n    \"\"\"\n    # Check if the inputs are LineString instances\n    if not isinstance(line1, LineString):\n        raise TypeError(\"The first argument must be a LineString object.\")\n    if not isinstance(line2, LineString):\n        raise TypeError(\"The second argument must be a LineString object.\")\n\n    return line1.distance(line2)\n</code></pre>"},{"location":"reference/sleap_roots/networklength/","title":"Networklength","text":""},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength","title":"networklength","text":"<p>Fraction of root network length in the lower fraction of the plant.</p>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_bbox","title":"get_bbox","text":"<pre><code>get_bbox(pts: ndarray) -&gt; Tuple[float, float, float, float]\n</code></pre> <p>Return the bounding box of all landmarks.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape (..., 2).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Tuple of four parameters in bounding box:</p> <code>float</code> <p>left_x, the x axis value of left side</p> <code>float</code> <p>top_y, the y axis value of top side</p> <code>float</code> <p>width, the width of the bounding box</p> <code>Tuple[float, float, float, float]</code> <p>height, the height of bounding box.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_bbox(pts: np.ndarray) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Return the bounding box of all landmarks.\n\n    Args:\n        pts: Root landmarks as array of shape (..., 2).\n\n    Returns:\n        Tuple of four parameters in bounding box:\n        left_x, the x axis value of left side\n        top_y, the y axis value of top side\n        width, the width of the bounding box\n        height, the height of bounding box.\n    \"\"\"\n    # reshape to (# instance, 2) and filter out NaNs.\n    pts2 = pts.reshape(-1, 2)\n    pts2 = pts2[~(np.isnan(pts2).any(axis=-1))]\n\n    # get the bounding box\n    if pts2.shape[0] == 0:\n        return (np.nan, np.nan, np.nan, np.nan)\n    else:\n        left_x, top_y = np.min(pts2[:, 0]), np.min(pts2[:, 1])\n        width, height = np.max(pts2[:, 0]) - np.min(pts2[:, 0]), np.max(\n            pts2[:, 1]\n        ) - np.min(pts2[:, 1])\n        bbox = (left_x, top_y, width, height)\n    return bbox\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_bbox_left_x","title":"get_bbox_left_x","text":"<pre><code>get_bbox_left_x(\n    bbox: Tuple[float, float, float, float],\n) -&gt; float\n</code></pre> <p>Return the x-axis value from the left side of a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>Tuple[float, float, float, float]</code> <p>A bounding box represented as a tuple of four floats:   (left_x, top_y, width, height).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The x-axis value (left_x) of the left side of the bounding box.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_bbox_left_x(bbox: Tuple[float, float, float, float]) -&gt; float:\n    \"\"\"Return the x-axis value from the left side of a bounding box.\n\n    Args:\n        bbox: A bounding box represented as a tuple of four floats:\n              (left_x, top_y, width, height).\n\n    Returns:\n        The x-axis value (left_x) of the left side of the bounding box.\n    \"\"\"\n    return bbox[0]\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_bbox_top_y","title":"get_bbox_top_y","text":"<pre><code>get_bbox_top_y(\n    bbox: Tuple[float, float, float, float],\n) -&gt; float\n</code></pre> <p>Return the x-axis value from the left side of a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>Tuple[float, float, float, float]</code> <p>A bounding box represented as a tuple of four floats:     (left_x, top_y, width, height).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The y-axis value (top_y) of the top side of the bounding box.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_bbox_top_y(bbox: Tuple[float, float, float, float]) -&gt; float:\n    \"\"\"Return the x-axis value from the left side of a bounding box.\n\n    Args:\n       bbox: A bounding box represented as a tuple of four floats:\n              (left_x, top_y, width, height).\n\n    Returns:\n        The y-axis value (top_y) of the top side of the bounding box.\n    \"\"\"\n    return bbox[1]\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_bbox_width","title":"get_bbox_width","text":"<pre><code>get_bbox_width(\n    bbox: Tuple[float, float, float, float],\n) -&gt; float\n</code></pre> <p>Return the x-axis value from the left side of a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>Tuple[float, float, float, float]</code> <p>A bounding box represented as a tuple of four floats:   (left_x, top_y, width, height).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The width of a bounding box.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_bbox_width(bbox: Tuple[float, float, float, float]) -&gt; float:\n    \"\"\"Return the x-axis value from the left side of a bounding box.\n\n    Args:\n        bbox: A bounding box represented as a tuple of four floats:\n              (left_x, top_y, width, height).\n\n    Returns:\n        The width of a bounding box.\n\n    \"\"\"\n    return bbox[2]\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_bbox_height","title":"get_bbox_height","text":"<pre><code>get_bbox_height(\n    bbox: Tuple[float, float, float, float],\n) -&gt; float\n</code></pre> <p>Return the x-axis value from the left side of a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>Tuple[float, float, float, float]</code> <p>A bounding box represented as a tuple of four floats:   (left_x, top_y, width, height).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The height of the bounding box.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_bbox_height(bbox: Tuple[float, float, float, float]) -&gt; float:\n    \"\"\"Return the x-axis value from the left side of a bounding box.\n\n    Args:\n        bbox: A bounding box represented as a tuple of four floats:\n              (left_x, top_y, width, height).\n\n    Returns:\n        The height of the bounding box.\n    \"\"\"\n    return bbox[3]\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_network_width_depth_ratio","title":"get_network_width_depth_ratio","text":"<pre><code>get_network_width_depth_ratio(\n    pts: Union[ndarray, Tuple[float, float, float, float]],\n) -&gt; float\n</code></pre> <p>Return width to depth ratio of bounding box for root network.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>Union[ndarray, Tuple[float, float, float, float]]</code> <p>Root landmarks as array of shape (..., 2) or boundary box.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Float of bounding box width to depth ratio of root network.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_width_depth_ratio(\n    pts: Union[np.ndarray, Tuple[float, float, float, float]],\n) -&gt; float:\n    \"\"\"Return width to depth ratio of bounding box for root network.\n\n    Args:\n        pts: Root landmarks as array of shape (..., 2) or boundary box.\n\n    Returns:\n        Float of bounding box width to depth ratio of root network.\n    \"\"\"\n    # get the bounding box\n    if type(pts) == tuple:\n        bbox = pts\n    else:\n        bbox = get_bbox(pts)\n    width, height = bbox[2], bbox[3]\n    if width &gt; 0 and height &gt; 0:\n        ratio = width / height\n        return ratio\n    else:\n        return np.nan\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_network_length","title":"get_network_length","text":"<pre><code>get_network_length(\n    lengths0: Union[float, ndarray],\n    *args: Optional[Union[float, ndarray]]\n) -&gt; float\n</code></pre> <p>Return the total root network length given primary and lateral root lengths.</p> <p>Parameters:</p> Name Type Description Default <code>lengths0</code> <code>Union[float, ndarray]</code> <p>Either a float representing the length of a single root or an array of root lengths with shape <code>(instances,)</code>.</p> required <code>*args</code> <code>Optional[Union[float, ndarray]]</code> <p>Additional optional floats representing the lengths of single roots or arrays of root lengths with shape <code>(instances,)</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>float</code> <p>Total length of root network.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_length(\n    lengths0: Union[float, np.ndarray],\n    *args: Optional[Union[float, np.ndarray]],\n) -&gt; float:\n    \"\"\"Return the total root network length given primary and lateral root lengths.\n\n    Args:\n        lengths0: Either a float representing the length of a single\n            root or an array of root lengths with shape `(instances,)`.\n        *args: Additional optional floats representing the lengths of single\n            roots or arrays of root lengths with shape `(instances,)`.\n\n    Returns:\n        Total length of root network.\n    \"\"\"\n    # Initialize an empty list to store the lengths\n    all_lengths = []\n    # Loop over the input arrays\n    for length in [lengths0] + list(args):\n        if length is None:\n            continue  # Skip None values\n        # Ensure length is either a scalar or has the correct shape\n        if not (np.isscalar(length) or (hasattr(length, \"ndim\") and length.ndim == 1)):\n            raise ValueError(\n                \"Input length must be a scalar or have shape (instances,).\"\n            )\n        # Add the length to the list\n        if np.isscalar(length):\n            all_lengths.append(length)\n        else:\n            all_lengths.extend(list(length))\n\n    # Calculate the total root network length using np.nansum so the total length\n    # will not be NaN if one of primary or lateral lengths are NaN\n    total_network_length = np.nansum(all_lengths)\n\n    return total_network_length\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_network_solidity","title":"get_network_solidity","text":"<pre><code>get_network_solidity(\n    network_length: float, chull_area: float\n) -&gt; float\n</code></pre> <p>Return the total network length divided by the network convex area.</p> <p>Parameters:</p> Name Type Description Default <code>network_length</code> <code>float</code> <p>Total root length of network.</p> required <code>chull_area</code> <code>float</code> <p>Convex hull area.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Float of the total network length divided by the network convex area.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_solidity(\n    network_length: float,\n    chull_area: float,\n) -&gt; float:\n    \"\"\"Return the total network length divided by the network convex area.\n\n    Args:\n        network_length: Total root length of network.\n        chull_area: Convex hull area.\n\n    Returns:\n        Float of the total network length divided by the network convex area.\n    \"\"\"\n    if network_length &gt; 0 and chull_area &gt; 0:\n        ratio = network_length / chull_area\n        return ratio\n    else:\n        return np.nan\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_network_distribution","title":"get_network_distribution","text":"<pre><code>get_network_distribution(\n    pts_list: List[ndarray],\n    bounding_box: Tuple[float, float, float, float],\n    fraction: float = 2 / 3,\n) -&gt; float\n</code></pre> <p>Return the root length in the lower fraction of the plant.</p> <p>Parameters:</p> Name Type Description Default <code>pts_list</code> <code>List[ndarray]</code> <p>A list of arrays, each having shape <code>(nodes, 2)</code>.</p> required <code>bounding_box</code> <code>Tuple[float, float, float, float]</code> <p>Tuple in the form <code>(left_x, top_y, width, height)</code>.</p> required <code>fraction</code> <code>float</code> <p>Lower fraction value. Defaults to 2/3.</p> <code>2 / 3</code> <p>Returns:</p> Type Description <code>float</code> <p>Root network length in the lower fraction of the plant.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_distribution(\n    pts_list: List[np.ndarray],\n    bounding_box: Tuple[float, float, float, float],\n    fraction: float = 2 / 3,\n) -&gt; float:\n    \"\"\"Return the root length in the lower fraction of the plant.\n\n    Args:\n        pts_list: A list of arrays, each having shape `(nodes, 2)`.\n        bounding_box: Tuple in the form `(left_x, top_y, width, height)`.\n        fraction: Lower fraction value. Defaults to 2/3.\n\n    Returns:\n        Root network length in the lower fraction of the plant.\n    \"\"\"\n    # Input validation for pts_list\n    if any(pts.ndim != 2 or pts.shape[-1] != 2 for pts in pts_list):\n        raise ValueError(\n            \"Each pts array in pts_list should have a shape of `(nodes, 2)`.\"\n        )\n\n    # Input validation for bounding_box\n    if len(bounding_box) != 4:\n        raise ValueError(\n            \"bounding_box must contain exactly 4 elements: `(left_x, top_y, width, height)`.\"\n        )\n\n    # Filter out NaN values\n    pts_list = [pts[~np.isnan(pts).any(axis=-1)] for pts in pts_list]\n\n    # Get the vertices of the bounding box\n    left_x, top_y, width, height = bounding_box\n\n    # Calculate the bounding box of the lower fraction\n    lower_height = height * fraction\n    if np.isnan(lower_height):\n        return np.nan\n\n    # Convert lower bounding box to polygon\n    lower_box = Polygon(\n        [\n            [left_x, top_y + (height - lower_height)],\n            [left_x, top_y + height],\n            [left_x + width, top_y + height],\n            [left_x + width, top_y + (height - lower_height)],\n        ]\n    )\n\n    # Calculate length of roots within the lower bounding box\n    network_length = 0\n    for root in pts_list:\n        if len(root) &gt; 1:  # Ensure that root has more than one point\n            root_poly = LineString(root)\n            lower_intersection = root_poly.intersection(lower_box)\n            root_length = lower_intersection.length\n            network_length += root_length if ~np.isnan(root_length) else 0\n\n    return network_length\n</code></pre>"},{"location":"reference/sleap_roots/networklength/#sleap_roots.networklength.get_network_distribution_ratio","title":"get_network_distribution_ratio","text":"<pre><code>get_network_distribution_ratio(\n    network_length: float, network_length_lower: float\n) -&gt; float\n</code></pre> <p>Return ratio of the root length in the lower fraction to total root length.</p> <p>Parameters:</p> Name Type Description Default <code>network_length_lower</code> <code>float</code> <p>The root length in the lower network.</p> required <code>network_length</code> <code>float</code> <p>Total root length of network.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Float of ratio of the root network length in the lower fraction of the plant over the total root length.</p> Source code in <code>sleap_roots/networklength.py</code> <pre><code>def get_network_distribution_ratio(\n    network_length: float,\n    network_length_lower: float,\n) -&gt; float:\n    \"\"\"Return ratio of the root length in the lower fraction to total root length.\n\n    Args:\n        network_length_lower: The root length in the lower network.\n        network_length: Total root length of network.\n\n    Returns:\n        Float of ratio of the root network length in the lower fraction of the plant\n            over the total root length.\n    \"\"\"\n    # Ensure primary_length is a scalar\n    if not isinstance(network_length, (float, np.float64)):\n        raise ValueError(\"Input network_length must be a scalar value.\")\n\n    # Ensure network_length_lower is a scalar\n    if not isinstance(network_length_lower, (float, np.float64)):\n        raise ValueError(\"Input network_length_lower must be a scalar value.\")\n\n    # Calculate the ratio\n    ratio = network_length_lower / network_length\n    return ratio\n</code></pre>"},{"location":"reference/sleap_roots/points/","title":"Points","text":""},{"location":"reference/sleap_roots/points/#sleap_roots.points","title":"points","text":"<p>Get traits related to the points.</p>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.extract_points_from_geometry","title":"extract_points_from_geometry","text":"<pre><code>extract_points_from_geometry(geometry) -&gt; List[ndarray]\n</code></pre> <p>Extracts coordinates as a list of numpy arrays from any given Shapely geometry object.</p> <p>This function supports Point, MultiPoint, LineString, and GeometryCollection types. It recursively extracts coordinates from complex geometries and aggregates them into a single list. For unsupported geometry types, it returns an empty list.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>BaseGeometry</code> <p>A Shapely geometry object from which to extract points.</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List[np.ndarray]: A list of numpy arrays, where each array represents the coordinates of a point.</p> <code>List[ndarray]</code> <p>The list will be empty if the geometry type is unsupported or contains no coordinates.</p> <p>Example:</p> <p>from shapely.geometry import Point, MultiPoint, LineString, GeometryCollection point = Point(1, 2) multipoint = MultiPoint([(1, 2), (3, 4)]) linestring = LineString([(0, 0), (1, 1), (2, 2)]) geom_col = GeometryCollection([point, multipoint, linestring]) extract_points_from_geometry(geom_col) [array([1, 2]), array([1, 2]), array([3, 4]), array([0, 0]), array([1, 1]), array([2, 2])]</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def extract_points_from_geometry(geometry) -&gt; List[np.ndarray]:\n    \"\"\"Extracts coordinates as a list of numpy arrays from any given Shapely geometry object.\n\n    This function supports Point, MultiPoint, LineString, and GeometryCollection types.\n    It recursively extracts coordinates from complex geometries and aggregates them into a single list.\n    For unsupported geometry types, it returns an empty list.\n\n    Args:\n        geometry (shapely.geometry.base.BaseGeometry): A Shapely geometry object from which to extract points.\n\n    Returns:\n        List[np.ndarray]: A list of numpy arrays, where each array represents the coordinates of a point.\n        The list will be empty if the geometry type is unsupported or contains no coordinates.\n\n    Example:\n    &gt;&gt;&gt; from shapely.geometry import Point, MultiPoint, LineString, GeometryCollection\n    &gt;&gt;&gt; point = Point(1, 2)\n    &gt;&gt;&gt; multipoint = MultiPoint([(1, 2), (3, 4)])\n    &gt;&gt;&gt; linestring = LineString([(0, 0), (1, 1), (2, 2)])\n    &gt;&gt;&gt; geom_col = GeometryCollection([point, multipoint, linestring])\n    &gt;&gt;&gt; extract_points_from_geometry(geom_col)\n    [array([1, 2]), array([1, 2]), array([3, 4]), array([0, 0]), array([1, 1]), array([2, 2])]\n    \"\"\"\n    logging.debug(f\"Geometry type: {type(geometry).__name__}\")\n    logging.debug(f\"Geometry: {geometry}\")\n    if isinstance(geometry, Point):\n        return [np.array([geometry.x, geometry.y])]\n    elif isinstance(geometry, MultiPoint):\n        return [np.array([point.x, point.y]) for point in geometry.geoms]\n    elif isinstance(geometry, LineString):\n        return [np.array([x, y]) for x, y in zip(*geometry.xy)]\n    elif isinstance(geometry, GeometryCollection):\n        points = []\n        for geom in geometry.geoms:\n            points.extend(extract_points_from_geometry(geom))\n        return points\n    else:\n        logging.info(f\"Unsupported geometry type: {type(geometry).__name__}\")\n        return []\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_count","title":"get_count","text":"<pre><code>get_count(pts: ndarray)\n</code></pre> <p>Get number of roots.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code>.</p> required Return <p>Scalar of number of  roots.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_count(pts: np.ndarray):\n    \"\"\"Get number of roots.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)`.\n\n    Return:\n        Scalar of number of  roots.\n    \"\"\"\n    # The number of roots is the number of instances\n    count = pts.shape[0]\n    return count\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.join_pts","title":"join_pts","text":"<pre><code>join_pts(\n    pts0: ndarray, *args: Optional[ndarray]\n) -&gt; List[ndarray]\n</code></pre> <p>Join an arbitrary number of points arrays and return them as a list.</p> <p>Parameters:</p> Name Type Description Default <code>pts0</code> <code>ndarray</code> <p>The first array of points. Should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <code>*args</code> <code>Optional[ndarray]</code> <p>Additional optional arrays of points. Each should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>A list of arrays, each having shape <code>(nodes, 2)</code>.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def join_pts(pts0: np.ndarray, *args: Optional[np.ndarray]) -&gt; List[np.ndarray]:\n    \"\"\"Join an arbitrary number of points arrays and return them as a list.\n\n    Args:\n        pts0: The first array of points. Should have shape `(instances, nodes, 2)`\n            or `(nodes, 2)`.\n        *args: Additional optional arrays of points. Each should have shape\n            `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        A list of arrays, each having shape `(nodes, 2)`.\n    \"\"\"\n    # Initialize an empty list to store the points\n    all_pts = []\n    # Loop over the input arrays\n    for pts in [pts0] + list(args):\n        if pts is None:\n            continue  # Skip None values\n\n        # If an array has shape `(nodes, 2)`, expand dimensions to `(1, nodes, 2)`\n        if pts.ndim == 2 and pts.shape[-1] == 2:\n            pts = pts[np.newaxis, :, :]\n\n        # Validate the shape of each array\n        if pts.ndim != 3 or pts.shape[-1] != 2:\n            raise ValueError(\n                \"Points should have a shape of `(instances, nodes, 2)` or `(nodes, 2)`.\"\n            )\n\n        # Add the points to the list\n        all_pts.extend(list(pts))\n\n    return all_pts\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_all_pts_array","title":"get_all_pts_array","text":"<pre><code>get_all_pts_array(\n    pts0: ndarray, *args: Optional[ndarray]\n) -&gt; ndarray\n</code></pre> <p>Get all landmark points within a given frame as a flat array of coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>pts0</code> <code>ndarray</code> <p>The first array of points. Should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <code>*args</code> <code>Optional[ndarray]</code> <p>Additional optional arrays of points. Each should have shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array of shape (n_points, 2), containing the coordinates of all extracted</p> <code>ndarray</code> <p>points.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_all_pts_array(pts0: np.ndarray, *args: Optional[np.ndarray]) -&gt; np.ndarray:\n    \"\"\"Get all landmark points within a given frame as a flat array of coordinates.\n\n    Args:\n        pts0: The first array of points. Should have shape `(instances, nodes, 2)`\n            or `(nodes, 2)`.\n        *args: Additional optional arrays of points. Each should have shape\n            `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        A 2D array of shape (n_points, 2), containing the coordinates of all extracted\n        points.\n    \"\"\"\n    # Initialize an empty list to store the points\n    concatenated_pts = []\n\n    # Loop over the input arrays\n    for pts in [pts0] + list(args):\n        if pts is None:\n            continue\n\n        # Check if the array has the right number of dimensions\n        if pts.ndim not in [2, 3]:\n            raise ValueError(\"Each input array should be 2D or 3D.\")\n\n        # Check if the last dimension of the array has size 2\n        # (representing x and y coordinates)\n        if pts.shape[-1] != 2:\n            raise ValueError(\n                \"The last dimension should have size 2, representing x and y coordinates.\"\n            )\n\n        # Flatten the array to 2D and append to list\n        flat_pts = pts.reshape(-1, 2)\n        concatenated_pts.append(flat_pts)\n\n    # Concatenate all points into a single array\n    return np.concatenate(concatenated_pts, axis=0)\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_nodes","title":"get_nodes","text":"<pre><code>get_nodes(pts: ndarray, node_index: int) -&gt; ndarray\n</code></pre> <p>Extracts the (x, y) coordinates of a specified node.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>An array of points. For multiple instances, the shape should be (instances, nodes, 2). For a single instance,the shape should be (nodes, 2).</p> required <code>node_index</code> <code>int</code> <p>The index of the node for which to extract the coordinates, based on the node's position in the sequence of connected nodes (0-based indexing).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of (x, y) coordinates for the specified node. For multiple instances, the shape will be (instances, 2). For a single instance, the shape will be (2,).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If node_index is out of bounds for the number of nodes.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_nodes(pts: np.ndarray, node_index: int) -&gt; np.ndarray:\n    \"\"\"Extracts the (x, y) coordinates of a specified node.\n\n    Args:\n        pts: An array of points. For multiple instances, the shape should be\n            (instances, nodes, 2). For a single instance,the shape should be (nodes, 2).\n        node_index: The index of the node for which to extract the coordinates, based on\n            the node's position in the sequence of connected nodes (0-based indexing).\n\n    Returns:\n        np.ndarray: An array of (x, y) coordinates for the specified node. For multiple\n            instances, the shape will be (instances, 2). For a single instance, the\n            shape will be (2,).\n\n    Raises:\n        ValueError: If node_index is out of bounds for the number of nodes.\n    \"\"\"\n    # Adjust for a single instance with shape (nodes, 2)\n    if pts.ndim == 2:\n        if not 0 &lt;= node_index &lt; pts.shape[0]:\n            raise ValueError(\"node_index is out of bounds for the number of nodes.\")\n        # Return a (2,) shape array for the node coordinates in a single instance\n        return pts[node_index, :]\n\n    # Handle multiple instances with shape (instances, nodes, 2)\n    elif pts.ndim == 3:\n        if not 0 &lt;= node_index &lt; pts.shape[1]:\n            raise ValueError(\"node_index is out of bounds for the number of nodes.\")\n        # Return (instances, 2) shape array for the node coordinates across instances\n        return pts[:, node_index, :]\n\n    else:\n        raise ValueError(\n            \"Input array should have shape (nodes, 2) for a single instance \"\n            \"or (instances, nodes, 2) for multiple instances.\"\n        )\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_root_vectors","title":"get_root_vectors","text":"<pre><code>get_root_vectors(\n    start_nodes: ndarray, end_nodes: ndarray\n) -&gt; ndarray\n</code></pre> <p>Calculate the vector from start to end for each instance in a set of points.</p> <p>Parameters:</p> Name Type Description Default <code>start_nodes</code> <code>ndarray</code> <p>array of points with shape (instances, 2) or (2,) representing the start node in each instance.</p> required <code>end_nodes</code> <code>ndarray</code> <p>array of points with shape (instances, 2) or (2,) representing the end node in each instance.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of vectors with shape (instances, 2), representing the vector from start</p> <code>ndarray</code> <p>to end for each instance.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_root_vectors(start_nodes: np.ndarray, end_nodes: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Calculate the vector from start to end for each instance in a set of points.\n\n    Args:\n        start_nodes: array of points with shape (instances, 2) or (2,) representing the\n            start node in each instance.\n        end_nodes: array of points with shape (instances, 2) or (2,) representing the\n            end node in each instance.\n\n    Returns:\n        An array of vectors with shape (instances, 2), representing the vector from start\n        to end for each instance.\n    \"\"\"\n    # Ensure that the start and end nodes have the same shapes\n    if start_nodes.shape != end_nodes.shape:\n        raise ValueError(\"start_nodes and end_nodes should have the same shape.\")\n    # Handle single instances with shape (2,)\n    if start_nodes.ndim == 1:\n        start_nodes = start_nodes[np.newaxis, :]\n    if end_nodes.ndim == 1:\n        end_nodes = end_nodes[np.newaxis, :]\n    # Calculate the vectors from start to end for each instance\n    vectors = start_nodes - end_nodes\n    return vectors\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_left_right_normalized_vectors","title":"get_left_right_normalized_vectors","text":"<pre><code>get_left_right_normalized_vectors(\n    r0_pts: ndarray, r1_pts: ndarray\n) -&gt; Tuple[ndarray, ndarray]\n</code></pre> <p>Get the unit vectors formed from r0 to r1 on the left and right sides of a crown root system.</p> <p>Parameters:</p> Name Type Description Default <code>r0_pts</code> <code>ndarray</code> <p>An array of points representing the r0 nodes, with shape (instances, 2),     where instances are different observations of r0 points, and 2 represents     the x and y coordinates.</p> required <code>r1_pts</code> <code>ndarray</code> <p>An array of points representing the r1 nodes, similar in structure to r0_pts.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A tuple containing two np.ndarray objects:</p> <code>ndarray</code> <ul> <li>The first is a normalized vector from r0 to r1 on the left side, or a vector of NaNs if normalization fails.</li> </ul> <code>Tuple[ndarray, ndarray]</code> <ul> <li>The second is a normalized vector from r0 to r1 on the right side, or a vector of NaNs if normalization fails.</li> </ul> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_left_right_normalized_vectors(\n    r0_pts: np.ndarray, r1_pts: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Get the unit vectors formed from r0 to r1 on the left and right sides of a crown root system.\n\n    Args:\n        r0_pts: An array of points representing the r0 nodes, with shape (instances, 2),\n                where instances are different observations of r0 points, and 2 represents\n                the x and y coordinates.\n        r1_pts: An array of points representing the r1 nodes, similar in structure to r0_pts.\n\n    Returns:\n        A tuple containing two np.ndarray objects:\n        - The first is a normalized vector from r0 to r1 on the left side, or a vector\n            of NaNs if normalization fails.\n        - The second is a normalized vector from r0 to r1 on the right side, or a vector\n            of NaNs if normalization fails.\n    \"\"\"\n    # Validate input shapes and ensure there are multiple instances for comparison\n    if (\n        r0_pts.ndim == 2\n        and r1_pts.ndim == 2\n        and r0_pts.shape == r1_pts.shape\n        and r0_pts.shape[0] &gt; 1\n    ):\n        # Find indices of the leftmost and rightmost r0 and r1 points\n        leftmost_r0_index = np.nanargmin(r0_pts[:, 0])\n        rightmost_r0_index = np.nanargmax(r0_pts[:, 0])\n        leftmost_r1_index = np.nanargmin(r1_pts[:, 0])\n        rightmost_r1_index = np.nanargmax(r1_pts[:, 0])\n\n        # Extract the corresponding r0 and r1 points for leftmost and rightmost nodes\n        r0_left = r0_pts[leftmost_r0_index]\n        r1_left = r1_pts[leftmost_r1_index]\n        r0_right = r0_pts[rightmost_r0_index]\n        r1_right = r1_pts[rightmost_r1_index]\n\n        # Calculate the vectors from r0 to r1 for both the leftmost and rightmost points\n        vector_left = r1_left - r0_left\n        vector_right = r1_right - r0_right\n\n        # Calculate norms of both vectors for normalization\n        norm_left = np.linalg.norm(vector_left)\n        norm_right = np.linalg.norm(vector_right)\n\n        # Normalize the vectors if their norms are non-zero\n        # otherwise, return vectors filled with NaNs\n        norm_vector_left = (\n            vector_left / norm_left if norm_left &gt; 0 else np.array([np.nan, np.nan])\n        )\n        norm_vector_right = (\n            vector_right / norm_right if norm_right &gt; 0 else np.array([np.nan, np.nan])\n        )\n\n        return norm_vector_left, norm_vector_right\n    else:\n        # Return pairs of NaN vectors if inputs are invalid or do not meet the requirements\n        return np.array([np.nan, np.nan]), np.array([np.nan, np.nan])\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_left_normalized_vector","title":"get_left_normalized_vector","text":"<pre><code>get_left_normalized_vector(\n    normalized_vectors: Tuple[ndarray, ndarray],\n) -&gt; ndarray\n</code></pre> <p>Get the normalized vector from r0 to r1 on the left side of a crown root system.</p> <p>Parameters:</p> Name Type Description Default <code>normalized_vectors</code> <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing two np.ndarray objects: - The first is a normalized vector from r0 to r1 on the left side, or a vector     of NaNs if normalization fails. - The second is a normalized vector from r0 to r1 on the right side, or a vector     of NaNs if normalization fails.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A normalized vector from r0 to r1 on the left side, or a vector of NaNs if normalization fails.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_left_normalized_vector(\n    normalized_vectors: Tuple[np.ndarray, np.ndarray],\n) -&gt; np.ndarray:\n    \"\"\"Get the normalized vector from r0 to r1 on the left side of a crown root system.\n\n    Args:\n        normalized_vectors: A tuple containing two np.ndarray objects:\n            - The first is a normalized vector from r0 to r1 on the left side, or a vector\n                of NaNs if normalization fails.\n            - The second is a normalized vector from r0 to r1 on the right side, or a vector\n                of NaNs if normalization fails.\n\n    Returns:\n        np.ndarray: A normalized vector from r0 to r1 on the left side, or a vector of NaNs\n            if normalization fails.\n    \"\"\"\n    return normalized_vectors[0]\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_right_normalized_vector","title":"get_right_normalized_vector","text":"<pre><code>get_right_normalized_vector(\n    normalized_vectors: Tuple[ndarray, ndarray],\n) -&gt; ndarray\n</code></pre> <p>Get the normalized vector from r0 to r1 on the right side of a crown root system.</p> <p>Parameters:</p> Name Type Description Default <code>normalized_vectors</code> <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing two np.ndarray objects: - The first is a normalized vector from r0 to r1 on the left side, or a vector     of NaNs if normalization fails. - The second is a normalized vector from r0 to r1 on the right side, or a vector     of NaNs if normalization fails.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A normalized vector from r0 to r1 on the right side, or a vector of NaNs if normalization fails.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_right_normalized_vector(\n    normalized_vectors: Tuple[np.ndarray, np.ndarray],\n) -&gt; np.ndarray:\n    \"\"\"Get the normalized vector from r0 to r1 on the right side of a crown root system.\n\n    Args:\n        normalized_vectors: A tuple containing two np.ndarray objects:\n            - The first is a normalized vector from r0 to r1 on the left side, or a vector\n                of NaNs if normalization fails.\n            - The second is a normalized vector from r0 to r1 on the right side, or a vector\n                of NaNs if normalization fails.\n\n    Returns:\n        np.ndarray: A normalized vector from r0 to r1 on the right side, or a vector of NaNs\n            if normalization fails.\n    \"\"\"\n    return normalized_vectors[1]\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_line_equation_from_points","title":"get_line_equation_from_points","text":"<pre><code>get_line_equation_from_points(pts1: ndarray, pts2: ndarray)\n</code></pre> <p>Calculate the slope (m) and y-intercept (b) of the line connecting two points.</p> <p>Parameters:</p> Name Type Description Default <code>pts1</code> <code>ndarray</code> <p>First point as (x, y). 1D array of shape (2,).</p> required <code>pts2</code> <code>ndarray</code> <p>Second point as (x, y). 1D array of shape (2,).</p> required <p>Returns:</p> Type Description <p>A tuple (m, b) representing the slope and y-intercept of the line. If the line is</p> <p>vertical, NaNs are returned.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_line_equation_from_points(pts1: np.ndarray, pts2: np.ndarray):\n    \"\"\"Calculate the slope (m) and y-intercept (b) of the line connecting two points.\n\n    Args:\n        pts1: First point as (x, y). 1D array of shape (2,).\n        pts2: Second point as (x, y). 1D array of shape (2,).\n\n    Returns:\n        A tuple (m, b) representing the slope and y-intercept of the line. If the line is\n        vertical, NaNs are returned.\n    \"\"\"\n    # Convert inputs to arrays if they're not already\n    pts1 = np.asarray(pts1)\n    pts2 = np.asarray(pts2)\n\n    # Validate input shapes\n    if pts1.ndim != 1 or pts1.shape[0] != 2 or pts2.ndim != 1 or pts2.shape[0] != 2:\n        raise ValueError(\"Each input point must be a 1D array of shape (2,).\")\n\n    # If the line is vertical return NaNs\n    if pts1[0] == pts2[0]:\n        return np.nan, np.nan\n    else:\n        # Calculate the slope\n        m = (pts2[1] - pts1[1]) / (pts2[0] - pts1[0])\n\n    # Calculate the y-intercept\n    b = pts1[1] - m * pts1[0]\n\n    return m, b\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.filter_roots_with_nans","title":"filter_roots_with_nans","text":"<pre><code>filter_roots_with_nans(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Remove roots with NaN values from an array of root points.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>An array of points representing roots, with shape (instances, nodes, 2), where 'instances' is the number of roots, 'nodes' is the number of points in each root, and '2' corresponds to the x and y coordinates.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of shape (instances, nodes, 2) with NaN-containing roots removed. If all roots contain NaN values, an empty array of shape (0, nodes, 2) is returned.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def filter_roots_with_nans(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Remove roots with NaN values from an array of root points.\n\n    Args:\n        pts: An array of points representing roots, with shape (instances, nodes, 2),\n            where 'instances' is the number of roots, 'nodes' is the number of points in\n            each root, and '2' corresponds to the x and y coordinates.\n\n    Returns:\n        np.ndarray: An array of shape (instances, nodes, 2) with NaN-containing roots\n            removed. If all roots contain NaN values, an empty array of shape\n            (0, nodes, 2) is returned.\n    \"\"\"\n    if not isinstance(pts, np.ndarray):\n        raise TypeError(\"Input must be a numpy array.\")\n    if pts.ndim != 3 or pts.shape[2] != 2:\n        raise ValueError(\"Input array must have a shape of (instances, nodes, 2).\")\n\n    cleaned_pts = np.array([root for root in pts if not np.isnan(root).any()])\n\n    if cleaned_pts.size == 0:\n        return np.empty((0, pts.shape[1], 2))\n\n    return cleaned_pts\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.filter_plants_with_unexpected_ct","title":"filter_plants_with_unexpected_ct","text":"<pre><code>filter_plants_with_unexpected_ct(\n    primary_pts: ndarray,\n    lateral_pts: ndarray,\n    expected_count: float,\n) -&gt; Tuple[ndarray, ndarray]\n</code></pre> <p>Filter out primary and lateral roots with an unexpected number of plants.</p> <p>Parameters:</p> Name Type Description Default <code>primary_pts</code> <code>ndarray</code> <p>A numpy array of primary root points with shape (instances, nodes, 2), where 'instances' is the number of primary roots, 'nodes' is the number of points in each root, and '2' corresponds to the x and y coordinates.</p> required <code>lateral_pts</code> <code>ndarray</code> <p>A numpy array of lateral root points with a shape similar to primary_pts, representing the lateral roots.</p> required <code>expected_count</code> <code>float</code> <p>The expected number of primary roots as a float or NaN. If NaN, no filtering is applied based on count. If a number, it will be rounded to the nearest integer for comparison.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A tuple containing the filtered primary and lateral root points arrays. If the</p> <code>ndarray</code> <p>input types are incorrect, the function will raise a ValueError.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input types are incorrect.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def filter_plants_with_unexpected_ct(\n    primary_pts: np.ndarray, lateral_pts: np.ndarray, expected_count: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Filter out primary and lateral roots with an unexpected number of plants.\n\n    Args:\n        primary_pts: A numpy array of primary root points with shape\n            (instances, nodes, 2), where 'instances' is the number of primary roots,\n            'nodes' is the number of points in each root, and '2' corresponds to the x and y\n            coordinates.\n        lateral_pts: A numpy array of lateral root points with a shape similar\n            to primary_pts, representing the lateral roots.\n        expected_count: The expected number of primary roots as a float or NaN. If NaN,\n            no filtering is applied based on count. If a number, it will be rounded to\n            the nearest integer for comparison.\n\n    Returns:\n        A tuple containing the filtered primary and lateral root points arrays. If the\n        input types are incorrect, the function will raise a ValueError.\n\n    Raises:\n        ValueError: If input types are incorrect.\n    \"\"\"\n    # Type checking\n    if not isinstance(primary_pts, np.ndarray) or not isinstance(\n        lateral_pts, np.ndarray\n    ):\n        raise ValueError(\"primary_pts and lateral_pts must be numpy arrays.\")\n    if not np.issubdtype(type(expected_count), np.number):\n        raise ValueError(\"expected_count must be a numeric type.\")\n\n    # Handle NaN expected_count: Skip filtering if expected_count is NaN\n    if not np.isnan(expected_count):\n        # Rounding expected_count to the nearest integer for comparison\n        expected_count_rounded = round(expected_count)\n\n        if len(primary_pts) != expected_count_rounded:\n            # Adjusting primary and lateral roots to empty arrays of the same shape\n            primary_pts = np.empty((0, primary_pts.shape[1], 2))\n            lateral_pts = np.empty((0, lateral_pts.shape[1], 2))\n\n    return primary_pts, lateral_pts\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.filter_primary_roots_with_unexpected_count","title":"filter_primary_roots_with_unexpected_count","text":"<pre><code>filter_primary_roots_with_unexpected_count(\n    primary_pts: ndarray, expected_count: float\n) -&gt; ndarray\n</code></pre> <p>Filter out primary roots if the number of detected roots doesn't match the expected count.</p> <p>Parameters:</p> Name Type Description Default <code>primary_pts</code> <code>ndarray</code> <p>A numpy array of primary root points with shape (instances, nodes, 2).</p> required <code>expected_count</code> <code>float</code> <p>The expected number of primary roots. If NaN, no filtering is applied.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The filtered primary root points array. If the count doesn't match, an empty array is returned.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def filter_primary_roots_with_unexpected_count(\n    primary_pts: np.ndarray, expected_count: float\n) -&gt; np.ndarray:\n    \"\"\"Filter out primary roots if the number of detected roots doesn't match the expected count.\n\n    Args:\n        primary_pts: A numpy array of primary root points with shape\n            (instances, nodes, 2).\n        expected_count: The expected number of primary roots. If NaN, no filtering is applied.\n\n    Returns:\n        The filtered primary root points array. If the count doesn't match, an empty array is returned.\n    \"\"\"\n    # Type check\n    if not isinstance(primary_pts, np.ndarray):\n        raise ValueError(\"primary_pts must be a numpy array.\")\n    if not np.issubdtype(type(expected_count), np.number):\n        raise ValueError(\"expected_count must be a numeric type.\")\n\n    # Handle NaN expected_count: Skip filtering if expected_count is NaN\n    if not np.isnan(expected_count):\n        # Round expected_count to the nearest integer for comparison\n        expected_count_rounded = round(expected_count)\n\n        if len(primary_pts) != expected_count_rounded:\n            # Adjusting primary roots to empty array of the same shape\n            primary_pts = np.empty((0, primary_pts.shape[1], 2))\n\n    return primary_pts\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_filtered_primary_pts","title":"get_filtered_primary_pts","text":"<pre><code>get_filtered_primary_pts(\n    filtered_pts: Tuple[ndarray, ndarray],\n) -&gt; ndarray\n</code></pre> <p>Get the filtered primary root points from a tuple of filtered primary and lateral roots.</p> <p>Parameters:</p> Name Type Description Default <code>filtered_pts</code> <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing the filtered primary and lateral root points arrays.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The filtered primary root points array.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_filtered_primary_pts(filtered_pts: Tuple[np.ndarray, np.ndarray]) -&gt; np.ndarray:\n    \"\"\"Get the filtered primary root points from a tuple of filtered primary and lateral roots.\n\n    Args:\n        filtered_pts: A tuple containing the filtered primary and lateral root points arrays.\n\n    Returns:\n        np.ndarray: The filtered primary root points array.\n    \"\"\"\n    return filtered_pts[0]\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.get_filtered_lateral_pts","title":"get_filtered_lateral_pts","text":"<pre><code>get_filtered_lateral_pts(\n    filtered_pts: Tuple[ndarray, ndarray],\n) -&gt; ndarray\n</code></pre> <p>Get the filtered lateral root points from a tuple of filtered primary and lateral roots.</p> <p>Parameters:</p> Name Type Description Default <code>filtered_pts</code> <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing the filtered primary and lateral root points arrays.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The filtered lateral root points array.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def get_filtered_lateral_pts(filtered_pts: Tuple[np.ndarray, np.ndarray]) -&gt; np.ndarray:\n    \"\"\"Get the filtered lateral root points from a tuple of filtered primary and lateral roots.\n\n    Args:\n        filtered_pts: A tuple containing the filtered primary and lateral root points arrays.\n\n    Returns:\n        np.ndarray: The filtered lateral root points array.\n    \"\"\"\n    return filtered_pts[1]\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.is_line_valid","title":"is_line_valid","text":"<pre><code>is_line_valid(line: ndarray) -&gt; bool\n</code></pre> <p>Check if a line (numpy array of points) does not contain NaN values, indicating it is valid.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>ndarray</code> <p>A numpy array representing a line with shape (nodes, 2), where 'nodes' is the number of points in the line.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the line does not contain any NaN values, False otherwise.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def is_line_valid(line: np.ndarray) -&gt; bool:\n    \"\"\"Check if a line (numpy array of points) does not contain NaN values, indicating it is valid.\n\n    Args:\n        line: A numpy array representing a line with shape (nodes, 2), where 'nodes' is\n            the number of points in the line.\n\n    Returns:\n        True if the line does not contain any NaN values, False otherwise.\n    \"\"\"\n    return not np.isnan(line).any()\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.clean_points","title":"clean_points","text":"<pre><code>clean_points(points)\n</code></pre> <p>Remove NaN points from root points.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <p>An array of points representing a root, with shape (nodes, 2).</p> required <p>Returns:</p> Type Description <p>np.ndarray: An array of the same points with NaN values removed.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def clean_points(points):\n    \"\"\"Remove NaN points from root points.\n\n    Args:\n        points: An array of points representing a root, with shape (nodes, 2).\n\n    Returns:\n        np.ndarray: An array of the same points with NaN values removed.\n    \"\"\"\n    # Filter out points with NaN values and return the cleaned array\n    return np.array([pt for pt in points if not np.isnan(pt).any()])\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.associate_lateral_to_primary","title":"associate_lateral_to_primary","text":"<pre><code>associate_lateral_to_primary(\n    primary_pts: ndarray, lateral_pts: ndarray\n) -&gt; dict\n</code></pre> <p>Associates each lateral root with the closest primary root.</p> <p>Parameters:</p> Name Type Description Default <code>primary_pts</code> <code>ndarray</code> <p>A numpy array of primary root points with shape (instances, nodes, 2), where 'instances' is the number of primary roots, 'nodes' is the number of points in each root, and '2' corresponds to the x and y coordinates. Points cannot have NaN values.</p> required <code>lateral_pts</code> <code>ndarray</code> <p>A numpy array of lateral root points with a shape similar to primary_pts, representing the lateral roots. Points cannot have NaN values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary where each key is an index of a primary root (from the primary_pts</p> <code>dict</code> <p>array) and each value is a dictionary containing 'primary_points' as the points of</p> <code>dict</code> <p>the primary root (1, nodes, 2) and 'lateral_points' as an array of</p> <code>dict</code> <p>lateral root points that are closest to that primary root. The shape of</p> <code>dict</code> <p>'lateral_points' is (instances, nodes, 2), where instances is the number of</p> <code>dict</code> <p>lateral roots associated with the primary root.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def associate_lateral_to_primary(\n    primary_pts: np.ndarray, lateral_pts: np.ndarray\n) -&gt; dict:\n    \"\"\"Associates each lateral root with the closest primary root.\n\n    Args:\n        primary_pts: A numpy array of primary root points with shape\n            (instances, nodes, 2), where 'instances' is the number of primary roots,\n            'nodes' is the number of points in each root, and '2' corresponds to the x and y\n            coordinates. Points cannot have NaN values.\n        lateral_pts: A numpy array of lateral root points with a shape similar\n            to primary_pts, representing the lateral roots. Points cannot have NaN values.\n\n    Returns:\n        dict: A dictionary where each key is an index of a primary root (from the primary_pts\n        array) and each value is a dictionary containing 'primary_points' as the points of\n        the primary root (1, nodes, 2) and 'lateral_points' as an array of\n        lateral root points that are closest to that primary root. The shape of\n        'lateral_points' is (instances, nodes, 2), where instances is the number of\n        lateral roots associated with the primary root.\n    \"\"\"\n    # Basic input validation\n    if not isinstance(primary_pts, np.ndarray) or not isinstance(\n        lateral_pts, np.ndarray\n    ):\n        raise ValueError(\"Both primary_pts and lateral_pts must be numpy arrays.\")\n    if len(primary_pts.shape) != 3 or len(lateral_pts.shape) != 3:\n        raise ValueError(\"Input arrays must have a shape of (instances, nodes, 2).\")\n    if primary_pts.shape[2] != 2 or lateral_pts.shape[2] != 2:\n        raise ValueError(\n            \"The last dimension of input arrays must be 2, representing x and y coordinates.\"\n        )\n\n    plant_associations = {}\n\n    # Initialize plant associations dictionary\n    for i, primary_root in enumerate(primary_pts):\n        if not is_line_valid(primary_root):\n            continue  # Skip primary roots containing NaN values\n        plant_associations[i] = {\n            \"primary_points\": primary_root,\n            \"lateral_points\": [],\n        }\n\n    # Associate each lateral root with the closest primary root\n    for lateral_root in lateral_pts:\n        if not is_line_valid(lateral_root):\n            continue  # Skip lateral roots containing NaN values\n\n        lateral_line = LineString(lateral_root)\n        min_distance = float(\"inf\")\n        closest_primary_index = None\n\n        for primary_index, primary_data in plant_associations.items():\n            primary_root = primary_data[\"primary_points\"]\n            try:\n                primary_line = LineString(primary_root)\n                distance = primary_line.distance(lateral_line)\n            except Exception as e:\n                print(f\"Error computing distance: {e}\")\n                continue\n\n            if distance &lt; min_distance:\n                min_distance = distance\n                closest_primary_index = primary_index\n\n        if closest_primary_index is not None:\n            plant_associations[closest_primary_index][\"lateral_points\"].append(\n                lateral_root\n            )\n\n    # Convert lateral points lists into arrays\n    for primary_index, data in plant_associations.items():\n        lateral_points_list = data[\"lateral_points\"]\n        if lateral_points_list:  # Check if there are any lateral points to convert\n            lateral_points_array = np.array(lateral_points_list)\n            plant_associations[primary_index][\"lateral_points\"] = lateral_points_array\n        else:\n            # Create an array of NaNs if there are no lateral points\n            shape = (1, lateral_pts.shape[1], 2)  # Shape of lateral points array\n            plant_associations[primary_index][\"lateral_points\"] = np.full(shape, np.nan)\n\n    return plant_associations\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.flatten_associated_points","title":"flatten_associated_points","text":"<pre><code>flatten_associated_points(associations: dict) -&gt; dict\n</code></pre> <p>Creates a dictionary of flattened arrays containing primary and lateral root points.</p> <p>Parameters:</p> Name Type Description Default <code>associations</code> <code>dict</code> <p>A dictionary where each key is an index of a primary root and each value is a dictionary containing 'primary_points' as the points of the primary root and 'lateral_points' as an array of lateral root points that are closest to that primary root.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with the same keys as associations. Each key corresponds to a flattened array containing all the primary and lateral root points for that plant.</p> Source code in <code>sleap_roots/points.py</code> <pre><code>def flatten_associated_points(associations: dict) -&gt; dict:\n    \"\"\"Creates a dictionary of flattened arrays containing primary and lateral root points.\n\n    Args:\n        associations: A dictionary where each key is an index of a primary root and each value\n            is a dictionary containing 'primary_points' as the points of the primary root\n            and 'lateral_points' as an array of lateral root points that are closest to\n            that primary root.\n\n    Returns:\n        A dictionary with the same keys as associations. Each key corresponds to a flattened\n            array containing all the primary and lateral root points for that plant.\n    \"\"\"\n    flattened_points = {}\n\n    for key, data in associations.items():\n        # Get the primary root points for the current key\n        primary_root_points = data[\"primary_points\"]\n\n        # Get the lateral root points array\n        lateral_root_points = data[\"lateral_points\"]\n\n        # Initialize an array with the primary root points\n        all_points = [primary_root_points]\n\n        # Check if there are lateral points and extend the array if so\n        if lateral_root_points.size &gt; 0 and not np.isnan(lateral_root_points[0][0][0]):\n            all_points.extend(lateral_root_points)\n\n        # Concatenate all the points into a single array\n        all_points_array = np.vstack(all_points)\n\n        # Flatten the array and add to the dictionary\n        flattened_points[key] = all_points_array.flatten()\n\n    return flattened_points\n</code></pre>"},{"location":"reference/sleap_roots/points/#sleap_roots.points.plot_root_associations","title":"plot_root_associations","text":"<pre><code>plot_root_associations(associations: dict)\n</code></pre> <p>Plots the associations between primary and lateral roots.</p> <p>Plots the associations between primary and lateral roots, including the line connecting the closest points between each lateral root and its closest primary root, and ensures the color map does not include red. Adds explanations in the legend and inverts the y-axis for image coordinate system.</p> <p>Parameters:</p> Name Type Description Default <code>associations</code> <code>dict</code> <p>The output dictionary from associate_lateral_to_primary function.</p> required Source code in <code>sleap_roots/points.py</code> <pre><code>def plot_root_associations(associations: dict):\n    \"\"\"Plots the associations between primary and lateral roots.\n\n    Plots the associations between primary and lateral roots, including the line\n    connecting the closest points between each lateral root and its closest primary root,\n    and ensures the color map does not include red. Adds explanations in the legend and\n    inverts the y-axis for image coordinate system.\n\n    Args:\n        associations: The output dictionary from associate_lateral_to_primary function.\n    \"\"\"\n    plt.figure(figsize=(12, 10))\n\n    # Generate a color map for primary roots\n    cmap = plt.cm.viridis  # Using viridis which doesn't contain red\n    colors = cmap(np.linspace(0, 1, len(associations)))\n\n    for primary_index, data in associations.items():\n        primary_points = data[\"primary_points\"]\n        lateral_points_list = data[\"lateral_points\"]\n        color = colors[primary_index]\n\n        # Convert primary points to LineString\n        primary_line = LineString(primary_points)\n\n        # Plot primary root\n        plt.plot(primary_points[:, 0], primary_points[:, 1], color=color, linewidth=2)\n\n        # Plot each associated lateral root\n        for lateral_points in lateral_points_list:\n            # Convert lateral points to LineString\n            lateral_line = LineString(lateral_points)\n            plt.plot(\n                lateral_points[:, 0],\n                lateral_points[:, 1],\n                color=color,\n                linestyle=\"--\",\n                linewidth=1,\n            )\n\n            # Use nearest_points to find the closest points between the two lines\n            p1, p2 = nearest_points(primary_line, lateral_line)\n            plt.plot([p1.x, p2.x], [p1.y, p2.y], \"r--\", linewidth=1)\n\n    # Invert y-axis\n    plt.gca().invert_yaxis()\n\n    # Custom legend\n    custom_lines = [\n        Line2D([0], [0], color=\"black\", lw=2),\n        Line2D([0], [0], color=\"black\", lw=2, linestyle=\"--\"),\n        Line2D([0], [0], color=\"red\", lw=1, linestyle=\"--\"),\n    ]\n    plt.legend(custom_lines, [\"Primary Root\", \"Lateral Root\", \"Minimum Distance\"])\n\n    plt.xlabel(\"X Coordinate\")\n    plt.ylabel(\"Y Coordinate\")\n    plt.title(\"Primary and Lateral Root Associations with Minimum Distances\")\n    plt.axis(\"equal\")  # Ensure equal aspect ratio for x and y axes\n    plt.show()\n</code></pre>"},{"location":"reference/sleap_roots/scanline/","title":"Scanline","text":""},{"location":"reference/sleap_roots/scanline/#sleap_roots.scanline","title":"scanline","text":"<p>Get intersections between roots and horizontal scan lines.</p>"},{"location":"reference/sleap_roots/scanline/#sleap_roots.scanline.count_scanline_intersections","title":"count_scanline_intersections","text":"<pre><code>count_scanline_intersections(\n    pts_list: List[ndarray],\n    height: int = 1080,\n    n_line: int = 50,\n) -&gt; ndarray\n</code></pre> <p>Count intersections of roots with a series of horizontal scanlines.</p> <p>This function calculates the number of intersections between the provided primary and lateral root points and a set of horizontal scanlines. The scanlines are equally spaced across the specified height.</p> <p>Parameters:</p> Name Type Description Default <code>pts_list</code> <code>List[ndarray]</code> <p>A list of arrays, each having shape <code>(nodes, 2)</code>.</p> required <code>height</code> <code>int</code> <p>The height of the image or cylinder. Defaults to 1080.</p> <code>1080</code> <code>n_line</code> <code>int</code> <p>Number of scanlines to use. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array with shape <code>(n_line,)</code> representing the number of intersections of roots with each scanline.</p> Source code in <code>sleap_roots/scanline.py</code> <pre><code>def count_scanline_intersections(\n    pts_list: List[np.ndarray],\n    height: int = 1080,\n    n_line: int = 50,\n) -&gt; np.ndarray:\n    \"\"\"Count intersections of roots with a series of horizontal scanlines.\n\n    This function calculates the number of intersections between the provided\n    primary and lateral root points and a set of horizontal scanlines. The scanlines\n    are equally spaced across the specified height.\n\n    Args:\n        pts_list: A list of arrays, each having shape `(nodes, 2)`.\n        height: The height of the image or cylinder. Defaults to 1080.\n        n_line: Number of scanlines to use. Defaults to 50.\n\n    Returns:\n        An array with shape `(n_line,)` representing the number of intersections\n            of roots with each scanline.\n    \"\"\"\n    # Input validation for pts_list\n    if any(pts.ndim != 2 or pts.shape[-1] != 2 for pts in pts_list):\n        raise ValueError(\n            \"Each pts array in pts_list should have a shape of `(nodes, 2)`.\"\n        )\n\n    # Calculate the interval between two scanlines\n    interval = height / (n_line - 1)\n\n    intersections = []\n\n    # Iterate over scanlines\n    for i in range(n_line):\n        y_coord = interval * i\n        line_intersections = 0\n\n        for root_points in pts_list:\n            # Remove NaN values\n            valid_points = root_points[(~np.isnan(root_points)).any(axis=1)]\n\n            if len(valid_points) &gt; 1:\n                for j in range(len(valid_points) - 1):\n                    y1 = valid_points[j][1]\n                    y2 = valid_points[j + 1][1]\n\n                    if (y1 &gt;= y_coord &gt;= y2) or (y2 &gt;= y_coord &gt;= y1):\n                        line_intersections += 1\n\n        intersections.append(line_intersections)\n\n    return np.array(intersections)\n</code></pre>"},{"location":"reference/sleap_roots/scanline/#sleap_roots.scanline.get_scanline_first_ind","title":"get_scanline_first_ind","text":"<pre><code>get_scanline_first_ind(\n    scanline_intersection_counts: ndarray,\n)\n</code></pre> <p>Get the index of count_scanline_interaction for the first interaction.</p> <p>Parameters:</p> Name Type Description Default <code>scanline_intersection_counts</code> <code>ndarray</code> <p>An array with shape of <code>(#Nline,)</code> of intersection numbers of each scan line.</p> required Return <p>Scalar of count_scanline_interaction index for the first interaction.</p> Source code in <code>sleap_roots/scanline.py</code> <pre><code>def get_scanline_first_ind(scanline_intersection_counts: np.ndarray):\n    \"\"\"Get the index of count_scanline_interaction for the first interaction.\n\n    Args:\n        scanline_intersection_counts: An array with shape of `(#Nline,)` of intersection\n            numbers of each scan line.\n\n    Return:\n        Scalar of count_scanline_interaction index for the first interaction.\n    \"\"\"\n    # get the first scanline index using scanline_intersection_counts\n    if np.where((scanline_intersection_counts &gt; 0))[0].shape[0] &gt; 0:\n        scanline_first_ind = np.where((scanline_intersection_counts &gt; 0))[0][0]\n        return scanline_first_ind\n    else:\n        return np.nan\n</code></pre>"},{"location":"reference/sleap_roots/scanline/#sleap_roots.scanline.get_scanline_last_ind","title":"get_scanline_last_ind","text":"<pre><code>get_scanline_last_ind(\n    scanline_intersection_counts: ndarray,\n)\n</code></pre> <p>Get the index of count_scanline_interaction for the last interaction.</p> <p>Parameters:</p> Name Type Description Default <code>scanline_intersection_counts</code> <code>ndarray</code> <p>An array with shape of <code>(#Nline,)</code> of intersection numbers of each scan line.</p> required Return <p>Scalar of count_scanline_interaction index for the last interaction.</p> Source code in <code>sleap_roots/scanline.py</code> <pre><code>def get_scanline_last_ind(scanline_intersection_counts: np.ndarray):\n    \"\"\"Get the index of count_scanline_interaction for the last interaction.\n\n    Args:\n        scanline_intersection_counts: An array with shape of `(#Nline,)` of intersection\n            numbers of each scan line.\n\n    Return:\n        Scalar of count_scanline_interaction index for the last interaction.\n    \"\"\"\n    # get the last scanline index using scanline_intersection_counts\n    if np.where((scanline_intersection_counts &gt; 0))[0].shape[0] &gt; 0:\n        scanline_last_ind = np.where((scanline_intersection_counts &gt; 0))[0][-1]\n        return scanline_last_ind\n    else:\n        return np.nan\n</code></pre>"},{"location":"reference/sleap_roots/series/","title":"Series","text":""},{"location":"reference/sleap_roots/series/#sleap_roots.series","title":"series","text":"<p>Series-level data loader.</p>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series","title":"Series","text":"<p>Data and predictions for a single image series.</p> <p>Attributes:</p> Name Type Description <code>series_name</code> <code>str</code> <p>Unique identifier for the series.</p> <code>h5_path</code> <code>Optional[str]</code> <p>Optional path to the HDF5-formatted image series.</p> <code>primary_path</code> <code>Optional[str]</code> <p>Optional path to the primary root predictions file. At least one of the primary, lateral, or crown paths must be provided.</p> <code>lateral_path</code> <code>Optional[str]</code> <p>Optional path to the lateral root predictions file. At least one of the primary, lateral, or crown paths must be provided.</p> <code>crown_path</code> <code>Optional[str]</code> <p>Optional path to the crown predictions file. At least one of the primary, lateral, or crown paths must be provided.</p> <code>primary_labels</code> <code>Optional[Labels]</code> <p>Optional <code>sio.Labels</code> corresponding to the primary root predictions.</p> <code>lateral_labels</code> <code>Optional[Labels]</code> <p>Optional <code>sio.Labels</code> corresponding to the lateral root predictions.</p> <code>crown_labels</code> <code>Optional[Labels]</code> <p>Optional <code>sio.Labels</code> corresponding to the crown predictions.</p> <code>video</code> <code>Optional[Video]</code> <p>Optional <code>sio.Video</code> corresponding to the image series.</p> <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <p>Methods:</p> Name Description <code>load</code> <p>Load a set of predictions for this series.</p> <code>__len__</code> <p>Length of the series (number of images).</p> <code>__getitem__</code> <p>Return labeled frames for predictions.</p> <code>__iter__</code> <p>Iterator for looping through predictions.</p> <code>get_frame</code> <p>Return labeled frames for predictions.</p> <code>plot</code> <p>Plot predictions on top of the image.</p> <code>get_primary_points</code> <p>Get primary root points.</p> <code>get_lateral_points</code> <p>Get lateral root points.</p> <code>get_crown_points</code> <p>Get crown root points.</p> Properties <p>expected_count: Fetch the expected plant count for this series from the CSV. group: Group name for the series from the CSV. qc_fail: Flag to indicate if the series failed QC from the CSV.</p>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.expected_count","title":"expected_count  <code>property</code>","text":"<pre><code>expected_count: Union[float, int]\n</code></pre> <p>Fetch the expected plant count for this series from the CSV.</p>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.group","title":"group  <code>property</code>","text":"<pre><code>group: str\n</code></pre> <p>Group name for the series from the CSV.</p>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.qc_fail","title":"qc_fail  <code>property</code>","text":"<pre><code>qc_fail: Union[int, float]\n</code></pre> <p>Flag to indicate if the series failed QC from the CSV.</p>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(\n    series_name: str,\n    h5_path: Optional[str] = None,\n    primary_path: Optional[str] = None,\n    lateral_path: Optional[str] = None,\n    crown_path: Optional[str] = None,\n    csv_path: Optional[str] = None,\n) -&gt; Series\n</code></pre> <p>Load a set of predictions for this series.</p> <p>Parameters:</p> Name Type Description Default <code>series_name</code> <code>str</code> <p>Unique identifier for the series.</p> required <code>h5_path</code> <code>Optional[str]</code> <p>Optional path to the HDF5-formatted image series, which will be used to load the video.</p> <code>None</code> <code>primary_path</code> <code>Optional[str]</code> <p>Optional path to the primary root '.slp' predictions file.</p> <code>None</code> <code>lateral_path</code> <code>Optional[str]</code> <p>Optional path to the lateral root '.slp' predictions file.</p> <code>None</code> <code>crown_path</code> <code>Optional[str]</code> <p>Optional path to the crown '.slp' predictions file.</p> <code>None</code> <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>An instance of Series loaded with the specified predictions.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>@classmethod\ndef load(\n    cls,\n    series_name: str,\n    h5_path: Optional[str] = None,\n    primary_path: Optional[str] = None,\n    lateral_path: Optional[str] = None,\n    crown_path: Optional[str] = None,\n    csv_path: Optional[str] = None,\n) -&gt; \"Series\":\n    \"\"\"Load a set of predictions for this series.\n\n    Args:\n        series_name: Unique identifier for the series.\n        h5_path: Optional path to the HDF5-formatted image series, which will be\n            used to load the video.\n        primary_path: Optional path to the primary root '.slp' predictions file.\n        lateral_path: Optional path to the lateral root '.slp' predictions file.\n        crown_path: Optional path to the crown '.slp' predictions file.\n        csv_path: Optional path to the CSV file containing the expected plant count.\n\n    Returns:\n        An instance of Series loaded with the specified predictions.\n    \"\"\"\n    # Initialize the labels as None\n    primary_labels, lateral_labels, crown_labels = None, None, None\n\n    # Attempt to load the predictions, with error handling\n    try:\n        if primary_path:\n            # Make path object\n            primary_path = Path(primary_path)\n            # Check if the file exists\n            if primary_path.exists():\n                # Make the primary_path POSIX-compliant\n                primary_path = primary_path.as_posix()\n                # Load the primary predictions\n                primary_labels = sio.load_slp(primary_path)\n            else:\n                print(f\"Primary prediction file not found: {primary_path}\")\n        if lateral_path:\n            # Make path object\n            lateral_path = Path(lateral_path)\n            # Check if the file exists\n            if lateral_path.exists():\n                # Make the lateral_path POSIX-compliant\n                lateral_path = lateral_path.as_posix()\n                # Load the lateral predictions\n                lateral_labels = sio.load_slp(lateral_path)\n            else:\n                print(f\"Lateral prediction file not found: {lateral_path}\")\n        if crown_path:\n            # Make path object\n            crown_path = Path(crown_path)\n            # Check if the file exists\n            if crown_path.exists():\n                # Make the crown_path POSIX-compliant\n                crown_path = crown_path.as_posix()\n                # Load the crown predictions\n                crown_labels = sio.load_slp(crown_path)\n            else:\n                print(f\"Crown prediction file not found: {crown_path}\")\n    except Exception as e:\n        print(f\"Error loading prediction files: {e}\")\n\n    # Attempt to load the video, with error handling\n    video = None\n    try:\n        if h5_path:\n            # Make path object\n            h5_path = Path(h5_path)\n            # Check if the file exists\n            if h5_path.exists():\n                # Make the h5_path POSIX-compliant\n                h5_path = h5_path.as_posix()\n                # Load the video\n                video = sio.Video.from_filename(h5_path)\n                # Replace the filename in the labels with the h5_path\n                for labels in [primary_labels, lateral_labels, crown_labels]:\n                    if labels is not None:\n                        labels.video.replace_filename(h5_path)\n            else:\n                print(f\"Video file not found: {h5_path}\")\n    except Exception as e:\n        print(f\"Error loading video file {h5_path}: {e}\")\n\n    # Make the csv path POSIX-compliant\n    if csv_path:\n        csv_path = Path(csv_path).as_posix()\n\n    return cls(\n        series_name=series_name,\n        h5_path=h5_path,\n        primary_path=primary_path,\n        lateral_path=lateral_path,\n        crown_path=crown_path,\n        primary_labels=primary_labels,\n        lateral_labels=lateral_labels,\n        crown_labels=crown_labels,\n        video=video,\n        csv_path=csv_path,\n    )\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Length of the series (number of images).</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Length of the series (number of images).\"\"\"\n    if self.video is not None:\n        return len(self.video)\n    else:\n        # Check all labels if video is None\n        for labels in [self.primary_labels, self.lateral_labels, self.crown_labels]:\n            if labels is not None:\n                return len(labels)\n        # If all labels are None, return 0\n        return 0\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; Dict[str, Optional[LabeledFrame]]\n</code></pre> <p>Return labeled frames for primary and/or lateral and/or crown predictions.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; Dict[str, Optional[sio.LabeledFrame]]:\n    \"\"\"Return labeled frames for primary and/or lateral and/or crown predictions.\"\"\"\n    return self.get_frame(idx)\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.__iter__","title":"__iter__","text":"<pre><code>__iter__()\n</code></pre> <p>Iterator for looping through predictions.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterator for looping through predictions.\"\"\"\n    for i in range(len(self)):\n        yield self[i]\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.get_frame","title":"get_frame","text":"<pre><code>get_frame(frame_idx: int) -&gt; dict\n</code></pre> <p>Return labeled frames for primary, lateral, and crown predictions.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Integer frame number.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with keys 'primary', 'lateral', and 'crown', each corresponding</p> <code>dict</code> <p>to the <code>sio.LabeledFrame</code> from each set of predictions on the same frame. If</p> <code>dict</code> <p>any set of predictions is not available, its value will be None.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_frame(self, frame_idx: int) -&gt; dict:\n    \"\"\"Return labeled frames for primary, lateral, and crown predictions.\n\n    Args:\n        frame_idx: Integer frame number.\n\n    Returns:\n        Dictionary with keys 'primary', 'lateral', and 'crown', each corresponding\n        to the `sio.LabeledFrame` from each set of predictions on the same frame. If\n        any set of predictions is not available, its value will be None.\n    \"\"\"\n    frames = {}\n\n    # For primary predictions\n    if self.primary_labels is not None:\n        frames[\"primary\"] = self.primary_labels.find(\n            self.primary_labels.video, frame_idx, return_new=True\n        )[0]\n    else:\n        frames[\"primary\"] = None\n\n    # For lateral predictions\n    if self.lateral_labels is not None:\n        frames[\"lateral\"] = self.lateral_labels.find(\n            self.lateral_labels.video, frame_idx, return_new=True\n        )[0]\n    else:\n        frames[\"lateral\"] = None\n\n    # For crown predictions\n    if self.crown_labels is not None:\n        frames[\"crown\"] = self.crown_labels.find(\n            self.crown_labels.video, frame_idx, return_new=True\n        )[0]\n    else:\n        frames[\"crown\"] = None\n\n    return frames\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.plot","title":"plot","text":"<pre><code>plot(\n    frame_idx: int, scale: float = 1.0, **kwargs\n) -&gt; Figure\n</code></pre> <p>Plot predictions on top of the image.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index to visualize.</p> required <code>scale</code> <code>float</code> <p>Relative size of the visualized image. Useful for plotting smaller images within notebooks.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Figure</code> <p>matplotlib.figure.Figure object that shows predictions on top of images.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def plot(\n    self, frame_idx: int, scale: float = 1.0, **kwargs\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"Plot predictions on top of the image.\n\n    Args:\n        frame_idx: Frame index to visualize.\n        scale: Relative size of the visualized image. Useful for plotting smaller\n            images within notebooks.\n\n    Returns:\n        matplotlib.figure.Figure object that shows predictions on top of images.\n    \"\"\"\n    # Check if the video is available\n    if self.video is None:\n        raise ValueError(\"Video is not available. Specify the h5_path to load it.\")\n\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n\n    # Generate the color palette from seaborn\n    cmap = sns.color_palette(\"tab10\")\n\n    # Define the order of preference for the predictions for plotting the image\n    prediction_order = [\"primary\", \"lateral\", \"crown\"]\n\n    # Variable to keep track if the image has been plotted\n    image_plotted = False\n\n    # First, find the first available prediction to plot the image\n    for prediction in prediction_order:\n        labeled_frame = frames.get(prediction)\n        if labeled_frame is not None and not image_plotted:\n            # Plot the image\n            plot_img(labeled_frame.image, scale=scale)\n            # Set the flag to True to avoid plotting the image again\n            image_plotted = True\n\n    # Then, iterate through all predictions to plot instances\n    for i, prediction in enumerate(prediction_order):\n        labeled_frame = frames.get(prediction)\n        if labeled_frame is not None:\n            # Use the color map index for each prediction type\n            # Modulo the length of the color map to avoid index out of range\n            color = cmap[i % len(cmap)]\n\n            # Plot the instances\n            plot_instances(labeled_frame.instances, cmap=[color], **kwargs)\n\n    # Capture the current plot after calling plot_img and plot_instances.\n    fig = plt.gcf()\n\n    # Close the captured fig to avoid duplicate rendering from Jupyter.\n    plt.close(fig)\n\n    # Return the figure. In a cell, Jupyter will automatically render the plot.\n    return fig\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.get_primary_points","title":"get_primary_points","text":"<pre><code>get_primary_points(frame_idx: int) -&gt; ndarray\n</code></pre> <p>Get primary root points.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Primary root points as array of shape <code>(n_instances, n_nodes, 2)</code>.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_primary_points(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Get primary root points.\n\n    Args:\n        frame_idx: Frame index.\n\n    Returns:\n        Primary root points as array of shape `(n_instances, n_nodes, 2)`.\n    \"\"\"\n    # Check that self.primary_labels is not None\n    if self.primary_labels is None:\n        raise ValueError(\"Primary labels are not available.\")\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n    # Get the primary labeled frame\n    primary_lf = frames.get(\"primary\")\n    # Get the ground truth instances and unused predictions\n    gt_instances_pr = primary_lf.user_instances + primary_lf.unused_predictions\n    # If there are no instances, return an empty array\n    if len(gt_instances_pr) == 0:\n        primary_pts = np.array([[(np.nan, np.nan), (np.nan, np.nan)]])\n    # Otherwise, stack the instances into an array\n    else:\n        primary_pts = np.stack([inst.numpy() for inst in gt_instances_pr], axis=0)\n    return primary_pts\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.get_lateral_points","title":"get_lateral_points","text":"<pre><code>get_lateral_points(frame_idx: int) -&gt; ndarray\n</code></pre> <p>Get lateral root points.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Lateral root points as array of shape <code>(n_instances, n_nodes, 2)</code>.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_lateral_points(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Get lateral root points.\n\n    Args:\n        frame_idx: Frame index.\n\n    Returns:\n        Lateral root points as array of shape `(n_instances, n_nodes, 2)`.\n    \"\"\"\n    # Check that self.lateral_labels is not None\n    if self.lateral_labels is None:\n        raise ValueError(\"Lateral labels are not available.\")\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n    # Get the lateral labeled frame\n    lateral_lf = frames.get(\"lateral\")\n    # Get the ground truth instances and unused predictions\n    gt_instances_lr = lateral_lf.user_instances + lateral_lf.unused_predictions\n    # If there are no instances, return an empty array\n    if len(gt_instances_lr) == 0:\n        lateral_pts = np.array([[(np.nan, np.nan), (np.nan, np.nan)]])\n    # Otherwise, stack the instances into an array\n    else:\n        lateral_pts = np.stack([inst.numpy() for inst in gt_instances_lr], axis=0)\n    return lateral_pts\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.Series.get_crown_points","title":"get_crown_points","text":"<pre><code>get_crown_points(frame_idx: int) -&gt; ndarray\n</code></pre> <p>Get crown root points.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Frame index.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Crown root points as array of shape <code>(n_instances, n_nodes, 2)</code>.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def get_crown_points(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Get crown root points.\n\n    Args:\n        frame_idx: Frame index.\n\n    Returns:\n        Crown root points as array of shape `(n_instances, n_nodes, 2)`.\n    \"\"\"\n    # Check that self.crown_labels is not None\n    if self.crown_labels is None:\n        raise ValueError(\"Crown labels are not available.\")\n    # Retrieve all available frames\n    frames = self.get_frame(frame_idx)\n    # Get the crown labeled frame\n    crown_lf = frames.get(\"crown\")\n    # Get the ground truth instances and unused predictions\n    gt_instances_cr = crown_lf.user_instances + crown_lf.unused_predictions\n    # If there are no instances, return an empty array\n    if len(gt_instances_cr) == 0:\n        crown_pts = np.array([[(np.nan, np.nan), (np.nan, np.nan)]])\n    # Otherwise, stack the instances into an array\n    else:\n        crown_pts = np.stack([inst.numpy() for inst in gt_instances_cr], axis=0)\n    return crown_pts\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.find_all_h5_paths","title":"find_all_h5_paths","text":"<pre><code>find_all_h5_paths(\n    data_folders: Union[str, List[str]],\n) -&gt; List[str]\n</code></pre> <p>Find all .h5 paths from a list of folders.</p> <p>Parameters:</p> Name Type Description Default <code>data_folders</code> <code>Union[str, List[str]]</code> <p>Path or list of paths to folders containing .h5 paths.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of filenames to .h5 paths.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def find_all_h5_paths(data_folders: Union[str, List[str]]) -&gt; List[str]:\n    \"\"\"Find all .h5 paths from a list of folders.\n\n    Args:\n        data_folders: Path or list of paths to folders containing .h5 paths.\n\n    Returns:\n        A list of filenames to .h5 paths.\n    \"\"\"\n    if type(data_folders) != list:\n        data_folders = [data_folders]\n\n    h5_paths = []\n    for data_folder in data_folders:\n        h5_paths.extend([Path(p).as_posix() for p in Path(data_folder).glob(\"*.h5\")])\n    return h5_paths\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.find_all_slp_paths","title":"find_all_slp_paths","text":"<pre><code>find_all_slp_paths(\n    data_folders: Union[str, List[str]],\n) -&gt; List[str]\n</code></pre> <p>Find all .slp paths from a list of folders.</p> <p>Parameters:</p> Name Type Description Default <code>data_folders</code> <code>Union[str, List[str]]</code> <p>Path or list of paths to folders containing .slp paths.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of filenames to .slp paths.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def find_all_slp_paths(data_folders: Union[str, List[str]]) -&gt; List[str]:\n    \"\"\"Find all .slp paths from a list of folders.\n\n    Args:\n        data_folders: Path or list of paths to folders containing .slp paths.\n\n    Returns:\n        A list of filenames to .slp paths.\n    \"\"\"\n    if type(data_folders) != list:\n        data_folders = [data_folders]\n\n    slp_paths = []\n    for data_folder in data_folders:\n        slp_paths.extend([Path(p).as_posix() for p in Path(data_folder).glob(\"*.slp\")])\n    return slp_paths\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.load_series_from_h5s","title":"load_series_from_h5s","text":"<pre><code>load_series_from_h5s(\n    h5_paths: List[str],\n    model_id: str,\n    csv_path: Optional[str] = None,\n) -&gt; List[Series]\n</code></pre> <p>Load a list of Series from a list of .h5 paths.</p> <p>To load the <code>Series</code>, the files must be named with the following convention: h5_path: '/path/to/scan/series_name.h5' primary_path: '/path/to/scan/series_name.model{model_id}.rootprimary.slp' lateral_path: '/path/to/scan/series_name.model{model_id}.rootlateral.slp' crown_path: '/path/to/scan/series_name.model{model_id}.rootcrown.slp'</p> <p>Our pipeline outputs prediction files with this format: //scan{scan_id}.model{model_id}.root{model_type}.slp <p>Parameters:</p> Name Type Description Default <code>h5_paths</code> <code>List[str]</code> <p>List of paths to .h5 files.</p> required <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Series]</code> <p>A list of Series loaded with the specified .h5 files.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def load_series_from_h5s(\n    h5_paths: List[str], model_id: str, csv_path: Optional[str] = None\n) -&gt; List[Series]:\n    \"\"\"Load a list of Series from a list of .h5 paths.\n\n    To load the `Series`, the files must be named with the following convention:\n    h5_path: '/path/to/scan/series_name.h5'\n    primary_path: '/path/to/scan/series_name.model{model_id}.rootprimary.slp'\n    lateral_path: '/path/to/scan/series_name.model{model_id}.rootlateral.slp'\n    crown_path: '/path/to/scan/series_name.model{model_id}.rootcrown.slp'\n\n    Our pipeline outputs prediction files with this format:\n    /&lt;output_folder&gt;/scan{scan_id}.model{model_id}.root{model_type}.slp\n\n    Args:\n        h5_paths: List of paths to .h5 files.\n        csv_path: Optional path to the CSV file containing the expected plant count.\n\n    Returns:\n        A list of Series loaded with the specified .h5 files.\n    \"\"\"\n    series_list = []\n    for h5_path in h5_paths:\n        # Extract the series name from the h5 path\n        series_name = Path(h5_path).name.split(\".\")[0]\n        # Generate the paths for the primary, lateral, and crown predictions\n        primary_path = h5_path.replace(\".h5\", f\".model{model_id}.rootprimary.slp\")\n        lateral_path = h5_path.replace(\".h5\", f\".model{model_id}.rootlateral.slp\")\n        crown_path = h5_path.replace(\".h5\", f\".model{model_id}.rootcrown.slp\")\n        # Load the Series\n        series = Series.load(\n            series_name,\n            h5_path=h5_path,\n            primary_path=primary_path,\n            lateral_path=lateral_path,\n            crown_path=crown_path,\n            csv_path=csv_path,\n        )\n        series_list.append(series)\n    return series_list\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.load_series_from_slps","title":"load_series_from_slps","text":"<pre><code>load_series_from_slps(\n    slp_paths: List[str],\n    h5s: bool = False,\n    csv_path: Optional[str] = None,\n) -&gt; List[Series]\n</code></pre> <p>Load a list of Series from a list of .slp paths.</p> <p>To load the <code>Series</code>, the files must be named with the following convention. The <code>slp_paths</code> are expeted to have the <code>series_name</code> in the filename and \"primary\", \"lateral\", or \"crown\" in the filename to differentiate the predictions. h5_path: '/path/to/scan/series_name.h5' Note that everything is expected to be in the same folder.</p> <p>Our pipeline outputs prediction files with this format: //scan{scan_id}.model{model_id}.root{model_type}.slp <p>Parameters:</p> Name Type Description Default <code>slp_paths</code> <code>List[str]</code> <p>List of paths to .slp files.</p> required <code>h5s</code> <code>bool</code> <p>Boolean flag to indicate if the .h5 files are available. Default is False.</p> <code>False</code> <code>csv_path</code> <code>Optional[str]</code> <p>Optional path to the CSV file containing the expected plant count.</p> <code>None</code> Source code in <code>sleap_roots/series.py</code> <pre><code>def load_series_from_slps(\n    slp_paths: List[str], h5s: bool = False, csv_path: Optional[str] = None\n) -&gt; List[Series]:\n    \"\"\"Load a list of Series from a list of .slp paths.\n\n    To load the `Series`, the files must be named with the following convention.\n    The `slp_paths` are expeted to have the `series_name` in the filename and \"primary\",\n    \"lateral\", or \"crown\" in the filename to differentiate the predictions.\n    h5_path: '/path/to/scan/series_name.h5'\n    Note that everything is expected to be in the same folder.\n\n    Our pipeline outputs prediction files with this format:\n    /&lt;output_folder&gt;/scan{scan_id}.model{model_id}.root{model_type}.slp\n\n\n    Args:\n        slp_paths: List of paths to .slp files.\n        h5s: Boolean flag to indicate if the .h5 files are available. Default is False.\n        csv_path: Optional path to the CSV file containing the expected plant count.\n    \"\"\"\n    series_list = []\n    series_names = list(set([Path(p).name.split(\".\")[0] for p in slp_paths]))\n    for series_name in series_names:\n        # Generate the paths for the primary, lateral, and crown predictions\n        primary_path = [p for p in slp_paths if series_name in p and \"primary\" in p]\n        lateral_path = [p for p in slp_paths if series_name in p and \"lateral\" in p]\n        crown_path = [p for p in slp_paths if series_name in p and \"crown\" in p]\n        # Check if the .h5 files are available\n        if h5s:\n            # Get directory of the h5s\n            h5_dir = Path(slp_paths[0]).parent\n            # Create path to the .h5 file\n            h5_path = h5_dir / f\"{series_name}.h5\"\n        else:\n            h5_path = None\n        # Load the Series\n        series = Series.load(\n            series_name,\n            primary_path=primary_path[0] if primary_path else None,\n            lateral_path=lateral_path[0] if lateral_path else None,\n            crown_path=crown_path[0] if crown_path else None,\n            h5_path=h5_path,\n            csv_path=csv_path,\n        )\n        series_list.append(series)\n    return series_list\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.imgfig","title":"imgfig","text":"<pre><code>imgfig(\n    size: Union[float, Tuple] = 6,\n    dpi: int = 72,\n    scale: float = 1.0,\n) -&gt; Figure\n</code></pre> <p>Create a tight figure for image plotting.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Union[float, Tuple]</code> <p>Scalar or 2-tuple specifying the (width, height) of the figure in inches. If scalar, will assume equal width and height.</p> <code>6</code> <code>dpi</code> <code>int</code> <p>Dots per inch, controlling the resolution of the image.</p> <code>72</code> <code>scale</code> <code>float</code> <p>Factor to scale the size of the figure by. This is a convenience for increasing the size of the plot at the same DPI.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A matplotlib.figure.Figure to use for plotting.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def imgfig(\n    size: Union[float, Tuple] = 6, dpi: int = 72, scale: float = 1.0\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"Create a tight figure for image plotting.\n\n    Args:\n        size: Scalar or 2-tuple specifying the (width, height) of the figure in inches.\n            If scalar, will assume equal width and height.\n        dpi: Dots per inch, controlling the resolution of the image.\n        scale: Factor to scale the size of the figure by. This is a convenience for\n            increasing the size of the plot at the same DPI.\n\n    Returns:\n        A matplotlib.figure.Figure to use for plotting.\n    \"\"\"\n    if not isinstance(size, (tuple, list)):\n        size = (size, size)\n    fig = plt.figure(figsize=(scale * size[0], scale * size[1]), dpi=dpi)\n    ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.autoscale(tight=True)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n    return fig\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.plot_img","title":"plot_img","text":"<pre><code>plot_img(\n    img: ndarray, dpi: int = 72, scale: float = 1.0\n) -&gt; Figure\n</code></pre> <p>Plot an image in a tight figure.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ndarray</code> <p>Image to plot. Can be a numpy array or a <code>tf.Tensor</code>.</p> required <code>dpi</code> <code>int</code> <p>Dots per inch, controlling the resolution of the image.</p> <code>72</code> <code>scale</code> <code>float</code> <p>Factor to scale the size of the figure by. This is a convenience for increasing the size of the plot at the same DPI.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A matplotlib.figure.Figure containing the image.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def plot_img(\n    img: np.ndarray, dpi: int = 72, scale: float = 1.0\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"Plot an image in a tight figure.\n\n    Args:\n        img: Image to plot. Can be a numpy array or a `tf.Tensor`.\n        dpi: Dots per inch, controlling the resolution of the image.\n        scale: Factor to scale the size of the figure by. This is a convenience for\n            increasing the size of the plot at the same DPI.\n\n    Returns:\n        A matplotlib.figure.Figure containing the image.\n    \"\"\"\n    if hasattr(img, \"numpy\"):\n        img = img.numpy()\n\n    if img.shape[0] == 1:\n        # Squeeze out batch singleton dimension.\n        img = img.squeeze(axis=0)\n\n    # Check if image is grayscale (single channel).\n    grayscale = img.shape[-1] == 1\n    if grayscale:\n        # Squeeze out singleton channel.\n        img = img.squeeze(axis=-1)\n\n    # Normalize the range of pixel values.\n    img_min = img.min()\n    img_max = img.max()\n    if img_min &lt; 0.0 or img_max &gt; 1.0:\n        img = (img - img_min) / (img_max - img_min)\n\n    fig = imgfig(\n        size=(float(img.shape[1]) / dpi, float(img.shape[0]) / dpi),\n        dpi=dpi,\n        scale=scale,\n    )\n\n    ax = fig.gca()\n    ax.imshow(\n        img,\n        cmap=\"gray\" if grayscale else None,\n        origin=\"upper\",\n        extent=[-0.5, img.shape[1] - 0.5, img.shape[0] - 0.5, -0.5],\n    )\n    return fig\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.plot_instance","title":"plot_instance","text":"<pre><code>plot_instance(\n    instance,\n    skeleton=None,\n    cmap=None,\n    color_by_node=False,\n    lw=2,\n    ms=10,\n    bbox=None,\n    scale=1.0,\n    **kwargs\n)\n</code></pre> <p>Plot a single instance with edge coloring.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def plot_instance(\n    instance,\n    skeleton=None,\n    cmap=None,\n    color_by_node=False,\n    lw=2,\n    ms=10,\n    bbox=None,\n    scale=1.0,\n    **kwargs,\n):\n    \"\"\"Plot a single instance with edge coloring.\"\"\"\n    if cmap is None:\n        cmap = sns.color_palette(\"tab20\")\n\n    if skeleton is None and hasattr(instance, \"skeleton\"):\n        skeleton = instance.skeleton\n\n    if skeleton is None:\n        color_by_node = True\n    else:\n        if len(skeleton.edges) == 0:\n            color_by_node = True\n\n    if hasattr(instance, \"numpy\"):\n        inst_pts = instance.numpy()\n    else:\n        inst_pts = instance\n\n    h_lines = []\n    if color_by_node:\n        for k, (x, y) in enumerate(inst_pts):\n            if bbox is not None:\n                x -= bbox[1]\n                y -= bbox[0]\n\n            x *= scale\n            y *= scale\n\n            h_lines_k = plt.plot(x, y, \".\", ms=ms, c=cmap[k % len(cmap)], **kwargs)\n            h_lines.append(h_lines_k)\n\n    else:\n        for k, (src_ind, dst_ind) in enumerate(skeleton.edge_inds):\n            src_pt = inst_pts[src_ind]\n            dst_pt = inst_pts[dst_ind]\n\n            x = np.array([src_pt[0], dst_pt[0]])\n            y = np.array([src_pt[1], dst_pt[1]])\n\n            if bbox is not None:\n                x -= bbox[1]\n                y -= bbox[0]\n\n            x *= scale\n            y *= scale\n\n            h_lines_k = plt.plot(\n                x, y, \".-\", ms=ms, lw=lw, c=cmap[k % len(cmap)], **kwargs\n            )\n\n            h_lines.append(h_lines_k)\n\n    return h_lines\n</code></pre>"},{"location":"reference/sleap_roots/series/#sleap_roots.series.plot_instances","title":"plot_instances","text":"<pre><code>plot_instances(\n    instances,\n    skeleton=None,\n    cmap=None,\n    color_by_track=False,\n    tracks=None,\n    **kwargs\n)\n</code></pre> <p>Plot a list of instances with identity coloring.</p> <p>Parameters:</p> Name Type Description Default <code>instances</code> <p>List of instances to plot.</p> required <code>skeleton</code> <p>Skeleton to use for edge coloring. If not provided, will use node coloring.</p> <code>None</code> <code>cmap</code> <p>Color map to use for coloring. If not provided, will use the default seaborn tab10 color palette.</p> <code>None</code> <code>color_by_track</code> <p>If True, will color instances by their track. If False, will color instances by their identity in the list.</p> <code>False</code> <code>tracks</code> <p>List of tracks to use for coloring. If not provided, will infer tracks from the instances.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>plot_instance</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>A list of handles to the plotted lines.</p> Source code in <code>sleap_roots/series.py</code> <pre><code>def plot_instances(\n    instances, skeleton=None, cmap=None, color_by_track=False, tracks=None, **kwargs\n):\n    \"\"\"Plot a list of instances with identity coloring.\n\n    Args:\n        instances: List of instances to plot.\n        skeleton: Skeleton to use for edge coloring. If not provided, will use node\n            coloring.\n        cmap: Color map to use for coloring. If not provided, will use the default\n            seaborn tab10 color palette.\n        color_by_track: If True, will color instances by their track. If False, will\n            color instances by their identity in the list.\n        tracks: List of tracks to use for coloring. If not provided, will infer tracks\n            from the instances.\n        **kwargs: Additional keyword arguments to pass to `plot_instance`.\n\n    Returns:\n        A list of handles to the plotted lines.\n    \"\"\"\n    if cmap is None:\n        cmap = sns.color_palette(\"tab10\")\n\n    if color_by_track and tracks is None:\n        # Infer tracks for ordering if not provided.\n        tracks = set()\n        for instance in instances:\n            tracks.add(instance.track)\n\n        # Sort by spawned frame.\n        tracks = sorted(list(tracks), key=lambda track: track.name)\n\n    h_lines = []\n    for i, instance in enumerate(instances):\n        if color_by_track:\n            if instance.track is None:\n                raise ValueError(\n                    \"Instances must have a set track when coloring by track.\"\n                )\n\n            if instance.track not in tracks:\n                raise ValueError(\"Instance has a track not found in specified tracks.\")\n\n            color = cmap[tracks.index(instance.track) % len(cmap)]\n\n        else:\n            # Color by identity (order in list).\n            color = cmap[i % len(cmap)]\n\n        h_lines_i = plot_instance(instance, skeleton=skeleton, cmap=[color], **kwargs)\n        h_lines.append(h_lines_i)\n\n    return h_lines\n</code></pre>"},{"location":"reference/sleap_roots/summary/","title":"Summary","text":""},{"location":"reference/sleap_roots/summary/#sleap_roots.summary","title":"summary","text":"<p>Get summary of the traits.</p>"},{"location":"reference/sleap_roots/summary/#sleap_roots.summary.get_summary","title":"get_summary","text":"<pre><code>get_summary(\n    X: ndarray, prefix: Optional[str] = None\n) -&gt; Dict[str, float]\n</code></pre> <p>Get summary of a vector of observations.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Vector of values as a numpy array of shape <code>(n,)</code>.</p> required <code>prefix</code> <code>Optional[str]</code> <p>Prefix of the variable name. If not <code>None</code>, this string will be appended to the key names of the returned dictionary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary of summary statistics of the input vector with keys: \"min\", \"max\", \"mean\", \"median\", \"std\", \"p5\", \"p25\", \"p75\", \"p95\"</p> <code>Dict[str, float]</code> <p>If <code>prefix</code> was specified, the keys will be prefixed with the string.</p> Source code in <code>sleap_roots/summary.py</code> <pre><code>def get_summary(\n    X: np.ndarray,\n    prefix: Optional[str] = None,\n) -&gt; Dict[str, float]:\n    \"\"\"Get summary of a vector of observations.\n\n    Args:\n        X: Vector of values as a numpy array of shape `(n,)`.\n        prefix: Prefix of the variable name. If not `None`, this string will be appended\n            to the key names of the returned dictionary.\n\n    Returns:\n        A dictionary of summary statistics of the input vector with keys:\n            \"min\", \"max\", \"mean\", \"median\", \"std\", \"p5\", \"p25\", \"p75\", \"p95\"\n\n        If `prefix` was specified, the keys will be prefixed with the string.\n    \"\"\"\n    if prefix is None:\n        prefix = \"\"\n\n    X = np.atleast_1d(X)\n\n    if len(X) == 0 or np.all(np.isnan(X)):\n        return {\n            f\"{prefix}min\": np.nan,\n            f\"{prefix}max\": np.nan,\n            f\"{prefix}mean\": np.nan,\n            f\"{prefix}median\": np.nan,\n            f\"{prefix}std\": np.nan,\n            f\"{prefix}p5\": np.nan,\n            f\"{prefix}p25\": np.nan,\n            f\"{prefix}p75\": np.nan,\n            f\"{prefix}p95\": np.nan,\n        }\n    elif np.issubdtype(X.dtype, np.number):\n        return {\n            f\"{prefix}min\": np.nanmin(X),\n            f\"{prefix}max\": np.nanmax(X),\n            f\"{prefix}mean\": np.nanmean(X),\n            f\"{prefix}median\": np.nanmedian(X),\n            f\"{prefix}std\": np.nanstd(X),\n            f\"{prefix}p5\": np.nanpercentile(X, 5),\n            f\"{prefix}p25\": np.nanpercentile(X, 25),\n            f\"{prefix}p75\": np.nanpercentile(X, 75),\n            f\"{prefix}p95\": np.nanpercentile(X, 95),\n        }\n    else:\n        print(\"X contains non-numeric values\")\n        return {\n            f\"{prefix}min\": np.nan,\n            f\"{prefix}max\": np.nan,\n            f\"{prefix}mean\": np.nan,\n            f\"{prefix}median\": np.nan,\n            f\"{prefix}std\": np.nan,\n            f\"{prefix}p5\": np.nan,\n            f\"{prefix}p25\": np.nan,\n            f\"{prefix}p75\": np.nan,\n            f\"{prefix}p95\": np.nan,\n        }\n</code></pre>"},{"location":"reference/sleap_roots/tips/","title":"Tips","text":""},{"location":"reference/sleap_roots/tips/#sleap_roots.tips","title":"tips","text":"<p>Trait calculations that rely on tips.</p>"},{"location":"reference/sleap_roots/tips/#sleap_roots.tips.get_tips","title":"get_tips","text":"<pre><code>get_tips(pts: ndarray) -&gt; ndarray\n</code></pre> <p>Return tips (last node) from each root.</p> <p>Parameters:</p> Name Type Description Default <code>pts</code> <code>ndarray</code> <p>Root landmarks as array of shape <code>(instances, nodes, 2)</code> or <code>(nodes, 2)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of tips. If the input is <code>(nodes, 2)</code>, an array of shape <code>(2,)</code> will be</p> <code>ndarray</code> <p>returned. If the input is <code>(instances, nodes, 2)</code>, an array of shape</p> <code>ndarray</code> <p><code>(instances, 2)</code> will be returned. If there is no root, or the roots don't have</p> <code>ndarray</code> <p>tips, an array of shape <code>(instances, 2)</code> of NaNs will be returned.</p> Source code in <code>sleap_roots/tips.py</code> <pre><code>def get_tips(pts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return tips (last node) from each root.\n\n    Args:\n        pts: Root landmarks as array of shape `(instances, nodes, 2)` or `(nodes, 2)`.\n\n    Returns:\n        Array of tips. If the input is `(nodes, 2)`, an array of shape `(2,)` will be\n        returned. If the input is `(instances, nodes, 2)`, an array of shape\n        `(instances, 2)` will be returned. If there is no root, or the roots don't have\n        tips, an array of shape `(instances, 2)` of NaNs will be returned.\n    \"\"\"\n    # If the input has shape `(nodes, 2)`, reshape it for consistency\n    if pts.ndim == 2:\n        pts = pts[np.newaxis, ...]\n\n    # Get the last point of each instance\n    tip_pts = pts[:, -1, :]  # Shape is `(instances, 2)`\n\n    # If the shape is `(1, 2)` return pts with shape `(2,)` instead\n    if tip_pts.shape[0] == 1:\n        return tip_pts[0]\n\n    return tip_pts\n</code></pre>"},{"location":"reference/sleap_roots/tips/#sleap_roots.tips.get_tip_xs","title":"get_tip_xs","text":"<pre><code>get_tip_xs(tip_pts: ndarray) -&gt; ndarray | floating\n</code></pre> <p>Get x coordinates of tip points.</p> <p>Parameters:</p> Name Type Description Default <code>tip_pts</code> <code>ndarray</code> <p>Root tip points as array of shape <code>(instances, 2)</code> or <code>(2,)</code> when there is only one tip.</p> required Return <p>An array of tip x-coordinates (instances,) or a scalar when there is only one root.</p> Source code in <code>sleap_roots/tips.py</code> <pre><code>def get_tip_xs(tip_pts: np.ndarray) -&gt; np.ndarray | np.floating:\n    \"\"\"Get x coordinates of tip points.\n\n    Args:\n        tip_pts: Root tip points as array of shape `(instances, 2)` or `(2,)` when there\n            is only one tip.\n\n    Return:\n        An array of tip x-coordinates (instances,) or a scalar when there is only one root.\n    \"\"\"\n    # Check for the 2D shape of the input array\n    if tip_pts.ndim == 1:\n        # If shape is `(2,)`, then reshape it to `(1, 2)` for consistency\n        tip_pts = tip_pts.reshape(1, 2)\n    elif tip_pts.ndim != 2:\n        raise ValueError(\"Input array must be of shape `(instances, 2)` or `(2, )`.\")\n\n    # At this point, `tip_pts` should be of shape `(instances, 2)`.\n    # Get the tip x-value\n    tip_xs = tip_pts[:, 0]\n\n    # Now it has shape `(instances,)`\n    if tip_xs.shape == (1,):\n        # Return a scalar\n        return tip_xs[0]\n\n    return tip_xs\n</code></pre>"},{"location":"reference/sleap_roots/tips/#sleap_roots.tips.get_tip_ys","title":"get_tip_ys","text":"<pre><code>get_tip_ys(tip_pts: ndarray) -&gt; ndarray | floating\n</code></pre> <p>Get y coordinates of tip points.</p> <p>Parameters:</p> Name Type Description Default <code>tip_pts</code> <code>ndarray</code> <p>Root tip points as array of shape <code>(instances, 2)</code> or <code>(2,)</code> when there is only one tip.</p> required Return <p>An array of tip y-coordinates (instances,) or a scalar when there is only one root.</p> Source code in <code>sleap_roots/tips.py</code> <pre><code>def get_tip_ys(tip_pts: np.ndarray) -&gt; np.ndarray | np.floating:\n    \"\"\"Get y coordinates of tip points.\n\n    Args:\n        tip_pts: Root tip points as array of shape `(instances, 2)` or `(2,)` when there\n            is only one tip.\n\n    Return:\n        An array of tip y-coordinates (instances,) or a scalar when there is only one root.\n    \"\"\"\n    # Check for the 2D shape of the input array\n    if tip_pts.ndim == 1:\n        # If shape is `(2,)`, then reshape it to `(1, 2)` for consistency\n        tip_pts = tip_pts.reshape(1, 2)\n    elif tip_pts.ndim != 2:\n        raise ValueError(\"Input array must be of shape `(instances, 2)` or `(2, )`.\")\n\n    # At this point, `tip_pts` should be of shape `(instances, 2)`.\n    # Get the tip y-value\n    tip_ys = tip_pts[:, 1]\n    # Now it has shape `(instances,)`\n    if tip_ys.shape == (1,):\n        # Return a scalar\n        return tip_ys[0]\n\n    return tip_ys\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/","title":"Trait pipelines","text":""},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines","title":"trait_pipelines","text":"<p>Extract traits in a pipeline based on a trait graph.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.NumpyArrayEncoder","title":"NumpyArrayEncoder","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Custom encoder for NumPy array types.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.NumpyArrayEncoder.default","title":"default","text":"<pre><code>default(obj)\n</code></pre> <p>Serialize NumPy arrays to lists.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>The object to serialize.</p> required <p>Returns:</p> Type Description <p>A list representation of the NumPy array.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def default(self, obj):\n    \"\"\"Serialize NumPy arrays to lists.\n\n    Args:\n        obj: The object to serialize.\n\n    Returns:\n        A list representation of the NumPy array.\n    \"\"\"\n    if isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, np.int64):\n        return int(obj)\n    # Let the base class default method raise the TypeError\n    return json.JSONEncoder.default(self, obj)\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.TraitDef","title":"TraitDef","text":"<p>Definition of how to compute a trait.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for the trait.</p> <code>fn</code> <code>Callable</code> <p>Function used to compute the trait's value.</p> <code>input_traits</code> <code>List[str]</code> <p>List of trait names that should be computed before the current trait and are expected as input positional arguments to <code>fn</code>.</p> <code>scalar</code> <code>bool</code> <p>Indicates if the trait is scalar (has a dimension of 0 per frame). If <code>True</code>, the trait is also listed in <code>SCALAR_TRAITS</code>.</p> <code>include_in_csv</code> <code>bool</code> <p><code>True</code>indicates the trait should be included in downstream CSV files.</p> <code>kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments to be passed to the <code>fn</code> function. These arguments are not reused from previously computed traits.</p> <code>description</code> <code>Optional[str]</code> <p>String describing the trait for documentation purposes.</p> Notes <p>The <code>fn</code> specified will be called with a pattern like:</p> <pre><code>trait_def = TraitDef(\n    name=\"my_trait\",\n    fn=compute_my_trait,\n    input_traits=[\"input_trait_1\", \"input_trait_2\"],\n    scalar=True,\n    include_in_csv=True,\n    kwargs={\"kwarg1\": True}\n)\ntraits[trait_def.name] = trait_def.fn(\n    *[traits[input_trait] for input_trait in trait_def.input_traits],\n    **trait_def.kwargs\n)\n</code></pre> <p>For this example, the last line is equivalent to:</p> <pre><code>traits[\"my_trait\"] = trait_def.fn(\n    traits[\"input_trait_1\"], traits[\"input_trait_2\"],\n    kwarg1=True\n)\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline","title":"Pipeline","text":"<p>Pipeline for computing traits.</p> <p>Attributes:</p> Name Type Description <code>traits</code> <code>List[TraitDef]</code> <p>List of <code>TraitDef</code> objects.</p> <code>trait_map</code> <code>Dict[str, TraitDef]</code> <p>Dictionary mapping trait names to their definitions.</p> <code>trait_computation_order</code> <code>List[str]</code> <p>List of trait names in the order they should be computed.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.summary_traits","title":"summary_traits  <code>property</code>","text":"<pre><code>summary_traits: List[str]\n</code></pre> <p>List of traits to include in the summary CSV.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.csv_traits","title":"csv_traits  <code>property</code>","text":"<pre><code>csv_traits: List[str]\n</code></pre> <p>List of frame-level traits to include in the CSV.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.csv_traits_multiple_plants","title":"csv_traits_multiple_plants  <code>property</code>","text":"<pre><code>csv_traits_multiple_plants: List[str]\n</code></pre> <p>List of frame-level traits to include in the CSV for multiple plants.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.__attrs_post_init__","title":"__attrs_post_init__","text":"<pre><code>__attrs_post_init__()\n</code></pre> <p>Build pipeline objects from traits list.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Build pipeline objects from traits list.\"\"\"\n    # Build list of trait definitions.\n    self.traits = self.define_traits()\n\n    # Check that trait names are unique.\n    trait_names = [trait.name for trait in self.traits]\n    if len(trait_names) != len(set(trait_names)):\n        raise ValueError(\"Trait names must be unique.\")\n\n    # Map trait names to their definitions.\n    self.trait_map = {trait_def.name: trait_def for trait_def in self.traits}\n\n    # Determine computation order by topologically sorting the nodes.\n    self.trait_computation_order = self.get_computation_order()\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Return list of <code>TraitDef</code> objects.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Return list of `TraitDef` objects.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.get_computation_order","title":"get_computation_order","text":"<pre><code>get_computation_order() -&gt; List[str]\n</code></pre> <p>Determine computation order by topologically sorting the nodes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of trait names in the order they should be computed.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_computation_order(self) -&gt; List[str]:\n    \"\"\"Determine computation order by topologically sorting the nodes.\n\n    Returns:\n        A list of trait names in the order they should be computed.\n    \"\"\"\n    # Infer edges from trait map.\n    edges = []\n    for trait_def in self.traits:\n        for input_trait in trait_def.input_traits:\n            edges.append((input_trait, trait_def.name))\n\n    # Build networkx graph from inferred edges.\n    G = nx.DiGraph()\n    G.add_edges_from(edges)\n\n    # Determine computation order by topologically sorting the nodes.\n    trait_computation_order = list(nx.topological_sort(G))\n\n    return trait_computation_order\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_frame_traits","title":"compute_frame_traits","text":"<pre><code>compute_frame_traits(\n    traits: Dict[str, Any],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Compute traits based on the pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>traits</code> <code>Dict[str, Any]</code> <p>Dictionary of traits where keys are trait names and values are the trait values.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of computed traits.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_frame_traits(self, traits: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Compute traits based on the pipeline.\n\n    Args:\n        traits: Dictionary of traits where keys are trait names and values are\n            the trait values.\n\n    Returns:\n        A dictionary of computed traits.\n    \"\"\"\n    # Initialize traits container with initial data.\n    traits = traits.copy()\n\n    # Compute traits!\n    for trait_name in self.trait_computation_order:\n        if trait_name in traits:\n            # Skip traits already computed.\n            continue\n\n        # Get trait definition.\n        trait_def = self.trait_map[trait_name]\n\n        # Compute trait based on trait definition.\n        traits[trait_name] = trait_def.fn(\n            *[traits[input_trait] for input_trait in trait_def.input_traits],\n            **trait_def.kwargs,\n        )\n\n    return traits\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits.</p> <code>Dict[str, Any]</code> <p>This is defined on a per-pipeline basis as different plant species will have</p> <code>Dict[str, Any]</code> <p>different initial points to be used as starting traits.</p> <code>Dict[str, Any]</code> <p>Most commonly, this will be the primary and lateral root points for the</p> <code>Dict[str, Any]</code> <p>current frame.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits.\n\n        This is defined on a per-pipeline basis as different plant species will have\n        different initial points to be used as starting traits.\n\n        Most commonly, this will be the primary and lateral root points for the\n        current frame.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_plant_traits","title":"compute_plant_traits","text":"<pre><code>compute_plant_traits(\n    plant: Series,\n    write_csv: bool = False,\n    output_dir: str = \".\",\n    csv_suffix: str = \".traits.csv\",\n    return_non_scalar: bool = False,\n) -&gt; DataFrame\n</code></pre> <p>Compute traits for a plant.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant image series as a <code>Series</code> object.</p> required <code>write_csv</code> <code>bool</code> <p>A boolean value. If True, it writes per plant detailed CSVs with traits for every instance on every frame.</p> <code>False</code> <code>output_dir</code> <code>str</code> <p>The directory to write the CSV files to.</p> <code>'.'</code> <code>csv_suffix</code> <code>str</code> <p>If <code>write_csv</code> is <code>True</code>, a CSV file will be saved with the same name as the plant's <code>{plant.series_name}{csv_suffix}</code>.</p> <code>'.traits.csv'</code> <code>return_non_scalar</code> <code>bool</code> <p>If <code>True</code>, return all non-scalar traits as well as the summarized traits.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The computed traits as a pandas DataFrame.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_plant_traits(\n    self,\n    plant: Series,\n    write_csv: bool = False,\n    output_dir: str = \".\",\n    csv_suffix: str = \".traits.csv\",\n    return_non_scalar: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Compute traits for a plant.\n\n    Args:\n        plant: The plant image series as a `Series` object.\n        write_csv: A boolean value. If True, it writes per plant detailed\n            CSVs with traits for every instance on every frame.\n        output_dir: The directory to write the CSV files to.\n        csv_suffix: If `write_csv` is `True`, a CSV file will be saved with the same\n            name as the plant's `{plant.series_name}{csv_suffix}`.\n        return_non_scalar: If `True`, return all non-scalar traits as well as the\n            summarized traits.\n\n    Returns:\n        The computed traits as a pandas DataFrame.\n    \"\"\"\n    traits = []\n    for frame in range(len(plant)):\n        # Get initial traits for the frame.\n        initial_traits = self.get_initial_frame_traits(plant, frame)\n\n        # Compute traits via the frame-level pipeline.\n        frame_traits = self.compute_frame_traits(initial_traits)\n\n        # Compute trait summaries.\n        for trait_name in self.summary_traits:\n            trait_summary = get_summary(\n                frame_traits[trait_name], prefix=f\"{trait_name}_\"\n            )\n            frame_traits.update(trait_summary)\n\n        # Add metadata.\n        frame_traits[\"plant_name\"] = plant.series_name\n        frame_traits[\"frame_idx\"] = frame\n        traits.append(frame_traits)\n    traits = pd.DataFrame(traits)\n\n    # Move metadata columns to the front.\n    plant_name = traits.pop(\"plant_name\")\n    frame_idx = traits.pop(\"frame_idx\")\n    traits = pd.concat([plant_name, frame_idx, traits], axis=1)\n\n    if write_csv:\n        csv_name = Path(output_dir) / f\"{plant.series_name}{csv_suffix}\"\n        traits[[\"plant_name\", \"frame_idx\"] + self.csv_traits].to_csv(\n            csv_name, index=False\n        )\n\n    if return_non_scalar:\n        return traits\n    else:\n        return traits[[\"plant_name\", \"frame_idx\"] + self.csv_traits]\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_multiple_dicots_traits","title":"compute_multiple_dicots_traits","text":"<pre><code>compute_multiple_dicots_traits(\n    series: Series,\n    write_json: bool = False,\n    json_suffix: str = \".all_frames_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".all_frames_summary.csv\",\n)\n</code></pre> <p>Computes plant traits for pipelines with multiple plants over all frames in a series.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The Series object containing the primary and lateral root points.</p> required <code>write_json</code> <code>bool</code> <p>Whether to write the aggregated traits to a JSON file. Default is False.</p> <code>False</code> <code>json_suffix</code> <code>str</code> <p>The suffix to append to the JSON file name. Default is \".all_frames_traits.json\".</p> <code>'.all_frames_traits.json'</code> <code>write_csv</code> <code>bool</code> <p>Whether to write the summary statistics to a CSV file. Default is False.</p> <code>False</code> <code>csv_suffix</code> <code>str</code> <p>The suffix to append to the CSV file name. Default is \".all_frames_summary.csv\".</p> <code>'.all_frames_summary.csv'</code> <p>Returns:</p> Type Description <p>A dictionary containing the series name, group, qc_fail, aggregated traits, and summary statistics.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_multiple_dicots_traits(\n    self,\n    series: Series,\n    write_json: bool = False,\n    json_suffix: str = \".all_frames_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".all_frames_summary.csv\",\n):\n    \"\"\"Computes plant traits for pipelines with multiple plants over all frames in a series.\n\n    Args:\n        series: The Series object containing the primary and lateral root points.\n        write_json: Whether to write the aggregated traits to a JSON file. Default is False.\n        json_suffix: The suffix to append to the JSON file name. Default is \".all_frames_traits.json\".\n        write_csv: Whether to write the summary statistics to a CSV file. Default is False.\n        csv_suffix: The suffix to append to the CSV file name. Default is \".all_frames_summary.csv\".\n\n    Returns:\n        A dictionary containing the series name, group, qc_fail, aggregated traits, and summary statistics.\n    \"\"\"\n    # Initialize the return structure with the series name and group\n    result = {\n        \"series\": str(series.series_name),\n        \"group\": str(series.group),\n        \"qc_fail\": series.qc_fail,\n        \"traits\": {},\n        \"summary_stats\": {},\n    }\n\n    # Check if the series has frames to process\n    if len(series) == 0:\n        print(f\"Series '{series.series_name}' contains no frames to process.\")\n        # Return early with the initialized structure\n        return result\n\n    # Initialize a separate dictionary to hold the aggregated traits across all frames\n    aggregated_traits = {}\n\n    # Iterate over frames in series\n    for frame in range(len(series)):\n        # Get initial points and number of plants per frame\n        initial_frame_traits = self.get_initial_frame_traits(series, frame)\n        # Compute initial associations and perform filter operations\n        frame_traits = self.compute_frame_traits(initial_frame_traits)\n\n        # Instantiate DicotPipeline\n        dicot_pipeline = DicotPipeline()\n\n        # Extract the plant associations for this frame\n        associations = frame_traits[\"plant_associations_dict\"]\n\n        for primary_idx, assoc in associations.items():\n            primary_pts = assoc[\"primary_points\"]\n            lateral_pts = assoc[\"lateral_points\"]\n            # Get the initial frame traits for this plant using the primary and lateral points\n            initial_frame_traits = {\n                \"primary_pts\": primary_pts,\n                \"lateral_pts\": lateral_pts,\n            }\n            # Use the dicot pipeline to compute the plant traits on this frame\n            plant_traits = dicot_pipeline.compute_frame_traits(initial_frame_traits)\n\n            # For each plant's traits in the frame\n            for trait_name, trait_value in plant_traits.items():\n                # Not all traits are added to the aggregated traits dictionary\n                if trait_name in dicot_pipeline.csv_traits_multiple_plants:\n                    if trait_name not in aggregated_traits:\n                        # Initialize the trait array if it's the first frame\n                        aggregated_traits[trait_name] = [np.atleast_1d(trait_value)]\n                    else:\n                        # Append new trait values for subsequent frames\n                        aggregated_traits[trait_name].append(\n                            np.atleast_1d(trait_value)\n                        )\n\n    # After processing, update the result dictionary with computed traits\n    for trait, arrays in aggregated_traits.items():\n        aggregated_traits[trait] = np.concatenate(arrays, axis=0)\n    result[\"traits\"] = aggregated_traits\n\n    # Write to JSON if requested\n    if write_json:\n        json_name = f\"{series.series_name}{json_suffix}\"\n        try:\n            with open(json_name, \"w\") as f:\n                json.dump(\n                    result, f, cls=NumpyArrayEncoder, ensure_ascii=False, indent=4\n                )\n            print(f\"Aggregated traits saved to {json_name}\")\n        except IOError as e:\n            print(f\"Error writing JSON file '{json_name}': {e}\")\n\n    # Compute summary statistics and update result\n    summary_stats = {}\n    for trait_name, trait_values in aggregated_traits.items():\n        trait_stats = get_summary(trait_values, prefix=f\"{trait_name}_\")\n        summary_stats.update(trait_stats)\n    result[\"summary_stats\"] = summary_stats\n\n    # Optionally write summary stats to CSV\n    if write_csv:\n        csv_name = f\"{series.series_name}{csv_suffix}\"\n        try:\n            summary_df = pd.DataFrame([summary_stats])\n            summary_df.insert(0, \"series\", series.series_name)\n            summary_df.to_csv(csv_name, index=False)\n            print(f\"Summary statistics saved to {csv_name}\")\n        except IOError as e:\n            print(f\"Failed to write CSV file '{csv_name}': {e}\")\n\n    # Return the final result structure\n    return result\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_multiple_dicots_traits_for_groups","title":"compute_multiple_dicots_traits_for_groups","text":"<pre><code>compute_multiple_dicots_traits_for_groups(\n    series_list: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    json_suffix: str = \".grouped_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".grouped_summary.csv\",\n) -&gt; List[\n    Dict[\n        str,\n        Union[\n            str,\n            List[str],\n            Dict[str, Union[List[float], ndarray]],\n        ],\n    ]\n]\n</code></pre> <p>Aggregates plant traits over groups of samples.</p> <p>Parameters:</p> Name Type Description Default <code>series_list</code> <code>List[Series]</code> <p>A list of Series objects containing the primary and lateral root points for each sample.</p> required <code>output_dir</code> <code>str</code> <p>The directory to write the JSON and CSV files to. Default is \"grouped_traits\".</p> <code>'grouped_traits'</code> <code>write_json</code> <code>bool</code> <p>Whether to write the aggregated traits to a JSON file. Default is False.</p> <code>False</code> <code>json_suffix</code> <code>str</code> <p>The suffix to append to the JSON file name. Default is \".grouped_traits.json\".</p> <code>'.grouped_traits.json'</code> <code>write_csv</code> <code>bool</code> <p>Whether to write the summary statistics to a CSV file. Default is False.</p> <code>False</code> <code>csv_suffix</code> <code>str</code> <p>The suffix to append to the CSV file name. Default is \".grouped_summary.csv\".</p> <code>'.grouped_summary.csv'</code> <p>Returns:</p> Type Description <code>List[Dict[str, Union[str, List[str], Dict[str, Union[List[float], ndarray]]]]]</code> <p>A list of dictionaries containing the aggregated traits and summary statistics for each group.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_multiple_dicots_traits_for_groups(\n    self,\n    series_list: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    json_suffix: str = \".grouped_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".grouped_summary.csv\",\n) -&gt; List[\n    Dict[str, Union[str, List[str], Dict[str, Union[List[float], np.ndarray]]]]\n]:\n    \"\"\"Aggregates plant traits over groups of samples.\n\n    Args:\n        series_list: A list of Series objects containing the primary and lateral root points for each sample.\n        output_dir: The directory to write the JSON and CSV files to. Default is \"grouped_traits\".\n        write_json: Whether to write the aggregated traits to a JSON file. Default is False.\n        json_suffix: The suffix to append to the JSON file name. Default is \".grouped_traits.json\".\n        write_csv: Whether to write the summary statistics to a CSV file. Default is False.\n        csv_suffix: The suffix to append to the CSV file name. Default is \".grouped_summary.csv\".\n\n    Returns:\n        A list of dictionaries containing the aggregated traits and summary statistics for each group.\n    \"\"\"\n    # Input Validation\n    if not isinstance(series_list, list) or not all(\n        isinstance(series, Series) for series in series_list\n    ):\n        raise ValueError(\"series_list must be a list of Series objects.\")\n\n    # Group series by their group property\n    series_groups = {}\n    for series in series_list:\n        # Exclude series with qc_fail flag set to 1\n        if int(series.qc_fail) == 1:\n            print(f\"Skipping series '{series.series_name}' due to qc_fail flag.\")\n            continue\n        # Get the group name from the series object\n        group_name = str(series.group)\n        if group_name not in series_groups:\n            series_groups[group_name] = {\"names\": [], \"series\": []}\n        # Store series names and objects in the dictionary\n        series_groups[group_name][\"names\"].append(str(series.series_name))\n        series_groups[group_name][\"series\"].append(series)  # Store Series objects\n\n    # Initialize the list to hold the results for each group\n    grouped_results = []\n    # Iterate over each group of series\n    for group_name, group_data in series_groups.items():\n        # Initialize the return structure with the group name\n        group_result = {\n            \"group\": group_name,\n            \"series\": group_data[\"names\"],  # Use series names\n            \"traits\": {},\n        }\n\n        # Aggregate traits over all samples in the group\n        aggregated_traits = {}\n        # Iterate over each series in the group\n        for series in group_data[\"series\"]:\n            print(f\"Processing series '{series.series_name}'\")\n            # Get the trait results for each series in the group\n            result = self.compute_multiple_dicots_traits(\n                series=series, write_json=False, write_csv=False\n            )\n            # Aggregate the series traits into the group traits\n            for trait, values in result[\"traits\"].items():\n                # Ensure values are at least 1D\n                values = np.atleast_1d(values)\n                if trait not in aggregated_traits:\n                    aggregated_traits[trait] = values\n                else:\n                    # Concatenate the current values with the existing array\n                    aggregated_traits[trait] = np.concatenate(\n                        (aggregated_traits[trait], values)\n                    )\n\n        group_result[\"traits\"] = aggregated_traits\n        print(f\"Finished processing group '{group_name}'\")\n\n        # Write to JSON if requested\n        if write_json:\n            # Make the output directory if it doesn't exist\n            Path(output_dir).mkdir(parents=True, exist_ok=True)\n            # Construct the JSON file name\n            json_name = f\"{group_name}{json_suffix}\"\n            # Join the output directory with the JSON file name\n            json_path = Path(output_dir) / json_name\n            try:\n                with open(json_path, \"w\") as f:\n                    json.dump(\n                        group_result,\n                        f,\n                        cls=NumpyArrayEncoder,\n                        ensure_ascii=False,\n                        indent=4,\n                    )\n                print(\n                    f\"Aggregated traits for group {group_name} saved to {str(json_path)}\"\n                )\n            except IOError as e:\n                print(f\"Error writing JSON file '{str(json_path)}': {e}\")\n\n        # Compute summary statistics\n        summary_stats = {}\n        for trait, trait_values in aggregated_traits.items():\n            trait_stats = get_summary(trait_values, prefix=f\"{trait}_\")\n            summary_stats.update(trait_stats)\n\n        group_result[\"summary_stats\"] = summary_stats\n\n        # Write summary stats to CSV if requested\n        if write_csv:\n            # Make the output directory if it doesn't exist\n            Path(output_dir).mkdir(parents=True, exist_ok=True)\n            # Construct the CSV file name\n            csv_name = f\"{group_name}{csv_suffix}\"\n            # Join the output directory with the CSV file name\n            csv_path = Path(output_dir) / csv_name\n            try:\n                summary_df = pd.DataFrame([summary_stats])\n                summary_df.insert(0, \"genotype\", group_name)\n                summary_df.to_csv(csv_path, index=False)\n                print(\n                    f\"Summary statistics for group {group_name} saved to {str(csv_path)}\"\n                )\n            except IOError as e:\n                print(f\"Failed to write CSV file '{str(csv_path)}': {e}\")\n\n        # Append the group result to the list of results\n        grouped_results.append(group_result)\n\n    return grouped_results\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_multiple_primary_roots_traits","title":"compute_multiple_primary_roots_traits","text":"<pre><code>compute_multiple_primary_roots_traits(\n    series: Series,\n    write_json: bool = False,\n    json_suffix: str = \".all_frames_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".all_frames_summary.csv\",\n    per_instance: bool = False,\n    flattened_csv_suffix: str = \".flattened_traits.csv\",\n)\n</code></pre> <p>Computes plant traits for pipelines with multiple primary roots over all frames in a series.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The Series object containing the primary and lateral root points.</p> required <code>write_json</code> <code>bool</code> <p>Whether to write the aggregated traits to a JSON file. Default is False.</p> <code>False</code> <code>json_suffix</code> <code>str</code> <p>The suffix to append to the JSON file name. Default is \".all_frames_traits.json\".</p> <code>'.all_frames_traits.json'</code> <code>write_csv</code> <code>bool</code> <p>Whether to write the summary statistics to a CSV file. Default is False.</p> <code>False</code> <code>csv_suffix</code> <code>str</code> <p>The suffix to append to the CSV file name. Default is \".all_frames_summary.csv\".</p> <code>'.all_frames_summary.csv'</code> <p>Returns:</p> Type Description <p>A dictionary with aggregated traits, summary stats, and optionally per-instance traits.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_multiple_primary_roots_traits(\n    self,\n    series: Series,\n    write_json: bool = False,\n    json_suffix: str = \".all_frames_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".all_frames_summary.csv\",\n    per_instance: bool = False,\n    flattened_csv_suffix: str = \".flattened_traits.csv\",\n):\n    \"\"\"Computes plant traits for pipelines with multiple primary roots over all frames in a series.\n\n    Args:\n        series: The Series object containing the primary and lateral root points.\n        write_json: Whether to write the aggregated traits to a JSON file. Default is False.\n        json_suffix: The suffix to append to the JSON file name. Default is \".all_frames_traits.json\".\n        write_csv: Whether to write the summary statistics to a CSV file. Default is False.\n        csv_suffix: The suffix to append to the CSV file name. Default is \".all_frames_summary.csv\".\n\n    Returns:\n        A dictionary with aggregated traits, summary stats, and optionally per-instance traits.\n    \"\"\"\n    result = {\n        \"series\": str(series.series_name),\n        \"group\": str(series.group),\n        \"qc_fail\": series.qc_fail,\n        \"traits\": {},\n        \"summary_stats\": {},\n    }\n\n    if per_instance:\n        result[\"per_instance_traits\"] = []\n\n    if len(series) == 0:\n        print(f\"Series '{series.series_name}' contains no frames to process.\")\n        return result\n\n    aggregated_traits = {}\n    primary_root_pipeline = PrimaryRootPipeline()\n\n    for frame_idx in range(len(series)):\n        initial_frame_traits = self.get_initial_frame_traits(series, frame_idx)\n        frame_traits = self.compute_frame_traits(initial_frame_traits)\n\n        primary_root_instances = frame_traits[\n            \"filtered_primary_pts_with_expected_ct\"\n        ]\n\n        for instance_idx, primary_root_inst in enumerate(primary_root_instances):\n            inst_input = {\"primary_pts\": primary_root_inst}\n            plant_traits = primary_root_pipeline.compute_frame_traits(inst_input)\n\n            if per_instance:\n                result[\"per_instance_traits\"].append(\n                    {\n                        \"frame\": frame_idx,\n                        \"instance\": instance_idx,\n                        \"traits\": plant_traits,\n                    }\n                )\n\n            for trait_name, trait_value in plant_traits.items():\n                if trait_name in primary_root_pipeline.csv_traits_multiple_plants:\n                    if trait_name not in aggregated_traits:\n                        aggregated_traits[trait_name] = [np.atleast_1d(trait_value)]\n                    else:\n                        aggregated_traits[trait_name].append(\n                            np.atleast_1d(trait_value)\n                        )\n\n    for trait, arrays in aggregated_traits.items():\n        aggregated_traits[trait] = np.concatenate(arrays, axis=0)\n    result[\"traits\"] = aggregated_traits\n\n    summary_stats = {}\n    for trait_name, trait_values in aggregated_traits.items():\n        trait_stats = get_summary(trait_values, prefix=f\"{trait_name}_\")\n        summary_stats.update(trait_stats)\n    result[\"summary_stats\"] = summary_stats\n\n    if write_json:\n        json_name = f\"{series.series_name}{json_suffix}\"\n        try:\n            with open(json_name, \"w\") as f:\n                json.dump(\n                    result, f, cls=NumpyArrayEncoder, ensure_ascii=False, indent=4\n                )\n            print(f\"Aggregated traits saved to {json_name}\")\n        except IOError as e:\n            print(f\"Error writing JSON file '{json_name}': {e}\")\n\n    if write_csv:\n        csv_name = f\"{series.series_name}{csv_suffix}\"\n        try:\n            summary_df = pd.DataFrame([summary_stats])\n            summary_df.insert(0, \"series\", series.series_name)\n            summary_df.to_csv(csv_name, index=False)\n            print(f\"Summary statistics saved to {csv_name}\")\n        except IOError as e:\n            print(f\"Failed to write summary CSV '{csv_name}': {e}\")\n\n    flat_df = None\n    if per_instance:\n        try:\n            rows = []\n            for inst in result[\"per_instance_traits\"]:\n                row = {\n                    \"series\": series.series_name,\n                    \"frame\": inst[\"frame\"],\n                    \"instance\": inst[\"instance\"],\n                }\n                for trait_name, trait_value in inst[\"traits\"].items():\n                    if isinstance(\n                        trait_value, (int, float, np.integer, np.floating)\n                    ):\n                        row[trait_name] = trait_value\n                    elif isinstance(trait_value, np.ndarray):\n                        if trait_value.ndim == 0:\n                            row[trait_name] = trait_value.item()\n                        elif trait_value.ndim == 1 and trait_value.shape[0] == 1:\n                            row[trait_name] = trait_value[0]\n                        else:\n                            continue\n                    else:\n                        continue\n                rows.append(row)\n\n            flat_df = pd.DataFrame(rows)\n\n            if write_csv:\n                flat_csv_name = f\"{series.series_name}{flattened_csv_suffix}\"\n                flat_df.to_csv(flat_csv_name, index=False)\n                print(f\"Flattened per-instance traits saved to {flat_csv_name}\")\n        except Exception as e:\n            print(f\"Failed to process flattened traits: {e}\")\n        return flat_df\n    else:\n        return result\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_multiple_primary_roots_traits_for_groups","title":"compute_multiple_primary_roots_traits_for_groups","text":"<pre><code>compute_multiple_primary_roots_traits_for_groups(\n    series_list: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    json_suffix: str = \".grouped_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".grouped_summary.csv\",\n) -&gt; List[\n    Dict[\n        str,\n        Union[\n            str,\n            List[str],\n            Dict[str, Union[List[float], ndarray]],\n        ],\n    ]\n]\n</code></pre> <p>Aggregates plant traits over groups of samples.</p> <p>Parameters:</p> Name Type Description Default <code>series_list</code> <code>List[Series]</code> <p>A list of Series objects containing the primary root points for each sample.</p> required <code>output_dir</code> <code>str</code> <p>The directory to write the JSON and CSV files to. Default is \"grouped_traits\".</p> <code>'grouped_traits'</code> <code>write_json</code> <code>bool</code> <p>Whether to write the aggregated traits to a JSON file. Default is False.</p> <code>False</code> <code>json_suffix</code> <code>str</code> <p>The suffix to append to the JSON file name. Default is \".grouped_traits.json\".</p> <code>'.grouped_traits.json'</code> <code>write_csv</code> <code>bool</code> <p>Whether to write the summary statistics to a CSV file. Default is False.</p> <code>False</code> <code>csv_suffix</code> <code>str</code> <p>The suffix to append to the CSV file name. Default is \".grouped_summary.csv\".</p> <code>'.grouped_summary.csv'</code> <p>Returns:</p> Type Description <code>List[Dict[str, Union[str, List[str], Dict[str, Union[List[float], ndarray]]]]]</code> <p>A list of dictionaries containing the aggregated traits and summary statistics for each group.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_multiple_primary_roots_traits_for_groups(\n    self,\n    series_list: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    json_suffix: str = \".grouped_traits.json\",\n    write_csv: bool = False,\n    csv_suffix: str = \".grouped_summary.csv\",\n) -&gt; List[\n    Dict[str, Union[str, List[str], Dict[str, Union[List[float], np.ndarray]]]]\n]:\n    \"\"\"Aggregates plant traits over groups of samples.\n\n    Args:\n        series_list: A list of Series objects containing the primary root points for each sample.\n        output_dir: The directory to write the JSON and CSV files to. Default is \"grouped_traits\".\n        write_json: Whether to write the aggregated traits to a JSON file. Default is False.\n        json_suffix: The suffix to append to the JSON file name. Default is \".grouped_traits.json\".\n        write_csv: Whether to write the summary statistics to a CSV file. Default is False.\n        csv_suffix: The suffix to append to the CSV file name. Default is \".grouped_summary.csv\".\n\n    Returns:\n        A list of dictionaries containing the aggregated traits and summary statistics for each group.\n    \"\"\"\n    # Input Validation\n    if not isinstance(series_list, list) or not all(\n        isinstance(series, Series) for series in series_list\n    ):\n        raise ValueError(\"series_list must be a list of Series objects.\")\n\n    # Group series by their group property\n    series_groups = {}\n    for series in series_list:\n        # Exclude series with qc_fail flag set to 1\n        if int(series.qc_fail) == 1:\n            print(f\"Skipping series '{series.series_name}' due to qc_fail flag.\")\n            continue\n        # Get the group name from the series object\n        group_name = str(series.group)\n        if group_name not in series_groups:\n            series_groups[group_name] = {\"names\": [], \"series\": []}\n        # Store series names and objects in the dictionary\n        series_groups[group_name][\"names\"].append(str(series.series_name))\n        series_groups[group_name][\"series\"].append(series)  # Store Series objects\n\n    # Initialize the list to hold the results for each group\n    grouped_results = []\n    # Iterate over each group of series\n    for group_name, group_data in series_groups.items():\n        # Initialize the return structure with the group name\n        group_result = {\n            \"group\": group_name,\n            \"series\": group_data[\"names\"],  # Use series names\n            \"traits\": {},\n        }\n\n        # Aggregate traits over all samples in the group\n        aggregated_traits = {}\n        # Iterate over each series in the group\n        for series in group_data[\"series\"]:\n            print(f\"Processing series '{series.series_name}'\")\n            # Get the trait results for each series in the group\n            result = self.compute_multiple_primary_roots_traits(\n                series=series, write_json=False, write_csv=False\n            )\n            # Aggregate the series traits into the group traits\n            for trait, values in result[\"traits\"].items():\n                # Ensure values are at least 1D\n                values = np.atleast_1d(values)\n                if trait not in aggregated_traits:\n                    aggregated_traits[trait] = values\n                else:\n                    # Concatenate the current values with the existing array\n                    aggregated_traits[trait] = np.concatenate(\n                        (aggregated_traits[trait], values)\n                    )\n\n        group_result[\"traits\"] = aggregated_traits\n        print(f\"Finished processing group '{group_name}'\")\n\n        # Write to JSON if requested\n        if write_json:\n            # Make the output directory if it doesn't exist\n            Path(output_dir).mkdir(parents=True, exist_ok=True)\n            # Construct the JSON file name\n            json_name = f\"{group_name}{json_suffix}\"\n            # Join the output directory with the JSON file name\n            json_path = Path(output_dir) / json_name\n            try:\n                with open(json_path, \"w\") as f:\n                    json.dump(\n                        group_result,\n                        f,\n                        cls=NumpyArrayEncoder,\n                        ensure_ascii=False,\n                        indent=4,\n                    )\n                print(\n                    f\"Aggregated traits for group {group_name} saved to {str(json_path)}\"\n                )\n            except IOError as e:\n                print(f\"Error writing JSON file '{str(json_path)}': {e}\")\n\n        # Compute summary statistics\n        summary_stats = {}\n        for trait, trait_values in aggregated_traits.items():\n            trait_stats = get_summary(trait_values, prefix=f\"{trait}_\")\n            summary_stats.update(trait_stats)\n\n        group_result[\"summary_stats\"] = summary_stats\n\n        # Write summary stats to CSV if requested\n        if write_csv:\n            # Make the output directory if it doesn't exist\n            Path(output_dir).mkdir(parents=True, exist_ok=True)\n            # Construct the CSV file name\n            csv_name = f\"{group_name}{csv_suffix}\"\n            # Join the output directory with the CSV file name\n            csv_path = Path(output_dir) / csv_name\n            try:\n                summary_df = pd.DataFrame([summary_stats])\n                summary_df.insert(0, \"genotype\", group_name)\n                summary_df.to_csv(csv_path, index=False)\n                print(\n                    f\"Summary statistics for group {group_name} saved to {str(csv_path)}\"\n                )\n            except IOError as e:\n                print(f\"Failed to write CSV file '{str(csv_path)}': {e}\")\n\n        # Append the group result to the list of results\n        grouped_results.append(group_result)\n\n    return grouped_results\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_batch_traits","title":"compute_batch_traits","text":"<pre><code>compute_batch_traits(\n    plants: List[Series],\n    write_csv: bool = False,\n    csv_path: str = \"traits.csv\",\n) -&gt; DataFrame\n</code></pre> <p>Compute traits for a batch of plants.</p> <p>Parameters:</p> Name Type Description Default <code>plants</code> <code>List[Series]</code> <p>List of <code>Series</code> objects.</p> required <code>write_csv</code> <code>bool</code> <p>If <code>True</code>, write the computed traits to a CSV file.</p> <code>False</code> <code>csv_path</code> <code>str</code> <p>Path to write the CSV file to.</p> <code>'traits.csv'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame of computed traits summarized over all frames of each</p> <code>DataFrame</code> <p>plant. The resulting dataframe will have a row for each plant and a column</p> <code>DataFrame</code> <p>for each plant-level summarized trait.</p> <code>DataFrame</code> <p>Summarized traits are prefixed with the trait name and an underscore,</p> <code>DataFrame</code> <p>followed by the summary statistic.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_batch_traits(\n    self,\n    plants: List[Series],\n    write_csv: bool = False,\n    csv_path: str = \"traits.csv\",\n) -&gt; pd.DataFrame:\n    \"\"\"Compute traits for a batch of plants.\n\n    Args:\n        plants: List of `Series` objects.\n        write_csv: If `True`, write the computed traits to a CSV file.\n        csv_path: Path to write the CSV file to.\n\n    Returns:\n        A pandas DataFrame of computed traits summarized over all frames of each\n        plant. The resulting dataframe will have a row for each plant and a column\n        for each plant-level summarized trait.\n\n        Summarized traits are prefixed with the trait name and an underscore,\n        followed by the summary statistic.\n    \"\"\"\n    all_traits = []\n    for plant in plants:\n        print(f\"Processing series: {plant.series_name}\")\n        # Compute frame level traits for the plant.\n        plant_traits = self.compute_plant_traits(plant)\n\n        # Summarize frame level traits.\n        plant_summary = {\"plant_name\": plant.series_name}\n        for trait_name in self.csv_traits:\n            trait_summary = get_summary(\n                plant_traits[trait_name], prefix=f\"{trait_name}_\"\n            )\n            plant_summary.update(trait_summary)\n        all_traits.append(plant_summary)\n\n    # Build dataframe from list of frame-level summaries.\n    all_traits = pd.DataFrame(all_traits)\n\n    if write_csv:\n        all_traits.to_csv(csv_path, index=False)\n        print(f\"Batch traits saved to {csv_path}\")\n    return all_traits\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_batch_multiple_dicots_traits","title":"compute_batch_multiple_dicots_traits","text":"<pre><code>compute_batch_multiple_dicots_traits(\n    all_series: List[Series],\n    write_csv: bool = False,\n    csv_path: str = \"traits.csv\",\n) -&gt; DataFrame\n</code></pre> <p>Compute traits for a batch of series with multiple dicots.</p> <p>Parameters:</p> Name Type Description Default <code>all_series</code> <code>List[Series]</code> <p>List of <code>Series</code> objects.</p> required <code>write_csv</code> <code>bool</code> <p>If <code>True</code>, write the computed traits to a CSV file.</p> <code>False</code> <code>csv_path</code> <code>str</code> <p>Path to write the CSV file to.</p> <code>'traits.csv'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame of computed traits summarized over all frames of each</p> <code>DataFrame</code> <p>series. The resulting dataframe will have a row for each series and a column</p> <code>DataFrame</code> <p>for each series-level summarized trait.</p> <code>DataFrame</code> <p>Summarized traits are prefixed with the trait name and an underscore,</p> <code>DataFrame</code> <p>followed by the summary statistic.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_batch_multiple_dicots_traits(\n    self,\n    all_series: List[Series],\n    write_csv: bool = False,\n    csv_path: str = \"traits.csv\",\n) -&gt; pd.DataFrame:\n    \"\"\"Compute traits for a batch of series with multiple dicots.\n\n    Args:\n        all_series: List of `Series` objects.\n        write_csv: If `True`, write the computed traits to a CSV file.\n        csv_path: Path to write the CSV file to.\n\n    Returns:\n        A pandas DataFrame of computed traits summarized over all frames of each\n        series. The resulting dataframe will have a row for each series and a column\n        for each series-level summarized trait.\n\n        Summarized traits are prefixed with the trait name and an underscore,\n        followed by the summary statistic.\n    \"\"\"\n    all_series_summaries = []\n\n    for series in all_series:\n        print(f\"Processing series '{series.series_name}'\")\n        # Use the updated function and access its return value\n        series_result = self.compute_multiple_dicots_traits(\n            series, write_json=False, write_csv=False\n        )\n        # Prepare the series-level summary.\n        series_summary = {\n            \"series_name\": series_result[\"series\"],\n            **series_result[\"summary_stats\"],  # Unpack summary_stats\n        }\n        all_series_summaries.append(series_summary)\n\n    # Convert list of dictionaries to a DataFrame\n    all_series_summaries_df = pd.DataFrame(all_series_summaries)\n\n    # Write to CSV if requested\n    if write_csv:\n        all_series_summaries_df.to_csv(csv_path, index=False)\n        print(f\"Computed traits for all series saved to {csv_path}\")\n\n    return all_series_summaries_df\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_batch_multiple_dicots_traits_for_groups","title":"compute_batch_multiple_dicots_traits_for_groups","text":"<pre><code>compute_batch_multiple_dicots_traits_for_groups(\n    all_series: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    write_csv: bool = False,\n    csv_path: str = \"group_summarized_traits.csv\",\n) -&gt; DataFrame\n</code></pre> <p>Compute traits for a batch of grouped series with multiple dicots.</p> <p>Parameters:</p> Name Type Description Default <code>all_series</code> <code>List[Series]</code> <p>List of <code>Series</code> objects.</p> required <code>output_dir</code> <code>str</code> <p>The directory to write the JSON and CSV files to. Default is \"grouped_traits\".</p> <code>'grouped_traits'</code> <code>write_json</code> <code>bool</code> <p>If <code>True</code>, write each set of group traits to a JSON file.</p> <code>False</code> <code>write_csv</code> <code>bool</code> <p>If <code>True</code>, write the computed traits to a CSV file.</p> <code>False</code> <code>csv_path</code> <code>str</code> <p>Path to write the CSV file to.</p> <code>'group_summarized_traits.csv'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame of computed traits summarized over all frames of each</p> <code>DataFrame</code> <p>group. The resulting dataframe will have a row for each series and a column</p> <code>DataFrame</code> <p>for each series-level summarized trait.</p> <code>DataFrame</code> <p>Summarized traits are prefixed with the trait name and an underscore,</p> <code>DataFrame</code> <p>followed by the summary statistic.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_batch_multiple_dicots_traits_for_groups(\n    self,\n    all_series: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    write_csv: bool = False,\n    csv_path: str = \"group_summarized_traits.csv\",\n) -&gt; pd.DataFrame:\n    \"\"\"Compute traits for a batch of grouped series with multiple dicots.\n\n    Args:\n        all_series: List of `Series` objects.\n        output_dir: The directory to write the JSON and CSV files to. Default is \"grouped_traits\".\n        write_json: If `True`, write each set of group traits to a JSON file.\n        write_csv: If `True`, write the computed traits to a CSV file.\n        csv_path: Path to write the CSV file to.\n\n    Returns:\n        A pandas DataFrame of computed traits summarized over all frames of each\n        group. The resulting dataframe will have a row for each series and a column\n        for each series-level summarized trait.\n\n        Summarized traits are prefixed with the trait name and an underscore,\n        followed by the summary statistic.\n    \"\"\"\n    # Check if the input list is empty\n    if not all_series:\n        raise ValueError(\"The input list 'all_series' is empty.\")\n\n    try:\n        # Compute traits for each group of series\n        grouped_results = self.compute_multiple_dicots_traits_for_groups(\n            all_series,\n            output_dir=output_dir,\n            write_json=write_json,\n            write_csv=False,\n        )\n    except Exception as e:\n        raise RuntimeError(f\"Error computing traits for groups: {e}\")\n\n    # Prepare the list of dictionaries for the DataFrame\n    all_group_summaries = []\n    for group_result in grouped_results:\n        # Validate the expected key exists in the result\n        if \"summary_stats\" not in group_result:\n            raise KeyError(\n                \"Expected key 'summary_stats' not found in group result.\"\n            )\n\n        # Assuming 'group' key exists in group_result and it indicates the genotype\n        genotype = group_result.get(\n            \"group\", \"Unknown Genotype\"\n        )  # Default to \"Unknown Genotype\" if not found\n\n        # Start with a dictionary containing the genotype\n        group_summary = {\"genotype\": genotype}\n\n        # Add each trait statistic from the summary_stats dictionary to the group_summary\n        # This assumes summary_stats is a dictionary where keys are trait names and values are the statistics\n        for trait, statistic in group_result[\"summary_stats\"].items():\n            group_summary[trait] = statistic\n\n        all_group_summaries.append(group_summary)\n\n    # Create a DataFrame from the list of dictionaries\n    all_group_summaries_df = pd.DataFrame(all_group_summaries)\n\n    # Write to CSV if requested\n    if write_csv:\n        try:\n            all_group_summaries_df.to_csv(csv_path, index=False)\n            print(f\"Computed traits for all groups saved to {csv_path}\")\n        except Exception as e:\n            raise IOError(f\"Failed to write computed traits to CSV: {e}\")\n\n    return all_group_summaries_df\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_batch_multiple_primary_roots_traits","title":"compute_batch_multiple_primary_roots_traits","text":"<pre><code>compute_batch_multiple_primary_roots_traits(\n    all_series: List[Series],\n    write_csv: bool = False,\n    csv_path: str = \"traits.csv\",\n) -&gt; DataFrame\n</code></pre> <p>Compute traits for a batch of series with multiple primary roots.</p> <p>Parameters:</p> Name Type Description Default <code>all_series</code> <code>List[Series]</code> <p>List of <code>Series</code> objects.</p> required <code>write_csv</code> <code>bool</code> <p>If <code>True</code>, write the computed traits to a CSV file.</p> <code>False</code> <code>csv_path</code> <code>str</code> <p>Path to write the CSV file to.</p> <code>'traits.csv'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame of computed traits summarized over all frames of each</p> <code>DataFrame</code> <p>series. The resulting dataframe will have a row for each series and a column</p> <code>DataFrame</code> <p>for each series-level summarized trait.</p> <code>DataFrame</code> <p>Summarized traits are prefixed with the trait name and an underscore,</p> <code>DataFrame</code> <p>followed by the summary statistic.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_batch_multiple_primary_roots_traits(\n    self,\n    all_series: List[Series],\n    write_csv: bool = False,\n    csv_path: str = \"traits.csv\",\n) -&gt; pd.DataFrame:\n    \"\"\"Compute traits for a batch of series with multiple primary roots.\n\n    Args:\n        all_series: List of `Series` objects.\n        write_csv: If `True`, write the computed traits to a CSV file.\n        csv_path: Path to write the CSV file to.\n\n    Returns:\n        A pandas DataFrame of computed traits summarized over all frames of each\n        series. The resulting dataframe will have a row for each series and a column\n        for each series-level summarized trait.\n\n        Summarized traits are prefixed with the trait name and an underscore,\n        followed by the summary statistic.\n    \"\"\"\n    all_series_summaries = []\n\n    for series in all_series:\n        print(f\"Processing series '{series.series_name}'\")\n        # Use the updated function and access its return value\n        series_result = self.compute_multiple_primary_roots_traits(\n            series, write_json=False, write_csv=False\n        )\n        # Prepare the series-level summary.\n        series_summary = {\n            \"series_name\": series_result[\"series\"],\n            **series_result[\"summary_stats\"],  # Unpack summary_stats\n        }\n        all_series_summaries.append(series_summary)\n\n    # Convert list of dictionaries to a DataFrame\n    all_series_summaries_df = pd.DataFrame(all_series_summaries)\n\n    # Write to CSV if requested\n    if write_csv:\n        all_series_summaries_df.to_csv(csv_path, index=False)\n        print(f\"Computed traits for all series saved to {csv_path}\")\n\n    return all_series_summaries_df\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.Pipeline.compute_batch_multiple_primary_roots_traits_for_groups","title":"compute_batch_multiple_primary_roots_traits_for_groups","text":"<pre><code>compute_batch_multiple_primary_roots_traits_for_groups(\n    all_series: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    write_csv: bool = False,\n    csv_path: str = \"group_summarized_traits.csv\",\n) -&gt; DataFrame\n</code></pre> <p>Compute traits for a batch of grouped series with multiple primary roots.</p> <p>Parameters:</p> Name Type Description Default <code>all_series</code> <code>List[Series]</code> <p>List of <code>Series</code> objects.</p> required <code>output_dir</code> <code>str</code> <p>The directory to write the JSON and CSV files to. Default is \"grouped_traits\".</p> <code>'grouped_traits'</code> <code>write_json</code> <code>bool</code> <p>If <code>True</code>, write each set of group traits to a JSON file.</p> <code>False</code> <code>write_csv</code> <code>bool</code> <p>If <code>True</code>, write the computed traits to a CSV file.</p> <code>False</code> <code>csv_path</code> <code>str</code> <p>Path to write the CSV file to.</p> <code>'group_summarized_traits.csv'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame of computed traits summarized over all frames of each</p> <code>DataFrame</code> <p>group. The resulting dataframe will have a row for each series and a column</p> <code>DataFrame</code> <p>for each series-level summarized trait.</p> <code>DataFrame</code> <p>Summarized traits are prefixed with the trait name and an underscore,</p> <code>DataFrame</code> <p>followed by the summary statistic.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def compute_batch_multiple_primary_roots_traits_for_groups(\n    self,\n    all_series: List[Series],\n    output_dir: str = \"grouped_traits\",\n    write_json: bool = False,\n    write_csv: bool = False,\n    csv_path: str = \"group_summarized_traits.csv\",\n) -&gt; pd.DataFrame:\n    \"\"\"Compute traits for a batch of grouped series with multiple primary roots.\n\n    Args:\n        all_series: List of `Series` objects.\n        output_dir: The directory to write the JSON and CSV files to. Default is \"grouped_traits\".\n        write_json: If `True`, write each set of group traits to a JSON file.\n        write_csv: If `True`, write the computed traits to a CSV file.\n        csv_path: Path to write the CSV file to.\n\n    Returns:\n        A pandas DataFrame of computed traits summarized over all frames of each\n        group. The resulting dataframe will have a row for each series and a column\n        for each series-level summarized trait.\n\n        Summarized traits are prefixed with the trait name and an underscore,\n        followed by the summary statistic.\n    \"\"\"\n    # Check if the input list is empty\n    if not all_series:\n        raise ValueError(\"The input list 'all_series' is empty.\")\n\n    try:\n        # Compute traits for each group of series\n        grouped_results = self.compute_multiple_primary_roots_traits_for_groups(\n            all_series,\n            output_dir=output_dir,\n            write_json=write_json,\n            write_csv=False,\n        )\n    except Exception as e:\n        raise RuntimeError(f\"Error computing traits for groups: {e}\")\n\n    # Prepare the list of dictionaries for the DataFrame\n    all_group_summaries = []\n    for group_result in grouped_results:\n        # Validate the expected key exists in the result\n        if \"summary_stats\" not in group_result:\n            raise KeyError(\n                \"Expected key 'summary_stats' not found in group result.\"\n            )\n\n        # Assuming 'group' key exists in group_result and it indicates the genotype\n        genotype = group_result.get(\n            \"group\", \"Unknown Genotype\"\n        )  # Default to \"Unknown Genotype\" if not found\n\n        # Start with a dictionary containing the genotype\n        group_summary = {\"genotype\": genotype}\n\n        # Add each trait statistic from the summary_stats dictionary to the group_summary\n        # This assumes summary_stats is a dictionary where keys are trait names and values are the statistics\n        for trait, statistic in group_result[\"summary_stats\"].items():\n            group_summary[trait] = statistic\n\n        all_group_summaries.append(group_summary)\n\n    # Create a DataFrame from the list of dictionaries\n    all_group_summaries_df = pd.DataFrame(all_group_summaries)\n\n    # Write to CSV if requested\n    if write_csv:\n        try:\n            all_group_summaries_df.to_csv(csv_path, index=False)\n            print(f\"Computed traits for all groups saved to {csv_path}\")\n        except Exception as e:\n            raise IOError(f\"Failed to write computed traits to CSV: {e}\")\n\n    return all_group_summaries_df\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.DicotPipeline","title":"DicotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for dicot plants (primary + lateral roots).</p> <p>Attributes:</p> Name Type Description <code>img_height</code> <code>int</code> <p>Image height.</p> <code>root_width_tolerance</code> <code>float</code> <p>Difference in projection norm between right and left side.</p> <code>n_scanlines</code> <code>int</code> <p>Number of scan lines, np.nan for no interaction.</p> <code>network_fraction</code> <code>float</code> <p>Length found in the lower fraction value of the network.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.DicotPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for dicot plants.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for dicot plants.\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"primary_max_length_pts\",\n            fn=get_max_length_pts,\n            input_traits=[\"primary_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Points of the primary root with maximum length.\",\n        ),\n        TraitDef(\n            name=\"pts_all_array\",\n            fn=get_all_pts_array,\n            input_traits=[\"primary_max_length_pts\", \"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Landmark points within a given frame as a flat array\"\n            \"of coordinates.\",\n        ),\n        TraitDef(\n            name=\"pts_list\",\n            fn=join_pts,\n            input_traits=[\"primary_max_length_pts\", \"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"A list of instance arrays, each having shape `(nodes, 2)`.\",\n        ),\n        TraitDef(\n            name=\"root_widths\",\n            fn=get_root_widths,\n            input_traits=[\"primary_max_length_pts\", \"lateral_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\n                \"tolerance\": self.root_width_tolerance,\n                \"return_inds\": False,\n            },\n            description=\"Estimate root width using bases of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_count\",\n            fn=get_count,\n            input_traits=[\"lateral_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Get the number of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_proximal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_distal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_lengths\",\n            fn=get_root_lengths,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of lateral root lengths of shape `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_base_pts\",\n            fn=get_bases,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of lateral bases `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"lateral_tip_pts\",\n            fn=get_tips,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of lateral tips `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"scanline_intersection_counts\",\n            fn=count_scanline_intersections,\n            input_traits=[\"pts_list\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\n                \"height\": self.img_height,\n                \"n_line\": self.n_scanlines,\n            },\n            description=\"Array of intersections of each scanline `(n_scanlines,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_angles_distal\",\n            fn=get_root_angle,\n            input_traits=[\"lateral_pts\", \"lateral_distal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": False, \"base_ind\": 0},\n            description=\"Array of lateral distal angles in degrees `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_angles_proximal\",\n            fn=get_root_angle,\n            input_traits=[\"lateral_pts\", \"lateral_proximal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": True, \"base_ind\": 0},\n            description=\"Array of lateral proximal angles in degrees \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"network_solidity\",\n            fn=get_network_solidity,\n            input_traits=[\"network_length\", \"chull_area\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the total network length divided by the network\"\n            \"convex area.\",\n        ),\n        TraitDef(\n            name=\"ellipse\",\n            fn=fit_ellipse,\n            input_traits=[\"pts_all_array\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of (a, b, ratio) containing the semi-major axis \"\n            \"length, semi-minor axis length, and the ratio of the major to minor \"\n            \"lengths.\",\n        ),\n        TraitDef(\n            name=\"bounding_box\",\n            fn=get_bbox,\n            input_traits=[\"pts_all_array\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of four parameters in bounding box.\",\n        ),\n        TraitDef(\n            name=\"convex_hull\",\n            fn=get_convhull,\n            input_traits=[\"pts_all_array\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Convex hull of the points.\",\n        ),\n        TraitDef(\n            name=\"primary_proximal_node_ind\",\n            fn=get_node_ind,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of primary roots.\",\n        ),\n        TraitDef(\n            name=\"primary_angle_proximal\",\n            fn=get_root_angle,\n            input_traits=[\"primary_max_length_pts\", \"primary_proximal_node_ind\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\"proximal\": True, \"base_ind\": 0},\n            description=\"Array of primary proximal angles in degrees \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"primary_distal_node_ind\",\n            fn=get_node_ind,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of primary roots.\",\n        ),\n        TraitDef(\n            name=\"primary_angle_distal\",\n            fn=get_root_angle,\n            input_traits=[\"primary_max_length_pts\", \"primary_distal_node_ind\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\"proximal\": False, \"base_ind\": 0},\n            description=\"Array of primary distal angles in degrees `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"primary_length\",\n            fn=get_root_lengths,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of primary root length.\",\n        ),\n        TraitDef(\n            name=\"primary_base_pt\",\n            fn=get_bases,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary root base point.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt\",\n            fn=get_tips,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary root tip point.\",\n        ),\n        TraitDef(\n            name=\"network_length_lower\",\n            fn=get_network_distribution,\n            input_traits=[\"pts_list\", \"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\n                \"fraction\": self.network_fraction,\n            },\n            description=\"Scalar of the root network length in the lower fraction \"\n            \"of the plant.\",\n        ),\n        TraitDef(\n            name=\"lateral_base_xs\",\n            fn=get_base_xs,\n            input_traits=[\"lateral_base_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Get x coordinates of the base of each lateral root.\",\n        ),\n        TraitDef(\n            name=\"lateral_base_ys\",\n            fn=get_base_ys,\n            input_traits=[\"lateral_base_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the y-coordinates of lateral bases \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"base_ct_density\",\n            fn=get_base_ct_density,\n            input_traits=[\"primary_length\", \"lateral_base_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of base count density.\",\n        ),\n        TraitDef(\n            name=\"lateral_tip_xs\",\n            fn=get_tip_xs,\n            input_traits=[\"lateral_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the x-coordinates of lateral tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_tip_ys\",\n            fn=get_tip_ys,\n            input_traits=[\"lateral_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the y-coordinates of lateral tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"network_distribution_ratio\",\n            fn=get_network_distribution_ratio,\n            input_traits=[\"network_length\", \"network_length_lower\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of ratio of the root network length in the lower \"\n            \"fraction of the plant over all root length.\",\n        ),\n        TraitDef(\n            name=\"network_length\",\n            fn=get_network_length,\n            input_traits=[\"primary_length\", \"lateral_lengths\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of all roots network length.\",\n        ),\n        TraitDef(\n            name=\"primary_base_pt_y\",\n            fn=get_base_ys,\n            input_traits=[\"primary_base_pt\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Y-coordinate of the primary root base node.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt_y\",\n            fn=get_tip_ys,\n            input_traits=[\"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Y-coordinate of the primary root tip node.\",\n        ),\n        TraitDef(\n            name=\"ellipse_a\",\n            fn=get_ellipse_a,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of semi-major axis length.\",\n        ),\n        TraitDef(\n            name=\"ellipse_b\",\n            fn=get_ellipse_b,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of semi-minor axis length.\",\n        ),\n        TraitDef(\n            name=\"network_width_depth_ratio\",\n            fn=get_network_width_depth_ratio,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of bounding box width to depth ratio of root \"\n            \"network.\",\n        ),\n        TraitDef(\n            name=\"chull_perimeter\",\n            fn=get_chull_perimeter,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull perimeter.\",\n        ),\n        TraitDef(\n            name=\"chull_area\",\n            fn=get_chull_area,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull area.\",\n        ),\n        TraitDef(\n            name=\"chull_max_width\",\n            fn=get_chull_max_width,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull maximum width.\",\n        ),\n        TraitDef(\n            name=\"chull_max_height\",\n            fn=get_chull_max_height,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull maximum height.\",\n        ),\n        TraitDef(\n            name=\"chull_line_lengths\",\n            fn=get_chull_line_lengths,\n            input_traits=[\"convex_hull\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of line lengths connecting any two vertices on the\"\n            \"convex hull.\",\n        ),\n        TraitDef(\n            name=\"base_length\",\n            fn=get_base_length,\n            input_traits=[\"lateral_base_ys\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the distance between the top and deepest base\"\n            \"y-coordinates.\",\n        ),\n        TraitDef(\n            name=\"base_median_ratio\",\n            fn=get_base_median_ratio,\n            input_traits=[\"lateral_base_ys\", \"primary_tip_pt_y\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of base median ratio.\",\n        ),\n        TraitDef(\n            name=\"curve_index\",\n            fn=get_curve_index,\n            input_traits=[\"primary_length\", \"primary_base_tip_dist\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of primary root curvature index.\",\n        ),\n        TraitDef(\n            name=\"base_length_ratio\",\n            fn=get_base_length_ratio,\n            input_traits=[\"primary_length\", \"base_length\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of base length ratio.\",\n        ),\n        TraitDef(\n            name=\"primary_base_tip_dist\",\n            fn=get_base_tip_dist,\n            input_traits=[\"primary_base_pt\", \"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of distance from primary root base to tip.\",\n        ),\n        TraitDef(\n            name=\"ellipse_ratio\",\n            fn=get_ellipse_ratio,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of ratio of the minor to major lengths.\",\n        ),\n        TraitDef(\n            name=\"scanline_last_ind\",\n            fn=get_scanline_last_ind,\n            input_traits=[\"scanline_intersection_counts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of count_scanline_interaction index for the last\"\n            \"interaction.\",\n        ),\n        TraitDef(\n            name=\"scanline_first_ind\",\n            fn=get_scanline_first_ind,\n            input_traits=[\"scanline_intersection_counts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of count_scanline_interaction index for the first\"\n            \"interaction.\",\n        ),\n    ]\n\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.DicotPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with keys: - \"primary_pts\": Array of primary root points. - \"lateral_pts\": Array of lateral root points.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with keys:\n            - \"primary_pts\": Array of primary root points.\n            - \"lateral_pts\": Array of lateral root points.\n    \"\"\"\n    primary_pts = plant.get_primary_points(frame_idx)\n    lateral_pts = plant.get_lateral_points(frame_idx)\n    return {\"primary_pts\": primary_pts, \"lateral_pts\": lateral_pts}\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.YoungerMonocotPipeline","title":"YoungerMonocotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for young monocot plants (primary + crown roots).</p> <p>Attributes:</p> Name Type Description <code>img_height</code> <code>int</code> <p>Image height.</p> <code>n_scanlines</code> <code>int</code> <p>Number of scan lines, np.nan for no interaction.</p> <code>network_fraction</code> <code>float</code> <p>Lower fraction value. Defaults to 2/3.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.YoungerMonocotPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for younger monocot plants.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for younger monocot plants.\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"primary_max_length_pts\",\n            fn=get_max_length_pts,\n            input_traits=[\"primary_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Points of the primary root with maximum length.\",\n        ),\n        TraitDef(\n            name=\"pts_all_array\",\n            fn=get_all_pts_array,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Crown root points within a given frame as a flat array\"\n            \"of coordinates.\",\n        ),\n        TraitDef(\n            name=\"crown_count\",\n            fn=get_count,\n            input_traits=[\"crown_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Get the number of crown roots.\",\n        ),\n        TraitDef(\n            name=\"crown_proximal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of crown roots.\",\n        ),\n        TraitDef(\n            name=\"crown_distal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of crown roots.\",\n        ),\n        TraitDef(\n            name=\"crown_lengths\",\n            fn=get_root_lengths,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of crown root lengths of shape `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_base_pts\",\n            fn=get_bases,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of crown bases `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"crown_tip_pts\",\n            fn=get_tips,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of crown tips `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"scanline_intersection_counts\",\n            fn=count_scanline_intersections,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\n                \"height\": self.img_height,\n                \"n_line\": self.n_scanlines,\n            },\n            description=\"Array of intersections of each scanline\"\n            \"`(n_scanlines,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_angles_distal\",\n            fn=get_root_angle,\n            input_traits=[\"crown_pts\", \"crown_distal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": False, \"base_ind\": 0},\n            description=\"Array of crown distal angles in degrees `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_angles_proximal\",\n            fn=get_root_angle,\n            input_traits=[\"crown_pts\", \"crown_proximal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": True, \"base_ind\": 0},\n            description=\"Array of crown proximal angles in degrees \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"network_length_lower\",\n            fn=get_network_distribution,\n            input_traits=[\n                \"crown_pts\",\n                \"bounding_box\",\n            ],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\n                \"fraction\": self.network_fraction,\n            },\n            description=\"Scalar of the root network length in the lower fraction \"\n            \"of the plant.\",\n        ),\n        TraitDef(\n            name=\"ellipse\",\n            fn=fit_ellipse,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of (a, b, ratio) containing the semi-major axis \"\n            \"length, semi-minor axis length, and the ratio of the major to minor \"\n            \"lengths.\",\n        ),\n        TraitDef(\n            name=\"bounding_box\",\n            fn=get_bbox,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of four parameters in bounding box.\",\n        ),\n        TraitDef(\n            name=\"convex_hull\",\n            fn=get_convhull,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Convex hull of the points.\",\n        ),\n        TraitDef(\n            name=\"primary_proximal_node_ind\",\n            fn=get_node_ind,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of primary roots.\",\n        ),\n        TraitDef(\n            name=\"primary_angle_proximal\",\n            fn=get_root_angle,\n            input_traits=[\n                \"primary_max_length_pts\",\n                \"primary_proximal_node_ind\",\n            ],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\"proximal\": True, \"base_ind\": 0},\n            description=\"Array of primary proximal angles in degrees \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"primary_distal_node_ind\",\n            fn=get_node_ind,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of primary roots.\",\n        ),\n        TraitDef(\n            name=\"primary_angle_distal\",\n            fn=get_root_angle,\n            input_traits=[\"primary_max_length_pts\", \"primary_distal_node_ind\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\"proximal\": False, \"base_ind\": 0},\n            description=\"Array of primary distal angles in degrees `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"primary_length\",\n            fn=get_root_lengths,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of primary root length.\",\n        ),\n        TraitDef(\n            name=\"primary_base_pt\",\n            fn=get_bases,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary root base point.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt\",\n            fn=get_tips,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary root tip point.\",\n        ),\n        TraitDef(\n            name=\"crown_tip_xs\",\n            fn=get_tip_xs,\n            input_traits=[\"crown_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the x-coordinates of crown tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_tip_ys\",\n            fn=get_tip_ys,\n            input_traits=[\"crown_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the y-coordinates of crown tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"network_distribution_ratio\",\n            fn=get_network_distribution_ratio,\n            input_traits=[\n                \"network_length\",\n                \"network_length_lower\",\n            ],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of ratio of the root network length in the lower\"\n            \"fraction of the plant over all root length.\",\n        ),\n        TraitDef(\n            name=\"network_length\",\n            fn=get_network_length,\n            input_traits=[\"crown_lengths\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of all roots network length.\",\n        ),\n        TraitDef(\n            name=\"crown_base_tip_dists\",\n            fn=get_base_tip_dist,\n            input_traits=[\"crown_base_pts\", \"crown_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Straight-line distance(s) from the base(s) to the\"\n            \"tip(s) of the crown root(s).\",\n        ),\n        TraitDef(\n            name=\"crown_curve_indices\",\n            fn=get_curve_index,\n            input_traits=[\"crown_lengths\", \"crown_base_tip_dists\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Curvature index for each crown root.\",\n        ),\n        TraitDef(\n            name=\"network_solidity\",\n            fn=get_network_solidity,\n            input_traits=[\"network_length\", \"chull_area\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the total network length divided by the\"\n            \"network convex hull area.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt_y\",\n            fn=get_tip_ys,\n            input_traits=[\"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Y-coordinate of the primary root tip node.\",\n        ),\n        TraitDef(\n            name=\"ellipse_a\",\n            fn=get_ellipse_a,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of semi-major axis length.\",\n        ),\n        TraitDef(\n            name=\"ellipse_b\",\n            fn=get_ellipse_b,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of semi-minor axis length.\",\n        ),\n        TraitDef(\n            name=\"network_width_depth_ratio\",\n            fn=get_network_width_depth_ratio,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of bounding box width to depth ratio of root \"\n            \"network.\",\n        ),\n        TraitDef(\n            name=\"chull_perimeter\",\n            fn=get_chull_perimeter,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull perimeter.\",\n        ),\n        TraitDef(\n            name=\"chull_area\",\n            fn=get_chull_area,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull area.\",\n        ),\n        TraitDef(\n            name=\"chull_max_width\",\n            fn=get_chull_max_width,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull maximum width.\",\n        ),\n        TraitDef(\n            name=\"chull_max_height\",\n            fn=get_chull_max_height,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull maximum height.\",\n        ),\n        TraitDef(\n            name=\"chull_line_lengths\",\n            fn=get_chull_line_lengths,\n            input_traits=[\"convex_hull\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of line lengths connecting any two vertices on the\"\n            \"convex hull.\",\n        ),\n        TraitDef(\n            name=\"curve_index\",\n            fn=get_curve_index,\n            input_traits=[\"primary_length\", \"primary_base_tip_dist\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of primary root curvature index.\",\n        ),\n        TraitDef(\n            name=\"primary_base_tip_dist\",\n            fn=get_base_tip_dist,\n            input_traits=[\"primary_base_pt\", \"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of distance from primary root base to tip.\",\n        ),\n        TraitDef(\n            name=\"ellipse_ratio\",\n            fn=get_ellipse_ratio,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of ratio of the minor to major lengths.\",\n        ),\n        TraitDef(\n            name=\"scanline_last_ind\",\n            fn=get_scanline_last_ind,\n            input_traits=[\"scanline_intersection_counts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of count_scanline_interaction index for the last\"\n            \"interaction.\",\n        ),\n        TraitDef(\n            name=\"scanline_first_ind\",\n            fn=get_scanline_first_ind,\n            input_traits=[\"scanline_intersection_counts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of count_scanline_interaction index for the first\"\n            \"interaction.\",\n        ),\n    ]\n\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.YoungerMonocotPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with keys: - \"primary_pts\": Array of primary root points. - \"crown_pts\": Array of crown root points.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with keys:\n            - \"primary_pts\": Array of primary root points.\n            - \"crown_pts\": Array of crown root points.\n    \"\"\"\n    primary_pts = plant.get_primary_points(frame_idx)\n    crown_pts = plant.get_crown_points(frame_idx)\n    return {\"primary_pts\": primary_pts, \"crown_pts\": crown_pts}\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.OlderMonocotPipeline","title":"OlderMonocotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for older monocot plants (crown roots only).</p> <p>Attributes:</p> Name Type Description <code>img_height</code> <code>int</code> <p>Image height.</p> <code>n_scanlines</code> <code>int</code> <p>Number of scan lines, np.nan for no interaction.</p> <code>network_fraction</code> <code>float</code> <p>Lower fraction value. Defaults to 2/3.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.OlderMonocotPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for older monocot plants (crown roots).</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for older monocot plants (crown roots).\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"pts_all_array\",\n            fn=get_all_pts_array,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Landmark points within a given frame as a flat array\"\n            \"of coordinates.\",\n        ),\n        TraitDef(\n            name=\"crown_count\",\n            fn=get_count,\n            input_traits=[\"crown_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Get the number of crown roots.\",\n        ),\n        TraitDef(\n            name=\"crown_proximal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of crown roots.\",\n        ),\n        TraitDef(\n            name=\"crown_distal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of crown roots.\",\n        ),\n        TraitDef(\n            name=\"crown_lengths\",\n            fn=get_root_lengths,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of crown root lengths of shape `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_base_pts\",\n            fn=get_bases,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of crown bases `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"crown_tip_pts\",\n            fn=get_tips,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of crown tips `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"scanline_intersection_counts\",\n            fn=count_scanline_intersections,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\n                \"height\": self.img_height,\n                \"n_line\": self.n_scanlines,\n            },\n            description=\"Array of intersections of each scanline\"\n            \"`(n_scanlines,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_angles_distal\",\n            fn=get_root_angle,\n            input_traits=[\"crown_pts\", \"crown_distal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": False, \"base_ind\": 0},\n            description=\"Array of crown distal angles in degrees `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_angles_proximal\",\n            fn=get_root_angle,\n            input_traits=[\"crown_pts\", \"crown_proximal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": True, \"base_ind\": 0},\n            description=\"Array of crown proximal angles in degrees \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"network_length_lower\",\n            fn=get_network_distribution,\n            input_traits=[\n                \"crown_pts\",\n                \"bounding_box\",\n            ],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={\n                \"fraction\": self.network_fraction,\n            },\n            description=\"Scalar of the root network length in the lower fraction \"\n            \"of the plant.\",\n        ),\n        TraitDef(\n            name=\"ellipse\",\n            fn=fit_ellipse,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of (a, b, ratio) containing the semi-major axis \"\n            \"length, semi-minor axis length, and the ratio of the major to minor \"\n            \"lengths.\",\n        ),\n        TraitDef(\n            name=\"bounding_box\",\n            fn=get_bbox,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of four parameters representing bounding box.\",\n        ),\n        TraitDef(\n            name=\"convex_hull\",\n            fn=get_convhull,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Convex hull of the crown points.\",\n        ),\n        TraitDef(\n            name=\"crown_tip_xs\",\n            fn=get_tip_xs,\n            input_traits=[\"crown_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the x-coordinates of crown tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"crown_tip_ys\",\n            fn=get_tip_ys,\n            input_traits=[\"crown_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the y-coordinates of crown tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"network_distribution_ratio\",\n            fn=get_network_distribution_ratio,\n            input_traits=[\n                \"network_length\",\n                \"network_length_lower\",\n            ],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of ratio of the root network length in the lower\"\n            \"fraction of the plant over all root length.\",\n        ),\n        TraitDef(\n            name=\"network_length\",\n            fn=get_network_length,\n            input_traits=[\"crown_lengths\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of all roots network length.\",\n        ),\n        TraitDef(\n            name=\"crown_base_tip_dists\",\n            fn=get_base_tip_dist,\n            input_traits=[\"crown_base_pts\", \"crown_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Straight-line distance(s) from the base(s) to the\"\n            \"tip(s) of the crown root(s).\",\n        ),\n        TraitDef(\n            name=\"crown_curve_indices\",\n            fn=get_curve_index,\n            input_traits=[\"crown_lengths\", \"crown_base_tip_dists\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Curvature index for each crown root.\",\n        ),\n        TraitDef(\n            name=\"network_solidity\",\n            fn=get_network_solidity,\n            input_traits=[\"network_length\", \"chull_area\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the total network length divided by the\"\n            \"network convex hull area.\",\n        ),\n        TraitDef(\n            name=\"ellipse_a\",\n            fn=get_ellipse_a,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of semi-major axis length.\",\n        ),\n        TraitDef(\n            name=\"ellipse_b\",\n            fn=get_ellipse_b,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of semi-minor axis length.\",\n        ),\n        TraitDef(\n            name=\"network_width_depth_ratio\",\n            fn=get_network_width_depth_ratio,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of bounding box width to depth ratio of root \"\n            \"network.\",\n        ),\n        TraitDef(\n            name=\"chull_perimeter\",\n            fn=get_chull_perimeter,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull perimeter.\",\n        ),\n        TraitDef(\n            name=\"chull_area\",\n            fn=get_chull_area,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull area.\",\n        ),\n        TraitDef(\n            name=\"chull_max_width\",\n            fn=get_chull_max_width,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull maximum width.\",\n        ),\n        TraitDef(\n            name=\"chull_max_height\",\n            fn=get_chull_max_height,\n            input_traits=[\"convex_hull\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of convex hull maximum height.\",\n        ),\n        TraitDef(\n            name=\"chull_line_lengths\",\n            fn=get_chull_line_lengths,\n            input_traits=[\"convex_hull\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of line lengths connecting any two vertices on the\"\n            \"convex hull.\",\n        ),\n        TraitDef(\n            name=\"ellipse_ratio\",\n            fn=get_ellipse_ratio,\n            input_traits=[\"ellipse\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of ratio of the minor to major lengths.\",\n        ),\n        TraitDef(\n            name=\"scanline_last_ind\",\n            fn=get_scanline_last_ind,\n            input_traits=[\"scanline_intersection_counts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of count_scanline_interaction index for the last\"\n            \"interaction.\",\n        ),\n        TraitDef(\n            name=\"scanline_first_ind\",\n            fn=get_scanline_first_ind,\n            input_traits=[\"scanline_intersection_counts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of count_scanline_interaction index for the first\"\n            \"interaction.\",\n        ),\n        TraitDef(\n            name=\"crown_r1_pts\",\n            fn=get_nodes,\n            input_traits=[\"crown_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"node_index\": 1},\n            description=\"Array of crown bases `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"chull_r1_intersection_vectors\",\n            fn=get_chull_intersection_vectors,\n            input_traits=[\n                \"crown_base_pts\",\n                \"crown_r1_pts\",\n                \"crown_pts\",\n                \"convex_hull\",\n            ],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"A tuple containing vectors from the top left point to the\"\n            \"left intersection point, and from the top right point to the right\"\n            \"intersection point with the convex hull.\",\n        ),\n        TraitDef(\n            name=\"chull_r1_left_intersection_vector\",\n            fn=get_chull_intersection_vectors_left,\n            input_traits=[\"chull_r1_intersection_vectors\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Vector from the base point to the left\"\n            \"intersection point with the convex hull.\",\n        ),\n        TraitDef(\n            name=\"chull_r1_right_intersection_vector\",\n            fn=get_chull_intersection_vectors_right,\n            input_traits=[\"chull_r1_intersection_vectors\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Vector from the base point to the right\"\n            \"intersection point with the convex hull.\",\n        ),\n        TraitDef(\n            name=\"angle_chull_r1_left_intersection_vector\",\n            fn=get_vector_angles_from_gravity,\n            input_traits=[\"chull_r1_left_intersection_vector\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Angle of the left intersection vector from gravity.\",\n        ),\n        TraitDef(\n            name=\"angle_chull_r1_right_intersection_vector\",\n            fn=get_vector_angles_from_gravity,\n            input_traits=[\"chull_r1_right_intersection_vector\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Angle of the right intersection vector from gravity.\",\n        ),\n        TraitDef(\n            name=\"chull_areas_r1_intersection\",\n            fn=get_chull_areas_via_intersection,\n            input_traits=[\"crown_r1_pts\", \"crown_pts\", \"convex_hull\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of the convex hull areas above and below the r1\"\n            \"intersection.\",\n        ),\n        TraitDef(\n            name=\"chull_area_above_r1_intersection\",\n            fn=get_chull_area_via_intersection_above,\n            input_traits=[\"chull_areas_r1_intersection\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the convex hull area above the r1 intersection.\",\n        ),\n        TraitDef(\n            name=\"chull_area_below_r1_intersection\",\n            fn=get_chull_area_via_intersection_below,\n            input_traits=[\"chull_areas_r1_intersection\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the convex hull area below the r1 intersection.\",\n        ),\n    ]\n\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.OlderMonocotPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with keys: - \"crown_pts\": Array of crown root points.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with keys:\n            - \"crown_pts\": Array of crown root points.\n    \"\"\"\n    crown_pts = plant.get_crown_points(frame_idx)\n    return {\"crown_pts\": crown_pts}\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.MultipleDicotPipeline","title":"MultipleDicotPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for multiple dicot plants.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.MultipleDicotPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for primary roots.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for primary roots.\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"primary_pts_no_nans\",\n            fn=filter_roots_with_nans,\n            input_traits=[\"primary_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary roots without any NaNs.\",\n        ),\n        TraitDef(\n            name=\"lateral_pts_no_nans\",\n            fn=filter_roots_with_nans,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Lateral roots without any NaNs.\",\n        ),\n        TraitDef(\n            name=\"filtered_pts_expected_plant_ct\",\n            fn=filter_plants_with_unexpected_ct,\n            input_traits=[\n                \"primary_pts_no_nans\",\n                \"lateral_pts_no_nans\",\n                \"expected_plant_ct\",\n            ],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of filtered points with expected plant count.\",\n        ),\n        TraitDef(\n            name=\"primary_pts_expected_plant_ct\",\n            fn=get_filtered_primary_pts,\n            input_traits=[\"filtered_pts_expected_plant_ct\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Filtered primary root points with expected plant count.\",\n        ),\n        TraitDef(\n            name=\"lateral_pts_expected_plant_ct\",\n            fn=get_filtered_lateral_pts,\n            input_traits=[\"filtered_pts_expected_plant_ct\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Filtered lateral root points with expected plant count.\",\n        ),\n        TraitDef(\n            name=\"plant_associations_dict\",\n            fn=associate_lateral_to_primary,\n            input_traits=[\n                \"primary_pts_expected_plant_ct\",\n                \"lateral_pts_expected_plant_ct\",\n            ],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Dictionary of plant associations.\",\n        ),\n    ]\n\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.MultipleDicotPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with keys: - \"primary_pts\": Array of primary root points. - \"lateral_pts\": Array of lateral root points. - \"expected_ct\": Expected number of plants as a float.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with keys:\n            - \"primary_pts\": Array of primary root points.\n            - \"lateral_pts\": Array of lateral root points.\n            - \"expected_ct\": Expected number of plants as a float.\n    \"\"\"\n    primary_pts = plant.get_primary_points(frame_idx)\n    lateral_pts = plant.get_lateral_points(frame_idx)\n    expected_plant_ct = plant.expected_count\n    return {\n        \"primary_pts\": primary_pts,\n        \"lateral_pts\": lateral_pts,\n        \"expected_plant_ct\": expected_plant_ct,\n    }\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.PrimaryRootPipeline","title":"PrimaryRootPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for a single primary root.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.PrimaryRootPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for primary roots.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for primary roots.\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"primary_max_length_pts\",\n            fn=get_max_length_pts,\n            input_traits=[\"primary_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Points of the primary root with maximum length.\",\n        ),\n        TraitDef(\n            name=\"primary_proximal_node_ind\",\n            fn=get_node_ind,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of primary root.\",\n        ),\n        TraitDef(\n            name=\"primary_distal_node_ind\",\n            fn=get_node_ind,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of primary roots.\",\n        ),\n        TraitDef(\n            name=\"primary_angle_proximal\",\n            fn=get_root_angle,\n            input_traits=[\"primary_max_length_pts\", \"primary_proximal_node_ind\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the primary proximal angle in degrees.\",\n        ),\n        TraitDef(\n            name=\"primary_angle_distal\",\n            fn=get_root_angle,\n            input_traits=[\"primary_max_length_pts\", \"primary_distal_node_ind\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the primary distal angle in degrees.\",\n        ),\n        TraitDef(\n            name=\"primary_length\",\n            fn=get_root_lengths,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the primary root length.\",\n        ),\n        TraitDef(\n            name=\"primary_base_pt\",\n            fn=get_bases,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary root base point.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt\",\n            fn=get_tips,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Primary root tip point.\",\n        ),\n        TraitDef(\n            name=\"primary_base_pt_x\",\n            fn=get_base_xs,\n            input_traits=[\"primary_base_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"X-coordinate of the primary root base node.\",\n        ),\n        TraitDef(\n            name=\"primary_base_pt_y\",\n            fn=get_base_ys,\n            input_traits=[\"primary_base_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Y-coordinate of the primary root base node.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt_x\",\n            fn=get_tip_xs,\n            input_traits=[\"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"X-coordinate of the primary root tip node.\",\n        ),\n        TraitDef(\n            name=\"primary_tip_pt_y\",\n            fn=get_tip_ys,\n            input_traits=[\"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Y-coordinate of the primary root tip node.\",\n        ),\n        TraitDef(\n            name=\"primary_base_tip_dist\",\n            fn=get_base_tip_dist,\n            input_traits=[\"primary_base_pt\", \"primary_tip_pt\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of distance from primary root base to tip.\",\n        ),\n        TraitDef(\n            name=\"curve_index\",\n            fn=get_curve_index,\n            input_traits=[\"primary_length\", \"primary_base_tip_dist\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the primary root curvature index.\",\n        ),\n        TraitDef(\n            name=\"bounding_box\",\n            fn=get_bbox,\n            input_traits=[\"primary_max_length_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Tuple of four parameters in bounding box.\",\n        ),\n        TraitDef(\n            name=\"bounding_box_left_x\",\n            fn=get_bbox_left_x,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the left x-axis value of the bounding box.\",\n        ),\n        TraitDef(\n            name=\"bounding_box_top_y\",\n            fn=get_bbox_top_y,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the y-axis value of top side of the bounding box.\",\n        ),\n        TraitDef(\n            name=\"bounding_box_width\",\n            fn=get_bbox_width,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the width of the bounding box.\",\n        ),\n        TraitDef(\n            name=\"bounding_box_height\",\n            fn=get_bbox_height,\n            input_traits=[\"bounding_box\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of the height of the bounding box.\",\n        ),\n    ]\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.PrimaryRootPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>Args</code> required <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with key: - \"primary_pts\": Array of primary root points.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with key:\n            - \"primary_pts\": Array of primary root points.\n    \"\"\"\n    primary_pts = plant.get_primary_points(frame_idx)\n    return {\"primary_pts\": primary_pts}\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.MultiplePrimaryRootPipeline","title":"MultiplePrimaryRootPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline for computing traits for multiple primary roots.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.MultiplePrimaryRootPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for primary roots.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for primary roots.\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"filtered_primary_pts_with_expected_ct\",\n            fn=filter_primary_roots_with_unexpected_count,\n            input_traits=[\"primary_pts\", \"expected_plant_ct\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Filtered points of the primary root with expected count.\",\n        )\n    ]\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.MultiplePrimaryRootPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>Args</code> required <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with key: - \"primary_pts\": Array of primary root points.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with key:\n            - \"primary_pts\": Array of primary root points.\n    \"\"\"\n    primary_pts = plant.get_primary_points(frame_idx)\n    expected_plant_count = plant.expected_count\n\n    return {\"primary_pts\": primary_pts, \"expected_plant_ct\": expected_plant_count}\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.LateralRootPipeline","title":"LateralRootPipeline","text":"<p>               Bases: <code>Pipeline</code></p> <p>Pipeline just for computing traits for lateral roots.</p>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.LateralRootPipeline.define_traits","title":"define_traits","text":"<pre><code>define_traits() -&gt; List[TraitDef]\n</code></pre> <p>Define the trait computation pipeline for dicot plants.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def define_traits(self) -&gt; List[TraitDef]:\n    \"\"\"Define the trait computation pipeline for dicot plants.\"\"\"\n    trait_definitions = [\n        TraitDef(\n            name=\"lateral_count\",\n            fn=get_count,\n            input_traits=[\"lateral_pts\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Get the number of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_proximal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": True},\n            description=\"Get the indices of the proximal nodes of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_distal_node_inds\",\n            fn=get_node_ind,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={\"proximal\": False},\n            description=\"Get the indices of the distal nodes of lateral roots.\",\n        ),\n        TraitDef(\n            name=\"lateral_lengths\",\n            fn=get_root_lengths,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of lateral root lengths of shape `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"total_lateral_length\",\n            fn=get_network_length,\n            input_traits=[\"lateral_lengths\"],\n            scalar=True,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Scalar of all lateral root network length.\",\n        ),\n        TraitDef(\n            name=\"lateral_base_pts\",\n            fn=get_bases,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of lateral bases `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"lateral_tip_pts\",\n            fn=get_tips,\n            input_traits=[\"lateral_pts\"],\n            scalar=False,\n            include_in_csv=False,\n            kwargs={},\n            description=\"Array of lateral tips `(instances, (x, y))`.\",\n        ),\n        TraitDef(\n            name=\"lateral_angles_distal\",\n            fn=get_root_angle,\n            input_traits=[\"lateral_pts\", \"lateral_distal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": False, \"base_ind\": 0},\n            description=\"Array of lateral distal angles in degrees `(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_angles_proximal\",\n            fn=get_root_angle,\n            input_traits=[\"lateral_pts\", \"lateral_proximal_node_inds\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={\"proximal\": True, \"base_ind\": 0},\n            description=\"Array of lateral proximal angles in degrees \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_base_xs\",\n            fn=get_base_xs,\n            input_traits=[\"lateral_base_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Get x coordinates of the base of each lateral root.\",\n        ),\n        TraitDef(\n            name=\"lateral_base_ys\",\n            fn=get_base_ys,\n            input_traits=[\"lateral_base_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the y-coordinates of lateral bases \"\n            \"`(instances,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_tip_xs\",\n            fn=get_tip_xs,\n            input_traits=[\"lateral_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the x-coordinates of lateral tips `(instance,)`.\",\n        ),\n        TraitDef(\n            name=\"lateral_tip_ys\",\n            fn=get_tip_ys,\n            input_traits=[\"lateral_tip_pts\"],\n            scalar=False,\n            include_in_csv=True,\n            kwargs={},\n            description=\"Array of the y-coordinates of lateral tips `(instance,)`.\",\n        ),\n    ]\n    return trait_definitions\n</code></pre>"},{"location":"reference/sleap_roots/trait_pipelines/#sleap_roots.trait_pipelines.LateralRootPipeline.get_initial_frame_traits","title":"get_initial_frame_traits","text":"<pre><code>get_initial_frame_traits(\n    plant: Series, frame_idx: int\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return initial traits for a plant frame.</p> <p>Parameters:</p> Name Type Description Default <code>plant</code> <code>Series</code> <p>The plant <code>Series</code> object.</p> required <code>frame_idx</code> <code>int</code> <p>The index of the current frame.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of initial traits with keys: - \"lateral_pts\": Array of lateral root points.</p> Source code in <code>sleap_roots/trait_pipelines.py</code> <pre><code>def get_initial_frame_traits(self, plant: Series, frame_idx: int) -&gt; Dict[str, Any]:\n    \"\"\"Return initial traits for a plant frame.\n\n    Args:\n        plant: The plant `Series` object.\n        frame_idx: The index of the current frame.\n\n    Returns:\n        A dictionary of initial traits with keys:\n            - \"lateral_pts\": Array of lateral root points.\n    \"\"\"\n    lateral_pts = plant.get_lateral_points(frame_idx)\n    return {\"lateral_pts\": lateral_pts}\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Welcome to the sleap-roots tutorials! These interactive Jupyter notebooks provide hands-on walkthroughs of analyzing plant root systems with different pipeline types.</p>"},{"location":"tutorials/#overview","title":"Overview","text":"<p>Each tutorial demonstrates a complete analysis workflow from loading SLEAP predictions to computing and exporting morphological traits. The notebooks include:</p> <ul> <li>Step-by-step code examples</li> <li>Visualization of intermediate results</li> <li>Trait computation and interpretation</li> <li>Export to CSV for downstream analysis</li> </ul>"},{"location":"tutorials/#available-tutorials","title":"Available Tutorials","text":""},{"location":"tutorials/#primary-pipelines","title":"Primary Pipelines","text":"<ul> <li> <p> Dicot Pipeline</p> <p>Analyze dicot root systems with primary and lateral roots (soy, canola, arabidopsis).</p> <p> Tutorial</p> </li> <li> <p> Younger Monocot Pipeline</p> <p>Process early-stage monocots with primary and crown roots (rice, maize).</p> <p> Tutorial</p> </li> <li> <p> Older Monocot Pipeline</p> <p>Analyze mature monocots with crown roots only (rice, maize).</p> <p> Tutorial</p> </li> </ul>"},{"location":"tutorials/#multi-plant-pipelines","title":"Multi-Plant Pipelines","text":"<ul> <li> <p> Multiple Dicot Pipeline</p> <p>Batch process multiple dicot plants in a single image.</p> <p> Tutorial</p> </li> <li> <p> Multiple Primary Root Pipeline</p> <p>Analyze multiple plants with primary roots.</p> <p> Tutorial</p> </li> </ul>"},{"location":"tutorials/#specialized-pipelines","title":"Specialized Pipelines","text":"<ul> <li> <p> Primary Root Pipeline</p> <p>Focus on primary root traits only.</p> <p> Tutorial</p> </li> <li> <p> Lateral Root Pipeline</p> <p>Specialized analysis for lateral root systems.</p> <p> Tutorial</p> </li> </ul>"},{"location":"tutorials/#how-to-use-these-tutorials","title":"How to Use These Tutorials","text":""},{"location":"tutorials/#option-1-view-online","title":"Option 1: View Online","text":"<p>All tutorials are rendered directly in the documentation. You can read through them and copy code snippets as needed.</p>"},{"location":"tutorials/#option-2-run-interactively","title":"Option 2: Run Interactively","text":"<p>To run the notebooks yourself:</p> <ol> <li> <p>Clone the sleap-roots repository:    <pre><code>git clone https://github.com/talmolab/sleap-roots.git\ncd sleap-roots\n</code></pre></p> </li> <li> <p>Install with dev dependencies:    <pre><code>pip install -e \".[dev]\"\n</code></pre></p> </li> <li> <p>Launch Jupyter:    <pre><code>jupyter notebook notebooks/\n</code></pre></p> </li> <li> <p>Open any tutorial notebook and run the cells.</p> </li> </ol>"},{"location":"tutorials/#data-requirements","title":"Data Requirements","text":"<p>The tutorials use example data included in the repository's test fixtures. To use your own data:</p> <ul> <li>Replace file paths with your SLEAP prediction files (<code>.h5</code>, <code>.slp</code>)</li> <li>Ensure your SLEAP models match the expected node structure for each pipeline</li> <li>See Data Formats for details</li> </ul>"},{"location":"tutorials/#troubleshooting","title":"Troubleshooting","text":"<p>Notebook won't run: - Ensure you've installed sleap-roots: <code>pip install sleap-roots</code> - Check that Git LFS data is downloaded: <code>git lfs pull</code></p> <p>Missing data files: - The example data is stored with Git LFS - Run <code>git lfs install &amp;&amp; git lfs pull</code> to download</p> <p>Trait values look wrong: - Verify your SLEAP predictions use the correct skeleton structure - Check pixel-to-mm conversion if needed (see Trait Reference)</p>"},{"location":"tutorials/#next-steps","title":"Next Steps","text":"<p>After completing a tutorial:</p> <ul> <li>Read the Pipeline Guide for in-depth explanations</li> <li>Explore the Trait Reference to understand computed traits</li> <li>Check the Cookbook for advanced recipes</li> <li>See Batch Processing for high-throughput analysis</li> </ul>"},{"location":"tutorials/dicot-pipeline/","title":"Dicot Pipeline Tutorial","text":"<p>This tutorial walks through a complete analysis of dicot root systems using the <code>DicotPipeline</code>. This pipeline is designed for plants with a primary root and lateral roots, such as soybean, canola, and arabidopsis.</p>"},{"location":"tutorials/dicot-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Load SLEAP predictions for primary and lateral roots</li> <li>Initialize and configure the DicotPipeline</li> <li>Compute 50+ morphological traits</li> <li>Visualize root networks and convex hulls</li> <li>Export results to CSV</li> </ul>"},{"location":"tutorials/dicot-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>DicotPipeline</code> computes traits in several categories:</p> <ul> <li>Primary root traits: Length, growth, tip angle</li> <li>Lateral root traits: Count, lengths, emergence angles</li> <li>Network traits: Total lengths, medoid calculations</li> <li>Topological traits: Root base counts, convex hull area</li> <li>Temporal traits: Growth rates over time</li> </ul>"},{"location":"tutorials/dicot-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/DicotPipeline.ipynb' }}</p>"},{"location":"tutorials/dicot-pipeline/#key-concepts","title":"Key Concepts","text":""},{"location":"tutorials/dicot-pipeline/#root-network-structure","title":"Root Network Structure","text":"<p>The pipeline expects SLEAP predictions with two files:</p> <ol> <li>Primary root (<code>.slp</code>): Single tracked root with nodes from base to tip</li> <li>Lateral roots (<code>.slp</code>): Multiple roots, each tracked from primary root junction to tip</li> </ol>"},{"location":"tutorials/dicot-pipeline/#trait-computation-flow","title":"Trait Computation Flow","text":"<pre><code>graph LR\n    A[Load SLEAP Files] --&gt; B[Series Object]\n    B --&gt; C[Get Root Landmarks]\n    C --&gt; D[Compute Primary Traits]\n    C --&gt; E[Compute Lateral Traits]\n    D --&gt; F[Compute Network Traits]\n    E --&gt; F\n    F --&gt; G[Export to CSV]</code></pre>"},{"location":"tutorials/dicot-pipeline/#important-parameters","title":"Important Parameters","text":"<ul> <li>primary_name: Node name for primary root base (default: <code>\"base\"</code>)</li> <li>lateral_name: Node name for lateral root bases (default: <code>\"lateral\"</code>)</li> <li>csv_path: Output path for trait CSV</li> <li>plot: Whether to generate visualizations</li> </ul>"},{"location":"tutorials/dicot-pipeline/#common-patterns","title":"Common Patterns","text":""},{"location":"tutorials/dicot-pipeline/#basic-usage","title":"Basic Usage","text":"<pre><code>import sleap_roots as sr\n\n# Load data\nseries = sr.Series.load(\"plant1\", h5_path=\"pred.h5\",\n                        primary_path=\"primary.slp\",\n                        lateral_path=\"lateral.slp\")\n\n# Compute traits\npipeline = sr.DicotPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n</code></pre>"},{"location":"tutorials/dicot-pipeline/#batch-processing","title":"Batch Processing","text":"<pre><code>from pathlib import Path\n\nfor h5_file in Path(\"data/\").glob(\"*.h5\"):\n    series = sr.Series.load(\n        series_name=h5_file.stem,\n        h5_path=h5_file,\n        primary_path=h5_file.with_suffix(\".primary.slp\"),\n        lateral_path=h5_file.with_suffix(\".lateral.slp\")\n    )\n    traits = pipeline.compute_plant_traits(series, write_csv=True)\n</code></pre>"},{"location":"tutorials/dicot-pipeline/#trait-highlights","title":"Trait Highlights","text":"<p>Key traits computed by this pipeline:</p> Trait Description Units <code>primary_length</code> Length of primary root from base to tip pixels <code>lateral_count</code> Number of lateral roots detected count <code>total_length</code> Sum of all root lengths pixels <code>primary_tip_angle</code> Angle of primary root tip relative to vertical degrees <code>convex_hull_area</code> Area of convex hull around all roots pixels\u00b2 <p>See the Trait Reference for all 50+ traits.</p>"},{"location":"tutorials/dicot-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>Try the Batch Processing guide</li> <li>Learn about Custom Pipelines</li> <li>Explore other tutorials:<ul> <li>Younger Monocot Pipeline</li> <li>Multiple Dicot Pipeline</li> </ul> </li> </ul>"},{"location":"tutorials/lateral-root-pipeline/","title":"Lateral Root Pipeline Tutorial","text":"<p>This tutorial demonstrates specialized analysis of lateral root systems using the <code>LateralRootPipeline</code>. This pipeline focuses exclusively on lateral roots, providing detailed metrics for lateral root architecture and development.</p>"},{"location":"tutorials/lateral-root-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Analyze lateral root systems independently</li> <li>Compute lateral-specific traits and topology</li> <li>Study lateral root emergence patterns</li> <li>Track lateral root development dynamics</li> </ul>"},{"location":"tutorials/lateral-root-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>LateralRootPipeline</code> computes:</p> <ul> <li>Lateral root counts: Total number and emergence timing</li> <li>Individual lateral lengths: Per-root measurements</li> <li>Emergence patterns: Angles, positions, spacing</li> <li>Network properties: Aggregate lateral root metrics</li> <li>Developmental dynamics: Growth rates, initiation patterns</li> </ul>"},{"location":"tutorials/lateral-root-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/LateralRootPipeline.ipynb' }}</p>"},{"location":"tutorials/lateral-root-pipeline/#when-to-use-this-pipeline","title":"When to Use This Pipeline","text":""},{"location":"tutorials/lateral-root-pipeline/#research-focus","title":"Research Focus","text":"<p>Ideal for studies examining:</p> <ul> <li>Lateral root initiation: Timing and frequency of lateral emergence</li> <li>Branching architecture: Spatial distribution patterns</li> <li>Lateral elongation: Growth dynamics of individual laterals</li> <li>Environmental responses: How conditions affect lateral development</li> <li>Comparative anatomy: Lateral root differences across genotypes</li> </ul>"},{"location":"tutorials/lateral-root-pipeline/#versus-full-pipelines","title":"Versus Full Pipelines","text":"Feature LateralRootPipeline DicotPipeline Primary root Not analyzed Analyzed Lateral roots Detailed analysis Standard analysis Use case Lateral-focused research Complete root system Traits Lateral-specific Primary + lateral + network"},{"location":"tutorials/lateral-root-pipeline/#root-architecture","title":"Root Architecture","text":""},{"location":"tutorials/lateral-root-pipeline/#expected-structure","title":"Expected Structure","text":"<pre><code>        Primary Root (not tracked)\n              |\n    ----------|----------\n   /     |    |    |     \\\n  L1    L2   L3   L4    L5  (Lateral roots tracked)\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#sleap-requirements","title":"SLEAP Requirements","text":"<ul> <li>Lateral root file: Contains all lateral roots</li> <li>Base nodes: Each lateral starts at emergence point</li> <li>Tip tracking: Each lateral tracked to tip</li> <li>No primary needed: Pipeline focuses on laterals only</li> </ul>"},{"location":"tutorials/lateral-root-pipeline/#usage-examples","title":"Usage Examples","text":""},{"location":"tutorials/lateral-root-pipeline/#basic-analysis","title":"Basic Analysis","text":"<pre><code>import sleap_roots as sr\n\n# Load lateral roots only\nseries = sr.Series.load(\n    \"plant_laterals\",\n    h5_path=\"predictions.h5\",\n    lateral_path=\"lateral.slp\"\n    # No primary_path needed\n)\n\n# Compute lateral traits\npipeline = sr.LateralRootPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\nprint(f\"Lateral root count: {traits['lateral_count'].iloc[0]}\")\nprint(f\"Total lateral length: {traits['total_lateral_length'].iloc[0]:.2f} px\")\nprint(f\"Mean lateral length: {traits['mean_lateral_length'].iloc[0]:.2f} px\")\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#emergence-pattern-analysis","title":"Emergence Pattern Analysis","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Analyze lateral emergence along primary axis\ntraits = pipeline.compute_plant_traits(series)\n\n# Get emergence positions (y-coordinates of base nodes)\nemergence_positions = traits['lateral_emergence_positions'].iloc[0]\n\n# Plot emergence pattern\nplt.figure(figsize=(8, 6))\nplt.scatter(emergence_positions, range(len(emergence_positions)))\nplt.xlabel('Position along primary root (pixels)')\nplt.ylabel('Lateral root index')\nplt.title('Lateral Root Emergence Pattern')\nplt.grid(True)\nplt.show()\n\n# Compute spacing statistics\nspacings = np.diff(sorted(emergence_positions))\nprint(f\"Mean spacing: {np.mean(spacings):.2f} px\")\nprint(f\"Spacing variability (std): {np.std(spacings):.2f} px\")\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#lateral-length-distribution","title":"Lateral Length Distribution","text":"<pre><code># Analyze distribution of lateral lengths\nlateral_lengths = traits['lateral_root_lengths'].iloc[0]\n\nplt.figure(figsize=(10, 6))\nplt.hist(lateral_lengths, bins=20, edgecolor='black')\nplt.xlabel('Lateral Root Length (pixels)')\nplt.ylabel('Count')\nplt.title('Distribution of Lateral Root Lengths')\nplt.axvline(np.mean(lateral_lengths), color='r',\n           linestyle='--', label=f'Mean: {np.mean(lateral_lengths):.1f} px')\nplt.legend()\nplt.show()\n\n# Identify longest and shortest\nprint(f\"Longest lateral: {max(lateral_lengths):.2f} px\")\nprint(f\"Shortest lateral: {min(lateral_lengths):.2f} px\")\nprint(f\"Length range: {max(lateral_lengths) - min(lateral_lengths):.2f} px\")\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#key-traits","title":"Key Traits","text":""},{"location":"tutorials/lateral-root-pipeline/#count-metrics","title":"Count Metrics","text":"Trait Description Units <code>lateral_count</code> Total number of lateral roots count <code>lateral_count_left</code> Laterals on left side count <code>lateral_count_right</code> Laterals on right side count"},{"location":"tutorials/lateral-root-pipeline/#length-measurements","title":"Length Measurements","text":"Trait Description Units <code>total_lateral_length</code> Sum of all lateral lengths pixels <code>mean_lateral_length</code> Average lateral length pixels <code>median_lateral_length</code> Median lateral length pixels <code>lateral_root_lengths</code> Individual lengths (array) pixels"},{"location":"tutorials/lateral-root-pipeline/#spatial-distribution","title":"Spatial Distribution","text":"Trait Description Units <code>lateral_emergence_positions</code> Position of each lateral base pixels (array) <code>lateral_emergence_spacing</code> Distance between adjacent laterals pixels <code>lateral_density</code> Laterals per unit primary length count/pixel"},{"location":"tutorials/lateral-root-pipeline/#angular-properties","title":"Angular Properties","text":"Trait Description Units <code>lateral_emergence_angles</code> Angle of each lateral at base degrees (array) <code>mean_emergence_angle</code> Average emergence angle degrees <code>angular_variance</code> Variability in emergence angles degrees\u00b2"},{"location":"tutorials/lateral-root-pipeline/#advanced-analysis","title":"Advanced Analysis","text":""},{"location":"tutorials/lateral-root-pipeline/#temporal-development","title":"Temporal Development","text":"<pre><code># Track lateral root development over time\nseries = sr.Series.load(\n    \"timeseries\",\n    h5_path=\"timeseries.h5\",\n    lateral_path=\"lateral.slp\"\n)\n\ntraits = pipeline.compute_plant_traits(series)\n\n# Plot lateral count over time\nplt.figure(figsize=(10, 6))\nplt.plot(traits['frame'], traits['lateral_count'], 'o-')\nplt.xlabel('Frame')\nplt.ylabel('Lateral Root Count')\nplt.title('Lateral Root Initiation Over Time')\nplt.grid(True)\nplt.show()\n\n# Calculate initiation rate\nframes_with_new_laterals = traits[traits['lateral_count'].diff() &gt; 0]\nmean_initiation_interval = frames_with_new_laterals['frame'].diff().mean()\nprint(f\"Average frames between new laterals: {mean_initiation_interval:.1f}\")\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#lateral-growth-dynamics","title":"Lateral Growth Dynamics","text":"<pre><code># Track individual lateral growth (requires consistent tracking)\n# Assuming laterals maintain consistent IDs across frames\n\nimport pandas as pd\n\ngrowth_data = []\nfor frame_idx in range(len(series.lateral_pts)):\n    frame_laterals = series.lateral_pts[frame_idx]\n\n    for lateral_id, lateral_pts in enumerate(frame_laterals):\n        if len(lateral_pts) &gt; 0:\n            length = sr.lengths.get_root_lengths([lateral_pts])[0]\n            growth_data.append({\n                'frame': frame_idx,\n                'lateral_id': lateral_id,\n                'length': length\n            })\n\ndf = pd.DataFrame(growth_data)\n\n# Plot growth curves for each lateral\nplt.figure(figsize=(12, 6))\nfor lateral_id in df['lateral_id'].unique():\n    lateral_data = df[df['lateral_id'] == lateral_id]\n    plt.plot(lateral_data['frame'], lateral_data['length'],\n            label=f'Lateral {lateral_id}')\n\nplt.xlabel('Frame')\nplt.ylabel('Lateral Length (pixels)')\nplt.title('Individual Lateral Root Growth Curves')\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#emergence-angle-analysis","title":"Emergence Angle Analysis","text":"<pre><code># Analyze lateral emergence angles\nemergence_angles = traits['lateral_emergence_angles'].iloc[0]\n\nplt.figure(figsize=(10, 6))\nplt.hist(emergence_angles, bins=30, edgecolor='black')\nplt.xlabel('Emergence Angle (degrees)')\nplt.ylabel('Count')\nplt.title('Distribution of Lateral Root Emergence Angles')\nplt.axvline(np.mean(emergence_angles), color='r',\n           linestyle='--', label=f'Mean: {np.mean(emergence_angles):.1f}\u00b0')\nplt.legend()\nplt.show()\n\n# Check for left-right asymmetry\nleft_angles = emergence_angles[emergence_angles &lt; 0]\nright_angles = emergence_angles[emergence_angles &gt; 0]\n\nprint(f\"Left-side mean angle: {np.mean(left_angles):.2f}\u00b0\")\nprint(f\"Right-side mean angle: {np.mean(right_angles):.2f}\u00b0\")\nprint(f\"Asymmetry: {abs(np.mean(left_angles)) - abs(np.mean(right_angles)):.2f}\u00b0\")\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#comparison-studies","title":"Comparison Studies","text":""},{"location":"tutorials/lateral-root-pipeline/#genotype-comparison","title":"Genotype Comparison","text":"<pre><code># Compare lateral root architecture across genotypes\ngenotypes = ['WT', 'mutant_high_lateral', 'mutant_low_lateral']\nresults = []\n\nfor genotype in genotypes:\n    series = sr.Series.load(\n        genotype,\n        h5_path=f\"{genotype}.h5\",\n        lateral_path=f\"{genotype}_lateral.slp\"\n    )\n    traits = pipeline.compute_plant_traits(series)\n    traits['genotype'] = genotype\n    results.append(traits)\n\ndf = pd.concat(results)\n\n# Compare lateral counts\nimport seaborn as sns\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nsns.boxplot(data=df, x='genotype', y='lateral_count', ax=axes[0])\naxes[0].set_title('Lateral Root Count by Genotype')\n\nsns.boxplot(data=df, x='genotype', y='mean_lateral_length', ax=axes[1])\naxes[1].set_title('Mean Lateral Length by Genotype')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#treatment-effects","title":"Treatment Effects","text":"<pre><code># Assess treatment impact on lateral development\ntreatments = ['control', 'nitrogen', 'drought']\nlateral_counts = []\nlateral_lengths = []\n\nfor treatment in treatments:\n    series = sr.Series.load(\n        treatment,\n        h5_path=f\"{treatment}.h5\",\n        lateral_path=f\"{treatment}_lateral.slp\"\n    )\n    traits = pipeline.compute_plant_traits(series)\n\n    lateral_counts.append(traits['lateral_count'].iloc[0])\n    lateral_lengths.append(traits['mean_lateral_length'].iloc[0])\n\n# Visualize treatment effects\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\naxes[0].bar(treatments, lateral_counts)\naxes[0].set_ylabel('Lateral Count')\naxes[0].set_title('Lateral Initiation by Treatment')\n\naxes[1].bar(treatments, lateral_lengths)\naxes[1].set_ylabel('Mean Length (pixels)')\naxes[1].set_title('Lateral Elongation by Treatment')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#lateral-root-topology","title":"Lateral Root Topology","text":""},{"location":"tutorials/lateral-root-pipeline/#branching-patterns","title":"Branching Patterns","text":"<pre><code># Analyze branching pattern characteristics\ntraits = pipeline.compute_plant_traits(series)\n\n# Compute branching index (laterals per unit length)\nif 'primary_length' in traits.columns:\n    branching_index = traits['lateral_count'] / traits['primary_length']\n    print(f\"Branching index: {branching_index.iloc[0]:.4f} laterals/pixel\")\n\n# Analyze spatial clustering\nemergence_pos = traits['lateral_emergence_positions'].iloc[0]\nsorted_pos = sorted(emergence_pos)\n\n# Detect clusters (laterals closer than threshold)\ncluster_threshold = 50  # pixels\nclusters = []\ncurrent_cluster = [sorted_pos[0]]\n\nfor pos in sorted_pos[1:]:\n    if pos - current_cluster[-1] &lt; cluster_threshold:\n        current_cluster.append(pos)\n    else:\n        clusters.append(current_cluster)\n        current_cluster = [pos]\nclusters.append(current_cluster)\n\nprint(f\"Detected {len(clusters)} lateral root clusters\")\nfor i, cluster in enumerate(clusters):\n    print(f\"Cluster {i+1}: {len(cluster)} laterals\")\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#troubleshooting","title":"Troubleshooting","text":"<p>Low lateral count detected: - Verify SLEAP model detects all lateral roots - Check tracking quality and confidence thresholds - Ensure laterals aren't merged into single track</p> <p>Inconsistent lengths: - Confirm lateral roots tracked from base to tip - Check for tracking discontinuities - Verify consistent frame-to-frame tracking</p> <p>Incorrect emergence positions: - Ensure lateral base nodes correctly positioned - Verify primary root alignment in SLEAP skeleton - Check for flipped coordinates</p> <p>Missing temporal data: - Confirm H5 file includes all frames - Verify frame indices align across timepoints - Check for tracking gaps</p>"},{"location":"tutorials/lateral-root-pipeline/#integration-with-full-pipelines","title":"Integration with Full Pipelines","text":"<p>Compare lateral-only results with full pipeline:</p> <pre><code># Run both pipelines\nlateral_pipeline = sr.LateralRootPipeline()\ndicot_pipeline = sr.DicotPipeline()\n\n# Load with both primary and lateral\nfull_series = sr.Series.load(\n    \"plant\",\n    h5_path=\"pred.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Load lateral-only\nlateral_series = sr.Series.load(\n    \"plant\",\n    h5_path=\"pred.h5\",\n    lateral_path=\"lateral.slp\"\n)\n\nlateral_traits = lateral_pipeline.compute_plant_traits(lateral_series)\nfull_traits = dicot_pipeline.compute_plant_traits(full_series)\n\n# Compare lateral metrics\nprint(\"Lateral-only pipeline:\", lateral_traits['lateral_count'].iloc[0])\nprint(\"Full dicot pipeline:\", full_traits['lateral_count'].iloc[0])\n</code></pre>"},{"location":"tutorials/lateral-root-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>See Dicot Pipeline for combined primary + lateral analysis</li> <li>Try Multiple Dicot Pipeline for multi-plant laterals</li> <li>Read Trait Reference for all lateral traits</li> <li>Explore Custom Traits for specialized lateral metrics</li> </ul>"},{"location":"tutorials/multiple-dicot-pipeline/","title":"Multiple Dicot Pipeline Tutorial","text":"<p>This tutorial demonstrates batch analysis of multiple dicot plants in a single image using the <code>MultipleDicotPipeline</code>. This pipeline extends the standard dicot analysis to handle multi-plant experimental setups.</p>"},{"location":"tutorials/multiple-dicot-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Analyze multiple dicot plants simultaneously</li> <li>Handle plant separation and identification</li> <li>Compute per-plant traits in batch</li> <li>Export organized multi-plant results</li> </ul>"},{"location":"tutorials/multiple-dicot-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>MultipleDicotPipeline</code> processes multiple plants by:</p> <ol> <li>Identifying individual plants from SLEAP tracks</li> <li>Computing dicot traits for each plant independently</li> <li>Organizing results by plant ID</li> <li>Exporting combined CSV with all plants</li> </ol>"},{"location":"tutorials/multiple-dicot-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/MultipleDicotPipeline.ipynb' }}</p>"},{"location":"tutorials/multiple-dicot-pipeline/#when-to-use-this-pipeline","title":"When to Use This Pipeline","text":""},{"location":"tutorials/multiple-dicot-pipeline/#experimental-designs","title":"Experimental Designs","text":"<p>Ideal for:</p> <ul> <li>High-throughput phenotyping: Multiple plants per image</li> <li>Comparative studies: Multiple genotypes or treatments in one frame</li> <li>Space-efficient imaging: Maximize plants per image</li> <li>Simultaneous growth tracking: Track development of multiple individuals</li> </ul>"},{"location":"tutorials/multiple-dicot-pipeline/#setup-requirements","title":"Setup Requirements","text":"<p>Your SLEAP predictions must:</p> <ul> <li>Use track IDs to distinguish individual plants</li> <li>Have consistent node naming across all plants</li> <li>Include both primary and lateral roots for each plant</li> <li>Maintain track continuity across frames</li> </ul>"},{"location":"tutorials/multiple-dicot-pipeline/#multi-plant-workflow","title":"Multi-Plant Workflow","text":""},{"location":"tutorials/multiple-dicot-pipeline/#data-organization","title":"Data Organization","text":"<pre><code>Single Image \u2192 Multiple SLEAP Tracks\n                \u251c\u2500\u2500 Track 0 (Plant A): Primary + Laterals\n                \u251c\u2500\u2500 Track 1 (Plant B): Primary + Laterals\n                \u251c\u2500\u2500 Track 2 (Plant C): Primary + Laterals\n                \u2514\u2500\u2500 Track 3 (Plant D): Primary + Laterals\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#processing-flow","title":"Processing Flow","text":"<pre><code>graph TD\n    A[Load SLEAP File] --&gt; B[Separate Plants by Track ID]\n    B --&gt; C1[Plant 1 Series]\n    B --&gt; C2[Plant 2 Series]\n    B --&gt; C3[Plant N Series]\n    C1 --&gt; D1[Compute Traits]\n    C2 --&gt; D2[Compute Traits]\n    C3 --&gt; D3[Compute Traits]\n    D1 --&gt; E[Combine Results]\n    D2 --&gt; E\n    D3 --&gt; E\n    E --&gt; F[Export Multi-Plant CSV]</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#usage-examples","title":"Usage Examples","text":""},{"location":"tutorials/multiple-dicot-pipeline/#basic-multi-plant-analysis","title":"Basic Multi-Plant Analysis","text":"<pre><code>import sleap_roots as sr\n\n# Load all plants from single file\nseries_list = sr.Series.load_multi(\n    h5_path=\"multi_plant.h5\",\n    primary_path=\"primary.slp\",\n    lateral_path=\"lateral.slp\"\n)\n\n# Process all plants\npipeline = sr.MultipleDicotPipeline()\nall_traits = pipeline.compute_multi_plant_traits(\n    series_list,\n    write_csv=True,\n    csv_path=\"all_plants_traits.csv\"\n)\n\nprint(f\"Processed {len(series_list)} plants\")\nprint(all_traits.head())\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#per-plant-iteration","title":"Per-Plant Iteration","text":"<pre><code># Process each plant individually with custom logic\nresults = []\nfor i, series in enumerate(series_list):\n    print(f\"Processing plant {i+1}/{len(series_list)}\")\n\n    traits = pipeline.compute_plant_traits(series)\n    traits['plant_id'] = i\n    traits['genotype'] = get_genotype(i)  # Custom metadata\n\n    results.append(traits)\n\ndf = pd.concat(results)\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#filtering-plants","title":"Filtering Plants","text":"<pre><code># Only process plants with sufficient data\nvalid_plants = [\n    series for series in series_list\n    if series.primary_pts.shape[0] &gt; 100  # Minimum primary root points\n]\n\ntraits = pipeline.compute_multi_plant_traits(valid_plants)\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#key-considerations","title":"Key Considerations","text":""},{"location":"tutorials/multiple-dicot-pipeline/#plant-separation","title":"Plant Separation","text":"<p>Critical: SLEAP tracking must correctly separate plants</p> <p>\u2705 Good tracking: - Each plant has unique, consistent track ID - No track swapping between plants - Complete tracks from base to tip</p> <p>\u274c Poor tracking issues: - Track IDs swap between frames - Multiple plants share same track - Fragmented tracks</p>"},{"location":"tutorials/multiple-dicot-pipeline/#trait-organization","title":"Trait Organization","text":"<p>Output CSV structure:</p> plant_id frame primary_length lateral_count ... plant_0 0 245.3 5 ... plant_0 1 247.1 5 ... plant_1 0 198.7 3 ... plant_1 1 201.2 4 ..."},{"location":"tutorials/multiple-dicot-pipeline/#performance-optimization","title":"Performance Optimization","text":"<p>For many plants:</p> <pre><code>from multiprocessing import Pool\n\ndef process_plant(series):\n    pipeline = sr.MultipleDicotPipeline()\n    return pipeline.compute_plant_traits(series)\n\n# Parallel processing\nwith Pool(processes=4) as pool:\n    results = pool.map(process_plant, series_list)\n\ndf = pd.concat(results)\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#comparison-analysis","title":"Comparison Analysis","text":""},{"location":"tutorials/multiple-dicot-pipeline/#genotype-comparison","title":"Genotype Comparison","text":"<pre><code>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming metadata is added\nall_traits['genotype'] = ['A', 'A', 'B', 'B', ...]\n\nsns.boxplot(data=all_traits, x='genotype', y='primary_length')\nplt.title('Primary Root Length by Genotype')\nplt.show()\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#treatment-effects","title":"Treatment Effects","text":"<pre><code># Compare control vs. treatment\ncontrol = all_traits[all_traits['treatment'] == 'control']\ntreated = all_traits[all_traits['treatment'] == 'nitrogen']\n\nprint(f\"Control mean lateral count: {control['lateral_count'].mean():.1f}\")\nprint(f\"Treated mean lateral count: {treated['lateral_count'].mean():.1f}\")\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#common-issues","title":"Common Issues","text":""},{"location":"tutorials/multiple-dicot-pipeline/#track-swapping","title":"Track Swapping","text":"<p>Problem: Plant identities swap between frames</p> <p>Solution: - Review SLEAP tracking parameters - Use stricter tracking thresholds - Manually correct in SLEAP GUI if needed</p>"},{"location":"tutorials/multiple-dicot-pipeline/#overlapping-plants","title":"Overlapping Plants","text":"<p>Problem: Root systems overlap, hard to separate</p> <p>Solution: - Increase plant spacing in imaging setup - Use colored markers or labels in image - Employ instance segmentation in SLEAP model</p>"},{"location":"tutorials/multiple-dicot-pipeline/#variable-plant-count","title":"Variable Plant Count","text":"<p>Problem: Different number of plants across timepoints</p> <p>Solution: <pre><code># Handle missing plants gracefully\nfor frame in range(num_frames):\n    frame_plants = [s for s in series_list if frame in s.frame_indices]\n    traits = pipeline.compute_multi_plant_traits(frame_plants)\n    # Process frame-specific results\n</code></pre></p>"},{"location":"tutorials/multiple-dicot-pipeline/#export-options","title":"Export Options","text":""},{"location":"tutorials/multiple-dicot-pipeline/#standard-csv","title":"Standard CSV","text":"<pre><code>all_traits.to_csv('multi_plant_traits.csv', index=False)\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#per-plant-files","title":"Per-Plant Files","text":"<pre><code>for plant_id, group in all_traits.groupby('plant_id'):\n    group.to_csv(f'plant_{plant_id}_traits.csv', index=False)\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#wide-format-for-statistics","title":"Wide Format for Statistics","text":"<pre><code># Pivot for statistical software\nwide_format = all_traits.pivot(\n    index='frame',\n    columns='plant_id',\n    values='primary_length'\n)\nwide_format.to_csv('traits_wide.csv')\n</code></pre>"},{"location":"tutorials/multiple-dicot-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>See Multiple Primary Root Pipeline for simpler multi-plant setups</li> <li>Read Batch Processing for large-scale experiments</li> <li>Explore Statistical Analysis Cookbook</li> <li>Learn about Custom Pipelines for specialized multi-plant needs</li> </ul>"},{"location":"tutorials/multiple-primary-root-pipeline/","title":"Multiple Primary Root Pipeline Tutorial","text":"<p>This tutorial demonstrates analysis of multiple plants with primary roots using the <code>MultiplePrimaryRootPipeline</code>. This pipeline is designed for multi-plant setups where each plant has a single primary root without lateral branches.</p>"},{"location":"tutorials/multiple-primary-root-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Process multiple primary-root plants simultaneously</li> <li>Handle simplified multi-plant architectures</li> <li>Compute primary root traits in batch</li> <li>Compare growth across multiple individuals</li> </ul>"},{"location":"tutorials/multiple-primary-root-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>MultiplePrimaryRootPipeline</code> provides:</p> <ul> <li>Individual plant identification via SLEAP track IDs</li> <li>Primary root trait computation for each plant</li> <li>Comparative metrics across plants</li> <li>Streamlined output for primary-root-only systems</li> </ul>"},{"location":"tutorials/multiple-primary-root-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/MultiplePrimaryRootPipeline.ipynb' }}</p>"},{"location":"tutorials/multiple-primary-root-pipeline/#use-cases","title":"Use Cases","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#ideal-applications","title":"Ideal Applications","text":"<ul> <li>Early-stage phenotyping: Young seedlings before lateral emergence</li> <li>Simple architectures: Species with minimal branching</li> <li>Root length screens: Focused on primary root growth</li> <li>High-throughput imaging: Maximum plants per frame</li> </ul>"},{"location":"tutorials/multiple-primary-root-pipeline/#experimental-examples","title":"Experimental Examples","text":"<p>Germination assays: - Screen 10-20 seedlings per image - Track primary root emergence and elongation - Compare germination vigor across genotypes</p> <p>Stress response: - Monitor primary root growth under drought, salinity - Compare control vs. treatment in same frame - Minimize imaging time and variability</p> <p>Gravitropism studies: - Track primary root angle and curvature - Multiple plants per treatment condition - Temporal analysis of root orientation</p>"},{"location":"tutorials/multiple-primary-root-pipeline/#root-system-architecture","title":"Root System Architecture","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#expected-structure","title":"Expected Structure","text":"<pre><code>Plant 1: Base \u2192 Primary Root \u2192 Tip\nPlant 2: Base \u2192 Primary Root \u2192 Tip\nPlant 3: Base \u2192 Primary Root \u2192 Tip\n   ...\nPlant N: Base \u2192 Primary Root \u2192 Tip\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#key-features","title":"Key Features","text":"<ul> <li>Single root per plant: No laterals or crown roots</li> <li>Track-based separation: Each plant has unique track ID</li> <li>Minimal complexity: Faster processing than full dicot/monocot pipelines</li> </ul>"},{"location":"tutorials/multiple-primary-root-pipeline/#usage-examples","title":"Usage Examples","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#basic-analysis","title":"Basic Analysis","text":"<pre><code>import sleap_roots as sr\n\n# Load all plants\nseries_list = sr.Series.load_multi(\n    h5_path=\"primary_roots.h5\",\n    primary_path=\"primary.slp\"\n    # Note: No lateral_path needed\n)\n\n# Process all plants\npipeline = sr.MultiplePrimaryRootPipeline()\ntraits = pipeline.compute_multi_plant_traits(\n    series_list,\n    write_csv=True,\n    csv_path=\"primary_traits.csv\"\n)\n\nprint(f\"Analyzed {len(series_list)} plants\")\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#germination-screen","title":"Germination Screen","text":"<pre><code># Screen many seedlings\nseries_list = sr.Series.load_multi(\n    h5_path=\"germination_plate.h5\",\n    primary_path=\"primary.slp\"\n)\n\ntraits = pipeline.compute_multi_plant_traits(series_list)\n\n# Filter by germination success\ngerminated = traits[traits['primary_length'] &gt; 50]  # &gt;50 pixels\nprint(f\"Germination rate: {len(germinated)/len(traits)*100:.1f}%\")\n\n# Find fastest growing\nfastest = traits.loc[traits['primary_length'].idxmax()]\nprint(f\"Fastest growth: {fastest['primary_length']:.1f} pixels\")\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#temporal-growth-analysis","title":"Temporal Growth Analysis","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Collect traits across multiple timepoints\nall_data = []\nfor hour in range(0, 72, 6):  # Every 6 hours for 3 days\n    series_list = sr.Series.load_multi(\n        h5_path=f\"hour_{hour}.h5\",\n        primary_path=f\"primary_{hour}.slp\"\n    )\n\n    traits = pipeline.compute_multi_plant_traits(series_list)\n    traits['hour'] = hour\n    all_data.append(traits)\n\ndf = pd.concat(all_data)\n\n# Plot growth curves\nfor plant_id in df['plant_id'].unique():\n    plant_data = df[df['plant_id'] == plant_id]\n    plt.plot(plant_data['hour'], plant_data['primary_length'],\n             label=f'Plant {plant_id}')\n\nplt.xlabel('Time (hours)')\nplt.ylabel('Primary Root Length (pixels)')\nplt.legend()\nplt.title('Primary Root Growth Over Time')\nplt.show()\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#key-traits","title":"Key Traits","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#length-metrics","title":"Length Metrics","text":"Trait Description Units <code>primary_length</code> Total root length from base to tip pixels <code>primary_length_smooth</code> Smoothed length (reduces noise) pixels"},{"location":"tutorials/multiple-primary-root-pipeline/#geometric-traits","title":"Geometric Traits","text":"Trait Description Units <code>primary_tip_angle</code> Angle of tip relative to vertical degrees <code>primary_curvature</code> Overall root curvature 1/pixels <code>primary_straightness</code> Euclidean distance / path length 0-1"},{"location":"tutorials/multiple-primary-root-pipeline/#growth-metrics","title":"Growth Metrics","text":"Trait Description Units <code>growth_rate</code> Length change per frame pixels/frame <code>relative_growth_rate</code> Proportional growth rate %/frame"},{"location":"tutorials/multiple-primary-root-pipeline/#multi-plant-comparisons","title":"Multi-Plant Comparisons","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#statistical-summaries","title":"Statistical Summaries","text":"<pre><code># Summary statistics across all plants\nsummary = traits.groupby('plant_id')['primary_length'].agg([\n    'mean', 'std', 'min', 'max'\n])\nprint(summary)\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#genotype-comparisons","title":"Genotype Comparisons","text":"<pre><code># Add genotype information\ngenotype_map = {0: 'WT', 1: 'WT', 2: 'mutant', 3: 'mutant'}\ntraits['genotype'] = traits['plant_id'].map(genotype_map)\n\n# Compare\nimport seaborn as sns\nsns.boxplot(data=traits, x='genotype', y='primary_length')\nplt.title('Primary Root Length by Genotype')\nplt.show()\n\n# Statistical test\nfrom scipy import stats\nwt = traits[traits['genotype'] == 'WT']['primary_length']\nmut = traits[traits['genotype'] == 'mutant']['primary_length']\nt_stat, p_value = stats.ttest_ind(wt, mut)\nprint(f\"P-value: {p_value:.4f}\")\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#ranking-and-selection","title":"Ranking and Selection","text":"<pre><code># Identify top performers\ntraits_sorted = traits.sort_values('primary_length', ascending=False)\ntop_5 = traits_sorted.head(5)\nprint(\"Top 5 longest roots:\")\nprint(top_5[['plant_id', 'primary_length']])\n\n# Select plants for next generation\nselection_threshold = traits['primary_length'].quantile(0.75)\nselected = traits[traits['primary_length'] &gt; selection_threshold]\nprint(f\"Selected {len(selected)} plants (top 25%)\")\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#data-quality-checks","title":"Data Quality Checks","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#detecting-tracking-issues","title":"Detecting Tracking Issues","text":"<pre><code># Check for abnormally short roots (tracking failures)\nmin_length = 20  # pixels\nfailed_tracks = traits[traits['primary_length'] &lt; min_length]\nprint(f\"Potential tracking failures: {len(failed_tracks)} plants\")\n\n# Remove problematic plants\nclean_traits = traits[traits['primary_length'] &gt;= min_length]\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#validating-plant-count","title":"Validating Plant Count","text":"<pre><code>expected_count = 12  # 12 plants in setup\nactual_count = len(series_list)\n\nif actual_count != expected_count:\n    print(f\"Warning: Expected {expected_count}, found {actual_count}\")\n    # Investigate missing or extra tracks\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#performance-optimization","title":"Performance Optimization","text":""},{"location":"tutorials/multiple-primary-root-pipeline/#parallel-processing","title":"Parallel Processing","text":"<pre><code>from concurrent.futures import ProcessPoolExecutor\n\ndef process_single(series):\n    pipeline = sr.MultiplePrimaryRootPipeline()\n    return pipeline.compute_plant_traits(series)\n\n# Process plants in parallel\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    results = list(executor.map(process_single, series_list))\n\ndf = pd.concat(results, ignore_index=True)\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#batch-vs-individual","title":"Batch vs. Individual","text":"<pre><code># Batch processing (recommended for &lt;20 plants)\ntraits = pipeline.compute_multi_plant_traits(series_list)\n\n# Individual processing (for custom logic per plant)\ntraits = pd.concat([\n    pipeline.compute_plant_traits(series)\n    for series in series_list\n])\n</code></pre>"},{"location":"tutorials/multiple-primary-root-pipeline/#troubleshooting","title":"Troubleshooting","text":"<p>Plant count mismatch: - Verify SLEAP tracking parameters - Check for merged or split tracks - Ensure one track per plant</p> <p>Inconsistent lengths: - Confirm all plants imaged at same scale - Verify pixel-to-mm calibration - Check for tracking discontinuities</p> <p>Missing frames: - Ensure H5 file includes all expected frames - Check for tracking gaps in SLEAP - Verify frame alignment across timepoints</p>"},{"location":"tutorials/multiple-primary-root-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>Compare with Multiple Dicot Pipeline for plants with laterals</li> <li>See Primary Root Pipeline for single-plant analysis</li> <li>Read Batch Processing for large experiments</li> <li>Explore Statistical Cookbook for analysis recipes</li> </ul>"},{"location":"tutorials/older-monocot-pipeline/","title":"Older Monocot Pipeline Tutorial","text":"<p>This tutorial covers analysis of mature monocot root systems using the <code>OlderMonocotPipeline</code>. This pipeline is designed for plants where the primary root has senesced or is no longer the dominant root, and the root system consists primarily of crown roots.</p>"},{"location":"tutorials/older-monocot-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Analyze crown root-dominated monocot systems</li> <li>Handle root systems without primary roots</li> <li>Compute traits for mature rice and maize plants</li> <li>Measure root system spread and architecture</li> </ul>"},{"location":"tutorials/older-monocot-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>OlderMonocotPipeline</code> focuses exclusively on crown roots:</p> <ul> <li>Crown root metrics: Individual and aggregate lengths, angles</li> <li>Root system architecture: Spread, density, symmetry</li> <li>Network properties: Total system characteristics</li> <li>Temporal dynamics: Growth rates across timepoints</li> </ul>"},{"location":"tutorials/older-monocot-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/OlderMonocotPipeline.ipynb' }}</p>"},{"location":"tutorials/older-monocot-pipeline/#when-to-use-this-pipeline","title":"When to Use This Pipeline","text":""},{"location":"tutorials/older-monocot-pipeline/#developmental-indicators","title":"Developmental Indicators","text":"<p>Use <code>OlderMonocotPipeline</code> when:</p> <ul> <li>Primary root is no longer visible or tracked</li> <li>Crown roots are the dominant root type</li> <li>Plant is beyond early seedling stage (typically &gt;2 weeks)</li> <li>Root system is primarily adventitious</li> </ul>"},{"location":"tutorials/older-monocot-pipeline/#versus-youngermonocotpipeline","title":"Versus YoungerMonocotPipeline","text":"Feature Younger Pipeline Older Pipeline Primary root Required Not present Crown roots Emerging Dominant Typical age Days 3-12 Days 12+ SLEAP files 2 files (primary + crown) 1 file (crown only)"},{"location":"tutorials/older-monocot-pipeline/#root-system-architecture","title":"Root System Architecture","text":""},{"location":"tutorials/older-monocot-pipeline/#crown-root-structure","title":"Crown Root Structure","text":"<p>Mature monocot root systems feature:</p> <pre><code>      Stem Base\n     /  |  |  \\\n    /   |  |   \\\n   CR1 CR2 CR3 ... CRn\n</code></pre> <p>Where CR = Crown Root</p>"},{"location":"tutorials/older-monocot-pipeline/#typical-characteristics","title":"Typical Characteristics","text":"<ul> <li>Root count: 6-15 crown roots (species-dependent)</li> <li>Angular distribution: Radially distributed around stem</li> <li>Length variation: Central roots often longer</li> <li>Growth dynamics: Continuous root initiation</li> </ul>"},{"location":"tutorials/older-monocot-pipeline/#common-workflows","title":"Common Workflows","text":""},{"location":"tutorials/older-monocot-pipeline/#basic-analysis","title":"Basic Analysis","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"mature_rice\",\n    h5_path=\"rice_day14.h5\",\n    crown_path=\"crown.slp\"  # Only crown roots needed\n)\n\npipeline = sr.OlderMonocotPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\nprint(f\"Crown root count: {traits['crown_count'].iloc[0]}\")\nprint(f\"Total root length: {traits['total_crown_length'].iloc[0]:.2f}\")\n</code></pre>"},{"location":"tutorials/older-monocot-pipeline/#time-series-analysis","title":"Time Series Analysis","text":"<pre><code>import pandas as pd\n\nresults = []\nfor day in range(12, 21):  # Days 12-20\n    series = sr.Series.load(\n        f\"plant_day{day}\",\n        h5_path=f\"day{day}.h5\",\n        crown_path=f\"crown_day{day}.slp\"\n    )\n    traits = pipeline.compute_plant_traits(series)\n    traits['day'] = day\n    results.append(traits)\n\ndf = pd.concat(results)\n# Analyze root system development over time\n</code></pre>"},{"location":"tutorials/older-monocot-pipeline/#key-traits","title":"Key Traits","text":""},{"location":"tutorials/older-monocot-pipeline/#root-count-and-length","title":"Root Count and Length","text":"Trait Description Units <code>crown_count</code> Number of crown roots count <code>crown_root_lengths</code> Individual crown root lengths pixels (array) <code>total_crown_length</code> Sum of all crown root lengths pixels <code>mean_crown_length</code> Average crown root length pixels"},{"location":"tutorials/older-monocot-pipeline/#spatial-distribution","title":"Spatial Distribution","text":"Trait Description Units <code>root_system_width</code> Maximum lateral spread pixels <code>root_system_depth</code> Maximum vertical extent pixels <code>convex_hull_area</code> Area encompassing all roots pixels\u00b2"},{"location":"tutorials/older-monocot-pipeline/#angular-properties","title":"Angular Properties","text":"Trait Description Units <code>crown_emergence_angles</code> Angles of each crown root degrees (array) <code>angular_spread</code> Standard deviation of angles degrees <code>root_symmetry_index</code> Measure of radial symmetry 0-1"},{"location":"tutorials/older-monocot-pipeline/#biological-insights","title":"Biological Insights","text":""},{"location":"tutorials/older-monocot-pipeline/#root-system-strategies","title":"Root System Strategies","text":"<p>Shallow vs. Deep: - Wide angular spread \u2192 Resource acquisition from broad area - Narrow angular spread \u2192 Deep penetration strategy</p> <p>Root Count Variation: - More roots \u2192 Greater resource capture potential - Fewer, longer roots \u2192 Efficient nutrient uptake</p>"},{"location":"tutorials/older-monocot-pipeline/#growth-patterns","title":"Growth Patterns","text":"<p>Monitor these dynamics: 1. Root initiation rate: New crown roots per day 2. Elongation rate: Length increase per root 3. System expansion: Increase in convex hull area 4. Architectural changes: Shifts in angular distribution</p>"},{"location":"tutorials/older-monocot-pipeline/#troubleshooting","title":"Troubleshooting","text":"<p>Low root count detected: - Verify SLEAP tracking caught all crown roots - Check for occlusion or poor image quality - Ensure contrast is sufficient at root base region</p> <p>Irregular trait values: - Confirm all roots start from stem base (not mis-tracked laterals) - Verify pixel-to-mm scaling if values seem off - Check for tracking errors in SLEAP predictions</p> <p>Missing temporal data: - Ensure frame numbers align across timepoints - Verify H5 file contains all expected frames - Check for gaps in SLEAP tracking</p>"},{"location":"tutorials/older-monocot-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>Compare with Younger Monocot Pipeline for developmental transitions</li> <li>See Multiple Primary Root Pipeline for multi-plant setups</li> <li>Read Batch Processing for high-throughput analysis</li> <li>Explore Trait Reference for detailed trait definitions</li> </ul>"},{"location":"tutorials/primary-root-pipeline/","title":"Primary Root Pipeline Tutorial","text":"<p>This tutorial covers analysis of single primary roots using the <code>PrimaryRootPipeline</code>. This specialized pipeline focuses exclusively on primary root traits, providing a streamlined workflow for simple root architectures.</p>"},{"location":"tutorials/primary-root-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Analyze primary roots in isolation</li> <li>Compute focused primary root metrics</li> <li>Track primary root development over time</li> <li>Export simplified trait datasets</li> </ul>"},{"location":"tutorials/primary-root-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>PrimaryRootPipeline</code> computes:</p> <ul> <li>Length metrics: Total length, smoothed length</li> <li>Geometric properties: Tip angle, curvature, straightness</li> <li>Growth dynamics: Elongation rates, temporal patterns</li> <li>Spatial features: Tip position, root trajectory</li> </ul>"},{"location":"tutorials/primary-root-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/PrimaryRootPipeline.ipynb' }}</p>"},{"location":"tutorials/primary-root-pipeline/#when-to-use-this-pipeline","title":"When to Use This Pipeline","text":""},{"location":"tutorials/primary-root-pipeline/#ideal-scenarios","title":"Ideal Scenarios","text":"<ul> <li>Early development: Seedlings before lateral emergence</li> <li>Primary root focus: Research targeting primary root only</li> <li>Simplified phenotyping: Quick screening of primary growth</li> <li>Gravitropism studies: Tracking primary root orientation</li> <li>Subset analysis: Extracting primary traits from larger pipelines</li> </ul>"},{"location":"tutorials/primary-root-pipeline/#versus-other-pipelines","title":"Versus Other Pipelines","text":"Pipeline Roots Analyzed Use When PrimaryRootPipeline Primary only No laterals/crown roots DicotPipeline Primary + laterals Full dicot system YoungerMonocotPipeline Primary + crown Early monocot MultiplePrimaryRootPipeline Multiple primary roots Multi-plant primary-only"},{"location":"tutorials/primary-root-pipeline/#root-architecture","title":"Root Architecture","text":""},{"location":"tutorials/primary-root-pipeline/#expected-structure","title":"Expected Structure","text":"<pre><code>Base\n  |\n  |  Primary Root\n  |  (tracked continuously)\n  |\n  \u2193\nTip\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#sleap-requirements","title":"SLEAP Requirements","text":"<ul> <li>Single tracked root: One root from base to tip</li> <li>Node consistency: Consistent node naming</li> <li>Complete tracking: No gaps from base to tip</li> </ul>"},{"location":"tutorials/primary-root-pipeline/#usage-examples","title":"Usage Examples","text":""},{"location":"tutorials/primary-root-pipeline/#basic-analysis","title":"Basic Analysis","text":"<pre><code>import sleap_roots as sr\n\n# Load primary root only\nseries = sr.Series.load(\n    \"plant_primary\",\n    h5_path=\"predictions.h5\",\n    primary_path=\"primary.slp\"\n    # No lateral_path needed\n)\n\n# Compute primary traits\npipeline = sr.PrimaryRootPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\nprint(f\"Primary root length: {traits['primary_length'].iloc[0]:.2f} px\")\nprint(f\"Tip angle: {traits['primary_tip_angle'].iloc[0]:.2f}\u00b0\")\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#temporal-growth-tracking","title":"Temporal Growth Tracking","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load time series\nseries = sr.Series.load(\n    \"plant_timeseries\",\n    h5_path=\"timeseries.h5\",\n    primary_path=\"primary.slp\"\n)\n\ntraits = pipeline.compute_plant_traits(series)\n\n# Plot growth curve\nplt.figure(figsize=(10, 6))\nplt.plot(traits['frame'], traits['primary_length'])\nplt.xlabel('Frame')\nplt.ylabel('Primary Root Length (pixels)')\nplt.title('Primary Root Growth Over Time')\nplt.grid(True)\nplt.show()\n\n# Calculate growth rate\ntraits['growth_rate'] = traits['primary_length'].diff()\navg_growth_rate = traits['growth_rate'].mean()\nprint(f\"Average growth rate: {avg_growth_rate:.2f} pixels/frame\")\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#gravitropism-analysis","title":"Gravitropism Analysis","text":"<pre><code># Analyze root angle changes over time\ntraits = pipeline.compute_plant_traits(series)\n\nplt.figure(figsize=(10, 6))\nplt.plot(traits['frame'], traits['primary_tip_angle'])\nplt.axhline(y=0, color='r', linestyle='--', label='Vertical')\nplt.xlabel('Frame')\nplt.ylabel('Tip Angle (degrees)')\nplt.title('Primary Root Gravitropic Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Detect gravity response\ninitial_angle = traits['primary_tip_angle'].iloc[0]\nfinal_angle = traits['primary_tip_angle'].iloc[-1]\nangle_change = final_angle - initial_angle\nprint(f\"Angle change: {angle_change:.2f}\u00b0 (negative = downward)\")\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#key-traits","title":"Key Traits","text":""},{"location":"tutorials/primary-root-pipeline/#length-measurements","title":"Length Measurements","text":"Trait Description Typical Use <code>primary_length</code> Total path length from base to tip Overall growth <code>primary_length_smooth</code> Smoothed length (noise-reduced) Robust measurement <code>primary_euclidean_length</code> Straight-line base to tip Straightness comparison"},{"location":"tutorials/primary-root-pipeline/#geometric-properties","title":"Geometric Properties","text":"Trait Description Range <code>primary_tip_angle</code> Angle of tip segment relative to vertical -180\u00b0 to 180\u00b0 <code>primary_curvature</code> Overall root curvature &gt;0 (lower = straighter) <code>primary_straightness</code> Euclidean / path length ratio 0-1 (1 = perfectly straight)"},{"location":"tutorials/primary-root-pipeline/#spatial-features","title":"Spatial Features","text":"Trait Description Units <code>primary_tip_x</code> Horizontal tip position pixels <code>primary_tip_y</code> Vertical tip position pixels <code>primary_depth</code> Vertical extent from base pixels"},{"location":"tutorials/primary-root-pipeline/#advanced-analysis","title":"Advanced Analysis","text":""},{"location":"tutorials/primary-root-pipeline/#root-curvature-profiles","title":"Root Curvature Profiles","text":"<pre><code>import numpy as np\n\n# Compute curvature along root length\ndef compute_curvature_profile(pts):\n    # pts: Nx2 array of root coordinates\n    # Returns curvature at each point\n    dx = np.gradient(pts[:, 0])\n    dy = np.gradient(pts[:, 1])\n    ddx = np.gradient(dx)\n    ddy = np.gradient(dy)\n\n    curvature = np.abs(dx * ddy - dy * ddx) / (dx**2 + dy**2)**1.5\n    return curvature\n\ncurvature = compute_curvature_profile(series.primary_pts[0])\n\nplt.plot(curvature)\nplt.xlabel('Position along root')\nplt.ylabel('Curvature')\nplt.title('Root Curvature Profile')\nplt.show()\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#growth-rate-analysis","title":"Growth Rate Analysis","text":"<pre><code># Compute instantaneous and average growth rates\ntraits['instantaneous_growth'] = traits['primary_length'].diff()\ntraits['cumulative_growth'] = traits['primary_length'] - traits['primary_length'].iloc[0]\n\n# Fit growth model\nfrom scipy.optimize import curve_fit\n\ndef exponential_growth(t, L0, k):\n    return L0 * np.exp(k * t)\n\nparams, _ = curve_fit(\n    exponential_growth,\n    traits['frame'],\n    traits['primary_length']\n)\n\nprint(f\"Initial length: {params[0]:.2f} px\")\nprint(f\"Growth rate constant: {params[1]:.4f}\")\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#tip-trajectory-visualization","title":"Tip Trajectory Visualization","text":"<pre><code># Extract and plot tip trajectory over time\ntip_trajectory = np.array([\n    series.primary_pts[i][-1]  # Last point = tip\n    for i in range(len(series.primary_pts))\n])\n\nplt.figure(figsize=(8, 10))\nplt.plot(tip_trajectory[:, 0], tip_trajectory[:, 1], 'o-')\nplt.scatter(tip_trajectory[0, 0], tip_trajectory[0, 1],\n           color='green', s=100, label='Start', zorder=5)\nplt.scatter(tip_trajectory[-1, 0], tip_trajectory[-1, 1],\n           color='red', s=100, label='End', zorder=5)\nplt.xlabel('X position (pixels)')\nplt.ylabel('Y position (pixels)')\nplt.title('Primary Root Tip Trajectory')\nplt.legend()\nplt.gca().invert_yaxis()  # Image coordinates\nplt.axis('equal')\nplt.show()\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#comparison-studies","title":"Comparison Studies","text":""},{"location":"tutorials/primary-root-pipeline/#genotype-comparison","title":"Genotype Comparison","text":"<pre><code># Compare primary root growth across genotypes\ngenotypes = ['WT', 'mutant_A', 'mutant_B']\nresults = []\n\nfor genotype in genotypes:\n    series = sr.Series.load(\n        genotype,\n        h5_path=f\"{genotype}.h5\",\n        primary_path=f\"{genotype}_primary.slp\"\n    )\n    traits = pipeline.compute_plant_traits(series)\n    traits['genotype'] = genotype\n    results.append(traits)\n\ndf = pd.concat(results)\n\n# Statistical comparison\nimport seaborn as sns\nsns.boxplot(data=df, x='genotype', y='primary_length')\nplt.title('Primary Root Length by Genotype')\nplt.show()\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#treatment-effects","title":"Treatment Effects","text":"<pre><code># Compare control vs. treated plants\ncontrol_series = sr.Series.load(\n    \"control\", h5_path=\"control.h5\", primary_path=\"control_primary.slp\"\n)\ntreated_series = sr.Series.load(\n    \"treated\", h5_path=\"treated.h5\", primary_path=\"treated_primary.slp\"\n)\n\ncontrol_traits = pipeline.compute_plant_traits(control_series)\ntreated_traits = pipeline.compute_plant_traits(treated_series)\n\n# Compare final lengths\ncontrol_length = control_traits['primary_length'].iloc[-1]\ntreated_length = treated_traits['primary_length'].iloc[-1]\npercent_change = (treated_length - control_length) / control_length * 100\n\nprint(f\"Control: {control_length:.2f} px\")\nprint(f\"Treated: {treated_length:.2f} px\")\nprint(f\"Change: {percent_change:.1f}%\")\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#troubleshooting","title":"Troubleshooting","text":"<p>Tracking discontinuities: - Review SLEAP predictions for gaps - Increase tracking confidence threshold - Manually correct breaks in SLEAP GUI</p> <p>Noisy length measurements: - Use <code>primary_length_smooth</code> instead of <code>primary_length</code> - Apply temporal smoothing to trait time series - Check image quality and contrast</p> <p>Incorrect tip angle: - Verify tip is correctly identified (last tracked point) - Check for tracking artifacts near tip - Ensure sufficient points near tip for angle calculation</p>"},{"location":"tutorials/primary-root-pipeline/#integration-with-larger-pipelines","title":"Integration with Larger Pipelines","text":"<p>Extract primary-only data from full pipeline results:</p> <pre><code># Run full dicot pipeline\nfull_pipeline = sr.DicotPipeline()\nfull_traits = full_pipeline.compute_plant_traits(series)\n\n# Extract primary traits (equivalent to PrimaryRootPipeline)\nprimary_traits = full_traits[[\n    'primary_length',\n    'primary_tip_angle',\n    'primary_length_smooth',\n    # ... other primary traits\n]]\n</code></pre>"},{"location":"tutorials/primary-root-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>See Dicot Pipeline for primary + lateral analysis</li> <li>Try Multiple Primary Root Pipeline for multi-plant setups</li> <li>Read Trait Reference for detailed trait definitions</li> <li>Explore Custom Traits Cookbook for advanced metrics</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/","title":"Younger Monocot Pipeline Tutorial","text":"<p>This tutorial demonstrates analysis of early-stage monocot root systems using the <code>YoungerMonocotPipeline</code>. This pipeline handles monocots with both primary and crown roots, typically seen in younger rice and maize plants.</p>"},{"location":"tutorials/younger-monocot-pipeline/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Load SLEAP predictions for primary and crown roots</li> <li>Configure the YoungerMonocotPipeline</li> <li>Compute monocot-specific traits</li> <li>Visualize crown root emergence patterns</li> <li>Compare primary vs. crown root development</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The <code>YoungerMonocotPipeline</code> computes traits for:</p> <ul> <li>Primary root: Single seminal root present at germination</li> <li>Crown roots: Adventitious roots emerging from stem base</li> <li>Combined metrics: Total root system characteristics</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#interactive-tutorial","title":"Interactive Tutorial","text":"<p>{{ '../../notebooks/YoungerMonocotPipeline.ipynb' }}</p>"},{"location":"tutorials/younger-monocot-pipeline/#key-differences-from-dicot-pipeline","title":"Key Differences from Dicot Pipeline","text":""},{"location":"tutorials/younger-monocot-pipeline/#root-system-architecture","title":"Root System Architecture","text":"<p>Unlike dicots with lateral branching, younger monocots have:</p> <ul> <li>One primary (seminal) root</li> <li>Multiple crown roots emerging from the stem base</li> <li>No lateral roots (or minimal branching)</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#node-structure","title":"Node Structure","text":"<p>Expected SLEAP skeleton:</p> <pre><code>Primary root: base \u2192 nodes \u2192 tip\nCrown roots: base \u2192 nodes \u2192 tip (multiple instances)\n</code></pre>"},{"location":"tutorials/younger-monocot-pipeline/#trait-categories","title":"Trait Categories","text":"<p>Specific to monocots:</p> <ul> <li>Crown root count and emergence timing</li> <li>Primary vs. crown root length comparison</li> <li>Root system symmetry measures</li> <li>Crown root angle distribution</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#common-use-cases","title":"Common Use Cases","text":""},{"location":"tutorials/younger-monocot-pipeline/#rice-phenotyping","title":"Rice Phenotyping","text":"<pre><code>import sleap_roots as sr\n\nseries = sr.Series.load(\n    \"rice_plant_day7\",\n    h5_path=\"rice.h5\",\n    primary_path=\"primary.slp\",\n    crown_path=\"crown.slp\"  # Note: crown instead of lateral\n)\n\npipeline = sr.YoungerMonocotPipeline()\ntraits = pipeline.compute_plant_traits(series, write_csv=True)\n\nprint(f\"Crown root count: {traits['crown_count'].iloc[0]}\")\nprint(f\"Primary length: {traits['primary_length'].iloc[0]:.2f}\")\n</code></pre>"},{"location":"tutorials/younger-monocot-pipeline/#maize-early-development","title":"Maize Early Development","text":"<pre><code># Track development over multiple timepoints\nfor day in range(3, 10):\n    series = sr.Series.load(\n        f\"maize_plant_day{day}\",\n        h5_path=f\"maize_day{day}.h5\",\n        primary_path=f\"primary_day{day}.slp\",\n        crown_path=f\"crown_day{day}.slp\"\n    )\n    traits = pipeline.compute_plant_traits(series)\n    # Analyze temporal patterns\n</code></pre>"},{"location":"tutorials/younger-monocot-pipeline/#key-traits","title":"Key Traits","text":"Trait Description Typical Values <code>crown_count</code> Number of crown roots 3-8 (early stage) <code>primary_length</code> Primary root length Longer than crown initially <code>crown_root_lengths</code> Individual crown lengths Variable, often shorter than primary <code>root_system_width</code> Lateral spread of crown roots Increases with age"},{"location":"tutorials/younger-monocot-pipeline/#developmental-stages","title":"Developmental Stages","text":""},{"location":"tutorials/younger-monocot-pipeline/#early-stage-days-3-5","title":"Early Stage (Days 3-5)","text":"<ul> <li>Primary root dominant</li> <li>2-4 crown roots emerging</li> <li>Crown roots shorter than primary</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#mid-stage-days-6-8","title":"Mid Stage (Days 6-8)","text":"<ul> <li>Crown roots elongating rapidly</li> <li>4-6 crown roots present</li> <li>Crown roots approaching primary length</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#late-young-stage-days-9-12","title":"Late Young Stage (Days 9-12)","text":"<ul> <li>Crown roots may exceed primary length</li> <li>6-10 crown roots typical</li> <li>Consider switching to <code>OlderMonocotPipeline</code> if primary root degrades</li> </ul>"},{"location":"tutorials/younger-monocot-pipeline/#troubleshooting","title":"Troubleshooting","text":"<p>Crown roots not detected: - Verify SLEAP model detects all root bases - Check tracking quality in crown root file - Ensure sufficient image contrast at stem base</p> <p>Primary root confused with crown: - Use consistent node naming in SLEAP skeleton - Primary should be tracked from seed location - Crown roots should originate from stem base (above seed)</p>"},{"location":"tutorials/younger-monocot-pipeline/#next-steps","title":"Next Steps","text":"<ul> <li>See Older Monocot Pipeline for mature plants</li> <li>Compare with Dicot Pipeline architecture differences</li> <li>Read Trait Reference for monocot-specific traits</li> </ul>"}]}