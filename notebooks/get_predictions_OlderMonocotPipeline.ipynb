{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sleap # requires sleap in environment\n",
    "import h5py\n",
    "import imageio as iio\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Input search folders to look for image folders\n",
    "search_folders = r\"\"\"\n",
    "Day3_09-12-2023_FastScanner/Day3_09-12-2023_FastScanner\n",
    "Day10_09-22-2023_FastScanner\n",
    "\"\"\".strip().split('\\n')\n",
    "\n",
    "# TODO: Output folder for h5 files and predictions\n",
    "dst_folder = r\"downstream_data_analysis_and_extraction/h5_files_and_predictions\"\n",
    "\n",
    "# TODO: Set overwrite to True to overwrite existing files\n",
    "overwrite = False\n",
    "\n",
    "# TODO: Model folder to use for predictions--should be for the older rice plants\n",
    "crown_model_folder = r\"training/rice_2023_09_12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort(l):\n",
    "    \"\"\"https://stackoverflow.com/a/4836734\"\"\"\n",
    "    l = [x.as_posix() if isinstance(x, Path) else x for x in l]\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "\n",
    "def convert_img_folder_to_h5(img_folder, dst_folder, overwrite=False):\n",
    "    \"\"\"Convert an image folder to an HDF5 file and save it to the dst_folder.\n",
    "    \n",
    "    Args:\n",
    "        img_folder: Path to a folder filled with PNGs named sequentially.\n",
    "        dst_folder: Path to a folder where HDF5 file will be saved. \n",
    "        overwrite: If True, save the HDF5 file even if it already exists.\n",
    "        \n",
    "    Notes:\n",
    "        This will save a file with the same filename as the image folder, but\n",
    "        with a .h5 extension. The resulting file will contain a dataset named\n",
    "        \"vol\" with shape (slices, height, width, 1).\n",
    "    \"\"\"\n",
    "    # Create a Path object from the img_folder path\n",
    "    img_folder_path = Path(img_folder)\n",
    "    # Get the img_folder as a string \n",
    "    img_folder = img_folder_path.as_posix()\n",
    "    # Get the parent directory using the .parent attribute\n",
    "    parent_name = img_folder_path.parent.parts[-1]\n",
    "    print(parent_name)\n",
    "    # Get the h5_name from the img_folder_path\n",
    "    h5_name = f\"{img_folder_path.stem}.h5\"\n",
    "    # Create a Path object from the dst_folder \n",
    "    dst_folder = Path(dst_folder)\n",
    "    \n",
    "    # Create the parent folder\n",
    "    parent_folder_path = dst_folder / parent_name\n",
    "    parent_folder_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Make the final h5 file path \n",
    "    dst_name = parent_folder_path / h5_name\n",
    "    \n",
    "    if not overwrite and Path.exists(dst_name):\n",
    "        return dst_name\n",
    "\n",
    "    p = Path(img_folder)\n",
    "    img_paths = natural_sort(list(p.glob(\"*.png\")))\n",
    "\n",
    "    vol = np.stack([iio.imread(p) for p in img_paths], axis=0)  # (slices, height, width)\n",
    "\n",
    "    with h5py.File(dst_name, \"w\") as f:\n",
    "        ds = f.create_dataset(\n",
    "            \"vol\",\n",
    "            data=np.expand_dims(vol, axis=-1),  # (slices, height, width, 1)\n",
    "            compression=1\n",
    "        )\n",
    "    return dst_name\n",
    "\n",
    "\n",
    "def predict(\n",
    "    h5_path: str,\n",
    "    model_input_dir: str,\n",
    "    model_type: str,\n",
    "    output_dir: str,\n",
    ") -> Tuple[sleap.Labels, dict]:\n",
    "    \"\"\"Get the SLEAP predictions.\n",
    "\n",
    "    Args:\n",
    "        h5_path: Path to h5 file containing the image data with shape \n",
    "            (slices, height, width, 1) and dataset name 'vol'.\n",
    "        model_input_dir: Directory containing the model.\n",
    "        model_type: Type of model to use for predictions: \"crown\", \"primary\", \"lateral\".\n",
    "        output_dir: Directory to save predictions and predictions.csv.\n",
    "\n",
    "    Returns:\n",
    "        sleap.Labels: SLEAP predictions.\n",
    "        preds_dict: A dictionary containing scan_id, model_type, and prediction path.\n",
    "    \"\"\"\n",
    "    # Create Path objects from the input strings\n",
    "    h5_path = Path(h5_path)\n",
    "    model_input_dir = Path(model_input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    # Check if h5_path is None\n",
    "    if h5_path is None:\n",
    "        return None, preds_dict\n",
    "    \n",
    "    # Extract the series name from the h5 path\n",
    "    series_name = h5_path.name.split(\".\")[0]\n",
    "    \n",
    "    # Initialize dictionary for prediction info\n",
    "    preds_dict = {}\n",
    "    # Add scan_id to dictionary\n",
    "    preds_dict[\"scan_id\"] = series_name\n",
    "\n",
    "    # Log sleap version\n",
    "    print(f\"SLEAP version: {sleap.versions()}\")\n",
    "\n",
    "    # Load the model info\n",
    "    model_id = model_input_dir.name.split(\".\")[0]\n",
    "\n",
    "    # Generate the paths for the crown predictions\n",
    "    crown_path = h5_path.replace(\".h5\", f\".model{model_id}.root{model_type}.slp\")\n",
    "\n",
    "    # Load the model\n",
    "    predictor = sleap.load_model(\n",
    "        model_input_dir.as_posix(), progress_reporting=\"none\"\n",
    "    )\n",
    "    print(f\"Loaded model {model_type} from {model_input_dir}.\")\n",
    "\n",
    "    # Get the predictions\n",
    "    labels = predictor.predict(h5_path.as_posix())\n",
    "    # Save the predictions\n",
    "    labels.save(crown_path.as_posix())\n",
    "    print(f\"Saved predictions to {crown_path.as_posix()}.\")\n",
    "\n",
    "    # Add the prediction path to the dictionary\n",
    "    preds_dict[model_type] = crown_path.as_posix()\n",
    "\n",
    "    return labels, preds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for image folders\n",
    "img_folders = []\n",
    "for search_folder in track(search_folders, description=\"Searching for image folders...\"):\n",
    "    p = Path(search_folder)\n",
    "    img_folders.extend([x.parent.as_posix() for x in p.rglob(\"1.png\")])\n",
    "print(f\"Found {len(img_folders)} image folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HDF5\n",
    "h5_files = []\n",
    "for img_folder in track(img_folders, description=\"Converting to HDF5...\"):\n",
    "    h5_files.append(convert_img_folder_to_h5(img_folder, dst_folder, overwrite=overwrite))\n",
    "print(f\"Converted {len(h5_files)} image folders to HDF5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = []\n",
    "for h5_file in track(h5_files, description=\"Predicting...\"):\n",
    "    for model_type in [\"crown\"]:\n",
    "        preds.append(predict(h5_file, crown_model_folder, model_type, dst_folder))\n",
    "print(f\"Predicted {len(preds)} HDF5 files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap_v1.3.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
