# Continuous integration
name: CI

on:
  pull_request:
    types: [opened, reopened, synchronize]
    paths:
      - "sleap_roots/**"
      - "tests/**"
      - ".github/workflows/ci.yml"
      - "pyproject.toml"
      - "uv.lock"
      - ".python-version"
  push:
    branches:
      - main
      - infra/*
    paths:
      - "sleap_roots/**"
      - "tests/**"
      - ".github/workflows/**"
      - "pyproject.toml"
      - "uv.lock"
      - ".python-version"

# Cancel in-progress runs when a new commit is pushed to the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    name: Lint (Black + pydocstyle)
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          github-token: ${{ secrets.GITHUB_TOKEN }}
          cache-dependency-glob: "**/uv.lock"

      - name: Install Python from .python-version
        run: uv python install

      - name: Sync deps
        run: uv sync --frozen

      - name: Run Black
        run: uv run black --check sleap_roots tests

      - name: Run pydocstyle
        run: uv run pydocstyle --convention=google sleap_roots/

  test:
    name: Test (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04, windows-2022, macos-14]

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true  # Fetch large files with Git LFS

      - name: Set up uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          github-token: ${{ secrets.GITHUB_TOKEN }}
          cache-dependency-glob: "**/uv.lock"

      - name: Install Python from .python-version
        run: uv python install

      - name: Sync deps (runtime + dev group)
        run: uv sync --frozen

      - name: Environment info
        run: |
          uv --version
          uv run python -c "import sys, platform; print(sys.version); print(platform.platform())"
          uv tree

      - name: Test with pytest
        if: ${{ !startsWith(matrix.os, 'ubuntu') }}
        run: uv run pytest tests/

      - name: Test with pytest (with coverage)
        if: ${{ startsWith(matrix.os, 'ubuntu') }}
        run: uv run pytest --cov=sleap_roots --cov-report=xml --cov-report=term-missing tests/

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        if: ${{ startsWith(matrix.os, 'ubuntu') }}
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: true
          verbose: false

  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-22.04
    # Only run benchmarks on pushes to main to avoid noise during development
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true  # Fetch large test data files

      - name: Set up uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          github-token: ${{ secrets.GITHUB_TOKEN }}
          cache-dependency-glob: "**/uv.lock"

      - name: Install Python from .python-version
        run: uv python install

      - name: Sync deps (runtime + dev group)
        run: uv sync --frozen

      - name: Run benchmarks
        run: |
          uv run pytest tests/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-columns=min,max,mean,stddev,median \
            --benchmark-sort=name

      - name: Display benchmark results
        if: always()
        run: |
          echo "=== Benchmark Results ==="
          if [ -f benchmark-results.json ]; then
            uv run python -c "
          import json
          with open('benchmark-results.json') as f:
              data = json.load(f)
              for bench in data['benchmarks']:
                  name = bench['name']
                  stats = bench['stats']
                  print(f'{name}:')
                  print(f'  Mean: {stats[\"mean\"]:.4f}s Â± {stats[\"stddev\"]:.4f}s')
                  print(f'  Min:  {stats[\"min\"]:.4f}s')
                  print(f'  Max:  {stats[\"max\"]:.4f}s')
                  print()
          "
          fi

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 30